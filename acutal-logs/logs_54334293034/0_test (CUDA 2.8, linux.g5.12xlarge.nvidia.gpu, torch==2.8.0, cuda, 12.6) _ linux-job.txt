2026-01-14T08:15:32.1227339Z Current runner version: '2.331.0'
2026-01-14T08:15:32.1233605Z Runner name: 'i-04e9aa7f2165d46e3'
2026-01-14T08:15:32.1234353Z Runner group name: 'default'
2026-01-14T08:15:32.1235174Z Machine name: 'ip-10-0-31-143'
2026-01-14T08:15:32.1237988Z ##[group]GITHUB_TOKEN Permissions
2026-01-14T08:15:32.1240423Z Contents: read
2026-01-14T08:15:32.1240965Z Metadata: read
2026-01-14T08:15:32.1241468Z Packages: read
2026-01-14T08:15:32.1241961Z ##[endgroup]
2026-01-14T08:15:32.1243917Z Secret source: None
2026-01-14T08:15:32.1244530Z Prepare workflow directory
2026-01-14T08:15:32.1794270Z Prepare all required actions
2026-01-14T08:15:32.1830315Z Getting action download info
2026-01-14T08:15:32.4365156Z Download action repository 'actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683' (SHA:11bd71901bbe5b1630ceea73d27597364c9af683)
2026-01-14T08:15:32.7847000Z Download action repository 'pytorch/pytorch@main' (SHA:b321605fc7207c672be72497ceeb20cbb6367319)
2026-01-14T08:15:48.9339250Z Download action repository 'actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093' (SHA:d3f86a106a0bac45b974a628896c90dbdf5c8093)
2026-01-14T08:15:49.3003302Z Download action repository 'pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1' (SHA:a2c1430e2bddadbad9f49a6f9b879f062c6b19b1)
2026-01-14T08:15:49.5100135Z Download action repository 'actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02' (SHA:ea165f8d65b6e75b540449e92b4886f43607fa02)
2026-01-14T08:15:49.9713185Z Getting action download info
2026-01-14T08:15:50.1107301Z Getting action download info
2026-01-14T08:15:50.2559275Z Download action repository 'aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722' (SHA:ececac1a45f3b08a01d2dd070d28d111c5fe6722)
2026-01-14T08:15:50.4800594Z Download action repository 'aws-actions/amazon-ecr-login@062b18b96a7aff071d4dc91bc00c4c1a7945b076' (SHA:062b18b96a7aff071d4dc91bc00c4c1a7945b076)
2026-01-14T08:15:50.7622196Z Uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@refs/heads/main (479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:15:50.7626215Z ##[group] Inputs
2026-01-14T08:15:50.7628215Z   script: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:50.7630682Z   timeout: 180
2026-01-14T08:15:50.7630950Z   runner: linux.g5.12xlarge.nvidia.gpu
2026-01-14T08:15:50.7631262Z   upload-artifact: 
2026-01-14T08:15:50.7631795Z   upload-artifact-to-s3: false
2026-01-14T08:15:50.7632104Z   download-artifact: 
2026-01-14T08:15:50.7632349Z   repository: 
2026-01-14T08:15:50.7632587Z   fetch-depth: 1
2026-01-14T08:15:50.7632811Z   submodules: recursive
2026-01-14T08:15:50.7633052Z   ref: 
2026-01-14T08:15:50.7633302Z   test-infra-repository: pytorch/test-infra
2026-01-14T08:15:50.7633631Z   test-infra-ref: 
2026-01-14T08:15:50.7633880Z   use-custom-docker-registry: true
2026-01-14T08:15:50.7634222Z   docker-image: pytorch/almalinux-builder
2026-01-14T08:15:50.7634535Z   docker-build-dir: .ci/docker
2026-01-14T08:15:50.7634816Z   gpu-arch-type: cuda
2026-01-14T08:15:50.7635067Z   gpu-arch-version: 12.6
2026-01-14T08:15:50.7635316Z   job-name: linux-job
2026-01-14T08:15:50.7635557Z   continue-on-error: false
2026-01-14T08:15:50.7635820Z   binary-matrix: 
2026-01-14T08:15:50.7636092Z   run-with-docker: true
2026-01-14T08:15:50.7636335Z   secrets-env: 
2026-01-14T08:15:50.7636563Z   no-sudo: false
2026-01-14T08:15:50.7636790Z ##[endgroup]
2026-01-14T08:15:50.7637248Z Complete job name: test (CUDA 2.8, linux.g5.12xlarge.nvidia.gpu, torch==2.8.0, cuda, 12.6) / linux-job
2026-01-14T08:15:50.8822054Z A job started hook has been configured by the self-hosted runner administrator
2026-01-14T08:15:50.8934799Z ##[group]Run '/home/ec2-user/runner-scripts/before_job.sh'
2026-01-14T08:15:50.8946935Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:50.8947509Z ##[endgroup]
2026-01-14T08:15:52.3907695Z Runner Type: linux.g5.12xlarge.nvidia.gpu
2026-01-14T08:15:52.3908193Z Instance Type: g5.12xlarge
2026-01-14T08:15:52.3908450Z AMI Name: unknown
2026-01-14T08:15:52.3955514Z AMI ID: ami-068c0051b15cdb816
2026-01-14T08:15:58.2078006Z ##[group]Run set -euxo pipefail
2026-01-14T08:15:58.2078396Z [36;1mset -euxo pipefail[0m
2026-01-14T08:15:58.2078705Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T08:15:58.2079111Z [36;1m  echo "::group::Cleanup with-sudo debug output"[0m
2026-01-14T08:15:58.2079503Z [36;1m  sudo rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:58.2079819Z [36;1melse[0m
2026-01-14T08:15:58.2080104Z [36;1m  echo "::group::Cleanup no-sudo debug output"[0m
2026-01-14T08:15:58.2080472Z [36;1m  rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:58.2080769Z [36;1mfi[0m
2026-01-14T08:15:58.2080969Z [36;1m[0m
2026-01-14T08:15:58.2081240Z [36;1mmkdir -p "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:58.2081587Z [36;1mecho "::endgroup::"[0m
2026-01-14T08:15:58.2096755Z shell: /usr/bin/bash -e {0}
2026-01-14T08:15:58.2097035Z env:
2026-01-14T08:15:58.2097298Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:58.2097664Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:58.2097957Z   PR_NUMBER: 3500
2026-01-14T08:15:58.2099531Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:58.2101183Z   NO_SUDO: false
2026-01-14T08:15:58.2101407Z ##[endgroup]
2026-01-14T08:15:58.2140439Z + [[ false == \f\a\l\s\e ]]
2026-01-14T08:15:58.2153340Z ##[group]Cleanup with-sudo debug output
2026-01-14T08:15:58.2156204Z + echo '::group::Cleanup with-sudo debug output'
2026-01-14T08:15:58.2156632Z + sudo rm -rfv /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:15:58.3552870Z removed directory '/home/ec2-user/actions-runner/_work/ao/ao'
2026-01-14T08:15:58.3577295Z + mkdir -p /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:15:58.3595122Z + echo ::endgroup::
2026-01-14T08:15:58.3595909Z ##[endgroup]
2026-01-14T08:15:58.3726608Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:15:58.3727049Z with:
2026-01-14T08:15:58.3727297Z   repository: pytorch/test-infra
2026-01-14T08:15:58.3727589Z   path: test-infra
2026-01-14T08:15:58.3727824Z   submodules: recursive
2026-01-14T08:15:58.3728261Z   token: ***
2026-01-14T08:15:58.3728487Z   ssh-strict: true
2026-01-14T08:15:58.3728706Z   ssh-user: git
2026-01-14T08:15:58.3728940Z   persist-credentials: true
2026-01-14T08:15:58.3729195Z   clean: true
2026-01-14T08:15:58.3729424Z   sparse-checkout-cone-mode: true
2026-01-14T08:15:58.3729723Z   fetch-depth: 1
2026-01-14T08:15:58.3729942Z   fetch-tags: false
2026-01-14T08:15:58.3730169Z   show-progress: true
2026-01-14T08:15:58.3730403Z   lfs: false
2026-01-14T08:15:58.3730612Z   set-safe-directory: true
2026-01-14T08:15:58.3730860Z env:
2026-01-14T08:15:58.3731104Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:58.3731448Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:58.3731732Z   PR_NUMBER: 3500
2026-01-14T08:15:58.3733297Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:58.3734920Z ##[endgroup]
2026-01-14T08:15:58.5195431Z Syncing repository: pytorch/test-infra
2026-01-14T08:15:58.5196566Z ##[group]Getting Git version info
2026-01-14T08:15:58.5197003Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/test-infra'
2026-01-14T08:15:58.5197623Z [command]/usr/bin/git version
2026-01-14T08:15:58.5197920Z git version 2.50.1
2026-01-14T08:15:58.5223401Z ##[endgroup]
2026-01-14T08:15:58.5249673Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/6ad4c50c-c451-419f-90a1-6298ad37909d' before making global git config changes
2026-01-14T08:15:58.5250590Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:15:58.5255388Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:15:58.5294748Z ##[group]Initializing the repository
2026-01-14T08:15:58.5299359Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:15:58.5346436Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:15:58.5347081Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:15:58.5347653Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:15:58.5348060Z hint:
2026-01-14T08:15:58.5348366Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:15:58.5348724Z hint:
2026-01-14T08:15:58.5349065Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:15:58.5349634Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:15:58.5350063Z hint:
2026-01-14T08:15:58.5350296Z hint: 	git branch -m <name>
2026-01-14T08:15:58.5350560Z hint:
2026-01-14T08:15:58.5350928Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:15:58.5351599Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.git/
2026-01-14T08:15:58.5358843Z [command]/usr/bin/git remote add origin https://github.com/pytorch/test-infra
2026-01-14T08:15:58.5396144Z ##[endgroup]
2026-01-14T08:15:58.5396610Z ##[group]Disabling automatic garbage collection
2026-01-14T08:15:58.5400370Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:15:58.5653933Z ##[endgroup]
2026-01-14T08:15:58.5654329Z ##[group]Setting up auth
2026-01-14T08:15:58.5659735Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:15:58.5697633Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:15:58.6154973Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:15:58.6190760Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:15:58.6613042Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:15:58.6665072Z ##[endgroup]
2026-01-14T08:15:58.6665491Z ##[group]Determining the default branch
2026-01-14T08:15:58.6668199Z Retrieving the default branch name
2026-01-14T08:15:58.9152706Z Default branch 'main'
2026-01-14T08:15:58.9153319Z ##[endgroup]
2026-01-14T08:15:58.9153738Z ##[group]Fetching the repository
2026-01-14T08:15:58.9158156Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/heads/main:refs/remotes/origin/main
2026-01-14T08:15:59.2749469Z From https://github.com/pytorch/test-infra
2026-01-14T08:15:59.2779174Z  * [new branch]      main       -> origin/main
2026-01-14T08:15:59.2780430Z ##[endgroup]
2026-01-14T08:15:59.2780832Z ##[group]Determining the checkout info
2026-01-14T08:15:59.2781310Z ##[endgroup]
2026-01-14T08:15:59.2786178Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:15:59.2832940Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:15:59.2865865Z ##[group]Checking out the ref
2026-01-14T08:15:59.2869874Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-01-14T08:15:59.4832573Z Switched to a new branch 'main'
2026-01-14T08:15:59.4834983Z branch 'main' set up to track 'origin/main'.
2026-01-14T08:15:59.4849232Z ##[endgroup]
2026-01-14T08:15:59.4849681Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:15:59.4855248Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:15:59.4906818Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:15:59.4944904Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:15:59.4985035Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:15:59.5018667Z ##[endgroup]
2026-01-14T08:15:59.5019080Z ##[group]Fetching submodules
2026-01-14T08:15:59.5022644Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:15:59.5441648Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:15:59.5857816Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:15:59.6257571Z ##[endgroup]
2026-01-14T08:15:59.6258021Z ##[group]Persisting credentials for submodules
2026-01-14T08:15:59.6262258Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:15:59.6669702Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:15:59.7065927Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:15:59.7462852Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:15:59.7881759Z ##[endgroup]
2026-01-14T08:15:59.7932085Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:15:59.7964695Z 479ee761cd164688ad6fe63fbc0f27d255b35fe1
2026-01-14T08:15:59.8190783Z Prepare all required actions
2026-01-14T08:15:59.8191300Z Getting action download info
2026-01-14T08:15:59.9276119Z Download action repository 'pytorch/test-infra@main' (SHA:479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:16:02.4451487Z Getting action download info
2026-01-14T08:16:02.5721863Z Download action repository 'nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482' (SHA:3e91a01664abd3c5cd539100d10d33b9c5b68482)
2026-01-14T08:16:02.7663026Z ##[group]Run ./test-infra/.github/actions/setup-linux
2026-01-14T08:16:02.7663397Z env:
2026-01-14T08:16:02.7663642Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:02.7663982Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:02.7664228Z   PR_NUMBER: 3500
2026-01-14T08:16:02.7682761Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:02.7684355Z ##[endgroup]
2026-01-14T08:16:02.7770961Z ##[group]Run set -euo pipefail
2026-01-14T08:16:02.7771279Z [36;1mset -euo pipefail[0m
2026-01-14T08:16:02.7771569Z [36;1mfunction get_ec2_metadata() {[0m
2026-01-14T08:16:02.7771949Z [36;1m  # Pulled from instance metadata endpoint for EC2[0m
2026-01-14T08:16:02.7772584Z [36;1m  # see https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html[0m
2026-01-14T08:16:02.7773357Z [36;1m  category=$1[0m
2026-01-14T08:16:02.7774273Z [36;1m  curl -H "X-aws-ec2-metadata-token: $(curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 30")" -fsSL "http://169.254.169.254/latest/meta-data/${category}"[0m
2026-01-14T08:16:02.7775221Z [36;1m}[0m
2026-01-14T08:16:02.7775504Z [36;1mecho "ami-id: $(get_ec2_metadata ami-id)"[0m
2026-01-14T08:16:02.7775925Z [36;1mecho "instance-id: $(get_ec2_metadata instance-id)"[0m
2026-01-14T08:16:02.7776417Z [36;1mecho "instance-type: $(get_ec2_metadata instance-type)"[0m
2026-01-14T08:16:02.7776829Z [36;1mecho "system info $(uname -a)"[0m
2026-01-14T08:16:02.7786464Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:02.7786821Z env:
2026-01-14T08:16:02.7787087Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:02.7787429Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:02.7787695Z   PR_NUMBER: 3500
2026-01-14T08:16:02.7789306Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:02.7790917Z ##[endgroup]
2026-01-14T08:16:02.7962980Z ami-id: ami-068c0051b15cdb816
2026-01-14T08:16:02.8092024Z instance-id: i-04e9aa7f2165d46e3
2026-01-14T08:16:02.8219403Z instance-type: g5.12xlarge
2026-01-14T08:16:02.8234977Z system info Linux ip-10-0-31-143.ec2.internal 6.1.158-180.294.amzn2023.x86_64 #1 SMP PREEMPT_DYNAMIC Mon Dec  1 05:36:50 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
2026-01-14T08:16:02.8278507Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:16:02.8279574Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:16:02.8290004Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:02.8290371Z env:
2026-01-14T08:16:02.8290624Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:02.8290980Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:02.8291477Z   PR_NUMBER: 3500
2026-01-14T08:16:02.8293030Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:02.8294633Z ##[endgroup]
2026-01-14T08:16:02.8388706Z ##[group]Run if ! docker version >/dev/null 2>/dev/null; then
2026-01-14T08:16:02.8389188Z [36;1mif ! docker version >/dev/null 2>/dev/null; then[0m
2026-01-14T08:16:02.8389601Z [36;1m  if systemctl is-active --quiet docker; then[0m
2026-01-14T08:16:02.8389989Z [36;1m      echo "Docker daemon is running...";[0m
2026-01-14T08:16:02.8390308Z [36;1m  else[0m
2026-01-14T08:16:02.8390677Z [36;1m      echo "Starting docker daemon..." && sudo systemctl start docker;[0m
2026-01-14T08:16:02.8391104Z [36;1m  fi[0m
2026-01-14T08:16:02.8391319Z [36;1mfi[0m
2026-01-14T08:16:02.8400434Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:02.8400790Z env:
2026-01-14T08:16:02.8401041Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:02.8401380Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:02.8401631Z   PR_NUMBER: 3500
2026-01-14T08:16:02.8403268Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:02.8405061Z ##[endgroup]
2026-01-14T08:16:02.9087908Z ##[group]Run AWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")
2026-01-14T08:16:02.9088583Z [36;1mAWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")[0m
2026-01-14T08:16:02.9089156Z [36;1mretry () { "$@"  || (sleep 1 && "$@") || (sleep 2 && "$@") }[0m
2026-01-14T08:16:02.9089757Z [36;1mretry aws ecr get-login-password --region "$AWS_DEFAULT_REGION" | docker login --username AWS \[0m
2026-01-14T08:16:02.9090481Z [36;1m    --password-stdin "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com"[0m
2026-01-14T08:16:02.9100594Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:02.9100961Z env:
2026-01-14T08:16:02.9101229Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:02.9101570Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:02.9101823Z   PR_NUMBER: 3500
2026-01-14T08:16:02.9103359Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:02.9105000Z   AWS_RETRY_MODE: standard
2026-01-14T08:16:02.9105265Z   AWS_MAX_ATTEMPTS: 5
2026-01-14T08:16:02.9105510Z   AWS_DEFAULT_REGION: us-east-1
2026-01-14T08:16:02.9105772Z ##[endgroup]
2026-01-14T08:16:04.0151504Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:16:04.0152097Z Configure a credential helper to remove this warning. See
2026-01-14T08:16:04.0152635Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:16:04.0153186Z 
2026-01-14T08:16:04.0153875Z Login Succeeded
2026-01-14T08:16:04.0215221Z ##[group]Run env | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"
2026-01-14T08:16:04.0215795Z [36;1menv | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:16:04.0216364Z [36;1menv | grep '^CI' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:16:04.0217144Z [36;1menv | grep '^RUNNER' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:16:04.0226325Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:04.0226947Z env:
2026-01-14T08:16:04.0227260Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:04.0242765Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:04.0243035Z   PR_NUMBER: 3500
2026-01-14T08:16:04.0244588Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:04.0246210Z ##[endgroup]
2026-01-14T08:16:04.0392906Z ##[group]Run RUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"
2026-01-14T08:16:04.0393388Z [36;1mRUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"[0m
2026-01-14T08:16:04.0393782Z [36;1msudo rm -rf "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:16:04.0394134Z [36;1mmkdir -p "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:16:04.0394571Z [36;1mecho "RUNNER_ARTIFACT_DIR=${RUNNER_ARTIFACT_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:16:04.0394994Z [36;1m[0m
2026-01-14T08:16:04.0395289Z [36;1mRUNNER_TEST_RESULTS_DIR="${RUNNER_TEMP}/test-results"[0m
2026-01-14T08:16:04.0395719Z [36;1msudo rm -rf "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:16:04.0396086Z [36;1mmkdir -p "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:16:04.0396740Z [36;1mecho "RUNNER_TEST_RESULTS_DIR=${RUNNER_TEST_RESULTS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:16:04.0397192Z [36;1m[0m
2026-01-14T08:16:04.0397426Z [36;1mRUNNER_DOCS_DIR="${RUNNER_TEMP}/docs"[0m
2026-01-14T08:16:04.0397764Z [36;1msudo rm -rf "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:16:04.0398078Z [36;1mmkdir -p "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:16:04.0398478Z [36;1mecho "RUNNER_DOCS_DIR=${RUNNER_DOCS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:16:04.0407859Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:04.0408220Z env:
2026-01-14T08:16:04.0408480Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:04.0408826Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:04.0409095Z   PR_NUMBER: 3500
2026-01-14T08:16:04.0410685Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:04.0412306Z ##[endgroup]
2026-01-14T08:16:04.5585464Z ##[group]Run needs=0
2026-01-14T08:16:04.5585724Z [36;1mneeds=0[0m
2026-01-14T08:16:04.5586103Z [36;1mif lspci -v | grep -e 'controller.*NVIDIA' >/dev/null 2>/dev/null; then[0m
2026-01-14T08:16:04.5586551Z [36;1m  needs=1[0m
2026-01-14T08:16:04.5586775Z [36;1mfi[0m
2026-01-14T08:16:04.5587024Z [36;1mecho "does=${needs}" >> $GITHUB_OUTPUT[0m
2026-01-14T08:16:04.5595865Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:04.5596213Z env:
2026-01-14T08:16:04.5596475Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:04.5596822Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:04.5597084Z   PR_NUMBER: 3500
2026-01-14T08:16:04.5598641Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:04.5600437Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:16:04.5601204Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:16:04.5601761Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:16:04.5602148Z ##[endgroup]
2026-01-14T08:16:04.6033373Z ##[group]Run pytorch/test-infra/.github/actions/setup-nvidia@main
2026-01-14T08:16:04.6033763Z with:
2026-01-14T08:16:04.6033985Z   driver-version: 580.65.06
2026-01-14T08:16:04.6034242Z env:
2026-01-14T08:16:04.6034487Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:04.6034853Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:04.6035107Z   PR_NUMBER: 3500
2026-01-14T08:16:04.6036648Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:04.6038390Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:16:04.6039158Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:16:04.6039707Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:16:04.6040078Z ##[endgroup]
2026-01-14T08:16:04.6068258Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:16:04.6069405Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:16:04.6079785Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:04.6080147Z env:
2026-01-14T08:16:04.6080405Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:04.6080752Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:04.6081020Z   PR_NUMBER: 3500
2026-01-14T08:16:04.6082648Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:04.6084381Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:16:04.6084979Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:16:04.6085527Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:16:04.6085921Z ##[endgroup]
2026-01-14T08:16:04.6172631Z ##[group]Run set -euo pipefail
2026-01-14T08:16:04.6172958Z [36;1mset -euo pipefail[0m
2026-01-14T08:16:04.6173215Z [36;1m[0m
2026-01-14T08:16:04.6173425Z [36;1mhas_gpu=false[0m
2026-01-14T08:16:04.6173663Z [36;1mdevices=""[0m
2026-01-14T08:16:04.6173896Z [36;1m[0m
2026-01-14T08:16:04.6174167Z [36;1mif command -v nvidia-smi >/dev/null 2>&1; then[0m
2026-01-14T08:16:04.6174626Z [36;1m  if nvidia-smi -L >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:16:04.6175010Z [36;1m    has_gpu=true[0m
2026-01-14T08:16:04.6175300Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:16:04.6175613Z [36;1m  fi[0m
2026-01-14T08:16:04.6175811Z [36;1mfi[0m
2026-01-14T08:16:04.6176006Z [36;1m[0m
2026-01-14T08:16:04.6176218Z [36;1mif [ "$has_gpu" = false ]; then[0m
2026-01-14T08:16:04.6176613Z [36;1m  if ls /dev/nvidia* >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:16:04.6176985Z [36;1m    has_gpu=true[0m
2026-01-14T08:16:04.6177274Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:16:04.6177579Z [36;1m  fi[0m
2026-01-14T08:16:04.6177789Z [36;1mfi[0m
2026-01-14T08:16:04.6177984Z [36;1m[0m
2026-01-14T08:16:04.6178287Z [36;1mif [ "$has_gpu" = false ] && command -v lspci >/dev/null 2>&1; then[0m
2026-01-14T08:16:04.6178976Z [36;1m  if lspci | grep -i 'nvidia' >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:16:04.6179444Z [36;1m    has_gpu=true[0m
2026-01-14T08:16:04.6179732Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:16:04.6180038Z [36;1m  fi[0m
2026-01-14T08:16:04.6180253Z [36;1mfi[0m
2026-01-14T08:16:04.6180446Z [36;1m[0m
2026-01-14T08:16:04.6180743Z [36;1mprintf 'HAS_NVIDIA=%s\n' "$has_gpu" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:16:04.6181270Z [36;1mprintf 'DETECTED_DEVICES<<EOF\n%s\nEOF\n' "$devices" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:16:04.6189891Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:04.6190244Z env:
2026-01-14T08:16:04.6190499Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:04.6190851Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:04.6191097Z   PR_NUMBER: 3500
2026-01-14T08:16:04.6192657Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:04.6194398Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:16:04.6194975Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:16:04.6195704Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:16:04.6196081Z ##[endgroup]
2026-01-14T08:16:08.1280988Z ##[group]Run if [ "${HAS_NVIDIA}" = "true" ]; then
2026-01-14T08:16:08.1281378Z [36;1mif [ "${HAS_NVIDIA}" = "true" ]; then[0m
2026-01-14T08:16:08.1281756Z [36;1m  echo "HAS_NVIDIA_GPU=true" >> "${GITHUB_ENV}"[0m
2026-01-14T08:16:08.1282350Z [36;1m  echo "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"[0m
2026-01-14T08:16:08.1282947Z [36;1melse[0m
2026-01-14T08:16:08.1283257Z [36;1m  echo "HAS_NVIDIA_GPU=false" >> "${GITHUB_ENV}"[0m
2026-01-14T08:16:08.1283606Z [36;1mfi[0m
2026-01-14T08:16:08.1296467Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:16:08.1296830Z env:
2026-01-14T08:16:08.1297089Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:08.1297452Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:08.1297715Z   PR_NUMBER: 3500
2026-01-14T08:16:08.1299274Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:08.1301102Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:16:08.1301711Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:16:08.1302265Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:16:08.1302661Z   HAS_NVIDIA: true
2026-01-14T08:16:08.1302890Z ##[endgroup]
2026-01-14T08:16:08.1398721Z ##[group]Run nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482
2026-01-14T08:16:08.1399131Z with:
2026-01-14T08:16:08.1399345Z   timeout_minutes: 10
2026-01-14T08:16:08.1399579Z   max_attempts: 3
2026-01-14T08:16:08.1431445Z   command: # Is it disgusting to have a full shell script here in this github action? Sure
# But is it the best way to make it so that this action relies on nothing else? Absolutely
set -eou pipefail

DISTRIBUTION=$(. /etc/os-release;echo $ID$VERSION_ID)
DRIVER_FN="NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"

install_nvidia_docker2_amzn2() {
    (
        set -x
        # Needed for yum-config-manager
        sudo yum install -y yum-utils
        if [[ "${DISTRIBUTION}" == "amzn2023" ]] ; then
          YUM_REPO_URL="https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo"
        else
          # Amazon Linux 2
          YUM_REPO_URL="https://nvidia.github.io/nvidia-docker/${DISTRIBUTION}/nvidia-docker.repo"
        fi

        sudo yum-config-manager --add-repo "${YUM_REPO_URL}"
        sudo yum install -y \
          nvidia-container-toolkit-1.17.8 \
          libnvidia-container-tools-1.17.8 \
          libnvidia-container1-1.17.8 \
          nvidia-container-toolkit-base-1.17.8
        sudo systemctl restart docker
    )
}

install_nvidia_docker2_ubuntu20() {
    (
        set -x
        # Install nvidia-driver package if not installed
        status="$(dpkg-query -W --showformat='${db:Status-Status}' nvidia-docker2 2>&1)"
        if [ ! $? = 0 ] || [ ! "$status" = installed ]; then
          sudo apt-get install -y nvidia-container-toolkit-1.17.8
          sudo systemctl restart docker
        fi
    )
}

pre_install_nvidia_driver_amzn2() {
    (
        # Purge any nvidia driver installed from RHEL repo
        sudo yum remove -y nvidia-driver-latest-dkms
    )
}

install_nvidia_driver_common() {
    (
        # Try to gather more information about the runner and its existing NVIDIA driver if any
        echo "Before installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        HAS_NVIDIA_DRIVER=0
        # Check if NVIDIA driver has already been installed
        if [ -x "$(command -v nvidia-smi)" ]; then
            set +e
            # The driver exists, check its version next. Also check only the first GPU if there are more than one of them
            # so that the same driver version is not print over multiple lines
            INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
            NVIDIA_SMI_STATUS=$?

            if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                echo "Failed to get NVIDIA driver version ($INSTALLED_DRIVER_VERSION). Continuing"
            elif [ "$INSTALLED_DRIVER_VERSION" != "$DRIVER_VERSION" ]; then
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has been installed, but we expect to have $DRIVER_VERSION instead. Continuing"

                # Turn off persistent mode so that the installation script can unload the kernel module
                sudo killall nvidia-persistenced || true
            else
                HAS_NVIDIA_DRIVER=1
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has already been installed. Skipping NVIDIA driver installation"
            fi
            set -e
        fi

        if [ "$HAS_NVIDIA_DRIVER" -eq 0 ]; then
            # CAUTION: this may need to be updated in future
            if [ "${DISTRIBUTION}" != ubuntu20.04 ]; then
                  sudo yum groupinstall -y "Development Tools"
                  # ensure our kernel install is the same as our underlying kernel,
                  # groupinstall "Development Tools" has a habit of mismatching kernel headers
                  sudo yum install -y "kernel-devel-uname-r == $(uname -r)"
                  sudo modprobe backlight
            fi
            sudo curl -fsL -o /tmp/nvidia_driver "https://s3.amazonaws.com/ossci-linux/nvidia_driver/$DRIVER_FN"

            set +e
            sudo /bin/bash /tmp/nvidia_driver -s --no-drm
            NVIDIA_INSTALLATION_STATUS=$?

            RESET_GPU=0
            if [ "$NVIDIA_INSTALLATION_STATUS" -ne 0 ]; then
                sudo cat /var/log/nvidia-installer.log
                # Fail to install NVIDIA driver, try to reset the GPU
                RESET_GPU=1
            elif [ -x "$(command -v nvidia-smi)" ]; then
                # Check again if nvidia-smi works even if the driver installation completes successfully
                INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
                NVIDIA_SMI_STATUS=$?

                if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                    RESET_GPU=1
                fi
            fi

            if [ "$RESET_GPU" -eq 1 ]; then
                NVIDIA_DEVICES=$(lspci -D | grep -i NVIDIA | cut -d' ' -f1)
                # The GPU can get stuck in a failure state if somehow the test crashs the GPU microcode. When this
                # happens, we'll try to reset all NVIDIA devices https://github.com/pytorch/pytorch/issues/88388
                for PCI_ID in $NVIDIA_DEVICES; do
                    DEVICE_ENABLED=$(cat /sys/bus/pci/devices/$PCI_ID/enable)

                    echo "Reseting $PCI_ID (enabled state: $DEVICE_ENABLED)"
                    # This requires sudo permission of course
                    echo "1" | sudo tee /sys/bus/pci/devices/$PCI_ID/reset
                    sleep 1
                done
            fi

            sudo rm -fv /tmp/nvidia_driver
            set -e
        fi
    )
}

post_install_nvidia_driver_common() {
    (
        sudo modprobe nvidia || true
        echo "After installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        (
            set +e

            nvidia-smi
            # NB: Annoyingly, nvidia-smi command returns successfully with return code 0 even in
            # the case where the driver has already crashed as it still can get the driver version
            # and some basic information like the bus ID.  However, the rest of the information
            # would be missing (ERR!), for example:
            #
            # +-----------------------------------------------------------------------------+
            # | NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |
            # |-------------------------------+----------------------+----------------------+
            # | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
            # | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
            # |                               |                      |               MIG M. |
            # |===============================+======================+======================|
            # |   0  ERR!                Off  | 00000000:00:1E.0 Off |                 ERR! |
            # |ERR!  ERR! ERR!    ERR! / ERR! |   4184MiB / 23028MiB |    ERR!      Default |
            # |                               |                      |                 ERR! |
            # +-------------------------------+----------------------+----------------------+
            #
            # +-----------------------------------------------------------------------------+
            # | Processes:                                                                  |
            # |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
            # |        ID   ID                                                   Usage      |
            # |=============================================================================|
            # +-----------------------------------------------------------------------------+
            #
            # This should be reported as a failure instead as it will guarantee to fail when
            # Docker tries to run with --gpus all
            #
            # So, the correct check here is to query one of the missing piece of info like
            # GPU name, so that the command can fail accordingly
            nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
            NVIDIA_SMI_STATUS=$?

            # Allowable exit statuses for nvidia-smi, see: https://github.com/NVIDIA/gpu-operator/issues/285
            if [ "$NVIDIA_SMI_STATUS" -eq 0 ] || [ "$NVIDIA_SMI_STATUS" -eq 14 ]; then
                echo "INFO: Ignoring allowed status ${NVIDIA_SMI_STATUS}"
            else
                echo "ERROR: nvidia-smi exited with unresolved status ${NVIDIA_SMI_STATUS}"
                exit ${NVIDIA_SMI_STATUS}
            fi
            set -e
        )
    )
}

install_nvidia_driver_amzn2() {
    (
        set -x
        pre_install_nvidia_driver_amzn2
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

install_nvidia_driver_ubuntu20() {
    (
        set -x
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

echo "== Installing nvidia driver ${DRIVER_FN} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_driver_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_driver_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Install container toolkit based on distribution
echo "== Installing nvidia container toolkit for ${DISTRIBUTION} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_docker2_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_docker2_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Fix https://github.com/NVIDIA/nvidia-docker/issues/1648 on runners with
# more than one GPUs. This just needs to be run once. The command fails
# on subsequent runs and complains that the mode is already on, but that's
# ok
sudo nvidia-persistenced || true
# This should show persistence mode ON
nvidia-smi

# check if the container-toolkit is correctly installed and CUDA is available inside a container
docker run --rm -t --gpus=all public.ecr.aws/docker/library/python:3.13 nvidia-smi

2026-01-14T08:16:08.1463913Z   retry_wait_seconds: 10
2026-01-14T08:16:08.1464174Z   polling_interval_seconds: 1
2026-01-14T08:16:08.1464447Z   warning_on_retry: true
2026-01-14T08:16:08.1464865Z   continue_on_error: false
2026-01-14T08:16:08.1465110Z env:
2026-01-14T08:16:08.1465352Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:16:08.1465697Z   REPOSITORY: pytorch/ao
2026-01-14T08:16:08.1465949Z   PR_NUMBER: 3500
2026-01-14T08:16:08.1467487Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:16:08.1469220Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:16:08.1469797Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:16:08.1470334Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:16:08.1470728Z   HAS_NVIDIA_GPU: true
2026-01-14T08:16:08.1471028Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:16:08.1471385Z   DRIVER_VERSION: 580.65.06
2026-01-14T08:16:08.1471629Z ##[endgroup]
2026-01-14T08:16:08.2358578Z == Installing nvidia driver NVIDIA-Linux-x86_64-580.65.06.run ==
2026-01-14T08:16:08.2359701Z + pre_install_nvidia_driver_amzn2
2026-01-14T08:16:08.2363260Z + sudo yum remove -y nvidia-driver-latest-dkms
2026-01-14T08:16:08.5269357Z No match for argument: nvidia-driver-latest-dkms
2026-01-14T08:16:08.5270100Z No packages marked for removal.
2026-01-14T08:16:08.5336769Z Dependencies resolved.
2026-01-14T08:16:08.5347249Z Nothing to do.
2026-01-14T08:16:08.5347838Z Complete!
2026-01-14T08:16:08.5687358Z + install_nvidia_driver_common
2026-01-14T08:16:08.5694403Z + echo 'Before installing NVIDIA driver'
2026-01-14T08:16:08.5694714Z + lspci
2026-01-14T08:16:08.5696135Z Before installing NVIDIA driver
2026-01-14T08:16:08.5813281Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:16:08.5813823Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:16:08.5814410Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:16:08.5814966Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:16:08.5815468Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:16:08.5816262Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:16:08.5816781Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:08.5817254Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:08.5817719Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:08.5818168Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:08.5818677Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:16:08.5819111Z + lsmod
2026-01-14T08:16:08.5871441Z Module                  Size  Used by
2026-01-14T08:16:08.5871742Z nvidia_uvm           1925120  0
2026-01-14T08:16:08.5872032Z nvidia              14286848  1 nvidia_uvm
2026-01-14T08:16:08.5872338Z drm                   602112  1 nvidia
2026-01-14T08:16:08.5872891Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:16:08.5873238Z backlight              24576  1 drm
2026-01-14T08:16:08.5873538Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:16:08.5873829Z mgc                    86016  1
2026-01-14T08:16:08.5874089Z lustre               1085440  4
2026-01-14T08:16:08.5874350Z mdc                   294912  2 lustre
2026-01-14T08:16:08.5874633Z fid                    36864  1 mdc
2026-01-14T08:16:08.5874916Z lov                   356352  5 mdc,lustre
2026-01-14T08:16:08.5875208Z osc                   479232  5 mdc
2026-01-14T08:16:08.5875478Z lmv                   225280  2 lustre
2026-01-14T08:16:08.5875966Z fld                    49152  2 lov,lmv
2026-01-14T08:16:08.5876248Z ksocklnd              188416  1
2026-01-14T08:16:08.5876605Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:16:08.5877100Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:16:08.5877611Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:16:08.5878230Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:16:08.5878732Z xt_conntrack           16384  1
2026-01-14T08:16:08.5878997Z nft_chain_nat          16384  3
2026-01-14T08:16:08.5879257Z xt_MASQUERADE          20480  1
2026-01-14T08:16:08.5879575Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:16:08.5879916Z nf_conntrack_netlink    57344  0
2026-01-14T08:16:08.5880335Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:16:08.5880849Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:16:08.5881191Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:16:08.5881488Z xfrm_user              57344  1
2026-01-14T08:16:08.5881767Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:16:08.5882067Z xt_addrtype            16384  2
2026-01-14T08:16:08.5882400Z nft_compat             20480  4
2026-01-14T08:16:08.5882718Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:16:08.5883155Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:16:08.5883559Z br_netfilter           36864  0
2026-01-14T08:16:08.5883837Z bridge                323584  1 br_netfilter
2026-01-14T08:16:08.5884147Z stp                    16384  1 bridge
2026-01-14T08:16:08.5884435Z llc                    16384  2 bridge,stp
2026-01-14T08:16:08.5884733Z overlay               167936  0
2026-01-14T08:16:08.5884996Z tls                   139264  0
2026-01-14T08:16:08.5885351Z nls_ascii              16384  1
2026-01-14T08:16:08.5885750Z nls_cp437              20480  1
2026-01-14T08:16:08.5886071Z vfat                   24576  1
2026-01-14T08:16:08.5886613Z fat                    86016  1 vfat
2026-01-14T08:16:08.5887021Z sunrpc                700416  2 lnet
2026-01-14T08:16:08.5887382Z ghash_clmulni_intel    16384  0
2026-01-14T08:16:08.5902837Z i8042                  45056  0
2026-01-14T08:16:08.5903127Z serio                  28672  3 i8042
2026-01-14T08:16:08.5903422Z ena                   196608  0
2026-01-14T08:16:08.5903856Z button                 24576  0
2026-01-14T08:16:08.5904124Z sch_fq_codel           20480  33
2026-01-14T08:16:08.5904389Z fuse                  184320  1
2026-01-14T08:16:08.5904639Z loop                   36864  0
2026-01-14T08:16:08.5904893Z dm_mod                188416  0
2026-01-14T08:16:08.5905139Z configfs               57344  1
2026-01-14T08:16:08.5905398Z dmi_sysfs              20480  0
2026-01-14T08:16:08.5905649Z crc32_pclmul           16384  0
2026-01-14T08:16:08.5905943Z crc32c_intel           24576  0
2026-01-14T08:16:08.5906207Z efivarfs               24576  1
2026-01-14T08:16:08.5906452Z + modinfo nvidia
2026-01-14T08:16:08.5906851Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:16:08.5907307Z import_ns:      DMA_BUF
2026-01-14T08:16:08.5907560Z alias:          char-major-195-*
2026-01-14T08:16:08.5907821Z version:        580.82.07
2026-01-14T08:16:08.5908070Z supported:      external
2026-01-14T08:16:08.5908329Z license:        Dual MIT/GPL
2026-01-14T08:16:08.5908618Z firmware:       nvidia/580.82.07/gsp_tu10x.bin
2026-01-14T08:16:08.5908961Z firmware:       nvidia/580.82.07/gsp_ga10x.bin
2026-01-14T08:16:08.5909287Z srcversion:     BA7240A71DCF7DC6FE88C1D
2026-01-14T08:16:08.5909636Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:16:08.5909990Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:16:08.5910402Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:16:08.5910748Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:16:08.5911207Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:16:08.5911553Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:16:08.5911884Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:16:08.5912202Z depends:        i2c-core,drm
2026-01-14T08:16:08.5912456Z retpoline:      Y
2026-01-14T08:16:08.5912678Z name:           nvidia
2026-01-14T08:16:08.5913050Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:16:08.5913620Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:16:08.5914096Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:16:08.5914536Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:16:08.5914861Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:16:08.5915171Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:16:08.5915505Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:16:08.5915826Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:16:08.5916146Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:16:08.5916522Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:16:08.5916933Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:16:08.5917276Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:16:08.5917588Z parm:           NVreg_EnableMSI:int
2026-01-14T08:16:08.5917906Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:16:08.5918294Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:16:08.5918724Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:16:08.5919124Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:16:08.5919567Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:16:08.5920006Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:16:08.5920454Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:16:08.5920892Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:16:08.5921247Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:16:08.5921640Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:16:08.5922030Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:16:08.5922454Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:16:08.5922789Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:16:08.5923251Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:16:08.5923589Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:16:08.5923918Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:16:08.5924300Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:16:08.5924687Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:16:08.5925052Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:16:08.5925435Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:16:08.5925779Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:16:08.5926142Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:16:08.5926506Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:16:08.5926869Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:16:08.5927219Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:16:08.5927567Z parm:           NVreg_RmMsg:charp
2026-01-14T08:16:08.5927868Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:16:08.5928206Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:16:08.5928544Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:16:08.5928865Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:16:08.5929213Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:16:08.5929576Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:16:08.5929947Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:16:08.5930283Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:16:08.5930744Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:16:08.5931104Z parm:           rm_firmware_active:charp
2026-01-14T08:16:08.5931394Z + HAS_NVIDIA_DRIVER=0
2026-01-14T08:16:08.5931643Z ++ command -v nvidia-smi
2026-01-14T08:16:08.5931902Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:16:08.5932170Z + set +e
2026-01-14T08:16:08.5932494Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:16:12.0420971Z + INSTALLED_DRIVER_VERSION=580.82.07
2026-01-14T08:16:12.0421323Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:16:12.0421593Z + '[' 0 -ne 0 ']'
2026-01-14T08:16:12.0421822Z + '[' 580.82.07 '!=' 580.65.06 ']'
2026-01-14T08:16:12.0422337Z + echo 'NVIDIA driver (580.82.07) has been installed, but we expect to have 580.65.06 instead. Continuing'
2026-01-14T08:16:12.0422896Z + sudo killall nvidia-persistenced
2026-01-14T08:16:12.0423384Z NVIDIA driver (580.82.07) has been installed, but we expect to have 580.65.06 instead. Continuing
2026-01-14T08:16:12.1476250Z nvidia-persistenced: no process found
2026-01-14T08:16:12.1501166Z + true
2026-01-14T08:16:12.1502173Z + set -e
2026-01-14T08:16:12.1502415Z + '[' 0 -eq 0 ']'
2026-01-14T08:16:12.1502657Z + '[' amzn2023 '!=' ubuntu20.04 ']'
2026-01-14T08:16:12.1502997Z + sudo yum groupinstall -y 'Development Tools'
2026-01-14T08:16:12.6431562Z Last metadata expiration check: 0:01:03 ago on Wed Jan 14 08:15:09 2026.
2026-01-14T08:16:12.6819226Z No match for group package "system-rpm-config"
2026-01-14T08:16:12.6837070Z No match for group package "rcs"
2026-01-14T08:16:12.6860538Z No match for group package "pkgconfig"
2026-01-14T08:16:12.7459851Z Dependencies resolved.
2026-01-14T08:16:12.7821196Z ================================================================================
2026-01-14T08:16:12.7822159Z  Package           Architecture     Version             Repository         Size
2026-01-14T08:16:12.7823068Z ================================================================================
2026-01-14T08:16:12.7823736Z Installing Groups:
2026-01-14T08:16:12.7824398Z  Development Tools                                                             
2026-01-14T08:16:12.7824986Z 
2026-01-14T08:16:12.7825180Z Transaction Summary
2026-01-14T08:16:12.7825711Z ================================================================================
2026-01-14T08:16:12.7826203Z 
2026-01-14T08:16:12.9913817Z ================================================================================
2026-01-14T08:16:12.9914767Z WARNING:
2026-01-14T08:16:12.9915346Z   A newer release of "Amazon Linux" is available.
2026-01-14T08:16:12.9915607Z 
2026-01-14T08:16:12.9915706Z   Available Versions:
2026-01-14T08:16:12.9915861Z 
2026-01-14T08:16:12.9915959Z   Version 2023.10.20260105:
2026-01-14T08:16:12.9916293Z     Run the following command to upgrade to 2023.10.20260105:
2026-01-14T08:16:12.9916578Z 
2026-01-14T08:16:12.9916704Z       dnf upgrade --releasever=2023.10.20260105
2026-01-14T08:16:12.9916927Z 
2026-01-14T08:16:12.9917016Z     Release notes:
2026-01-14T08:16:12.9917458Z      https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.10.20260105.html
2026-01-14T08:16:12.9917850Z 
2026-01-14T08:16:12.9918000Z ================================================================================
2026-01-14T08:16:12.9925306Z Complete!
2026-01-14T08:16:13.0376339Z ++ uname -r
2026-01-14T08:16:13.0393895Z + sudo yum install -y 'kernel-devel-uname-r == 6.1.158-180.294.amzn2023.x86_64'
2026-01-14T08:16:13.5201784Z Last metadata expiration check: 0:01:04 ago on Wed Jan 14 08:15:09 2026.
2026-01-14T08:16:13.5465523Z Using '==' operator in reldeps can result in an undefined behavior. It is deprecated and the support will be dropped in future versions. Use '=' operator instead.
2026-01-14T08:16:13.5580531Z Package kernel-devel-1:6.1.158-180.294.amzn2023.x86_64 is already installed.
2026-01-14T08:16:13.6224409Z Dependencies resolved.
2026-01-14T08:16:13.6586397Z Nothing to do.
2026-01-14T08:16:13.6586668Z Complete!
2026-01-14T08:16:13.7001762Z + sudo modprobe backlight
2026-01-14T08:16:13.8647753Z + sudo curl -fsL -o /tmp/nvidia_driver https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-580.65.06.run
2026-01-14T08:16:18.0244864Z + set +e
2026-01-14T08:16:18.0245180Z + sudo /bin/bash /tmp/nvidia_driver -s --no-drm
2026-01-14T08:16:19.4309383Z Verifying archive integrity... OK
2026-01-14T08:16:22.2684691Z Uncompressing NVIDIA Accelerated Graphics Driver for Linux-x86_64 580.65.06....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
2026-01-14T08:16:22.8727625Z 
2026-01-14T08:16:22.8728607Z WARNING: The nvidia-drm module will not be installed. As a result, DRM-KMS will not function with this installation of the NVIDIA driver.
2026-01-14T08:16:22.8729266Z 
2026-01-14T08:16:45.6832656Z 
2026-01-14T08:16:45.6836567Z WARNING: nvidia-installer was forced to guess the X library path '/usr/lib64' and X module path '/usr/lib64/xorg/modules'; these paths were not queryable from the system.  If X fails to find the NVIDIA X driver module, please install the `pkg-config` utility and the X.Org SDK/development package for your distribution and reinstall the driver.
2026-01-14T08:16:45.6837978Z 
2026-01-14T08:16:45.6858601Z 
2026-01-14T08:16:45.6860349Z WARNING: This NVIDIA driver package includes Vulkan components, but no Vulkan ICD loader was detected on this system. The NVIDIA Vulkan ICD will not function without the loader. Most distributions package the Vulkan loader; try installing the "vulkan-loader", "vulkan-icd-loader", or "libvulkan1" package.
2026-01-14T08:16:45.6861620Z 
2026-01-14T08:16:58.4687981Z + NVIDIA_INSTALLATION_STATUS=0
2026-01-14T08:16:58.4688321Z + RESET_GPU=0
2026-01-14T08:16:58.4688550Z + '[' 0 -ne 0 ']'
2026-01-14T08:16:58.4690998Z ++ command -v nvidia-smi
2026-01-14T08:16:58.4694773Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:16:58.4700284Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:17:02.3112177Z + INSTALLED_DRIVER_VERSION=580.65.06
2026-01-14T08:17:02.3112514Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:17:02.3112754Z + '[' 0 -ne 0 ']'
2026-01-14T08:17:02.3112967Z + '[' 0 -eq 1 ']'
2026-01-14T08:17:02.3113194Z + sudo rm -fv /tmp/nvidia_driver
2026-01-14T08:17:02.5228541Z removed '/tmp/nvidia_driver'
2026-01-14T08:17:02.5252106Z + set -e
2026-01-14T08:17:02.5257452Z + post_install_nvidia_driver_common
2026-01-14T08:17:02.5261657Z + sudo modprobe nvidia
2026-01-14T08:17:02.6747932Z + echo 'After installing NVIDIA driver'
2026-01-14T08:17:02.6748280Z + lspci
2026-01-14T08:17:02.6748506Z After installing NVIDIA driver
2026-01-14T08:17:02.6866932Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:17:02.6867457Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:17:02.6868041Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:17:02.6868598Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:17:02.6869517Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:17:02.6870067Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:17:02.6870581Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:17:02.6871046Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:17:02.6871513Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:17:02.6871964Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:17:02.6872468Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:17:02.6872902Z + lsmod
2026-01-14T08:17:02.6917911Z Module                  Size  Used by
2026-01-14T08:17:02.6918405Z nvidia_uvm           1921024  0
2026-01-14T08:17:02.6918800Z nvidia              14274560  1 nvidia_uvm
2026-01-14T08:17:02.6919217Z drm                   602112  1 nvidia
2026-01-14T08:17:02.6919677Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:17:02.6920124Z backlight              24576  1 drm
2026-01-14T08:17:02.6920528Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:17:02.6920926Z mgc                    86016  1
2026-01-14T08:17:02.6921283Z lustre               1085440  4
2026-01-14T08:17:02.6921634Z mdc                   294912  2 lustre
2026-01-14T08:17:02.6921993Z fid                    36864  1 mdc
2026-01-14T08:17:02.6922470Z lov                   356352  5 mdc,lustre
2026-01-14T08:17:02.6922840Z osc                   479232  5 mdc
2026-01-14T08:17:02.6923127Z lmv                   225280  2 lustre
2026-01-14T08:17:02.6923400Z fld                    49152  2 lov,lmv
2026-01-14T08:17:02.6923677Z ksocklnd              188416  1
2026-01-14T08:17:02.6924017Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:17:02.6924505Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:17:02.6925017Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:17:02.6925625Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:17:02.6926122Z xt_conntrack           16384  1
2026-01-14T08:17:02.6926390Z nft_chain_nat          16384  3
2026-01-14T08:17:02.6926649Z xt_MASQUERADE          20480  1
2026-01-14T08:17:02.6926958Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:17:02.6927768Z nf_conntrack_netlink    57344  0
2026-01-14T08:17:02.6928185Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:17:02.6928642Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:17:02.6928950Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:17:02.6929245Z xfrm_user              57344  1
2026-01-14T08:17:02.6929521Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:17:02.6929809Z xt_addrtype            16384  2
2026-01-14T08:17:02.6930072Z nft_compat             20480  4
2026-01-14T08:17:02.6930378Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:17:02.6930813Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:17:02.6931196Z br_netfilter           36864  0
2026-01-14T08:17:02.6931475Z bridge                323584  1 br_netfilter
2026-01-14T08:17:02.6931766Z stp                    16384  1 bridge
2026-01-14T08:17:02.6932059Z llc                    16384  2 bridge,stp
2026-01-14T08:17:02.6932336Z overlay               167936  0
2026-01-14T08:17:02.6932587Z tls                   139264  0
2026-01-14T08:17:02.6932836Z nls_ascii              16384  1
2026-01-14T08:17:02.6933078Z nls_cp437              20480  1
2026-01-14T08:17:02.6933330Z vfat                   24576  1
2026-01-14T08:17:02.6933570Z fat                    86016  1 vfat
2026-01-14T08:17:02.6933840Z sunrpc                700416  2 lnet
2026-01-14T08:17:02.6934107Z ghash_clmulni_intel    16384  0
2026-01-14T08:17:02.6934503Z i8042                  45056  0
2026-01-14T08:17:02.6934746Z serio                  28672  3 i8042
2026-01-14T08:17:02.6935013Z ena                   196608  0
2026-01-14T08:17:02.6935253Z button                 24576  0
2026-01-14T08:17:02.6935507Z sch_fq_codel           20480  33
2026-01-14T08:17:02.6935757Z fuse                  184320  1
2026-01-14T08:17:02.6935996Z loop                   36864  0
2026-01-14T08:17:02.6936240Z dm_mod                188416  0
2026-01-14T08:17:02.6936487Z configfs               57344  1
2026-01-14T08:17:02.6936735Z dmi_sysfs              20480  0
2026-01-14T08:17:02.6936978Z crc32_pclmul           16384  0
2026-01-14T08:17:02.6937233Z crc32c_intel           24576  0
2026-01-14T08:17:02.6937476Z efivarfs               24576  1
2026-01-14T08:17:02.6937725Z + modinfo nvidia
2026-01-14T08:17:02.6940126Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:17:02.6940621Z import_ns:      DMA_BUF
2026-01-14T08:17:02.6940886Z alias:          char-major-195-*
2026-01-14T08:17:02.6941150Z version:        580.65.06
2026-01-14T08:17:02.6941395Z supported:      external
2026-01-14T08:17:02.6941639Z license:        Dual MIT/GPL
2026-01-14T08:17:02.6941923Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:17:02.6942318Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:17:02.6942653Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:17:02.6943000Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:17:02.6943360Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:17:02.6943722Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:17:02.6944077Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:17:02.6944432Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:17:02.6944776Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:17:02.6945125Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:17:02.6945442Z depends:        i2c-core,drm
2026-01-14T08:17:02.6945731Z retpoline:      Y
2026-01-14T08:17:02.6945989Z name:           nvidia
2026-01-14T08:17:02.6946362Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:17:02.6946871Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:17:02.6947337Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:17:02.6947784Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:17:02.6948261Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:17:02.6948580Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:17:02.6948907Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:17:02.6949219Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:17:02.6949533Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:17:02.6949911Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:17:02.6950321Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:17:02.6950669Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:17:02.6950985Z parm:           NVreg_EnableMSI:int
2026-01-14T08:17:02.6951320Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:17:02.6951694Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:17:02.6952119Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:17:02.6952514Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:17:02.6952960Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:17:02.6953392Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:17:02.6953835Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:17:02.6954270Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:17:02.6954619Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:17:02.6955003Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:17:02.6955389Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:17:02.6955871Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:17:02.6956203Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:17:02.6956554Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:17:02.6956886Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:17:02.6957205Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:17:02.6957562Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:17:02.6957943Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:17:02.6958307Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:17:02.6958688Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:17:02.6959035Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:17:02.6959386Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:17:02.6959755Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:17:02.6960104Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:17:02.6960459Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:17:02.6960805Z parm:           NVreg_RmMsg:charp
2026-01-14T08:17:02.6961107Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:17:02.6961440Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:17:02.6961779Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:17:02.6962101Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:17:02.6962517Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:17:02.6962894Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:17:02.6963257Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:17:02.6963597Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:17:02.6963951Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:17:02.6964308Z parm:           rm_firmware_active:charp
2026-01-14T08:17:02.6964587Z + set +e
2026-01-14T08:17:02.6964791Z + nvidia-smi
2026-01-14T08:17:05.0265897Z Wed Jan 14 08:17:05 2026       
2026-01-14T08:17:05.0266338Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:05.0266976Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:17:05.0267509Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:05.0268073Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:17:05.0269089Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:17:05.0269578Z |                                         |                        |               MIG M. |
2026-01-14T08:17:05.0269981Z |=========================================+========================+======================|
2026-01-14T08:17:05.0648398Z |   0  NVIDIA A10G                    Off |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:17:05.0648930Z |  0%   24C    P0             55W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:05.0649387Z |                                         |                        |                  N/A |
2026-01-14T08:17:05.0649840Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:05.0650351Z |   1  NVIDIA A10G                    Off |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:17:05.0650839Z |  0%   25C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:05.0651277Z |                                         |                        |                  N/A |
2026-01-14T08:17:05.0651736Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:05.0652235Z |   2  NVIDIA A10G                    Off |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:17:05.0652732Z |  0%   25C    P0             59W /  300W |       0MiB /  23028MiB |      2%      Default |
2026-01-14T08:17:05.0653340Z |                                         |                        |                  N/A |
2026-01-14T08:17:05.0653801Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:05.0654309Z |   3  NVIDIA A10G                    Off |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:17:05.0654806Z |  0%   25C    P0             58W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:05.0655260Z |                                         |                        |                  N/A |
2026-01-14T08:17:05.0655717Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:05.0656197Z 
2026-01-14T08:17:05.0656399Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:05.0656891Z | Processes:                                                                              |
2026-01-14T08:17:05.0657396Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:17:05.0657880Z |        ID   ID                                                               Usage      |
2026-01-14T08:17:05.0658291Z |=========================================================================================|
2026-01-14T08:17:05.0676678Z |  No running processes found                                                             |
2026-01-14T08:17:05.0677230Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:06.7329105Z + nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
2026-01-14T08:17:09.0445218Z NVIDIA A10G
2026-01-14T08:17:10.1310021Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:17:10.1310299Z + '[' 0 -eq 0 ']'
2026-01-14T08:17:10.1310542Z + echo 'INFO: Ignoring allowed status 0'
2026-01-14T08:17:10.1310856Z INFO: Ignoring allowed status 0
2026-01-14T08:17:10.1311111Z + set -e
2026-01-14T08:17:10.1324439Z == Installing nvidia container toolkit for amzn2023 ==
2026-01-14T08:17:10.1330427Z + sudo yum install -y yum-utils
2026-01-14T08:17:10.5844760Z Last metadata expiration check: 0:02:01 ago on Wed Jan 14 08:15:09 2026.
2026-01-14T08:17:10.6126840Z Package dnf-utils-4.3.0-13.amzn2023.0.5.noarch is already installed.
2026-01-14T08:17:10.6792715Z Dependencies resolved.
2026-01-14T08:17:10.7150471Z Nothing to do.
2026-01-14T08:17:10.7150716Z Complete!
2026-01-14T08:17:10.7607619Z + [[ amzn2023 == \a\m\z\n\2\0\2\3 ]]
2026-01-14T08:17:10.7608713Z + YUM_REPO_URL=https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:17:10.7609749Z + sudo yum-config-manager --add-repo https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:17:11.1041015Z Adding repo from: https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:17:11.1512627Z + sudo yum install -y nvidia-container-toolkit-1.17.8 libnvidia-container-tools-1.17.8 libnvidia-container1-1.17.8 nvidia-container-toolkit-base-1.17.8
2026-01-14T08:17:11.7570488Z nvidia-container-toolkit                         17 kB/s | 833  B     00:00    
2026-01-14T08:17:11.8526187Z Dependencies resolved.
2026-01-14T08:17:11.8894505Z ================================================================================
2026-01-14T08:17:11.8895430Z  Package                       Arch   Version    Repository                Size
2026-01-14T08:17:11.8896289Z ================================================================================
2026-01-14T08:17:11.8896958Z Downgrading:
2026-01-14T08:17:11.8897706Z  libnvidia-container-tools     x86_64 1.17.8-1   nvidia-container-toolkit  40 k
2026-01-14T08:17:11.8898623Z  libnvidia-container1          x86_64 1.17.8-1   nvidia-container-toolkit 1.0 M
2026-01-14T08:17:11.8899225Z  nvidia-container-toolkit      x86_64 1.17.8-1   nvidia-container-toolkit 1.2 M
2026-01-14T08:17:11.8899848Z  nvidia-container-toolkit-base x86_64 1.17.8-1   nvidia-container-toolkit 5.8 M
2026-01-14T08:17:11.8900492Z 
2026-01-14T08:17:11.8900592Z Transaction Summary
2026-01-14T08:17:11.8900863Z ================================================================================
2026-01-14T08:17:11.8901215Z Downgrade  4 Packages
2026-01-14T08:17:11.8901370Z 
2026-01-14T08:17:11.8901488Z Total download size: 8.0 M
2026-01-14T08:17:11.8901755Z Downloading Packages:
2026-01-14T08:17:11.9084891Z (1/4): libnvidia-container-tools-1.17.8-1.x86_6 2.3 MB/s |  40 kB     00:00    
2026-01-14T08:17:11.9267516Z (2/4): libnvidia-container1-1.17.8-1.x86_64.rpm  28 MB/s | 1.0 MB     00:00    
2026-01-14T08:17:11.9349326Z (3/4): nvidia-container-toolkit-1.17.8-1.x86_64  28 MB/s | 1.2 MB     00:00    
2026-01-14T08:17:11.9746743Z (4/4): nvidia-container-toolkit-base-1.17.8-1.x  88 MB/s | 5.8 MB     00:00    
2026-01-14T08:17:11.9756138Z --------------------------------------------------------------------------------
2026-01-14T08:17:11.9758817Z Total                                            94 MB/s | 8.0 MB     00:00     
2026-01-14T08:17:11.9761346Z Running transaction check
2026-01-14T08:17:11.9892055Z Transaction check succeeded.
2026-01-14T08:17:11.9892688Z Running transaction test
2026-01-14T08:17:12.0402692Z Transaction test succeeded.
2026-01-14T08:17:12.0405773Z Running transaction
2026-01-14T08:17:12.6380296Z   Preparing        :                                                        1/1 
2026-01-14T08:17:12.7272290Z   Downgrading      : nvidia-container-toolkit-base-1.17.8-1.x86_64          1/8 
2026-01-14T08:17:12.7310465Z   Downgrading      : libnvidia-container1-1.17.8-1.x86_64                   2/8 
2026-01-14T08:17:12.7604117Z   Running scriptlet: libnvidia-container1-1.17.8-1.x86_64                   2/8 
2026-01-14T08:17:12.8688490Z   Downgrading      : libnvidia-container-tools-1.17.8-1.x86_64              3/8 
2026-01-14T08:17:12.8731326Z   Downgrading      : nvidia-container-toolkit-1.17.8-1.x86_64               4/8 
2026-01-14T08:17:12.8961059Z   Running scriptlet: nvidia-container-toolkit-1.17.8-1.x86_64               4/8 
2026-01-14T08:17:12.9044614Z   Running scriptlet: nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:17:12.9045210Z   Cleanup          : nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:17:12.9170778Z   Running scriptlet: nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:17:12.9255703Z   Running scriptlet: libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:17:12.9256512Z   Cleanup          : libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:17:12.9386826Z   Running scriptlet: libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:17:12.9480213Z   Running scriptlet: libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:17:12.9480817Z   Cleanup          : libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:17:12.9617488Z   Running scriptlet: libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:17:12.9706276Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:17:12.9707047Z   Cleanup          : nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:17:12.9842368Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:17:13.0492371Z   Running scriptlet: nvidia-container-toolkit-1.17.8-1.x86_64               8/8 
2026-01-14T08:17:15.0500058Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:17:15.0500696Z   Verifying        : libnvidia-container-tools-1.17.8-1.x86_64              1/8 
2026-01-14T08:17:15.0501263Z   Verifying        : libnvidia-container-tools-1.18.1-1.x86_64              2/8 
2026-01-14T08:17:15.0501835Z   Verifying        : libnvidia-container1-1.17.8-1.x86_64                   3/8 
2026-01-14T08:17:15.0502399Z   Verifying        : libnvidia-container1-1.18.1-1.x86_64                   4/8 
2026-01-14T08:17:15.0502962Z   Verifying        : nvidia-container-toolkit-1.17.8-1.x86_64               5/8 
2026-01-14T08:17:15.0503790Z   Verifying        : nvidia-container-toolkit-1.18.1-1.x86_64               6/8 
2026-01-14T08:17:15.0504361Z   Verifying        : nvidia-container-toolkit-base-1.17.8-1.x86_64          7/8 
2026-01-14T08:17:15.1992768Z   Verifying        : nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8================================================================================
2026-01-14T08:17:15.1994028Z WARNING:
2026-01-14T08:17:15.1994522Z   A newer release of "Amazon Linux" is available.
2026-01-14T08:17:15.1995012Z 
2026-01-14T08:17:15.1995201Z   Available Versions:
2026-01-14T08:17:15.1995506Z 
2026-01-14T08:17:15.1995696Z   Version 2023.10.20260105:
2026-01-14T08:17:15.1996353Z     Run the following command to upgrade to 2023.10.20260105:
2026-01-14T08:17:15.1996890Z 
2026-01-14T08:17:15.1997159Z       dnf upgrade --releasever=2023.10.20260105
2026-01-14T08:17:15.1997599Z 
2026-01-14T08:17:15.1997776Z     Release notes:
2026-01-14T08:17:15.1998626Z      https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.10.20260105.html
2026-01-14T08:17:15.1999414Z 
2026-01-14T08:17:15.1999671Z ================================================================================
2026-01-14T08:17:15.2719070Z  
2026-01-14T08:17:15.2719196Z 
2026-01-14T08:17:15.2719936Z Downgraded:
2026-01-14T08:17:15.2720305Z   libnvidia-container-tools-1.17.8-1.x86_64                                     
2026-01-14T08:17:15.2720906Z   libnvidia-container1-1.17.8-1.x86_64                                          
2026-01-14T08:17:15.2721473Z   nvidia-container-toolkit-1.17.8-1.x86_64                                      
2026-01-14T08:17:15.2722078Z   nvidia-container-toolkit-base-1.17.8-1.x86_64                                 
2026-01-14T08:17:15.2722503Z 
2026-01-14T08:17:15.2722597Z Complete!
2026-01-14T08:17:15.3361404Z + sudo systemctl restart docker
2026-01-14T08:17:23.6041918Z Wed Jan 14 08:17:23 2026       
2026-01-14T08:17:23.6042682Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:23.6043252Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:17:23.6043794Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:23.6044351Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:17:23.6045264Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:17:23.6045757Z |                                         |                        |               MIG M. |
2026-01-14T08:17:23.6046161Z |=========================================+========================+======================|
2026-01-14T08:17:23.6395140Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:17:23.6396159Z |  0%   25C    P0             55W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:23.6397059Z |                                         |                        |                  N/A |
2026-01-14T08:17:23.6397972Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:23.6398960Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:17:23.6399928Z |  0%   25C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:23.6400787Z |                                         |                        |                  N/A |
2026-01-14T08:17:23.6401741Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:23.6402676Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:17:23.6403281Z |  0%   25C    P0             57W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:23.6404022Z |                                         |                        |                  N/A |
2026-01-14T08:17:23.6404542Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:23.6405120Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:17:23.6405676Z |  0%   25C    P0             52W /  300W |       0MiB /  23028MiB |      2%      Default |
2026-01-14T08:17:23.6406185Z |                                         |                        |                  N/A |
2026-01-14T08:17:23.6406726Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:23.6407107Z 
2026-01-14T08:17:23.6407334Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:23.6407900Z | Processes:                                                                              |
2026-01-14T08:17:23.6408462Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:17:23.6409016Z |        ID   ID                                                               Usage      |
2026-01-14T08:17:23.6409483Z |=========================================================================================|
2026-01-14T08:17:23.6423443Z |  No running processes found                                                             |
2026-01-14T08:17:23.6424070Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:24.2796414Z Unable to find image 'public.ecr.aws/docker/library/python:3.13' locally
2026-01-14T08:17:24.5253552Z 3.13: Pulling from docker/library/python
2026-01-14T08:17:24.6328276Z 2ca1bfae7ba8: Pulling fs layer
2026-01-14T08:17:24.6329056Z 82e18c5e1c15: Pulling fs layer
2026-01-14T08:17:24.6329807Z be442a7e0d6f: Pulling fs layer
2026-01-14T08:17:24.6330463Z 26d823e3848f: Pulling fs layer
2026-01-14T08:17:24.6330989Z ca4b54413202: Pulling fs layer
2026-01-14T08:17:24.6331578Z b6513238a015: Pulling fs layer
2026-01-14T08:17:24.6332121Z 9b57076d00d4: Pulling fs layer
2026-01-14T08:17:24.6332523Z 26d823e3848f: Waiting
2026-01-14T08:17:24.6332762Z b6513238a015: Waiting
2026-01-14T08:17:24.6333004Z ca4b54413202: Waiting
2026-01-14T08:17:24.6333238Z 9b57076d00d4: Waiting
2026-01-14T08:17:24.7751097Z 82e18c5e1c15: Verifying Checksum
2026-01-14T08:17:24.7751959Z 82e18c5e1c15: Download complete
2026-01-14T08:17:24.7903665Z 2ca1bfae7ba8: Download complete
2026-01-14T08:17:24.8389045Z ca4b54413202: Verifying Checksum
2026-01-14T08:17:24.8389369Z ca4b54413202: Download complete
2026-01-14T08:17:24.8655211Z be442a7e0d6f: Download complete
2026-01-14T08:17:24.9095367Z 9b57076d00d4: Download complete
2026-01-14T08:17:24.9841763Z b6513238a015: Verifying Checksum
2026-01-14T08:17:24.9842077Z b6513238a015: Download complete
2026-01-14T08:17:25.4053703Z 26d823e3848f: Verifying Checksum
2026-01-14T08:17:25.4054103Z 26d823e3848f: Download complete
2026-01-14T08:17:26.5673317Z 2ca1bfae7ba8: Pull complete
2026-01-14T08:17:27.2899624Z 82e18c5e1c15: Pull complete
2026-01-14T08:17:29.8637098Z be442a7e0d6f: Pull complete
2026-01-14T08:17:36.9475895Z 26d823e3848f: Pull complete
2026-01-14T08:17:37.2425243Z ca4b54413202: Pull complete
2026-01-14T08:17:38.0335270Z b6513238a015: Pull complete
2026-01-14T08:17:38.0569236Z 9b57076d00d4: Pull complete
2026-01-14T08:17:38.0709961Z Digest: sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:17:38.0751128Z Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.13
2026-01-14T08:17:43.8515921Z Wed Jan 14 08:17:43 2026       
2026-01-14T08:17:43.8516380Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:43.8516938Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:17:43.8517480Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:43.8518410Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:17:43.8518992Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:17:43.8519485Z |                                         |                        |               MIG M. |
2026-01-14T08:17:43.8519885Z |=========================================+========================+======================|
2026-01-14T08:17:43.9136936Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:17:43.9137679Z |  0%   21C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:43.9138320Z |                                         |                        |                  N/A |
2026-01-14T08:17:43.9139243Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:43.9139986Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:17:43.9140695Z |  0%   21C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:43.9141315Z |                                         |                        |                  N/A |
2026-01-14T08:17:43.9141970Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:43.9142706Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:17:43.9143380Z |  0%   22C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:43.9144007Z |                                         |                        |                  N/A |
2026-01-14T08:17:43.9144656Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:43.9145377Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:17:43.9146072Z |  0%   22C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:43.9146685Z |                                         |                        |                  N/A |
2026-01-14T08:17:43.9147351Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:43.9164595Z 
2026-01-14T08:17:43.9165386Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:43.9166116Z | Processes:                                                                              |
2026-01-14T08:17:43.9166833Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:17:43.9167546Z |        ID   ID                                                               Usage      |
2026-01-14T08:17:43.9168164Z |=========================================================================================|
2026-01-14T08:17:43.9204402Z |  No running processes found                                                             |
2026-01-14T08:17:43.9205174Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:46.2879820Z Command completed after 1 attempt(s).
2026-01-14T08:17:46.2999938Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T08:17:46.3000621Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T08:17:46.3001190Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T08:17:46.3001611Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T08:17:46.3002024Z [36;1m# Prune all of the docker images[0m
2026-01-14T08:17:46.3002773Z [36;1mdocker system prune -af[0m
2026-01-14T08:17:46.3019509Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:46.3020064Z env:
2026-01-14T08:17:46.3020418Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:46.3020817Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:46.3021459Z   PR_NUMBER: 3500
2026-01-14T08:17:46.3023071Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:46.3024940Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:46.3025671Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:46.3026383Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:46.3026852Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:46.3027329Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:46.3027739Z ##[endgroup]
2026-01-14T08:17:46.3357880Z "docker stop" requires at least 1 argument.
2026-01-14T08:17:46.3358606Z See 'docker stop --help'.
2026-01-14T08:17:46.3358817Z 
2026-01-14T08:17:46.3359008Z Usage:  docker stop [OPTIONS] CONTAINER [CONTAINER...]
2026-01-14T08:17:46.3359338Z 
2026-01-14T08:17:46.3359505Z Stop one or more running containers
2026-01-14T08:17:47.5441632Z Deleted Images:
2026-01-14T08:17:47.5442138Z untagged: public.ecr.aws/docker/library/python:3.13
2026-01-14T08:17:47.5443542Z untagged: public.ecr.aws/docker/library/python@sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:17:47.5444814Z deleted: sha256:6b1b86f270ccdb848adf78330c7a27041a2f8e971cfd9c808e1ad503d236f9ae
2026-01-14T08:17:47.5445825Z deleted: sha256:ab3ff5992dd09a2d006ef37d701d92e11590962848a698a0824ab2129505b946
2026-01-14T08:17:47.5446608Z deleted: sha256:c839d2b1d0949c101d8e022855435eedb0179697af77be6012f911dfcb69742c
2026-01-14T08:17:47.5447338Z deleted: sha256:b3fb8a2c0606137f473565b54a51bb1e18dfca24cbc417e0f7a0b3d68395d9ea
2026-01-14T08:17:47.5448014Z deleted: sha256:a643465a85469890e6e498fe0d0ac4e6a251e77c92a179ac27085d4ffeb4c8da
2026-01-14T08:17:47.5448830Z deleted: sha256:09db7ba2ba0ebb76125f8bf37573369eb90202594586d30c6f9c202d968f4d00
2026-01-14T08:17:47.5449571Z deleted: sha256:ba4e59af8cdbb2e2cd899773f1cdbcb3027d48d9be333f5a823d9cccfd5c4a15
2026-01-14T08:17:47.5450261Z deleted: sha256:da7213941eca995ecec09e85fe1affcac44194792b48cbacdd3c0d9038bbaf9e
2026-01-14T08:17:47.5450736Z 
2026-01-14T08:17:47.6513354Z Total reclaimed space: 1.109GB
2026-01-14T08:17:47.6628299Z ##[group]Run ./test-infra/.github/actions/setup-ssh
2026-01-14T08:17:47.6628693Z with:
2026-01-14T08:17:47.6629348Z   github-secret: ***
2026-01-14T08:17:47.6630037Z   instructions: All testing is done inside the container, to start an interactive session run:
   docker exec -it $(docker container ps --format '{{.ID}}') bash

2026-01-14T08:17:47.6630789Z   activate-with-label: false
2026-01-14T08:17:47.6631062Z   label: with-ssh
2026-01-14T08:17:47.6631294Z   remove-existing-keys: true
2026-01-14T08:17:47.6631580Z   fail-silently: true
2026-01-14T08:17:47.6631806Z env:
2026-01-14T08:17:47.6632056Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:47.6632408Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:47.6632656Z   PR_NUMBER: 3500
2026-01-14T08:17:47.6634209Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:47.6635934Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:47.6636508Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:47.6637055Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:47.6637625Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:47.6637931Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:47.6638276Z ##[endgroup]
2026-01-14T08:17:47.7888390Z Please see https://github.com/pytorch/pytorch/wiki/Debugging-using-with-ssh-for-Github-Actions for more info.
2026-01-14T08:17:48.4132800Z Grabbing public ssh keys from https://github.com/zxd1997066.keys
2026-01-14T08:17:48.5360705Z ~/.ssh/authorized_keys file found on node, removing ~/.ssh and starting fresh
2026-01-14T08:17:48.5376250Z Public keys pulled and installed to /home/ec2-user/.ssh/authorized_keys
2026-01-14T08:17:48.5415540Z Login using: ssh ec2-user@ec2-3-230-1-248.compute-1.amazonaws.com
2026-01-14T08:17:48.5416076Z All testing is done inside the container, to start an interactive session run:
2026-01-14T08:17:48.5416600Z    docker exec -it $(docker container ps --format '{{.ID}}') bash
2026-01-14T08:17:48.5578149Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:17:48.5578579Z with:
2026-01-14T08:17:48.5578803Z   repository: pytorch/ao
2026-01-14T08:17:48.5579075Z   ref: refs/pull/3500/merge
2026-01-14T08:17:48.5579336Z   path: pytorch/ao
2026-01-14T08:17:48.5579565Z   fetch-depth: 1
2026-01-14T08:17:48.5579792Z   submodules: recursive
2026-01-14T08:17:48.5580192Z   token: ***
2026-01-14T08:17:48.5580410Z   ssh-strict: true
2026-01-14T08:17:48.5580624Z   ssh-user: git
2026-01-14T08:17:48.5580858Z   persist-credentials: true
2026-01-14T08:17:48.5581112Z   clean: true
2026-01-14T08:17:48.5581354Z   sparse-checkout-cone-mode: true
2026-01-14T08:17:48.5581645Z   fetch-tags: false
2026-01-14T08:17:48.5581876Z   show-progress: true
2026-01-14T08:17:48.5582108Z   lfs: false
2026-01-14T08:17:48.5582324Z   set-safe-directory: true
2026-01-14T08:17:48.5582566Z env:
2026-01-14T08:17:48.5582812Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:48.5583179Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:48.5583420Z   PR_NUMBER: 3500
2026-01-14T08:17:48.5584952Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:48.5586679Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:48.5587255Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:48.5587793Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:48.5588179Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:48.5588485Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:48.5588838Z ##[endgroup]
2026-01-14T08:17:48.6590981Z Syncing repository: pytorch/ao
2026-01-14T08:17:48.6599582Z ##[group]Getting Git version info
2026-01-14T08:17:48.6600028Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao'
2026-01-14T08:17:48.6626675Z [command]/usr/bin/git version
2026-01-14T08:17:48.6679267Z git version 2.50.1
2026-01-14T08:17:48.6705332Z ##[endgroup]
2026-01-14T08:17:48.6729807Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/f5d3417c-5d79-459b-ae84-a4d2a9771f12' before making global git config changes
2026-01-14T08:17:48.6730720Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:17:48.6735541Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:17:48.6775569Z ##[group]Initializing the repository
2026-01-14T08:17:48.6780212Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:17:48.6831963Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:17:48.6832571Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:17:48.6833359Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:17:48.6833772Z hint:
2026-01-14T08:17:48.6834050Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:17:48.6834396Z hint:
2026-01-14T08:17:48.6834721Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:17:48.6835283Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:17:48.6835709Z hint:
2026-01-14T08:17:48.6835932Z hint: 	git branch -m <name>
2026-01-14T08:17:48.6836189Z hint:
2026-01-14T08:17:48.6836551Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:17:48.6837228Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/
2026-01-14T08:17:48.6845202Z [command]/usr/bin/git remote add origin https://github.com/pytorch/ao
2026-01-14T08:17:48.6891338Z ##[endgroup]
2026-01-14T08:17:48.6891777Z ##[group]Disabling automatic garbage collection
2026-01-14T08:17:48.6895629Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:17:48.6932205Z ##[endgroup]
2026-01-14T08:17:48.6932581Z ##[group]Setting up auth
2026-01-14T08:17:48.6938323Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:17:48.6973967Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:17:48.7384975Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:17:48.7420721Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:17:48.7825023Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:17:48.7877508Z ##[endgroup]
2026-01-14T08:17:48.7877931Z ##[group]Fetching the repository
2026-01-14T08:17:48.7884922Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/pull/3500/merge:refs/remotes/pull/3500/merge
2026-01-14T08:17:49.5195896Z From https://github.com/pytorch/ao
2026-01-14T08:17:49.5196707Z  * [new ref]         refs/pull/3500/merge -> pull/3500/merge
2026-01-14T08:17:49.5226170Z ##[endgroup]
2026-01-14T08:17:49.5226593Z ##[group]Determining the checkout info
2026-01-14T08:17:49.5228695Z ##[endgroup]
2026-01-14T08:17:49.5233215Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:17:49.5277285Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:17:49.5312185Z ##[group]Checking out the ref
2026-01-14T08:17:49.5315642Z [command]/usr/bin/git checkout --progress --force refs/remotes/pull/3500/merge
2026-01-14T08:17:49.6743176Z Note: switching to 'refs/remotes/pull/3500/merge'.
2026-01-14T08:17:49.6743549Z 
2026-01-14T08:17:49.6743864Z You are in 'detached HEAD' state. You can look around, make experimental
2026-01-14T08:17:49.6744403Z changes and commit them, and you can discard any commits you make in this
2026-01-14T08:17:49.6744930Z state without impacting any branches by switching back to a branch.
2026-01-14T08:17:49.6745236Z 
2026-01-14T08:17:49.6745441Z If you want to create a new branch to retain commits you create, you may
2026-01-14T08:17:49.6745947Z do so (now or later) by using -c with the switch command. Example:
2026-01-14T08:17:49.6746230Z 
2026-01-14T08:17:49.6746344Z   git switch -c <new-branch-name>
2026-01-14T08:17:49.6746539Z 
2026-01-14T08:17:49.6746642Z Or undo this operation with:
2026-01-14T08:17:49.6746817Z 
2026-01-14T08:17:49.6746911Z   git switch -
2026-01-14T08:17:49.6747038Z 
2026-01-14T08:17:49.6747287Z Turn off this advice by setting config variable advice.detachedHead to false
2026-01-14T08:17:49.6747638Z 
2026-01-14T08:17:49.6748244Z HEAD is now at b34f898 Merge f07387cd29b2a97703e501a48808c413bf9d95ea into 985d970b5e16b58c1e5b8bab440169d3da78cf16
2026-01-14T08:17:49.6764504Z ##[endgroup]
2026-01-14T08:17:49.6764938Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:17:49.6771406Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:17:49.6824777Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:17:49.6863036Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:17:49.6901733Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:17:49.6934471Z ##[endgroup]
2026-01-14T08:17:49.6934884Z ##[group]Fetching submodules
2026-01-14T08:17:49.6937948Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:17:49.7338271Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:17:49.7731801Z Submodule 'third_party/cutlass' (https://github.com/NVIDIA/cutlass) registered for path 'third_party/cutlass'
2026-01-14T08:17:49.7766029Z Cloning into '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/third_party/cutlass'...
2026-01-14T08:17:51.9924547Z From https://github.com/NVIDIA/cutlass
2026-01-14T08:17:51.9925104Z  * branch            e51efbfe18fe4f4cbb66ab814c55bf4aa0185491 -> FETCH_HEAD
2026-01-14T08:17:52.7828952Z Submodule path 'third_party/cutlass': checked out 'e51efbfe18fe4f4cbb66ab814c55bf4aa0185491'
2026-01-14T08:17:52.7894550Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:17:52.8279162Z Entering 'third_party/cutlass'
2026-01-14T08:17:52.8362542Z ##[endgroup]
2026-01-14T08:17:52.8362986Z ##[group]Persisting credentials for submodules
2026-01-14T08:17:52.8369489Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:17:52.8750636Z Entering 'third_party/cutlass'
2026-01-14T08:17:52.8859225Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:17:52.9246642Z Entering 'third_party/cutlass'
2026-01-14T08:17:52.9325708Z file:/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/modules/third_party/cutlass/config	remote.origin.url
2026-01-14T08:17:52.9392310Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:17:52.9778436Z Entering 'third_party/cutlass'
2026-01-14T08:17:52.9866335Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:17:53.0254464Z Entering 'third_party/cutlass'
2026-01-14T08:17:53.0336875Z ##[endgroup]
2026-01-14T08:17:53.0382800Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:17:53.0414191Z b34f89824bef6a4573349bfbefa82a7db14ede35
2026-01-14T08:17:53.0679383Z Prepare all required actions
2026-01-14T08:17:53.0679806Z Getting action download info
2026-01-14T08:17:53.2262620Z Download action repository 'nick-fields/retry@v3.0.0' (SHA:7152eba30c6575329ac0576536151aca5a72780e)
2026-01-14T08:17:53.4976807Z ##[group]Run ./test-infra/.github/actions/calculate-docker-image
2026-01-14T08:17:53.4977212Z with:
2026-01-14T08:17:53.4977440Z   use-custom-docker-registry: true
2026-01-14T08:17:53.4977810Z   docker-image-name: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:53.4978184Z   docker-build-dir: .ci/docker
2026-01-14T08:17:53.4978469Z   working-directory: pytorch/ao
2026-01-14T08:17:53.4978766Z   docker-build-script: ./build.sh
2026-01-14T08:17:53.4979144Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:53.4979734Z   force-push: false
2026-01-14T08:17:53.4979951Z env:
2026-01-14T08:17:53.4980227Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:53.4980604Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:53.4980890Z   PR_NUMBER: 3500
2026-01-14T08:17:53.4982438Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:53.4984185Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:53.4984786Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:53.4985339Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:53.4985744Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:53.4986082Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:53.4986436Z ##[endgroup]
2026-01-14T08:17:53.5012214Z ##[group]Run set -ex
2026-01-14T08:17:53.5012738Z [36;1mset -ex[0m
2026-01-14T08:17:53.5013075Z [36;1m[0m
2026-01-14T08:17:53.5013530Z [36;1m# If the docker build directory or the build script doesn't exist, the action will[0m
2026-01-14T08:17:53.5014350Z [36;1m# gracefully return the docker image name as it is.  Pulling docker image in Linux[0m
2026-01-14T08:17:53.5014985Z [36;1m# job could then download the pre-built image as usual[0m
2026-01-14T08:17:53.5015833Z [36;1mif [[ -d "${DOCKER_BUILD_DIR}" ]] && [[ -f "${DOCKER_BUILD_DIR}/${DOCKER_BUILD_SCRIPT}" ]] && [[ "${USE_CUSTOM_DOCKER_REGISTRY}" == "true" ]]; then[0m
2026-01-14T08:17:53.5016666Z [36;1m  echo "skip=false" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:53.5017074Z [36;1melse[0m
2026-01-14T08:17:53.5017442Z [36;1m  echo "skip=true" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:53.5018062Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:53.5032326Z [36;1m[0m
2026-01-14T08:17:53.5032941Z [36;1m  echo "Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ${REPO_NAME} repo..."[0m
2026-01-14T08:17:53.5033595Z [36;1m  exit 0[0m
2026-01-14T08:17:53.5033809Z [36;1mfi[0m
2026-01-14T08:17:53.5034016Z [36;1m[0m
2026-01-14T08:17:53.5034354Z [36;1mif [[ "${DOCKER_IMAGE_NAME}" == *"${DOCKER_REGISTRY}/${REPO_NAME}"* ]]; then[0m
2026-01-14T08:17:53.5034973Z [36;1m  # The docker image name already includes the ECR prefix and tag, so we can just[0m
2026-01-14T08:17:53.5035516Z [36;1m  # use it as it is, but first let's extract the tag[0m
2026-01-14T08:17:53.5036012Z [36;1m  DOCKER_TAG=$(echo "${DOCKER_IMAGE_NAME}" | awk -F '[:,]' '{print $2}')[0m
2026-01-14T08:17:53.5036527Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:53.5037015Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:53.5037428Z [36;1melse[0m
2026-01-14T08:17:53.5037684Z [36;1m  if [[ "${DOCKER_IMAGE_NAME}" == *:* ]]; then[0m
2026-01-14T08:17:53.5038345Z [36;1m    CUSTOM_TAG_PREFIX=${DOCKER_IMAGE_NAME#*:}[0m
2026-01-14T08:17:53.5038753Z [36;1m    DOCKER_IMAGE_NAME=${DOCKER_IMAGE_NAME%%:*}[0m
2026-01-14T08:17:53.5039257Z [36;1m  fi[0m
2026-01-14T08:17:53.5039718Z [36;1m  DOCKER_TAG=${CUSTOM_TAG_PREFIX:+${CUSTOM_TAG_PREFIX}-}$(git rev-parse HEAD:"${DOCKER_BUILD_DIR}")[0m
2026-01-14T08:17:53.5040377Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:53.5041045Z [36;1m  echo "docker-image=${DOCKER_REGISTRY}/${REPO_NAME}/${DOCKER_IMAGE_NAME}:${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:53.5041753Z [36;1m  echo "custom-tag-prefix=${CUSTOM_TAG_PREFIX}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:53.5042173Z [36;1mfi[0m
2026-01-14T08:17:53.5051630Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:53.5052155Z env:
2026-01-14T08:17:53.5052422Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:53.5052768Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:53.5053034Z   PR_NUMBER: 3500
2026-01-14T08:17:53.5054567Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:53.5056305Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:53.5056890Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:53.5057428Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:53.5057810Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:53.5058124Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:53.5058487Z   REPO_NAME: ao
2026-01-14T08:17:53.5058786Z   DOCKER_IMAGE_NAME: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:53.5059144Z   DOCKER_BUILD_DIR: .ci/docker
2026-01-14T08:17:53.5059429Z   DOCKER_BUILD_SCRIPT: ./build.sh
2026-01-14T08:17:53.5059797Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:53.5060209Z   USE_CUSTOM_DOCKER_REGISTRY: true
2026-01-14T08:17:53.5060520Z   CUSTOM_TAG_PREFIX: 
2026-01-14T08:17:53.5060760Z ##[endgroup]
2026-01-14T08:17:53.5100137Z + [[ -d .ci/docker ]]
2026-01-14T08:17:53.5100428Z + echo skip=true
2026-01-14T08:17:53.5100749Z + echo docker-image=pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:53.5101405Z + echo 'Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...'
2026-01-14T08:17:53.5101984Z + exit 0
2026-01-14T08:17:53.5102447Z Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...
2026-01-14T08:17:53.5147270Z ##[group]Run set -eux
2026-01-14T08:17:53.5147563Z [36;1mset -eux[0m
2026-01-14T08:17:53.5148033Z [36;1m# It's ok if this steps fails, it would then be an anonymous user like what we used to have[0m
2026-01-14T08:17:53.5149233Z [36;1maws secretsmanager get-secret-value --secret-id docker_hub_readonly_token | jq --raw-output '.SecretString' | jq -r .docker_hub_readonly_token | docker login --username pytorchbot --password-stdin || true[0m
2026-01-14T08:17:53.5159275Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:53.5159661Z env:
2026-01-14T08:17:53.5159935Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:53.5160309Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:53.5160571Z   PR_NUMBER: 3500
2026-01-14T08:17:53.5162435Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:53.5164224Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:53.5164830Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:53.5165383Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:53.5165795Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:53.5166117Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:53.5166485Z ##[endgroup]
2026-01-14T08:17:53.5203934Z + aws secretsmanager get-secret-value --secret-id docker_hub_readonly_token
2026-01-14T08:17:53.5204666Z + jq --raw-output .SecretString
2026-01-14T08:17:53.5206293Z + jq -r .docker_hub_readonly_token
2026-01-14T08:17:53.5207626Z + docker login --username pytorchbot --password-stdin
2026-01-14T08:17:54.1331156Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:17:54.1331759Z Configure a credential helper to remove this warning. See
2026-01-14T08:17:54.1332302Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:17:54.1332675Z 
2026-01-14T08:17:54.1333262Z Login Succeeded
2026-01-14T08:17:54.1414550Z Prepare all required actions
2026-01-14T08:17:54.1456726Z ##[group]Run ./test-infra/.github/actions/pull-docker-image
2026-01-14T08:17:54.1457096Z with:
2026-01-14T08:17:54.1457365Z   docker-image: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:54.1457810Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:54.1458191Z env:
2026-01-14T08:17:54.1458457Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:54.1458809Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:54.1459072Z   PR_NUMBER: 3500
2026-01-14T08:17:54.1460677Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:54.1462473Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:54.1463053Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:54.1463608Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:54.1464006Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:54.1464319Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:54.1464680Z ##[endgroup]
2026-01-14T08:17:54.1487840Z ##[group]Run set -x
2026-01-14T08:17:54.1488203Z [36;1mset -x[0m
2026-01-14T08:17:54.1488418Z [36;1mset +e[0m
2026-01-14T08:17:54.1488635Z [36;1m[0m
2026-01-14T08:17:54.1488833Z [36;1mlogin() {[0m
2026-01-14T08:17:54.1489307Z [36;1m  aws ecr get-login-password --region us-east-1 | docker login -u AWS --password-stdin "$1"[0m
2026-01-14T08:17:54.1489822Z [36;1m}[0m
2026-01-14T08:17:54.1490026Z [36;1m[0m
2026-01-14T08:17:54.1490223Z [36;1mretry () {[0m
2026-01-14T08:17:54.1490504Z [36;1m  $*  || (sleep 1 && $*) || (sleep 2 && $*)[0m
2026-01-14T08:17:54.1490814Z [36;1m}[0m
2026-01-14T08:17:54.1491018Z [36;1m[0m
2026-01-14T08:17:54.1491249Z [36;1mretry login "${DOCKER_REGISTRY}"[0m
2026-01-14T08:17:54.1491559Z [36;1m[0m
2026-01-14T08:17:54.1504766Z [36;1mIMAGE_SIZE=$(docker manifest inspect "${DOCKER_IMAGE}" | jq '[.layers[].size, .config.size] | add / 1024 / 1024')[0m
2026-01-14T08:17:54.1505439Z [36;1mecho "Compressed size of image in MB: ${IMAGE_SIZE}"[0m
2026-01-14T08:17:54.1505808Z [36;1m[0m
2026-01-14T08:17:54.1506004Z [36;1mset -e[0m
2026-01-14T08:17:54.1506331Z [36;1m# ignore output since only exit code is used for conditional[0m
2026-01-14T08:17:54.1506819Z [36;1m# only pull docker image if it's not available locally[0m
2026-01-14T08:17:54.1507374Z [36;1mif ! docker inspect --type=image "${DOCKER_IMAGE}" >/dev/null 2>/dev/null; then[0m
2026-01-14T08:17:54.1507874Z [36;1m  retry docker pull "${DOCKER_IMAGE}"[0m
2026-01-14T08:17:54.1508174Z [36;1mfi[0m
2026-01-14T08:17:54.1517925Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:54.1518284Z env:
2026-01-14T08:17:54.1518534Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:54.1518887Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:54.1519143Z   PR_NUMBER: 3500
2026-01-14T08:17:54.1520891Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:54.1523099Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:54.1523681Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:54.1524217Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:54.1524802Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:54.1525111Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:54.1525570Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:54.1525951Z ##[endgroup]
2026-01-14T08:17:54.1558327Z + set +e
2026-01-14T08:17:54.1558637Z + retry login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:54.1559054Z + login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:54.1562607Z + aws ecr get-login-password --region us-east-1
2026-01-14T08:17:54.1563634Z + docker login -u AWS --password-stdin 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:54.7398393Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:17:54.7399007Z Configure a credential helper to remove this warning. See
2026-01-14T08:17:54.7399555Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:17:54.7399935Z 
2026-01-14T08:17:54.7400105Z Login Succeeded
2026-01-14T08:17:54.7431882Z ++ docker manifest inspect pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:54.7432535Z ++ jq '[.layers[].size, .config.size] | add / 1024 / 1024'
2026-01-14T08:17:54.9174248Z + IMAGE_SIZE=7985.954789161682
2026-01-14T08:17:54.9174621Z + echo 'Compressed size of image in MB: 7985.954789161682'
2026-01-14T08:17:54.9174973Z + set -e
2026-01-14T08:17:54.9175306Z + docker inspect --type=image pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:54.9175745Z Compressed size of image in MB: 7985.954789161682
2026-01-14T08:17:54.9339467Z + retry docker pull pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:54.9339913Z + docker pull pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:55.1314394Z cuda12.6: Pulling from pytorch/almalinux-builder
2026-01-14T08:17:55.1315169Z 19877a9af8e3: Pulling fs layer
2026-01-14T08:17:55.1315713Z 7335f5694751: Pulling fs layer
2026-01-14T08:17:55.1316249Z e89b428500ef: Pulling fs layer
2026-01-14T08:17:55.1316825Z 2890bcc97ae2: Pulling fs layer
2026-01-14T08:17:55.1317379Z 8e7a9d654295: Pulling fs layer
2026-01-14T08:17:55.1317907Z 55070e1f6d59: Pulling fs layer
2026-01-14T08:17:55.1318463Z a6ffcda215dd: Pulling fs layer
2026-01-14T08:17:55.1319019Z 4f4fb700ef54: Pulling fs layer
2026-01-14T08:17:55.1319554Z d4e5a2339eb1: Pulling fs layer
2026-01-14T08:17:55.1320098Z 3b50177ed801: Pulling fs layer
2026-01-14T08:17:55.1320603Z 657cfc9d9d43: Pulling fs layer
2026-01-14T08:17:55.1320883Z 039239a19e2c: Pulling fs layer
2026-01-14T08:17:55.1321154Z 301a59dd8ea1: Pulling fs layer
2026-01-14T08:17:55.1321434Z 747a1c0117bc: Pulling fs layer
2026-01-14T08:17:55.1321721Z 2d6f0c29ad9f: Pulling fs layer
2026-01-14T08:17:55.1322005Z 5b7921a1b019: Pulling fs layer
2026-01-14T08:17:55.1322331Z a4392ccb83ef: Pulling fs layer
2026-01-14T08:17:55.1322611Z 3f0968dff130: Pulling fs layer
2026-01-14T08:17:55.1322886Z 9323969b3930: Pulling fs layer
2026-01-14T08:17:55.1323158Z b9f6732b07f0: Pulling fs layer
2026-01-14T08:17:55.1323442Z 32117f6e66ab: Pulling fs layer
2026-01-14T08:17:55.1323717Z bed95346686d: Pulling fs layer
2026-01-14T08:17:55.1323993Z a73f5cbdff4f: Pulling fs layer
2026-01-14T08:17:55.1324260Z 4f4fb700ef54: Waiting
2026-01-14T08:17:55.1324500Z 747a1c0117bc: Waiting
2026-01-14T08:17:55.1324737Z 2d6f0c29ad9f: Waiting
2026-01-14T08:17:55.1324979Z d4e5a2339eb1: Waiting
2026-01-14T08:17:55.1325214Z 5b7921a1b019: Waiting
2026-01-14T08:17:55.1325469Z a4392ccb83ef: Waiting
2026-01-14T08:17:55.1325708Z 3b50177ed801: Waiting
2026-01-14T08:17:55.1325936Z 3f0968dff130: Waiting
2026-01-14T08:17:55.1326178Z 9323969b3930: Waiting
2026-01-14T08:17:55.1326617Z 657cfc9d9d43: Waiting
2026-01-14T08:17:55.1326849Z 039239a19e2c: Waiting
2026-01-14T08:17:55.1327074Z b9f6732b07f0: Waiting
2026-01-14T08:17:55.1327310Z 301a59dd8ea1: Waiting
2026-01-14T08:17:55.1327540Z 32117f6e66ab: Waiting
2026-01-14T08:17:55.1327775Z bed95346686d: Waiting
2026-01-14T08:17:55.1328008Z 8e7a9d654295: Waiting
2026-01-14T08:17:55.1328249Z a73f5cbdff4f: Waiting
2026-01-14T08:17:55.1328663Z 55070e1f6d59: Waiting
2026-01-14T08:17:55.1328894Z a6ffcda215dd: Waiting
2026-01-14T08:17:55.1329126Z 2890bcc97ae2: Waiting
2026-01-14T08:17:55.2897645Z e89b428500ef: Verifying Checksum
2026-01-14T08:17:55.2897971Z e89b428500ef: Download complete
2026-01-14T08:17:55.6828905Z 2890bcc97ae2: Verifying Checksum
2026-01-14T08:17:55.6829209Z 2890bcc97ae2: Download complete
2026-01-14T08:17:55.8668230Z 19877a9af8e3: Verifying Checksum
2026-01-14T08:17:55.8668583Z 19877a9af8e3: Download complete
2026-01-14T08:17:55.9131829Z 55070e1f6d59: Verifying Checksum
2026-01-14T08:17:55.9132422Z 55070e1f6d59: Download complete
2026-01-14T08:17:56.3981440Z a6ffcda215dd: Verifying Checksum
2026-01-14T08:17:56.3981751Z a6ffcda215dd: Download complete
2026-01-14T08:17:56.4369692Z 4f4fb700ef54: Verifying Checksum
2026-01-14T08:17:56.4370276Z 4f4fb700ef54: Download complete
2026-01-14T08:17:56.4901370Z d4e5a2339eb1: Verifying Checksum
2026-01-14T08:17:56.4901816Z d4e5a2339eb1: Download complete
2026-01-14T08:17:56.5331007Z 3b50177ed801: Verifying Checksum
2026-01-14T08:17:56.5331305Z 3b50177ed801: Download complete
2026-01-14T08:17:56.5753202Z 657cfc9d9d43: Download complete
2026-01-14T08:17:56.6156754Z 039239a19e2c: Download complete
2026-01-14T08:17:57.0459335Z 7335f5694751: Verifying Checksum
2026-01-14T08:17:57.0459654Z 7335f5694751: Download complete
2026-01-14T08:17:57.1617410Z 747a1c0117bc: Verifying Checksum
2026-01-14T08:17:57.1617715Z 747a1c0117bc: Download complete
2026-01-14T08:17:57.2071894Z 2d6f0c29ad9f: Verifying Checksum
2026-01-14T08:17:57.2072204Z 2d6f0c29ad9f: Download complete
2026-01-14T08:17:57.7648162Z 8e7a9d654295: Verifying Checksum
2026-01-14T08:17:57.7648661Z 8e7a9d654295: Download complete
2026-01-14T08:17:57.8091015Z a4392ccb83ef: Verifying Checksum
2026-01-14T08:17:57.8091356Z a4392ccb83ef: Download complete
2026-01-14T08:17:57.8683196Z 3f0968dff130: Verifying Checksum
2026-01-14T08:17:57.8683568Z 3f0968dff130: Download complete
2026-01-14T08:17:57.9071086Z 9323969b3930: Verifying Checksum
2026-01-14T08:17:57.9071567Z 9323969b3930: Download complete
2026-01-14T08:17:58.0400876Z b9f6732b07f0: Verifying Checksum
2026-01-14T08:17:58.0401224Z b9f6732b07f0: Download complete
2026-01-14T08:17:58.1184439Z 32117f6e66ab: Download complete
2026-01-14T08:17:58.1659445Z bed95346686d: Download complete
2026-01-14T08:17:58.5848920Z 19877a9af8e3: Pull complete
2026-01-14T08:18:01.6623922Z 5b7921a1b019: Verifying Checksum
2026-01-14T08:18:01.6624244Z 5b7921a1b019: Download complete
2026-01-14T08:18:02.4289389Z 7335f5694751: Pull complete
2026-01-14T08:18:02.6276878Z e89b428500ef: Pull complete
2026-01-14T08:18:02.9291827Z 2890bcc97ae2: Pull complete
2026-01-14T08:18:04.1038660Z a73f5cbdff4f: Verifying Checksum
2026-01-14T08:18:04.1039380Z a73f5cbdff4f: Download complete
2026-01-14T08:18:09.1368985Z 8e7a9d654295: Pull complete
2026-01-14T08:18:09.1596649Z 55070e1f6d59: Pull complete
2026-01-14T08:18:10.4397579Z a6ffcda215dd: Pull complete
2026-01-14T08:18:10.4624255Z 4f4fb700ef54: Pull complete
2026-01-14T08:19:01.8918102Z d4e5a2339eb1: Pull complete
2026-01-14T08:19:01.9179875Z 3b50177ed801: Pull complete
2026-01-14T08:19:01.9400374Z 657cfc9d9d43: Pull complete
2026-01-14T08:19:01.9628662Z 039239a19e2c: Pull complete
2026-01-14T08:19:04.3781362Z 301a59dd8ea1: Verifying Checksum
2026-01-14T08:19:04.3781680Z 301a59dd8ea1: Download complete
2026-01-14T08:20:04.8601878Z 301a59dd8ea1: Pull complete
2026-01-14T08:20:05.4882119Z 747a1c0117bc: Pull complete
2026-01-14T08:20:05.9647657Z 2d6f0c29ad9f: Pull complete
2026-01-14T08:20:23.9722799Z 5b7921a1b019: Pull complete
2026-01-14T08:20:24.4260990Z a4392ccb83ef: Pull complete
2026-01-14T08:20:24.8509687Z 3f0968dff130: Pull complete
2026-01-14T08:20:25.2799175Z 9323969b3930: Pull complete
2026-01-14T08:20:25.9243361Z b9f6732b07f0: Pull complete
2026-01-14T08:20:26.2842698Z 32117f6e66ab: Pull complete
2026-01-14T08:20:26.6461795Z bed95346686d: Pull complete
2026-01-14T08:20:48.3662491Z a73f5cbdff4f: Pull complete
2026-01-14T08:20:48.6206231Z Digest: sha256:38e012b20747e9f72b4c4dc2ffb4134a450ad6e57e64886e7daf42b9a8ffa9f2
2026-01-14T08:20:48.6923933Z Status: Downloaded newer image for pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:48.7224350Z docker.io/pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:48.7293829Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:20:48.7294803Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:48.7308513Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:48.7308893Z env:
2026-01-14T08:20:48.7309154Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:48.7309513Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:48.7309824Z   PR_NUMBER: 3500
2026-01-14T08:20:48.7311396Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:48.7313126Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:48.7313702Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:48.7314250Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:48.7314633Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:48.7314956Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:48.7315303Z ##[endgroup]
2026-01-14T08:20:48.7520996Z Prepare all required actions
2026-01-14T08:20:48.7521360Z Getting action download info
2026-01-14T08:20:48.9733326Z ##[group]Run ./test-infra/.github/actions/setup-nvidia
2026-01-14T08:20:48.9733688Z with:
2026-01-14T08:20:48.9733912Z   driver-version: 580.65.06
2026-01-14T08:20:48.9734168Z env:
2026-01-14T08:20:48.9734437Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:48.9734797Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:48.9735064Z   PR_NUMBER: 3500
2026-01-14T08:20:48.9736613Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:48.9738404Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:48.9739266Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:48.9739819Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:48.9740225Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:48.9740539Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:48.9740895Z ##[endgroup]
2026-01-14T08:20:48.9883584Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:20:48.9884540Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:48.9894832Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:48.9895198Z env:
2026-01-14T08:20:48.9895462Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:48.9896038Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:48.9896315Z   PR_NUMBER: 3500
2026-01-14T08:20:48.9897868Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:48.9899604Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:48.9900188Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:48.9900746Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:48.9901143Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:48.9901504Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:48.9901859Z ##[endgroup]
2026-01-14T08:20:49.0031234Z ##[group]Run set -euo pipefail
2026-01-14T08:20:49.0031581Z [36;1mset -euo pipefail[0m
2026-01-14T08:20:49.0031838Z [36;1m[0m
2026-01-14T08:20:49.0032049Z [36;1mhas_gpu=false[0m
2026-01-14T08:20:49.0032295Z [36;1mdevices=""[0m
2026-01-14T08:20:49.0032526Z [36;1m[0m
2026-01-14T08:20:49.0032789Z [36;1mif command -v nvidia-smi >/dev/null 2>&1; then[0m
2026-01-14T08:20:49.0033237Z [36;1m  if nvidia-smi -L >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:49.0033626Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:49.0033914Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:49.0034223Z [36;1m  fi[0m
2026-01-14T08:20:49.0034422Z [36;1mfi[0m
2026-01-14T08:20:49.0034621Z [36;1m[0m
2026-01-14T08:20:49.0034834Z [36;1mif [ "$has_gpu" = false ]; then[0m
2026-01-14T08:20:49.0035222Z [36;1m  if ls /dev/nvidia* >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:49.0035595Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:49.0035891Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:49.0036190Z [36;1m  fi[0m
2026-01-14T08:20:49.0036602Z [36;1mfi[0m
2026-01-14T08:20:49.0036810Z [36;1m[0m
2026-01-14T08:20:49.0037111Z [36;1mif [ "$has_gpu" = false ] && command -v lspci >/dev/null 2>&1; then[0m
2026-01-14T08:20:49.0037639Z [36;1m  if lspci | grep -i 'nvidia' >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:49.0038045Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:49.0038336Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:49.0038639Z [36;1m  fi[0m
2026-01-14T08:20:49.0038845Z [36;1mfi[0m
2026-01-14T08:20:49.0040375Z [36;1m[0m
2026-01-14T08:20:49.0040826Z [36;1mprintf 'HAS_NVIDIA=%s\n' "$has_gpu" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:49.0041556Z [36;1mprintf 'DETECTED_DEVICES<<EOF\n%s\nEOF\n' "$devices" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:49.0051378Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:49.0051738Z env:
2026-01-14T08:20:49.0051999Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:49.0052343Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:49.0052600Z   PR_NUMBER: 3500
2026-01-14T08:20:49.0054149Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:49.0055874Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:49.0056453Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:49.0056989Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:49.0057365Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:49.0057677Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:49.0058218Z ##[endgroup]
2026-01-14T08:20:49.0994322Z ##[group]Run if [ "${HAS_NVIDIA}" = "true" ]; then
2026-01-14T08:20:49.0994697Z [36;1mif [ "${HAS_NVIDIA}" = "true" ]; then[0m
2026-01-14T08:20:49.0995071Z [36;1m  echo "HAS_NVIDIA_GPU=true" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:49.0995599Z [36;1m  echo "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:49.0996062Z [36;1melse[0m
2026-01-14T08:20:49.0996353Z [36;1m  echo "HAS_NVIDIA_GPU=false" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:49.0996688Z [36;1mfi[0m
2026-01-14T08:20:49.1005632Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:49.1005996Z env:
2026-01-14T08:20:49.1006279Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:49.1006666Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:49.1006944Z   PR_NUMBER: 3500
2026-01-14T08:20:49.1008835Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:49.1010977Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:49.1011659Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:49.1012297Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:49.1012732Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:49.1013079Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:49.1013473Z   HAS_NVIDIA: true
2026-01-14T08:20:49.1013714Z ##[endgroup]
2026-01-14T08:20:49.1179993Z ##[group]Run nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482
2026-01-14T08:20:49.1180409Z with:
2026-01-14T08:20:49.1180618Z   timeout_minutes: 10
2026-01-14T08:20:49.1180879Z   max_attempts: 3
2026-01-14T08:20:49.1211893Z   command: # Is it disgusting to have a full shell script here in this github action? Sure
# But is it the best way to make it so that this action relies on nothing else? Absolutely
set -eou pipefail

DISTRIBUTION=$(. /etc/os-release;echo $ID$VERSION_ID)
DRIVER_FN="NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"

install_nvidia_docker2_amzn2() {
    (
        set -x
        # Needed for yum-config-manager
        sudo yum install -y yum-utils
        if [[ "${DISTRIBUTION}" == "amzn2023" ]] ; then
          YUM_REPO_URL="https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo"
        else
          # Amazon Linux 2
          YUM_REPO_URL="https://nvidia.github.io/nvidia-docker/${DISTRIBUTION}/nvidia-docker.repo"
        fi

        sudo yum-config-manager --add-repo "${YUM_REPO_URL}"
        sudo yum install -y \
          nvidia-container-toolkit-1.17.8 \
          libnvidia-container-tools-1.17.8 \
          libnvidia-container1-1.17.8 \
          nvidia-container-toolkit-base-1.17.8
        sudo systemctl restart docker
    )
}

install_nvidia_docker2_ubuntu20() {
    (
        set -x
        # Install nvidia-driver package if not installed
        status="$(dpkg-query -W --showformat='${db:Status-Status}' nvidia-docker2 2>&1)"
        if [ ! $? = 0 ] || [ ! "$status" = installed ]; then
          sudo apt-get install -y nvidia-container-toolkit-1.17.8
          sudo systemctl restart docker
        fi
    )
}

pre_install_nvidia_driver_amzn2() {
    (
        # Purge any nvidia driver installed from RHEL repo
        sudo yum remove -y nvidia-driver-latest-dkms
    )
}

install_nvidia_driver_common() {
    (
        # Try to gather more information about the runner and its existing NVIDIA driver if any
        echo "Before installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        HAS_NVIDIA_DRIVER=0
        # Check if NVIDIA driver has already been installed
        if [ -x "$(command -v nvidia-smi)" ]; then
            set +e
            # The driver exists, check its version next. Also check only the first GPU if there are more than one of them
            # so that the same driver version is not print over multiple lines
            INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
            NVIDIA_SMI_STATUS=$?

            if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                echo "Failed to get NVIDIA driver version ($INSTALLED_DRIVER_VERSION). Continuing"
            elif [ "$INSTALLED_DRIVER_VERSION" != "$DRIVER_VERSION" ]; then
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has been installed, but we expect to have $DRIVER_VERSION instead. Continuing"

                # Turn off persistent mode so that the installation script can unload the kernel module
                sudo killall nvidia-persistenced || true
            else
                HAS_NVIDIA_DRIVER=1
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has already been installed. Skipping NVIDIA driver installation"
            fi
            set -e
        fi

        if [ "$HAS_NVIDIA_DRIVER" -eq 0 ]; then
            # CAUTION: this may need to be updated in future
            if [ "${DISTRIBUTION}" != ubuntu20.04 ]; then
                  sudo yum groupinstall -y "Development Tools"
                  # ensure our kernel install is the same as our underlying kernel,
                  # groupinstall "Development Tools" has a habit of mismatching kernel headers
                  sudo yum install -y "kernel-devel-uname-r == $(uname -r)"
                  sudo modprobe backlight
            fi
            sudo curl -fsL -o /tmp/nvidia_driver "https://s3.amazonaws.com/ossci-linux/nvidia_driver/$DRIVER_FN"

            set +e
            sudo /bin/bash /tmp/nvidia_driver -s --no-drm
            NVIDIA_INSTALLATION_STATUS=$?

            RESET_GPU=0
            if [ "$NVIDIA_INSTALLATION_STATUS" -ne 0 ]; then
                sudo cat /var/log/nvidia-installer.log
                # Fail to install NVIDIA driver, try to reset the GPU
                RESET_GPU=1
            elif [ -x "$(command -v nvidia-smi)" ]; then
                # Check again if nvidia-smi works even if the driver installation completes successfully
                INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
                NVIDIA_SMI_STATUS=$?

                if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                    RESET_GPU=1
                fi
            fi

            if [ "$RESET_GPU" -eq 1 ]; then
                NVIDIA_DEVICES=$(lspci -D | grep -i NVIDIA | cut -d' ' -f1)
                # The GPU can get stuck in a failure state if somehow the test crashs the GPU microcode. When this
                # happens, we'll try to reset all NVIDIA devices https://github.com/pytorch/pytorch/issues/88388
                for PCI_ID in $NVIDIA_DEVICES; do
                    DEVICE_ENABLED=$(cat /sys/bus/pci/devices/$PCI_ID/enable)

                    echo "Reseting $PCI_ID (enabled state: $DEVICE_ENABLED)"
                    # This requires sudo permission of course
                    echo "1" | sudo tee /sys/bus/pci/devices/$PCI_ID/reset
                    sleep 1
                done
            fi

            sudo rm -fv /tmp/nvidia_driver
            set -e
        fi
    )
}

post_install_nvidia_driver_common() {
    (
        sudo modprobe nvidia || true
        echo "After installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        (
            set +e

            nvidia-smi
            # NB: Annoyingly, nvidia-smi command returns successfully with return code 0 even in
            # the case where the driver has already crashed as it still can get the driver version
            # and some basic information like the bus ID.  However, the rest of the information
            # would be missing (ERR!), for example:
            #
            # +-----------------------------------------------------------------------------+
            # | NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |
            # |-------------------------------+----------------------+----------------------+
            # | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
            # | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
            # |                               |                      |               MIG M. |
            # |===============================+======================+======================|
            # |   0  ERR!                Off  | 00000000:00:1E.0 Off |                 ERR! |
            # |ERR!  ERR! ERR!    ERR! / ERR! |   4184MiB / 23028MiB |    ERR!      Default |
            # |                               |                      |                 ERR! |
            # +-------------------------------+----------------------+----------------------+
            #
            # +-----------------------------------------------------------------------------+
            # | Processes:                                                                  |
            # |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
            # |        ID   ID                                                   Usage      |
            # |=============================================================================|
            # +-----------------------------------------------------------------------------+
            #
            # This should be reported as a failure instead as it will guarantee to fail when
            # Docker tries to run with --gpus all
            #
            # So, the correct check here is to query one of the missing piece of info like
            # GPU name, so that the command can fail accordingly
            nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
            NVIDIA_SMI_STATUS=$?

            # Allowable exit statuses for nvidia-smi, see: https://github.com/NVIDIA/gpu-operator/issues/285
            if [ "$NVIDIA_SMI_STATUS" -eq 0 ] || [ "$NVIDIA_SMI_STATUS" -eq 14 ]; then
                echo "INFO: Ignoring allowed status ${NVIDIA_SMI_STATUS}"
            else
                echo "ERROR: nvidia-smi exited with unresolved status ${NVIDIA_SMI_STATUS}"
                exit ${NVIDIA_SMI_STATUS}
            fi
            set -e
        )
    )
}

install_nvidia_driver_amzn2() {
    (
        set -x
        pre_install_nvidia_driver_amzn2
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

install_nvidia_driver_ubuntu20() {
    (
        set -x
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

echo "== Installing nvidia driver ${DRIVER_FN} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_driver_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_driver_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Install container toolkit based on distribution
echo "== Installing nvidia container toolkit for ${DISTRIBUTION} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_docker2_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_docker2_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Fix https://github.com/NVIDIA/nvidia-docker/issues/1648 on runners with
# more than one GPUs. This just needs to be run once. The command fails
# on subsequent runs and complains that the mode is already on, but that's
# ok
sudo nvidia-persistenced || true
# This should show persistence mode ON
nvidia-smi

# check if the container-toolkit is correctly installed and CUDA is available inside a container
docker run --rm -t --gpus=all public.ecr.aws/docker/library/python:3.13 nvidia-smi

2026-01-14T08:20:49.1243677Z   retry_wait_seconds: 10
2026-01-14T08:20:49.1244133Z   polling_interval_seconds: 1
2026-01-14T08:20:49.1244602Z   warning_on_retry: true
2026-01-14T08:20:49.1244949Z   continue_on_error: false
2026-01-14T08:20:49.1245268Z env:
2026-01-14T08:20:49.1245722Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:49.1246158Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:49.1246514Z   PR_NUMBER: 3500
2026-01-14T08:20:49.1248146Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:49.1249980Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:49.1250664Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:49.1251351Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:49.1251837Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:49.1252249Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:49.1252691Z   DRIVER_VERSION: 580.65.06
2026-01-14T08:20:49.1253041Z ##[endgroup]
2026-01-14T08:20:49.2192921Z == Installing nvidia driver NVIDIA-Linux-x86_64-580.65.06.run ==
2026-01-14T08:20:49.2194686Z + pre_install_nvidia_driver_amzn2
2026-01-14T08:20:49.2197548Z + sudo yum remove -y nvidia-driver-latest-dkms
2026-01-14T08:20:49.5614394Z No match for argument: nvidia-driver-latest-dkms
2026-01-14T08:20:49.5614918Z No packages marked for removal.
2026-01-14T08:20:49.5666516Z Dependencies resolved.
2026-01-14T08:20:49.5676018Z Nothing to do.
2026-01-14T08:20:49.5676356Z Complete!
2026-01-14T08:20:49.6841746Z + install_nvidia_driver_common
2026-01-14T08:20:49.6846349Z + echo 'Before installing NVIDIA driver'
2026-01-14T08:20:49.6846782Z + lspci
2026-01-14T08:20:49.6847826Z Before installing NVIDIA driver
2026-01-14T08:20:49.6969087Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:20:49.6970047Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:20:49.6971107Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:20:49.6971806Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:20:49.6972477Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:20:49.6973158Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:20:49.6973914Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:49.6974458Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:49.6975043Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:49.6975544Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:49.6976227Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:20:49.6976866Z + lsmod
2026-01-14T08:20:49.7037493Z Module                  Size  Used by
2026-01-14T08:20:49.7038443Z veth                   36864  0
2026-01-14T08:20:49.7039828Z nvidia_modeset       1740800  0
2026-01-14T08:20:49.7040826Z video                  65536  1 nvidia_modeset
2026-01-14T08:20:49.7041531Z wmi                    36864  1 video
2026-01-14T08:20:49.7042297Z nvidia_uvm           1921024  0
2026-01-14T08:20:49.7043112Z nvidia              14274560  19 nvidia_uvm,nvidia_modeset
2026-01-14T08:20:49.7043653Z drm                   602112  1 nvidia
2026-01-14T08:20:49.7044106Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:20:49.7044623Z backlight              24576  3 video,drm,nvidia_modeset
2026-01-14T08:20:49.7045104Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:20:49.7045452Z mgc                    86016  1
2026-01-14T08:20:49.7045878Z lustre               1085440  4
2026-01-14T08:20:49.7046406Z mdc                   294912  2 lustre
2026-01-14T08:20:49.7046790Z fid                    36864  1 mdc
2026-01-14T08:20:49.7047276Z lov                   356352  5 mdc,lustre
2026-01-14T08:20:49.7047650Z osc                   479232  5 mdc
2026-01-14T08:20:49.7048026Z lmv                   225280  2 lustre
2026-01-14T08:20:49.7048478Z fld                    49152  2 lov,lmv
2026-01-14T08:20:49.7048910Z ksocklnd              188416  1
2026-01-14T08:20:49.7049323Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:49.7049955Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:49.7050611Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:20:49.7051294Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:20:49.7051945Z xt_conntrack           16384  1
2026-01-14T08:20:49.7052327Z nft_chain_nat          16384  3
2026-01-14T08:20:49.7052701Z xt_MASQUERADE          20480  1
2026-01-14T08:20:49.7053172Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:20:49.7053598Z nf_conntrack_netlink    57344  0
2026-01-14T08:20:49.7054120Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:20:49.7054707Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:20:49.7055223Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:20:49.7055585Z xfrm_user              57344  1
2026-01-14T08:20:49.7055963Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:20:49.7056383Z xt_addrtype            16384  2
2026-01-14T08:20:49.7056749Z nft_compat             20480  4
2026-01-14T08:20:49.7057172Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:20:49.7057737Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:20:49.7058224Z br_netfilter           36864  0
2026-01-14T08:20:49.7058598Z bridge                323584  1 br_netfilter
2026-01-14T08:20:49.7059061Z stp                    16384  1 bridge
2026-01-14T08:20:49.7059553Z llc                    16384  2 bridge,stp
2026-01-14T08:20:49.7060042Z overlay               167936  0
2026-01-14T08:20:49.7060451Z tls                   139264  0
2026-01-14T08:20:49.7060765Z nls_ascii              16384  1
2026-01-14T08:20:49.7061153Z nls_cp437              20480  1
2026-01-14T08:20:49.7061515Z vfat                   24576  1
2026-01-14T08:20:49.7061926Z fat                    86016  1 vfat
2026-01-14T08:20:49.7062267Z sunrpc                700416  2 lnet
2026-01-14T08:20:49.7062726Z ghash_clmulni_intel    16384  0
2026-01-14T08:20:49.7063050Z i8042                  45056  0
2026-01-14T08:20:49.7063418Z serio                  28672  3 i8042
2026-01-14T08:20:49.7063861Z ena                   196608  0
2026-01-14T08:20:49.7064181Z button                 24576  0
2026-01-14T08:20:49.7064542Z sch_fq_codel           20480  33
2026-01-14T08:20:49.7065026Z fuse                  184320  1
2026-01-14T08:20:49.7065368Z loop                   36864  0
2026-01-14T08:20:49.7065710Z dm_mod                188416  0
2026-01-14T08:20:49.7066126Z configfs               57344  1
2026-01-14T08:20:49.7066433Z dmi_sysfs              20480  0
2026-01-14T08:20:49.7066812Z crc32_pclmul           16384  0
2026-01-14T08:20:49.7067220Z crc32c_intel           24576  0
2026-01-14T08:20:49.7067531Z efivarfs               24576  1
2026-01-14T08:20:49.7067921Z + modinfo nvidia
2026-01-14T08:20:49.7068483Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:20:49.7069032Z import_ns:      DMA_BUF
2026-01-14T08:20:49.7069374Z alias:          char-major-195-*
2026-01-14T08:20:49.7069810Z version:        580.65.06
2026-01-14T08:20:49.7070191Z supported:      external
2026-01-14T08:20:49.7070503Z license:        Dual MIT/GPL
2026-01-14T08:20:49.7070925Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:20:49.7071369Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:20:49.7071887Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:20:49.7072363Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:20:49.7072838Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:20:49.7073289Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:20:49.7073692Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:20:49.7074241Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:20:49.7074654Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:20:49.7075162Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:20:49.7075681Z depends:        i2c-core,drm
2026-01-14T08:20:49.7076002Z retpoline:      Y
2026-01-14T08:20:49.7076302Z name:           nvidia
2026-01-14T08:20:49.7076842Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:20:49.7077447Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:20:49.7077987Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:20:49.7078601Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:20:49.7079014Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:20:49.7079415Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:20:49.7079896Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:20:49.7080277Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:20:49.7080784Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:20:49.7081267Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:20:49.7081794Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:20:49.7082218Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:20:49.7082738Z parm:           NVreg_EnableMSI:int
2026-01-14T08:20:49.7083170Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:20:49.7083632Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:20:49.7084192Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:20:49.7084685Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:20:49.7085343Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:49.7085833Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:20:49.7086276Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:49.7086708Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:20:49.7087065Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:20:49.7087445Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:20:49.7087837Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:20:49.7088187Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:20:49.7088520Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:20:49.7088856Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:20:49.7089196Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:20:49.7089516Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:20:49.7089890Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:20:49.7090266Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:20:49.7090630Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:20:49.7091012Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:20:49.7091353Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:20:49.7104570Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:20:49.7104956Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:20:49.7105308Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:20:49.7105665Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:20:49.7106001Z parm:           NVreg_RmMsg:charp
2026-01-14T08:20:49.7106289Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:20:49.7106622Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:20:49.7106967Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:20:49.7107404Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:20:49.7107755Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:20:49.7108139Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:20:49.7108501Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:20:49.7108845Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:20:49.7109210Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:20:49.7109580Z parm:           rm_firmware_active:charp
2026-01-14T08:20:49.7109890Z + HAS_NVIDIA_DRIVER=0
2026-01-14T08:20:49.7110158Z ++ command -v nvidia-smi
2026-01-14T08:20:49.7110471Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:20:49.7110780Z + set +e
2026-01-14T08:20:49.7111126Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:20:49.7602378Z + INSTALLED_DRIVER_VERSION=580.65.06
2026-01-14T08:20:49.7603594Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:20:49.7604085Z + '[' 0 -ne 0 ']'
2026-01-14T08:20:49.7604617Z + '[' 580.65.06 '!=' 580.65.06 ']'
2026-01-14T08:20:49.7605249Z + HAS_NVIDIA_DRIVER=1
2026-01-14T08:20:49.7606419Z + echo 'NVIDIA driver (580.65.06) has already been installed. Skipping NVIDIA driver installation'
2026-01-14T08:20:49.7607422Z + set -e
2026-01-14T08:20:49.7607828Z + '[' 1 -eq 0 ']'
2026-01-14T08:20:49.7608627Z NVIDIA driver (580.65.06) has already been installed. Skipping NVIDIA driver installation
2026-01-14T08:20:49.7609627Z + post_install_nvidia_driver_common
2026-01-14T08:20:49.7612658Z + sudo modprobe nvidia
2026-01-14T08:20:49.8950541Z + echo 'After installing NVIDIA driver'
2026-01-14T08:20:49.8950881Z + lspci
2026-01-14T08:20:49.8951126Z After installing NVIDIA driver
2026-01-14T08:20:49.9070089Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:20:49.9070627Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:20:49.9071244Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:20:49.9071840Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:20:49.9072635Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:20:49.9073198Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:20:49.9073713Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:49.9074177Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:49.9074625Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:49.9075075Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:49.9075575Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:20:49.9076004Z + lsmod
2026-01-14T08:20:49.9122936Z Module                  Size  Used by
2026-01-14T08:20:49.9123252Z veth                   36864  0
2026-01-14T08:20:49.9123544Z nvidia_modeset       1740800  0
2026-01-14T08:20:49.9123855Z video                  65536  1 nvidia_modeset
2026-01-14T08:20:49.9124174Z wmi                    36864  1 video
2026-01-14T08:20:49.9124462Z nvidia_uvm           1921024  0
2026-01-14T08:20:49.9124785Z nvidia              14274560  19 nvidia_uvm,nvidia_modeset
2026-01-14T08:20:49.9125135Z drm                   602112  1 nvidia
2026-01-14T08:20:49.9125473Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:20:49.9125860Z backlight              24576  3 video,drm,nvidia_modeset
2026-01-14T08:20:49.9126222Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:20:49.9126524Z mgc                    86016  1
2026-01-14T08:20:49.9126781Z lustre               1085440  4
2026-01-14T08:20:49.9127047Z mdc                   294912  2 lustre
2026-01-14T08:20:49.9127330Z fid                    36864  1 mdc
2026-01-14T08:20:49.9127620Z lov                   356352  5 mdc,lustre
2026-01-14T08:20:49.9127916Z osc                   479232  5 mdc
2026-01-14T08:20:49.9128189Z lmv                   225280  2 lustre
2026-01-14T08:20:49.9128690Z fld                    49152  2 lov,lmv
2026-01-14T08:20:49.9128982Z ksocklnd              188416  1
2026-01-14T08:20:49.9129334Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:49.9129817Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:49.9130337Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:20:49.9130964Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:20:49.9131513Z xt_conntrack           16384  1
2026-01-14T08:20:49.9131801Z nft_chain_nat          16384  3
2026-01-14T08:20:49.9132072Z xt_MASQUERADE          20480  1
2026-01-14T08:20:49.9132391Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:20:49.9132739Z nf_conntrack_netlink    57344  0
2026-01-14T08:20:49.9133161Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:20:49.9133640Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:20:49.9133978Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:20:49.9134293Z xfrm_user              57344  1
2026-01-14T08:20:49.9134569Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:20:49.9134869Z xt_addrtype            16384  2
2026-01-14T08:20:49.9135133Z nft_compat             20480  4
2026-01-14T08:20:49.9135457Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:20:49.9135893Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:20:49.9136299Z br_netfilter           36864  0
2026-01-14T08:20:49.9136581Z bridge                323584  1 br_netfilter
2026-01-14T08:20:49.9136891Z stp                    16384  1 bridge
2026-01-14T08:20:49.9137190Z llc                    16384  2 bridge,stp
2026-01-14T08:20:49.9137477Z overlay               167936  0
2026-01-14T08:20:49.9137739Z tls                   139264  0
2026-01-14T08:20:49.9137998Z nls_ascii              16384  1
2026-01-14T08:20:49.9138268Z nls_cp437              20480  1
2026-01-14T08:20:49.9138630Z vfat                   24576  1
2026-01-14T08:20:49.9138895Z fat                    86016  1 vfat
2026-01-14T08:20:49.9139516Z sunrpc                700416  2 lnet
2026-01-14T08:20:49.9139805Z ghash_clmulni_intel    16384  0
2026-01-14T08:20:49.9140065Z i8042                  45056  0
2026-01-14T08:20:49.9140331Z serio                  28672  3 i8042
2026-01-14T08:20:49.9140612Z ena                   196608  0
2026-01-14T08:20:49.9140860Z button                 24576  0
2026-01-14T08:20:49.9141117Z sch_fq_codel           20480  33
2026-01-14T08:20:49.9141380Z fuse                  184320  1
2026-01-14T08:20:49.9141632Z loop                   36864  0
2026-01-14T08:20:49.9141890Z dm_mod                188416  0
2026-01-14T08:20:49.9142151Z configfs               57344  1
2026-01-14T08:20:49.9142411Z dmi_sysfs              20480  0
2026-01-14T08:20:49.9142669Z crc32_pclmul           16384  0
2026-01-14T08:20:49.9142927Z crc32c_intel           24576  0
2026-01-14T08:20:49.9143194Z efivarfs               24576  1
2026-01-14T08:20:49.9143463Z + modinfo nvidia
2026-01-14T08:20:49.9143909Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:20:49.9144378Z import_ns:      DMA_BUF
2026-01-14T08:20:49.9144623Z alias:          char-major-195-*
2026-01-14T08:20:49.9144926Z version:        580.65.06
2026-01-14T08:20:49.9145176Z supported:      external
2026-01-14T08:20:49.9145421Z license:        Dual MIT/GPL
2026-01-14T08:20:49.9145713Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:20:49.9146053Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:20:49.9146386Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:20:49.9146760Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:20:49.9147130Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:20:49.9147491Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:20:49.9147994Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:20:49.9148357Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:20:49.9148701Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:20:49.9149049Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:20:49.9149361Z depends:        i2c-core,drm
2026-01-14T08:20:49.9149621Z retpoline:      Y
2026-01-14T08:20:49.9149832Z name:           nvidia
2026-01-14T08:20:49.9150214Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:20:49.9150715Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:20:49.9151214Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:20:49.9151677Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:20:49.9151986Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:20:49.9152298Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:20:49.9152616Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:20:49.9152937Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:20:49.9153245Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:20:49.9153623Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:20:49.9154037Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:20:49.9154378Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:20:49.9154686Z parm:           NVreg_EnableMSI:int
2026-01-14T08:20:49.9154995Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:20:49.9155372Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:20:49.9155791Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:20:49.9156188Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:20:49.9156620Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:49.9157056Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:20:49.9157498Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:49.9157939Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:20:49.9158417Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:20:49.9158800Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:20:49.9159190Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:20:49.9159542Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:20:49.9159872Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:20:49.9160203Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:20:49.9160533Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:20:49.9160849Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:20:49.9161202Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:20:49.9161577Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:20:49.9161943Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:20:49.9162321Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:20:49.9162751Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:20:49.9163121Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:20:49.9163492Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:20:49.9163854Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:20:49.9164211Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:20:49.9164557Z parm:           NVreg_RmMsg:charp
2026-01-14T08:20:49.9164867Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:20:49.9165206Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:20:49.9165551Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:20:49.9165880Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:20:49.9166233Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:20:49.9166604Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:20:49.9166976Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:20:49.9167321Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:20:49.9167772Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:20:49.9168140Z parm:           rm_firmware_active:charp
2026-01-14T08:20:49.9168440Z + set +e
2026-01-14T08:20:49.9168643Z + nvidia-smi
2026-01-14T08:20:49.9588507Z Wed Jan 14 08:20:49 2026       
2026-01-14T08:20:49.9589589Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:49.9590646Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:20:49.9591642Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:49.9592400Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:20:49.9592979Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:20:49.9593465Z |                                         |                        |               MIG M. |
2026-01-14T08:20:49.9593890Z |=========================================+========================+======================|
2026-01-14T08:20:50.0194795Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:20:50.0195520Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:50.0196151Z |                                         |                        |                  N/A |
2026-01-14T08:20:50.0196816Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:50.0197521Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:20:50.0198200Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:50.0198810Z |                                         |                        |                  N/A |
2026-01-14T08:20:50.0199449Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:50.0200467Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:20:50.0201139Z |  0%   20C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:50.0201753Z |                                         |                        |                  N/A |
2026-01-14T08:20:50.0202388Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:50.0203157Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:20:50.0203835Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:50.0204448Z |                                         |                        |                  N/A |
2026-01-14T08:20:50.0205080Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:50.0223500Z 
2026-01-14T08:20:50.0224061Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:50.0224598Z | Processes:                                                                              |
2026-01-14T08:20:50.0225121Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:20:50.0225626Z |        ID   ID                                                               Usage      |
2026-01-14T08:20:50.0226048Z |=========================================================================================|
2026-01-14T08:20:50.0261924Z |  No running processes found                                                             |
2026-01-14T08:20:50.0262482Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:51.0983442Z + nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
2026-01-14T08:20:51.1164700Z NVIDIA A10G
2026-01-14T08:20:51.1440907Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:20:51.1441199Z + '[' 0 -eq 0 ']'
2026-01-14T08:20:51.1441888Z + echo 'INFO: Ignoring allowed status 0'
2026-01-14T08:20:51.1442437Z + set -e
2026-01-14T08:20:51.1442769Z INFO: Ignoring allowed status 0
2026-01-14T08:20:51.1454314Z == Installing nvidia container toolkit for amzn2023 ==
2026-01-14T08:20:51.1458858Z + sudo yum install -y yum-utils
2026-01-14T08:20:51.6751268Z Last metadata expiration check: 0:03:40 ago on Wed Jan 14 08:17:11 2026.
2026-01-14T08:20:51.7037574Z Package dnf-utils-4.3.0-13.amzn2023.0.5.noarch is already installed.
2026-01-14T08:20:51.7685953Z Dependencies resolved.
2026-01-14T08:20:51.8042893Z Nothing to do.
2026-01-14T08:20:51.8043156Z Complete!
2026-01-14T08:20:51.9345702Z + [[ amzn2023 == \a\m\z\n\2\0\2\3 ]]
2026-01-14T08:20:51.9346890Z + YUM_REPO_URL=https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:51.9348702Z + sudo yum-config-manager --add-repo https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:52.2201947Z Adding repo from: https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:52.2726444Z + sudo yum install -y nvidia-container-toolkit-1.17.8 libnvidia-container-tools-1.17.8 libnvidia-container1-1.17.8 nvidia-container-toolkit-base-1.17.8
2026-01-14T08:20:52.8074793Z nvidia-container-toolkit                         17 kB/s | 833  B     00:00    
2026-01-14T08:20:52.8356288Z Package nvidia-container-toolkit-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:52.8363994Z Package libnvidia-container-tools-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:52.8368826Z Package libnvidia-container1-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:52.8378184Z Package nvidia-container-toolkit-base-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:52.9008424Z Dependencies resolved.
2026-01-14T08:20:52.9378556Z Nothing to do.
2026-01-14T08:20:52.9378983Z Complete!
2026-01-14T08:20:53.0734078Z + sudo systemctl restart docker
2026-01-14T08:21:36.8211923Z nvidia-persistenced failed to initialize. Check syslog for more details.
2026-01-14T08:21:36.8677858Z Wed Jan 14 08:21:36 2026       
2026-01-14T08:21:36.8678260Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:36.8678834Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:21:36.8679392Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:36.8679960Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:21:36.8680549Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:21:36.8681041Z |                                         |                        |               MIG M. |
2026-01-14T08:21:36.8681448Z |=========================================+========================+======================|
2026-01-14T08:21:36.9279568Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:21:36.9280081Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:36.9280530Z |                                         |                        |                  N/A |
2026-01-14T08:21:36.9280985Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:36.9281495Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:21:36.9281984Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:36.9282421Z |                                         |                        |                  N/A |
2026-01-14T08:21:36.9282937Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:36.9283665Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:21:36.9284152Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:36.9284584Z |                                         |                        |                  N/A |
2026-01-14T08:21:36.9285039Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:36.9285540Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:21:36.9286016Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:36.9286454Z |                                         |                        |                  N/A |
2026-01-14T08:21:36.9286903Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:36.9308355Z 
2026-01-14T08:21:36.9308575Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:36.9309084Z | Processes:                                                                              |
2026-01-14T08:21:36.9309589Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:21:36.9310072Z |        ID   ID                                                               Usage      |
2026-01-14T08:21:36.9310490Z |=========================================================================================|
2026-01-14T08:21:36.9345382Z |  No running processes found                                                             |
2026-01-14T08:21:36.9345915Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:38.0681122Z Unable to find image 'public.ecr.aws/docker/library/python:3.13' locally
2026-01-14T08:21:38.2801816Z 3.13: Pulling from docker/library/python
2026-01-14T08:21:38.4069718Z 2ca1bfae7ba8: Pulling fs layer
2026-01-14T08:21:38.4070414Z 82e18c5e1c15: Pulling fs layer
2026-01-14T08:21:38.4071481Z be442a7e0d6f: Pulling fs layer
2026-01-14T08:21:38.4072062Z 26d823e3848f: Pulling fs layer
2026-01-14T08:21:38.4072600Z ca4b54413202: Pulling fs layer
2026-01-14T08:21:38.4073134Z b6513238a015: Pulling fs layer
2026-01-14T08:21:38.4073671Z 9b57076d00d4: Pulling fs layer
2026-01-14T08:21:38.4074179Z ca4b54413202: Waiting
2026-01-14T08:21:38.4074626Z 9b57076d00d4: Waiting
2026-01-14T08:21:38.4074897Z b6513238a015: Waiting
2026-01-14T08:21:38.4075118Z 26d823e3848f: Waiting
2026-01-14T08:21:38.5567759Z 82e18c5e1c15: Verifying Checksum
2026-01-14T08:21:38.5568055Z 82e18c5e1c15: Download complete
2026-01-14T08:21:38.6137502Z 2ca1bfae7ba8: Verifying Checksum
2026-01-14T08:21:38.6137804Z 2ca1bfae7ba8: Download complete
2026-01-14T08:21:38.6901269Z ca4b54413202: Verifying Checksum
2026-01-14T08:21:38.6901598Z ca4b54413202: Download complete
2026-01-14T08:21:38.7857044Z b6513238a015: Download complete
2026-01-14T08:21:38.8189141Z 9b57076d00d4: Verifying Checksum
2026-01-14T08:21:38.8189576Z 9b57076d00d4: Download complete
2026-01-14T08:21:38.8587897Z be442a7e0d6f: Verifying Checksum
2026-01-14T08:21:38.8588359Z be442a7e0d6f: Download complete
2026-01-14T08:21:39.2317797Z 26d823e3848f: Verifying Checksum
2026-01-14T08:21:39.2318137Z 26d823e3848f: Download complete
2026-01-14T08:21:40.3841681Z 2ca1bfae7ba8: Pull complete
2026-01-14T08:21:41.1256713Z 82e18c5e1c15: Pull complete
2026-01-14T08:21:43.6772082Z be442a7e0d6f: Pull complete
2026-01-14T08:21:50.4067279Z 26d823e3848f: Pull complete
2026-01-14T08:21:50.7013665Z ca4b54413202: Pull complete
2026-01-14T08:21:51.4838663Z b6513238a015: Pull complete
2026-01-14T08:21:51.5077461Z 9b57076d00d4: Pull complete
2026-01-14T08:21:51.5215028Z Digest: sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:21:51.5257971Z Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.13
2026-01-14T08:21:58.2681544Z Wed Jan 14 08:21:58 2026       
2026-01-14T08:21:58.2682383Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:58.2683008Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:21:58.2683555Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:58.2684108Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:21:58.2684681Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:21:58.2685180Z |                                         |                        |               MIG M. |
2026-01-14T08:21:58.2685580Z |=========================================+========================+======================|
2026-01-14T08:21:58.3284901Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:21:58.3285425Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:58.3285884Z |                                         |                        |                  N/A |
2026-01-14T08:21:58.3286351Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:58.3286855Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:21:58.3287345Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:58.3287791Z |                                         |                        |                  N/A |
2026-01-14T08:21:58.3288243Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:58.3288749Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:21:58.3289237Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:58.3289889Z |                                         |                        |                  N/A |
2026-01-14T08:21:58.3301348Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:58.3301884Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:21:58.3302377Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:58.3302837Z |                                         |                        |                  N/A |
2026-01-14T08:21:58.3303296Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:58.3314204Z 
2026-01-14T08:21:58.3314464Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:58.3314984Z | Processes:                                                                              |
2026-01-14T08:21:58.3315500Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:21:58.3315997Z |        ID   ID                                                               Usage      |
2026-01-14T08:21:58.3316418Z |=========================================================================================|
2026-01-14T08:21:58.3352572Z |  No running processes found                                                             |
2026-01-14T08:21:58.3353129Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:22:00.2364305Z Command completed after 1 attempt(s).
2026-01-14T08:22:00.2476166Z ##[group]Run set -ex
2026-01-14T08:22:00.2476440Z [36;1mset -ex[0m
2026-01-14T08:22:00.2476664Z [36;1m{[0m
2026-01-14T08:22:00.2476889Z [36;1m  echo "#!/usr/bin/env bash";[0m
2026-01-14T08:22:00.2477212Z [36;1m  echo "set -eou pipefail";[0m
2026-01-14T08:22:00.2477536Z [36;1m  # shellcheck disable=SC2016[0m
2026-01-14T08:22:00.2478060Z [36;1m  echo 'eval "$(conda shell.bash hook)"';[0m
2026-01-14T08:22:00.2478408Z [36;1m  echo "set -x";[0m
2026-01-14T08:22:00.2478678Z [36;1m  echo "${SCRIPT}";[0m
2026-01-14T08:22:00.2478986Z [36;1m} > "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:22:00.2479324Z [36;1mchmod +x "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:22:00.2479955Z [36;1mpython3 "/home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py" ""[0m
2026-01-14T08:22:00.2495796Z shell: /usr/bin/bash -e {0}
2026-01-14T08:22:00.2496070Z env:
2026-01-14T08:22:00.2496323Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:22:00.2496713Z   REPOSITORY: pytorch/ao
2026-01-14T08:22:00.2496967Z   PR_NUMBER: 3500
2026-01-14T08:22:00.2498534Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:22:00.2500287Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:22:00.2500873Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:22:00.2501467Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:22:00.2501858Z   HAS_NVIDIA_GPU: true
2026-01-14T08:22:00.2502174Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:22:00.2502833Z   ALL_SECRETS: {
  "github_token": "***"
}
2026-01-14T08:22:00.2503136Z ##[endgroup]
2026-01-14T08:22:00.2542575Z + echo '#!/usr/bin/env bash'
2026-01-14T08:22:00.2542869Z + echo 'set -eou pipefail'
2026-01-14T08:22:00.2543147Z + echo 'eval "$(conda shell.bash hook)"'
2026-01-14T08:22:00.2543462Z + echo 'set -x'
2026-01-14T08:22:00.2543825Z + echo 'conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:00.2544269Z conda activate venv
2026-01-14T08:22:00.2544518Z python -m pip install --upgrade pip
2026-01-14T08:22:00.2544817Z pip install torch==2.8.0
2026-01-14T08:22:00.2545080Z sed -i '\'''\'' dev-requirements.txt
2026-01-14T08:22:00.2545395Z pip install -r dev-requirements.txt
2026-01-14T08:22:00.2545712Z pip install . --no-build-isolation
2026-01-14T08:22:00.2546039Z export CONDA=$(dirname $(dirname $(which conda)))
2026-01-14T08:22:00.2546425Z export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
2026-01-14T08:22:00.2546771Z pytest test --verbose -s
2026-01-14T08:22:00.2547024Z '
2026-01-14T08:22:00.2547316Z + chmod +x /home/ec2-user/actions-runner/_work/_temp/exec_script
2026-01-14T08:22:00.2561026Z + python3 /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py ''
2026-01-14T08:22:20.7380347Z Running command: 
2026-01-14T08:22:20.7386073Z         docker run             -e PR_NUMBER             -e RUNNER_ARTIFACT_DIR=/artifacts             -e RUNNER_DOCS_DIR=/docs             -e RUNNER_TEST_RESULTS_DIR=/test-results             --env-file="/home/ec2-user/actions-runner/_work/_temp/github_env_20985547555"             `# It is unknown why the container sees a different value for this.`             -e GITHUB_STEP_SUMMARY             -e SECRET_GITHUB_TOKEN             --cap-add=SYS_PTRACE             --detach             --ipc=host             --security-opt seccomp=unconfined             --shm-size=2g             --tty             --ulimit stack=10485760:83886080             --ulimit core=0             --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all             -v "/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao:/pytorch/ao"             -v "/home/ec2-user/actions-runner/_work/ao/ao/test-infra:/test-infra"             -v "/home/ec2-user/actions-runner/_work/_temp/artifacts:/artifacts"             -v "/home/ec2-user/actions-runner/_work/_temp/docs:/docs"             -v "/home/ec2-user/actions-runner/_work/_temp/test-results:/test-results"             -v "/home/ec2-user/actions-runner/_work/_temp/exec_script:/exec"             -v "/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_354438fb-6549-4bf4-acc2-b518e48ede2c":"/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_354438fb-6549-4bf4-acc2-b518e48ede2c"             -w /pytorch/ao             "pytorch/almalinux-builder:cuda12.6"
2026-01-14T08:22:20.7391678Z         
2026-01-14T08:22:20.7392014Z 4db5761fa99698ce26f570affb4f6bad002151a35d2ebe70166fe05eb60c3afb
2026-01-14T08:22:20.7392673Z Running command: docker exec -t 4db5761fa99698ce26f570affb4f6bad002151a35d2ebe70166fe05eb60c3afb /exec
2026-01-14T08:22:20.7393358Z + conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:20.7393763Z + local cmd=create
2026-01-14T08:22:20.7393987Z + case "$cmd" in
2026-01-14T08:22:20.7394351Z + __conda_exe create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:20.7394961Z + /opt/conda/bin/conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:20.7395456Z Could not load conda plugin `menuinst`:
2026-01-14T08:22:20.7395668Z 
2026-01-14T08:22:20.7395783Z Plugin requires `conda` to be installed.
2026-01-14T08:22:20.7396819Z Collecting package metadata (current_repodata.json): - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - done
2026-01-14T08:22:20.7397941Z Solving environment: | unsuccessful attempt using repodata from current_repodata.json, retrying with next repodata source.
2026-01-14T08:22:20.7399331Z Collecting package metadata (repodata.json): - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | done
2026-01-14T08:22:20.7400284Z Solving environment: - \ | / - \ done
2026-01-14T08:22:20.7400518Z 
2026-01-14T08:22:20.7400523Z 
2026-01-14T08:22:20.7400666Z ==> WARNING: A newer version of conda exists. <==
2026-01-14T08:22:20.7400985Z   current version: 23.5.2
2026-01-14T08:22:20.7401242Z   latest version: 25.11.1
2026-01-14T08:22:20.7401399Z 
2026-01-14T08:22:20.7401504Z Please update conda by running
2026-01-14T08:22:20.7401691Z 
2026-01-14T08:22:20.7401808Z     $ conda update -n base -c defaults conda
2026-01-14T08:22:20.7402023Z 
2026-01-14T08:22:20.7402241Z Or to minimize the number of packages updated during conda update use
2026-01-14T08:22:20.7402553Z 
2026-01-14T08:22:20.7402741Z      conda install conda=25.11.1
2026-01-14T08:22:20.7402924Z 
2026-01-14T08:22:20.7402935Z 
2026-01-14T08:22:20.7402939Z 
2026-01-14T08:22:20.7403030Z ## Package Plan ##
2026-01-14T08:22:20.7403164Z 
2026-01-14T08:22:20.7403287Z   environment location: /opt/conda/envs/venv
2026-01-14T08:22:20.7403519Z 
2026-01-14T08:22:20.7403618Z   added / updated specs:
2026-01-14T08:22:20.7403873Z     - libgcc-ng=11.2.0
2026-01-14T08:22:20.7404114Z     - libstdcxx-ng=11.2.0
2026-01-14T08:22:20.7404363Z     - python=3.10
2026-01-14T08:22:20.7404493Z 
2026-01-14T08:22:20.7404497Z 
2026-01-14T08:22:20.7404621Z The following packages will be downloaded:
2026-01-14T08:22:20.7404844Z 
2026-01-14T08:22:20.7404962Z     package                    |            build
2026-01-14T08:22:20.7405300Z     ---------------------------|-----------------
2026-01-14T08:22:20.7405669Z     bzip2-1.0.8                |       h5eee18b_6         262 KB
2026-01-14T08:22:20.7406218Z     ld_impl_linux-64-2.44      |       h153f514_2         672 KB
2026-01-14T08:22:20.7406637Z     libffi-3.4.4               |       h6a678d5_1         141 KB
2026-01-14T08:22:20.7407051Z     libnsl-2.0.0               |       h5eee18b_0          31 KB
2026-01-14T08:22:20.7407457Z     libxcb-1.17.0              |       h9b100fa_0         430 KB
2026-01-14T08:22:20.7407952Z     libzlib-1.3.1              |       hb25bd0a_0          59 KB
2026-01-14T08:22:20.7408362Z     ncurses-6.5                |       h7934f7d_0         1.1 MB
2026-01-14T08:22:20.7408761Z     pip-25.3                   |     pyhc872135_0         1.1 MB
2026-01-14T08:22:20.7409178Z     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
2026-01-14T08:22:20.7409593Z     python-3.10.19             |       h6fa692b_0        24.5 MB
2026-01-14T08:22:20.7410010Z     readline-8.3               |       hc2a1206_0         471 KB
2026-01-14T08:22:20.7410431Z     setuptools-80.9.0          |  py310h06a4308_0         1.4 MB
2026-01-14T08:22:20.7410868Z     sqlite-3.51.0              |       h2a70700_0         1.2 MB
2026-01-14T08:22:20.7411265Z     tk-8.6.15                  |       h54e0aa7_0         3.4 MB
2026-01-14T08:22:20.7411667Z     tzdata-2025b               |       h04d1e81_0         116 KB
2026-01-14T08:22:20.7412083Z     wheel-0.45.1               |  py310h06a4308_0         115 KB
2026-01-14T08:22:20.7412507Z     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
2026-01-14T08:22:20.7412946Z     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
2026-01-14T08:22:20.7413376Z     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
2026-01-14T08:22:20.7413856Z     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
2026-01-14T08:22:20.7414278Z     xz-5.6.4                   |       h5eee18b_1         567 KB
2026-01-14T08:22:20.7414661Z     zlib-1.3.1                 |       hb25bd0a_0          96 KB
2026-01-14T08:22:20.7415057Z     ------------------------------------------------------------
2026-01-14T08:22:20.7415429Z                                            Total:        37.1 MB
2026-01-14T08:22:20.7415657Z 
2026-01-14T08:22:20.7415789Z The following NEW packages will be INSTALLED:
2026-01-14T08:22:20.7416020Z 
2026-01-14T08:22:20.7416235Z   _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main 
2026-01-14T08:22:20.7416702Z   _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu 
2026-01-14T08:22:20.7417159Z   bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 
2026-01-14T08:22:20.7417667Z   ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 
2026-01-14T08:22:20.7418183Z   expat              pkgs/main/linux-64::expat-2.7.3-h3385a95_0 
2026-01-14T08:22:20.7418667Z   ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 
2026-01-14T08:22:20.7419154Z   libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 
2026-01-14T08:22:20.7419622Z   libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 
2026-01-14T08:22:20.7420109Z   libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 
2026-01-14T08:22:20.7420562Z   libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 
2026-01-14T08:22:20.7421050Z   libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 
2026-01-14T08:22:20.7421538Z   libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 
2026-01-14T08:22:20.7422001Z   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
2026-01-14T08:22:20.7422461Z   libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 
2026-01-14T08:22:20.7422918Z   ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 
2026-01-14T08:22:20.7423379Z   openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 
2026-01-14T08:22:20.7423821Z   pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 
2026-01-14T08:22:20.7424304Z   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
2026-01-14T08:22:20.7424891Z   python             pkgs/main/linux-64::python-3.10.19-h6fa692b_0 
2026-01-14T08:22:20.7425359Z   readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 
2026-01-14T08:22:20.7425861Z   setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 
2026-01-14T08:22:20.7426355Z   sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 
2026-01-14T08:22:20.7426783Z   tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 
2026-01-14T08:22:20.7427283Z   tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 
2026-01-14T08:22:20.7427743Z   wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 
2026-01-14T08:22:20.7428229Z   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
2026-01-14T08:22:20.7428731Z   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
2026-01-14T08:22:20.7429262Z   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
2026-01-14T08:22:20.7429809Z   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
2026-01-14T08:22:20.7430466Z   xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 
2026-01-14T08:22:20.7430876Z   zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 
2026-01-14T08:22:20.7431137Z 
2026-01-14T08:22:20.7431141Z 
2026-01-14T08:22:20.7431145Z 
2026-01-14T08:22:20.7431258Z Downloading and Extracting Packages
2026-01-14T08:22:20.7431468Z 
2026-01-14T08:22:20.7431637Z setuptools-80.9.0    | 1.4 MB    | :   0% 0/1 [00:00<?, ?it/s]
2026-01-14T08:22:20.7431911Z 
2026-01-14T08:22:20.7432158Z ncurses-6.5          | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s][A
2026-01-14T08:22:20.7432432Z 
2026-01-14T08:22:20.7432436Z 
2026-01-14T08:22:20.7432673Z libzlib-1.3.1        | 59 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A
2026-01-14T08:22:20.7432947Z 
2026-01-14T08:22:20.7432951Z 
2026-01-14T08:22:20.7432954Z 
2026-01-14T08:22:20.7433180Z tk-8.6.15            | 3.4 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A
2026-01-14T08:22:20.7433444Z 
2026-01-14T08:22:20.7433448Z 
2026-01-14T08:22:20.7433452Z 
2026-01-14T08:22:20.7433459Z 
2026-01-14T08:22:20.7433729Z pthread-stubs-0.3    | 5 KB      | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A
2026-01-14T08:22:20.7434034Z 
2026-01-14T08:22:20.7434037Z 
2026-01-14T08:22:20.7434041Z 
2026-01-14T08:22:20.7434045Z 
2026-01-14T08:22:20.7434049Z 
2026-01-14T08:22:20.7434296Z libffi-3.4.4         | 141 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A
2026-01-14T08:22:20.7434595Z 
2026-01-14T08:22:20.7434598Z 
2026-01-14T08:22:20.7434602Z 
2026-01-14T08:22:20.7434606Z 
2026-01-14T08:22:20.7434609Z 
2026-01-14T08:22:20.7434613Z 
2026-01-14T08:22:20.7434885Z xorg-libxau-1.0.12   | 13 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A
2026-01-14T08:22:20.7435196Z 
2026-01-14T08:22:20.7435209Z 
2026-01-14T08:22:20.7435212Z 
2026-01-14T08:22:20.7435216Z 
2026-01-14T08:22:20.7435220Z 
2026-01-14T08:22:20.7435223Z 
2026-01-14T08:22:20.7435227Z 
2026-01-14T08:22:20.7435508Z xorg-libx11-1.8.12   | 895 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A
2026-01-14T08:22:20.7435823Z 
2026-01-14T08:22:20.7435832Z 
2026-01-14T08:22:20.7435835Z 
2026-01-14T08:22:20.7435839Z 
2026-01-14T08:22:20.7435849Z 
2026-01-14T08:22:20.7435852Z 
2026-01-14T08:22:20.7435856Z 
2026-01-14T08:22:20.7435860Z 
2026-01-14T08:22:20.7436155Z ld_impl_linux-64-2.4 | 672 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A
2026-01-14T08:22:20.7436482Z 
2026-01-14T08:22:20.7436485Z 
2026-01-14T08:22:20.7436489Z 
2026-01-14T08:22:20.7436492Z 
2026-01-14T08:22:20.7436496Z 
2026-01-14T08:22:20.7436500Z 
2026-01-14T08:22:20.7436509Z 
2026-01-14T08:22:20.7436513Z 
2026-01-14T08:22:20.7436516Z 
2026-01-14T08:22:20.7436797Z libxcb-1.17.0        | 430 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A
2026-01-14T08:22:20.7437115Z 
2026-01-14T08:22:20.7437118Z 
2026-01-14T08:22:20.7437122Z 
2026-01-14T08:22:20.7437126Z 
2026-01-14T08:22:20.7437129Z 
2026-01-14T08:22:20.7437133Z 
2026-01-14T08:22:20.7437137Z 
2026-01-14T08:22:20.7437147Z 
2026-01-14T08:22:20.7437150Z 
2026-01-14T08:22:20.7437154Z 
2026-01-14T08:22:20.7437609Z xorg-libxdmcp-1.1.5  | 19 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:20.7437956Z 
2026-01-14T08:22:20.7437959Z 
2026-01-14T08:22:20.7437963Z 
2026-01-14T08:22:20.7437967Z 
2026-01-14T08:22:20.7437970Z 
2026-01-14T08:22:20.7437974Z 
2026-01-14T08:22:20.7437978Z 
2026-01-14T08:22:20.7438062Z 
2026-01-14T08:22:20.7438066Z 
2026-01-14T08:22:20.7438070Z 
2026-01-14T08:22:20.7438073Z 
2026-01-14T08:22:24.1869579Z libnsl-2.0.0         | 31 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1870019Z 
2026-01-14T08:22:24.1870025Z 
2026-01-14T08:22:24.1870030Z 
2026-01-14T08:22:24.1870036Z 
2026-01-14T08:22:24.1870041Z 
2026-01-14T08:22:24.1870047Z 
2026-01-14T08:22:24.1870052Z 
2026-01-14T08:22:24.1870057Z 
2026-01-14T08:22:24.1870062Z 
2026-01-14T08:22:24.1870069Z 
2026-01-14T08:22:24.1870074Z 
2026-01-14T08:22:24.1870079Z 
2026-01-14T08:22:24.1870563Z tzdata-2025b         | 116 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1871066Z 
2026-01-14T08:22:24.1871072Z 
2026-01-14T08:22:24.1871077Z 
2026-01-14T08:22:24.1871083Z 
2026-01-14T08:22:24.1871088Z 
2026-01-14T08:22:24.1871092Z 
2026-01-14T08:22:24.1871097Z 
2026-01-14T08:22:24.1871102Z 
2026-01-14T08:22:24.1871107Z 
2026-01-14T08:22:24.1871112Z 
2026-01-14T08:22:24.1871133Z 
2026-01-14T08:22:24.1871138Z 
2026-01-14T08:22:24.1871143Z 
2026-01-14T08:22:24.1871601Z sqlite-3.51.0        | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1872081Z 
2026-01-14T08:22:24.1872086Z 
2026-01-14T08:22:24.1872091Z 
2026-01-14T08:22:24.1872096Z 
2026-01-14T08:22:24.1872101Z 
2026-01-14T08:22:24.1872106Z 
2026-01-14T08:22:24.1872111Z 
2026-01-14T08:22:24.1872116Z 
2026-01-14T08:22:24.1872122Z 
2026-01-14T08:22:24.1872128Z 
2026-01-14T08:22:24.1872133Z 
2026-01-14T08:22:24.1872138Z 
2026-01-14T08:22:24.1872143Z 
2026-01-14T08:22:24.1872148Z 
2026-01-14T08:22:24.1872613Z bzip2-1.0.8          | 262 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1873080Z 
2026-01-14T08:22:24.1873086Z 
2026-01-14T08:22:24.1873091Z 
2026-01-14T08:22:24.1873096Z 
2026-01-14T08:22:24.1873101Z 
2026-01-14T08:22:24.1873106Z 
2026-01-14T08:22:24.1873111Z 
2026-01-14T08:22:24.1873116Z 
2026-01-14T08:22:24.1873128Z 
2026-01-14T08:22:24.1873142Z 
2026-01-14T08:22:24.1873147Z 
2026-01-14T08:22:24.1873152Z 
2026-01-14T08:22:24.1873158Z 
2026-01-14T08:22:24.1873163Z 
2026-01-14T08:22:24.1873168Z 
2026-01-14T08:22:24.1873761Z xorg-xorgproto-2024. | 580 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1874276Z 
2026-01-14T08:22:24.1874281Z 
2026-01-14T08:22:24.1874286Z 
2026-01-14T08:22:24.1874302Z 
2026-01-14T08:22:24.1874307Z 
2026-01-14T08:22:24.1874312Z 
2026-01-14T08:22:24.1874317Z 
2026-01-14T08:22:24.1874322Z 
2026-01-14T08:22:24.1874327Z 
2026-01-14T08:22:24.1874332Z 
2026-01-14T08:22:24.1874337Z 
2026-01-14T08:22:24.1874352Z 
2026-01-14T08:22:24.1874357Z 
2026-01-14T08:22:24.1874362Z 
2026-01-14T08:22:24.1874366Z 
2026-01-14T08:22:24.1874371Z 
2026-01-14T08:22:24.1874744Z wheel-0.45.1         | 115 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1875207Z 
2026-01-14T08:22:24.1875212Z 
2026-01-14T08:22:24.1875223Z 
2026-01-14T08:22:24.1875228Z 
2026-01-14T08:22:24.1875233Z 
2026-01-14T08:22:24.1875240Z 
2026-01-14T08:22:24.1875245Z 
2026-01-14T08:22:24.1875250Z 
2026-01-14T08:22:24.1875255Z 
2026-01-14T08:22:24.1875260Z 
2026-01-14T08:22:24.1875265Z 
2026-01-14T08:22:24.1875270Z 
2026-01-14T08:22:24.1875275Z 
2026-01-14T08:22:24.1875279Z 
2026-01-14T08:22:24.1875284Z 
2026-01-14T08:22:24.1875289Z 
2026-01-14T08:22:24.1875294Z 
2026-01-14T08:22:24.1875797Z readline-8.3         | 471 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1876310Z 
2026-01-14T08:22:24.1876315Z 
2026-01-14T08:22:24.1876320Z 
2026-01-14T08:22:24.1876603Z 
2026-01-14T08:22:24.1876610Z 
2026-01-14T08:22:24.1876615Z 
2026-01-14T08:22:24.1876620Z 
2026-01-14T08:22:24.1876625Z 
2026-01-14T08:22:24.1876630Z 
2026-01-14T08:22:24.1876635Z 
2026-01-14T08:22:24.1876640Z 
2026-01-14T08:22:24.1876645Z 
2026-01-14T08:22:24.1876660Z 
2026-01-14T08:22:24.1876665Z 
2026-01-14T08:22:24.1876670Z 
2026-01-14T08:22:24.1876820Z 
2026-01-14T08:22:24.1876825Z 
2026-01-14T08:22:24.1876830Z 
2026-01-14T08:22:24.1877260Z zlib-1.3.1           | 96 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1877628Z 
2026-01-14T08:22:24.1877631Z 
2026-01-14T08:22:24.1877635Z 
2026-01-14T08:22:24.1877638Z 
2026-01-14T08:22:24.1877651Z 
2026-01-14T08:22:24.1877655Z 
2026-01-14T08:22:24.1877659Z 
2026-01-14T08:22:24.1877663Z 
2026-01-14T08:22:24.1877666Z 
2026-01-14T08:22:24.1877670Z 
2026-01-14T08:22:24.1877674Z 
2026-01-14T08:22:24.1877678Z 
2026-01-14T08:22:24.1877681Z 
2026-01-14T08:22:24.1877685Z 
2026-01-14T08:22:24.1877695Z 
2026-01-14T08:22:24.1877699Z 
2026-01-14T08:22:24.1877702Z 
2026-01-14T08:22:24.1877706Z 
2026-01-14T08:22:24.1877710Z 
2026-01-14T08:22:24.1878020Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1878540Z setuptools-80.9.0    | 1.4 MB    | :   1% 0.010887210650647725/1 [00:00<00:16, 16.38s/it]
2026-01-14T08:22:24.1878876Z 
2026-01-14T08:22:24.1878879Z 
2026-01-14T08:22:24.1879192Z libzlib-1.3.1        | 59 KB     | :  27% 0.2699309685816432/1 [00:00<00:00,  1.48it/s][A[A
2026-01-14T08:22:24.1879515Z 
2026-01-14T08:22:24.1879519Z 
2026-01-14T08:22:24.1879523Z 
2026-01-14T08:22:24.1879526Z 
2026-01-14T08:22:24.1879821Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  5.48it/s][A[A[A[A
2026-01-14T08:22:24.1880154Z 
2026-01-14T08:22:24.1880450Z ncurses-6.5          | 1.1 MB    | :   1% 0.014401655346517857/1 [00:00<00:13, 13.44s/it][A
2026-01-14T08:22:24.1880768Z 
2026-01-14T08:22:24.1880771Z 
2026-01-14T08:22:24.1880775Z 
2026-01-14T08:22:24.1881091Z tk-8.6.15            | 3.4 MB    | :   0% 0.00453827661272385/1 [00:00<00:41, 42.01s/it][A[A[A
2026-01-14T08:22:24.1881416Z 
2026-01-14T08:22:24.1881420Z 
2026-01-14T08:22:24.1881423Z 
2026-01-14T08:22:24.1881427Z 
2026-01-14T08:22:24.1881720Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  5.48it/s][A[A[A[A
2026-01-14T08:22:24.1882049Z 
2026-01-14T08:22:24.1882053Z 
2026-01-14T08:22:24.1882357Z libzlib-1.3.1        | 59 KB     | : 100% 1.0/1 [00:00<00:00,  1.48it/s]               [A[A
2026-01-14T08:22:24.1882786Z 
2026-01-14T08:22:24.1882789Z 
2026-01-14T08:22:24.1882793Z 
2026-01-14T08:22:24.1882797Z 
2026-01-14T08:22:24.1882800Z 
2026-01-14T08:22:24.1882804Z 
2026-01-14T08:22:24.1883113Z xorg-libxau-1.0.12   | 13 KB     | : 100% 1.0/1 [00:00<00:00,  4.33it/s][A[A[A[A[A[A
2026-01-14T08:22:24.1883443Z 
2026-01-14T08:22:24.1883447Z 
2026-01-14T08:22:24.1883451Z 
2026-01-14T08:22:24.1883460Z 
2026-01-14T08:22:24.1883463Z 
2026-01-14T08:22:24.1883820Z libffi-3.4.4         | 141 KB    | :  11% 0.11323440988036575/1 [00:00<00:01,  2.05s/it][A[A[A[A[A
2026-01-14T08:22:24.1884182Z 
2026-01-14T08:22:24.1884186Z 
2026-01-14T08:22:24.1884190Z 
2026-01-14T08:22:24.1884193Z 
2026-01-14T08:22:24.1884197Z 
2026-01-14T08:22:24.1884201Z 
2026-01-14T08:22:24.1884204Z 
2026-01-14T08:22:24.1884599Z xorg-libx11-1.8.12   | 895 KB    | :   2% 0.017882324178246957/1 [00:00<00:14, 14.55s/it][A[A[A[A[A[A[A
2026-01-14T08:22:24.1885005Z 
2026-01-14T08:22:24.1885009Z 
2026-01-14T08:22:24.1885012Z 
2026-01-14T08:22:24.1885016Z 
2026-01-14T08:22:24.1885020Z 
2026-01-14T08:22:24.1885023Z 
2026-01-14T08:22:24.1885329Z xorg-libxau-1.0.12   | 13 KB     | : 100% 1.0/1 [00:00<00:00,  4.33it/s][A[A[A[A[A[A
2026-01-14T08:22:24.1885662Z 
2026-01-14T08:22:24.1885666Z 
2026-01-14T08:22:24.1885669Z 
2026-01-14T08:22:24.1885975Z tk-8.6.15            | 3.4 MB    | :  76% 0.7624304709376067/1 [00:00<00:00,  3.26it/s] [A[A[A
2026-01-14T08:22:24.1886309Z 
2026-01-14T08:22:24.1886313Z 
2026-01-14T08:22:24.1886425Z 
2026-01-14T08:22:24.1886429Z 
2026-01-14T08:22:24.1886433Z 
2026-01-14T08:22:24.1886436Z 
2026-01-14T08:22:24.1886440Z 
2026-01-14T08:22:24.1886444Z 
2026-01-14T08:22:24.1886847Z ld_impl_linux-64-2.4 | 672 KB    | :   2% 0.02380578754961961/1 [00:00<00:12, 12.33s/it][A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1887270Z 
2026-01-14T08:22:24.1887350Z 
2026-01-14T08:22:24.1887353Z 
2026-01-14T08:22:24.1887357Z 
2026-01-14T08:22:24.1887361Z 
2026-01-14T08:22:24.1887364Z 
2026-01-14T08:22:24.1887368Z 
2026-01-14T08:22:24.1887372Z 
2026-01-14T08:22:24.1887375Z 
2026-01-14T08:22:24.1887769Z libxcb-1.17.0        | 430 KB    | :   4% 0.03717806167600808/1 [00:00<00:07,  8.06s/it][A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1888183Z 
2026-01-14T08:22:24.1888187Z 
2026-01-14T08:22:24.1888191Z 
2026-01-14T08:22:24.1888194Z 
2026-01-14T08:22:24.1888198Z 
2026-01-14T08:22:24.1888202Z 
2026-01-14T08:22:24.1888205Z 
2026-01-14T08:22:24.1888209Z 
2026-01-14T08:22:24.1888213Z 
2026-01-14T08:22:24.1888221Z 
2026-01-14T08:22:24.1888636Z xorg-libxdmcp-1.1.5  | 19 KB     | :  85% 0.85067497403946/1 [00:00<00:00,  2.64it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1889067Z 
2026-01-14T08:22:24.1889070Z 
2026-01-14T08:22:24.1889074Z 
2026-01-14T08:22:24.1889078Z 
2026-01-14T08:22:24.1889081Z 
2026-01-14T08:22:24.1889085Z 
2026-01-14T08:22:24.1889097Z 
2026-01-14T08:22:24.1889100Z 
2026-01-14T08:22:24.1889104Z 
2026-01-14T08:22:24.1889107Z 
2026-01-14T08:22:24.1889111Z 
2026-01-14T08:22:24.1889520Z libnsl-2.0.0         | 31 KB     | :  52% 0.515966492410405/1 [00:00<00:00,  1.49it/s][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1889938Z 
2026-01-14T08:22:24.1889942Z 
2026-01-14T08:22:24.1889946Z 
2026-01-14T08:22:24.1889949Z 
2026-01-14T08:22:24.1889953Z 
2026-01-14T08:22:24.1889957Z 
2026-01-14T08:22:24.1889960Z 
2026-01-14T08:22:24.1889964Z 
2026-01-14T08:22:24.1889968Z 
2026-01-14T08:22:24.1889971Z 
2026-01-14T08:22:24.1889975Z 
2026-01-14T08:22:24.1889978Z 
2026-01-14T08:22:24.1890419Z tzdata-2025b         | 116 KB    | :  14% 0.13742430088406501/1 [00:00<00:02,  2.72s/it][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1890851Z 
2026-01-14T08:22:24.1890855Z 
2026-01-14T08:22:24.1890858Z 
2026-01-14T08:22:24.1890862Z 
2026-01-14T08:22:24.1890866Z 
2026-01-14T08:22:24.1890869Z 
2026-01-14T08:22:24.1890873Z 
2026-01-14T08:22:24.1890881Z 
2026-01-14T08:22:24.1890885Z 
2026-01-14T08:22:24.1890888Z 
2026-01-14T08:22:24.1890892Z 
2026-01-14T08:22:24.1890895Z 
2026-01-14T08:22:24.1890899Z 
2026-01-14T08:22:24.1890903Z 
2026-01-14T08:22:24.1890906Z 
2026-01-14T08:22:24.1891405Z xorg-xorgproto-2024. | 580 KB    | :   3% 0.02757436782092818/1 [00:00<00:13, 13.71s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1891886Z 
2026-01-14T08:22:24.1891889Z 
2026-01-14T08:22:24.1891893Z 
2026-01-14T08:22:24.1891897Z 
2026-01-14T08:22:24.1891900Z 
2026-01-14T08:22:24.1891904Z 
2026-01-14T08:22:24.1891908Z 
2026-01-14T08:22:24.1891911Z 
2026-01-14T08:22:24.1891915Z 
2026-01-14T08:22:24.1891923Z 
2026-01-14T08:22:24.1891926Z 
2026-01-14T08:22:24.1891930Z 
2026-01-14T08:22:24.1891942Z 
2026-01-14T08:22:24.1891946Z 
2026-01-14T08:22:24.1892377Z bzip2-1.0.8          | 262 KB    | :   6% 0.06104685823297961/1 [00:00<00:05,  6.29s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1892815Z 
2026-01-14T08:22:24.1892818Z 
2026-01-14T08:22:24.1892827Z 
2026-01-14T08:22:24.1892830Z 
2026-01-14T08:22:24.1892834Z 
2026-01-14T08:22:24.1892838Z 
2026-01-14T08:22:24.1892841Z 
2026-01-14T08:22:24.1892857Z 
2026-01-14T08:22:24.1892860Z 
2026-01-14T08:22:24.1892864Z 
2026-01-14T08:22:24.1892868Z 
2026-01-14T08:22:24.1892871Z 
2026-01-14T08:22:24.1892875Z 
2026-01-14T08:22:24.1893318Z sqlite-3.51.0        | 1.2 MB    | :   1% 0.013350140517073497/1 [00:00<00:28, 29.07s/it][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1893751Z 
2026-01-14T08:22:24.1893755Z 
2026-01-14T08:22:24.1893759Z 
2026-01-14T08:22:24.1893769Z 
2026-01-14T08:22:24.1893772Z 
2026-01-14T08:22:24.1893776Z 
2026-01-14T08:22:24.1894579Z 
2026-01-14T08:22:24.1894583Z 
2026-01-14T08:22:24.1894587Z 
2026-01-14T08:22:24.1894591Z 
2026-01-14T08:22:24.1894594Z 
2026-01-14T08:22:24.1894598Z 
2026-01-14T08:22:24.1894602Z 
2026-01-14T08:22:24.1894605Z 
2026-01-14T08:22:24.1894609Z 
2026-01-14T08:22:24.1894613Z 
2026-01-14T08:22:24.1895090Z wheel-0.45.1         | 115 KB    | :  14% 0.13956539146286406/1 [00:00<00:02,  2.81s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1895624Z 
2026-01-14T08:22:24.1895627Z 
2026-01-14T08:22:24.1895631Z 
2026-01-14T08:22:24.1895634Z 
2026-01-14T08:22:24.1895638Z 
2026-01-14T08:22:24.1895642Z 
2026-01-14T08:22:24.1895645Z 
2026-01-14T08:22:24.1895649Z 
2026-01-14T08:22:24.1895653Z 
2026-01-14T08:22:24.1895656Z 
2026-01-14T08:22:24.1895660Z 
2026-01-14T08:22:24.1895663Z 
2026-01-14T08:22:24.1895667Z 
2026-01-14T08:22:24.1895671Z 
2026-01-14T08:22:24.1895674Z 
2026-01-14T08:22:24.1895678Z 
2026-01-14T08:22:24.1895681Z 
2026-01-14T08:22:24.1896170Z readline-8.3         | 471 KB    | :   3% 0.03400397653924861/1 [00:00<00:12, 13.06s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1896638Z 
2026-01-14T08:22:24.1896642Z 
2026-01-14T08:22:24.1896645Z 
2026-01-14T08:22:24.1896649Z 
2026-01-14T08:22:24.1896652Z 
2026-01-14T08:22:24.1896656Z 
2026-01-14T08:22:24.1896660Z 
2026-01-14T08:22:24.1896668Z 
2026-01-14T08:22:24.1896672Z 
2026-01-14T08:22:24.1896675Z 
2026-01-14T08:22:24.1896679Z 
2026-01-14T08:22:24.1896682Z 
2026-01-14T08:22:24.1896693Z 
2026-01-14T08:22:24.1896697Z 
2026-01-14T08:22:24.1896701Z 
2026-01-14T08:22:24.1896704Z 
2026-01-14T08:22:24.1896708Z 
2026-01-14T08:22:24.1896712Z 
2026-01-14T08:22:24.1897173Z zlib-1.3.1           | 96 KB     | :  17% 0.16692817116658176/1 [00:00<00:02,  2.68s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1897628Z 
2026-01-14T08:22:24.1897631Z 
2026-01-14T08:22:24.1897635Z 
2026-01-14T08:22:24.1897645Z 
2026-01-14T08:22:24.1897649Z 
2026-01-14T08:22:24.1897652Z 
2026-01-14T08:22:24.1897660Z 
2026-01-14T08:22:24.1897664Z 
2026-01-14T08:22:24.1897667Z 
2026-01-14T08:22:24.1897671Z 
2026-01-14T08:22:24.1897675Z 
2026-01-14T08:22:24.1897678Z 
2026-01-14T08:22:24.1897682Z 
2026-01-14T08:22:24.1897685Z 
2026-01-14T08:22:24.1897689Z 
2026-01-14T08:22:24.1897693Z 
2026-01-14T08:22:24.1897696Z 
2026-01-14T08:22:24.1897700Z 
2026-01-14T08:22:24.1897708Z 
2026-01-14T08:22:24.1897968Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1898281Z 
2026-01-14T08:22:24.1898285Z 
2026-01-14T08:22:24.1898288Z 
2026-01-14T08:22:24.1898292Z 
2026-01-14T08:22:24.1898296Z 
2026-01-14T08:22:24.1898299Z 
2026-01-14T08:22:24.1898303Z 
2026-01-14T08:22:24.1898307Z 
2026-01-14T08:22:24.1898310Z 
2026-01-14T08:22:24.1898314Z 
2026-01-14T08:22:24.1898318Z 
2026-01-14T08:22:24.1898321Z 
2026-01-14T08:22:24.1898325Z 
2026-01-14T08:22:24.1898329Z 
2026-01-14T08:22:24.1898332Z 
2026-01-14T08:22:24.1898336Z 
2026-01-14T08:22:24.1898339Z 
2026-01-14T08:22:24.1898349Z 
2026-01-14T08:22:24.1898357Z 
2026-01-14T08:22:24.1898610Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1898913Z 
2026-01-14T08:22:24.1898916Z 
2026-01-14T08:22:24.1898920Z 
2026-01-14T08:22:24.1898924Z 
2026-01-14T08:22:24.1898928Z 
2026-01-14T08:22:24.1898931Z 
2026-01-14T08:22:24.1898935Z 
2026-01-14T08:22:24.1898943Z 
2026-01-14T08:22:24.1898954Z 
2026-01-14T08:22:24.1898958Z 
2026-01-14T08:22:24.1898962Z 
2026-01-14T08:22:24.1898965Z 
2026-01-14T08:22:24.1898969Z 
2026-01-14T08:22:24.1898973Z 
2026-01-14T08:22:24.1898977Z 
2026-01-14T08:22:24.1898980Z 
2026-01-14T08:22:24.1898984Z 
2026-01-14T08:22:24.1898988Z 
2026-01-14T08:22:24.1898992Z 
2026-01-14T08:22:24.1899242Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1899549Z 
2026-01-14T08:22:24.1899553Z 
2026-01-14T08:22:24.1899557Z 
2026-01-14T08:22:24.1899560Z 
2026-01-14T08:22:24.1899564Z 
2026-01-14T08:22:24.1899568Z 
2026-01-14T08:22:24.1899688Z 
2026-01-14T08:22:24.1899692Z 
2026-01-14T08:22:24.1899696Z 
2026-01-14T08:22:24.1899700Z 
2026-01-14T08:22:24.1899703Z 
2026-01-14T08:22:24.1899707Z 
2026-01-14T08:22:24.1899711Z 
2026-01-14T08:22:24.1899714Z 
2026-01-14T08:22:24.1899718Z 
2026-01-14T08:22:24.1899722Z 
2026-01-14T08:22:24.1899725Z 
2026-01-14T08:22:24.1899729Z 
2026-01-14T08:22:24.1899801Z 
2026-01-14T08:22:24.1900063Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1900358Z 
2026-01-14T08:22:24.1900362Z 
2026-01-14T08:22:24.1900365Z 
2026-01-14T08:22:24.1900369Z 
2026-01-14T08:22:24.1900373Z 
2026-01-14T08:22:24.1900707Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  1.36it/s]                [A[A[A[A[A
2026-01-14T08:22:24.1901068Z 
2026-01-14T08:22:24.1901071Z 
2026-01-14T08:22:24.1901075Z 
2026-01-14T08:22:24.1901079Z 
2026-01-14T08:22:24.1901082Z 
2026-01-14T08:22:24.1901364Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  1.36it/s][A[A[A[A[A
2026-01-14T08:22:24.1901689Z 
2026-01-14T08:22:24.1901693Z 
2026-01-14T08:22:24.1901696Z 
2026-01-14T08:22:24.1901700Z 
2026-01-14T08:22:24.1901704Z 
2026-01-14T08:22:24.1901707Z 
2026-01-14T08:22:24.1901711Z 
2026-01-14T08:22:24.1901715Z 
2026-01-14T08:22:24.1901718Z 
2026-01-14T08:22:24.1901722Z 
2026-01-14T08:22:24.1901725Z 
2026-01-14T08:22:24.1901736Z 
2026-01-14T08:22:24.1901739Z 
2026-01-14T08:22:24.1901743Z 
2026-01-14T08:22:24.1901746Z 
2026-01-14T08:22:24.1901750Z 
2026-01-14T08:22:24.1901754Z 
2026-01-14T08:22:24.1901757Z 
2026-01-14T08:22:24.1901761Z 
2026-01-14T08:22:24.1902017Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1902311Z 
2026-01-14T08:22:24.1902315Z 
2026-01-14T08:22:24.1902318Z 
2026-01-14T08:22:24.1902322Z 
2026-01-14T08:22:24.1902326Z 
2026-01-14T08:22:24.1902329Z 
2026-01-14T08:22:24.1902333Z 
2026-01-14T08:22:24.1902337Z 
2026-01-14T08:22:24.1902340Z 
2026-01-14T08:22:24.1902344Z 
2026-01-14T08:22:24.1902348Z 
2026-01-14T08:22:24.1902356Z 
2026-01-14T08:22:24.1902360Z 
2026-01-14T08:22:24.1902363Z 
2026-01-14T08:22:24.1902367Z 
2026-01-14T08:22:24.1902378Z 
2026-01-14T08:22:24.1902381Z 
2026-01-14T08:22:24.1902385Z 
2026-01-14T08:22:24.1902388Z 
2026-01-14T08:22:24.1902636Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1902932Z 
2026-01-14T08:22:24.1902936Z 
2026-01-14T08:22:24.1902939Z 
2026-01-14T08:22:24.1902943Z 
2026-01-14T08:22:24.1902947Z 
2026-01-14T08:22:24.1902950Z 
2026-01-14T08:22:24.1902959Z 
2026-01-14T08:22:24.1902963Z 
2026-01-14T08:22:24.1902967Z 
2026-01-14T08:22:24.1902970Z 
2026-01-14T08:22:24.1902974Z 
2026-01-14T08:22:24.1902977Z 
2026-01-14T08:22:24.1902981Z 
2026-01-14T08:22:24.1902985Z 
2026-01-14T08:22:24.1902988Z 
2026-01-14T08:22:24.1902992Z 
2026-01-14T08:22:24.1902996Z 
2026-01-14T08:22:24.1902999Z 
2026-01-14T08:22:24.1903003Z 
2026-01-14T08:22:24.1903250Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1903550Z 
2026-01-14T08:22:24.1903554Z 
2026-01-14T08:22:24.1903558Z 
2026-01-14T08:22:24.1903561Z 
2026-01-14T08:22:24.1903565Z 
2026-01-14T08:22:24.1903569Z 
2026-01-14T08:22:24.1903572Z 
2026-01-14T08:22:24.1903576Z 
2026-01-14T08:22:24.1903579Z 
2026-01-14T08:22:24.1903583Z 
2026-01-14T08:22:24.1903587Z 
2026-01-14T08:22:24.1903590Z 
2026-01-14T08:22:24.1903602Z 
2026-01-14T08:22:24.1903605Z 
2026-01-14T08:22:24.1903609Z 
2026-01-14T08:22:24.1903613Z 
2026-01-14T08:22:24.1903616Z 
2026-01-14T08:22:24.1903620Z 
2026-01-14T08:22:24.1903623Z 
2026-01-14T08:22:24.1903877Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1904169Z 
2026-01-14T08:22:24.1904173Z 
2026-01-14T08:22:24.1904176Z 
2026-01-14T08:22:24.1904180Z 
2026-01-14T08:22:24.1904184Z 
2026-01-14T08:22:24.1904187Z 
2026-01-14T08:22:24.1904191Z 
2026-01-14T08:22:24.1904573Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.14s/it]                 [A[A[A[A[A[A[A
2026-01-14T08:22:24.1905042Z 
2026-01-14T08:22:24.1905046Z 
2026-01-14T08:22:24.1905050Z 
2026-01-14T08:22:24.1905053Z 
2026-01-14T08:22:24.1905057Z 
2026-01-14T08:22:24.1905060Z 
2026-01-14T08:22:24.1905064Z 
2026-01-14T08:22:24.1905383Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.14s/it][A[A[A[A[A[A[A
2026-01-14T08:22:24.1905803Z 
2026-01-14T08:22:24.1905806Z 
2026-01-14T08:22:24.1905810Z 
2026-01-14T08:22:24.1905814Z 
2026-01-14T08:22:24.1905817Z 
2026-01-14T08:22:24.1905821Z 
2026-01-14T08:22:24.1905825Z 
2026-01-14T08:22:24.1905828Z 
2026-01-14T08:22:24.1905832Z 
2026-01-14T08:22:24.1905836Z 
2026-01-14T08:22:24.1905839Z 
2026-01-14T08:22:24.1905843Z 
2026-01-14T08:22:24.1905847Z 
2026-01-14T08:22:24.1905850Z 
2026-01-14T08:22:24.1905854Z 
2026-01-14T08:22:24.1905858Z 
2026-01-14T08:22:24.1905861Z 
2026-01-14T08:22:24.1905871Z 
2026-01-14T08:22:24.1905875Z 
2026-01-14T08:22:24.1906123Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1906476Z 
2026-01-14T08:22:24.1906479Z 
2026-01-14T08:22:24.1906483Z 
2026-01-14T08:22:24.1906487Z 
2026-01-14T08:22:24.1906490Z 
2026-01-14T08:22:24.1906494Z 
2026-01-14T08:22:24.1906498Z 
2026-01-14T08:22:24.1906509Z 
2026-01-14T08:22:24.1906513Z 
2026-01-14T08:22:24.1906877Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:01<00:00,  1.35s/it]                [A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1907254Z 
2026-01-14T08:22:24.1907258Z 
2026-01-14T08:22:24.1907262Z 
2026-01-14T08:22:24.1907265Z 
2026-01-14T08:22:24.1907269Z 
2026-01-14T08:22:24.1907273Z 
2026-01-14T08:22:24.1907276Z 
2026-01-14T08:22:24.1907286Z 
2026-01-14T08:22:24.1907290Z 
2026-01-14T08:22:24.1907634Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:01<00:00,  1.35s/it][A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1907978Z 
2026-01-14T08:22:24.1907982Z 
2026-01-14T08:22:24.1907985Z 
2026-01-14T08:22:24.1907989Z 
2026-01-14T08:22:24.1907993Z 
2026-01-14T08:22:24.1907996Z 
2026-01-14T08:22:24.1908000Z 
2026-01-14T08:22:24.1908007Z 
2026-01-14T08:22:24.1908010Z 
2026-01-14T08:22:24.1908014Z 
2026-01-14T08:22:24.1908442Z xorg-libxdmcp-1.1.5  | 19 KB     | : 100% 1.0/1 [00:01<00:00,  2.64it/s]             [A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1909083Z setuptools-80.9.0    | 1.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.73s/it]                 
2026-01-14T08:22:24.1909606Z setuptools-80.9.0    | 1.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.73s/it]
2026-01-14T08:22:24.1909896Z 
2026-01-14T08:22:24.1909899Z 
2026-01-14T08:22:24.1909903Z 
2026-01-14T08:22:24.1909907Z 
2026-01-14T08:22:24.1909911Z 
2026-01-14T08:22:24.1909914Z 
2026-01-14T08:22:24.1909918Z 
2026-01-14T08:22:24.1909930Z 
2026-01-14T08:22:24.1910306Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:01<00:00,  1.77s/it]                [A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1910695Z 
2026-01-14T08:22:24.1910698Z 
2026-01-14T08:22:24.1910702Z 
2026-01-14T08:22:24.1910706Z 
2026-01-14T08:22:24.1910709Z 
2026-01-14T08:22:24.1910713Z 
2026-01-14T08:22:24.1910723Z 
2026-01-14T08:22:24.1910726Z 
2026-01-14T08:22:24.1911066Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:01<00:00,  1.77s/it][A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1911417Z 
2026-01-14T08:22:24.1911421Z 
2026-01-14T08:22:24.1911424Z 
2026-01-14T08:22:24.1911428Z 
2026-01-14T08:22:24.1911432Z 
2026-01-14T08:22:24.1911436Z 
2026-01-14T08:22:24.1911444Z 
2026-01-14T08:22:24.1911448Z 
2026-01-14T08:22:24.1911451Z 
2026-01-14T08:22:24.1911455Z 
2026-01-14T08:22:24.1911468Z 
2026-01-14T08:22:24.1911844Z libnsl-2.0.0         | 31 KB     | : 100% 1.0/1 [00:01<00:00,  2.10s/it]              [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1912226Z 
2026-01-14T08:22:24.1912230Z 
2026-01-14T08:22:24.1912234Z 
2026-01-14T08:22:24.1912237Z 
2026-01-14T08:22:24.1912241Z 
2026-01-14T08:22:24.1912245Z 
2026-01-14T08:22:24.1912248Z 
2026-01-14T08:22:24.1912252Z 
2026-01-14T08:22:24.1912256Z 
2026-01-14T08:22:24.1912266Z 
2026-01-14T08:22:24.1912270Z 
2026-01-14T08:22:24.1912759Z libnsl-2.0.0         | 31 KB     | : 100% 1.0/1 [00:01<00:00,  2.10s/it][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1913117Z 
2026-01-14T08:22:24.1913121Z 
2026-01-14T08:22:24.1913124Z 
2026-01-14T08:22:24.1913425Z tk-8.6.15            | 3.4 MB    | : 100% 1.0/1 [00:02<00:00,  3.26it/s]               [A[A[A
2026-01-14T08:22:24.1913743Z 
2026-01-14T08:22:24.1913820Z 
2026-01-14T08:22:24.1913824Z 
2026-01-14T08:22:24.1913828Z 
2026-01-14T08:22:24.1913831Z 
2026-01-14T08:22:24.1913835Z 
2026-01-14T08:22:24.1913838Z 
2026-01-14T08:22:24.1913842Z 
2026-01-14T08:22:24.1913846Z 
2026-01-14T08:22:24.1913850Z 
2026-01-14T08:22:24.1913853Z 
2026-01-14T08:22:24.1913857Z 
2026-01-14T08:22:24.1913861Z 
2026-01-14T08:22:24.1913864Z 
2026-01-14T08:22:24.1914277Z bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:02<00:00,  2.19s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1914681Z 
2026-01-14T08:22:24.1914685Z 
2026-01-14T08:22:24.1914689Z 
2026-01-14T08:22:24.1914692Z 
2026-01-14T08:22:24.1914701Z 
2026-01-14T08:22:24.1914705Z 
2026-01-14T08:22:24.1914709Z 
2026-01-14T08:22:24.1914712Z 
2026-01-14T08:22:24.1914716Z 
2026-01-14T08:22:24.1914726Z 
2026-01-14T08:22:24.1914729Z 
2026-01-14T08:22:24.1914733Z 
2026-01-14T08:22:24.1914737Z 
2026-01-14T08:22:24.1914741Z 
2026-01-14T08:22:24.1915104Z bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:02<00:00,  2.19s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1915479Z 
2026-01-14T08:22:24.1915483Z 
2026-01-14T08:22:24.1915487Z 
2026-01-14T08:22:24.1915490Z 
2026-01-14T08:22:24.1915502Z 
2026-01-14T08:22:24.1915505Z 
2026-01-14T08:22:24.1915509Z 
2026-01-14T08:22:24.1915513Z 
2026-01-14T08:22:24.1915517Z 
2026-01-14T08:22:24.1915520Z 
2026-01-14T08:22:24.1915524Z 
2026-01-14T08:22:24.1915528Z 
2026-01-14T08:22:24.1915532Z 
2026-01-14T08:22:24.1915535Z 
2026-01-14T08:22:24.1915539Z 
2026-01-14T08:22:24.1915543Z 
2026-01-14T08:22:24.1915962Z wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:02<00:00,  2.36s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1916389Z 
2026-01-14T08:22:24.1916393Z 
2026-01-14T08:22:24.1916396Z 
2026-01-14T08:22:24.1916400Z 
2026-01-14T08:22:24.1916404Z 
2026-01-14T08:22:24.1916408Z 
2026-01-14T08:22:24.1916411Z 
2026-01-14T08:22:24.1916415Z 
2026-01-14T08:22:24.1916419Z 
2026-01-14T08:22:24.1916422Z 
2026-01-14T08:22:24.1916431Z 
2026-01-14T08:22:24.1916434Z 
2026-01-14T08:22:24.1916438Z 
2026-01-14T08:22:24.1916442Z 
2026-01-14T08:22:24.1916445Z 
2026-01-14T08:22:24.1916449Z 
2026-01-14T08:22:24.1916833Z wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:02<00:00,  2.36s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1917223Z 
2026-01-14T08:22:24.1917227Z 
2026-01-14T08:22:24.1917230Z 
2026-01-14T08:22:24.1917234Z 
2026-01-14T08:22:24.1917238Z 
2026-01-14T08:22:24.1917241Z 
2026-01-14T08:22:24.1917245Z 
2026-01-14T08:22:24.1917249Z 
2026-01-14T08:22:24.1917252Z 
2026-01-14T08:22:24.1917256Z 
2026-01-14T08:22:24.1917260Z 
2026-01-14T08:22:24.1917267Z 
2026-01-14T08:22:24.1917674Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:02<00:00,  2.57s/it]                [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1918074Z 
2026-01-14T08:22:24.1918078Z 
2026-01-14T08:22:24.1918082Z 
2026-01-14T08:22:24.1918085Z 
2026-01-14T08:22:24.1918089Z 
2026-01-14T08:22:24.1918093Z 
2026-01-14T08:22:24.1918099Z 
2026-01-14T08:22:24.1918103Z 
2026-01-14T08:22:24.1918107Z 
2026-01-14T08:22:24.1918110Z 
2026-01-14T08:22:24.1918114Z 
2026-01-14T08:22:24.1918118Z 
2026-01-14T08:22:24.1918482Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:02<00:00,  2.57s/it][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1918858Z 
2026-01-14T08:22:24.1918861Z 
2026-01-14T08:22:24.1918865Z 
2026-01-14T08:22:24.1918869Z 
2026-01-14T08:22:24.1918872Z 
2026-01-14T08:22:24.1918876Z 
2026-01-14T08:22:24.1918880Z 
2026-01-14T08:22:24.1918884Z 
2026-01-14T08:22:24.1918887Z 
2026-01-14T08:22:24.1918899Z 
2026-01-14T08:22:24.1918903Z 
2026-01-14T08:22:24.1918907Z 
2026-01-14T08:22:24.1919001Z 
2026-01-14T08:22:24.1919401Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:02<00:00,  2.55s/it]                 [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1919801Z 
2026-01-14T08:22:24.1919804Z 
2026-01-14T08:22:24.1919808Z 
2026-01-14T08:22:24.1919812Z 
2026-01-14T08:22:24.1919816Z 
2026-01-14T08:22:24.1919927Z 
2026-01-14T08:22:24.1919931Z 
2026-01-14T08:22:24.1919935Z 
2026-01-14T08:22:24.1919938Z 
2026-01-14T08:22:24.1919942Z 
2026-01-14T08:22:24.1919946Z 
2026-01-14T08:22:24.1919950Z 
2026-01-14T08:22:24.1919953Z 
2026-01-14T08:22:24.1920317Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:02<00:00,  2.55s/it][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1920692Z 
2026-01-14T08:22:24.1920696Z 
2026-01-14T08:22:24.1920708Z 
2026-01-14T08:22:24.1920712Z 
2026-01-14T08:22:24.1920716Z 
2026-01-14T08:22:24.1920719Z 
2026-01-14T08:22:24.1920723Z 
2026-01-14T08:22:24.1920727Z 
2026-01-14T08:22:24.1920731Z 
2026-01-14T08:22:24.1920734Z 
2026-01-14T08:22:24.1920743Z 
2026-01-14T08:22:24.1920746Z 
2026-01-14T08:22:24.1920750Z 
2026-01-14T08:22:24.1920754Z 
2026-01-14T08:22:24.1920757Z 
2026-01-14T08:22:24.1920761Z 
2026-01-14T08:22:24.1920765Z 
2026-01-14T08:22:24.1920768Z 
2026-01-14T08:22:24.1921192Z zlib-1.3.1           | 96 KB     | : 100% 1.0/1 [00:02<00:00,  2.70s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1921623Z 
2026-01-14T08:22:24.1921627Z 
2026-01-14T08:22:24.1921630Z 
2026-01-14T08:22:24.1921634Z 
2026-01-14T08:22:24.1921638Z 
2026-01-14T08:22:24.1921641Z 
2026-01-14T08:22:24.1921645Z 
2026-01-14T08:22:24.1921649Z 
2026-01-14T08:22:24.1921652Z 
2026-01-14T08:22:24.1921656Z 
2026-01-14T08:22:24.1921660Z 
2026-01-14T08:22:24.1921663Z 
2026-01-14T08:22:24.1921667Z 
2026-01-14T08:22:24.1921671Z 
2026-01-14T08:22:24.1921674Z 
2026-01-14T08:22:24.1921678Z 
2026-01-14T08:22:24.1921682Z 
2026-01-14T08:22:24.1921694Z 
2026-01-14T08:22:24.1922088Z zlib-1.3.1           | 96 KB     | : 100% 1.0/1 [00:02<00:00,  2.70s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1922484Z 
2026-01-14T08:22:24.1922488Z 
2026-01-14T08:22:24.1922492Z 
2026-01-14T08:22:24.1922495Z 
2026-01-14T08:22:24.1922499Z 
2026-01-14T08:22:24.1922503Z 
2026-01-14T08:22:24.1922506Z 
2026-01-14T08:22:24.1922510Z 
2026-01-14T08:22:24.1922518Z 
2026-01-14T08:22:24.1922526Z 
2026-01-14T08:22:24.1922529Z 
2026-01-14T08:22:24.1922533Z 
2026-01-14T08:22:24.1922537Z 
2026-01-14T08:22:24.1922540Z 
2026-01-14T08:22:24.1922544Z 
2026-01-14T08:22:24.1922548Z 
2026-01-14T08:22:24.1922551Z 
2026-01-14T08:22:24.1935719Z readline-8.3         | 471 KB    | : 100% 1.0/1 [00:02<00:00,  2.67s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1936212Z 
2026-01-14T08:22:24.1936217Z 
2026-01-14T08:22:24.1936221Z 
2026-01-14T08:22:24.1936225Z 
2026-01-14T08:22:24.1936229Z 
2026-01-14T08:22:24.1936233Z 
2026-01-14T08:22:24.1936236Z 
2026-01-14T08:22:24.1936240Z 
2026-01-14T08:22:24.1936244Z 
2026-01-14T08:22:24.1936255Z 
2026-01-14T08:22:24.1936259Z 
2026-01-14T08:22:24.1936262Z 
2026-01-14T08:22:24.1936266Z 
2026-01-14T08:22:24.1936270Z 
2026-01-14T08:22:24.1936273Z 
2026-01-14T08:22:24.1936277Z 
2026-01-14T08:22:24.1936281Z 
2026-01-14T08:22:24.1936723Z readline-8.3         | 471 KB    | : 100% 1.0/1 [00:02<00:00,  2.67s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1937132Z 
2026-01-14T08:22:24.1937136Z 
2026-01-14T08:22:24.1937139Z 
2026-01-14T08:22:24.1937143Z 
2026-01-14T08:22:24.1937147Z 
2026-01-14T08:22:24.1937150Z 
2026-01-14T08:22:24.1937154Z 
2026-01-14T08:22:24.1937158Z 
2026-01-14T08:22:24.1937161Z 
2026-01-14T08:22:24.1937165Z 
2026-01-14T08:22:24.1937169Z 
2026-01-14T08:22:24.1937172Z 
2026-01-14T08:22:24.1937176Z 
2026-01-14T08:22:24.1937179Z 
2026-01-14T08:22:24.1937183Z 
2026-01-14T08:22:24.1937632Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:02<00:00,  2.68s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1938200Z 
2026-01-14T08:22:24.1938205Z 
2026-01-14T08:22:24.1938209Z 
2026-01-14T08:22:24.1938213Z 
2026-01-14T08:22:24.1938216Z 
2026-01-14T08:22:24.1938220Z 
2026-01-14T08:22:24.1938224Z 
2026-01-14T08:22:24.1938227Z 
2026-01-14T08:22:24.1938231Z 
2026-01-14T08:22:24.1938235Z 
2026-01-14T08:22:24.1938245Z 
2026-01-14T08:22:24.1938249Z 
2026-01-14T08:22:24.1938325Z 
2026-01-14T08:22:24.1938329Z 
2026-01-14T08:22:24.1938332Z 
2026-01-14T08:22:24.1938734Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:02<00:00,  2.68s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:24.1939546Z 
2026-01-14T08:22:31.9896871Z ncurses-6.5          | 1.1 MB    | : 100% 1.0/1 [00:03<00:00,  3.42s/it]                 [A
2026-01-14T08:22:31.9897379Z 
2026-01-14T08:22:31.9897763Z ncurses-6.5          | 1.1 MB    | : 100% 1.0/1 [00:03<00:00,  3.42s/it][A
2026-01-14T08:22:31.9898150Z 
2026-01-14T08:22:31.9898155Z 
2026-01-14T08:22:31.9898161Z 
2026-01-14T08:22:31.9898166Z 
2026-01-14T08:22:31.9898171Z 
2026-01-14T08:22:31.9898205Z 
2026-01-14T08:22:31.9898211Z 
2026-01-14T08:22:31.9898216Z 
2026-01-14T08:22:31.9898221Z 
2026-01-14T08:22:31.9898226Z 
2026-01-14T08:22:31.9898240Z 
2026-01-14T08:22:31.9898245Z 
2026-01-14T08:22:31.9898250Z 
2026-01-14T08:22:31.9898255Z 
2026-01-14T08:22:31.9898260Z 
2026-01-14T08:22:31.9898265Z 
2026-01-14T08:22:31.9898270Z 
2026-01-14T08:22:31.9898289Z 
2026-01-14T08:22:31.9898294Z 
2026-01-14T08:22:31.9898635Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9898940Z 
2026-01-14T08:22:31.9898952Z 
2026-01-14T08:22:31.9898956Z 
2026-01-14T08:22:31.9898959Z 
2026-01-14T08:22:31.9898963Z 
2026-01-14T08:22:31.9898967Z 
2026-01-14T08:22:31.9898970Z 
2026-01-14T08:22:31.9898974Z 
2026-01-14T08:22:31.9898978Z 
2026-01-14T08:22:31.9898982Z 
2026-01-14T08:22:31.9898985Z 
2026-01-14T08:22:31.9898989Z 
2026-01-14T08:22:31.9898993Z 
2026-01-14T08:22:31.9898997Z 
2026-01-14T08:22:31.9899000Z 
2026-01-14T08:22:31.9899004Z 
2026-01-14T08:22:31.9899013Z 
2026-01-14T08:22:31.9899017Z 
2026-01-14T08:22:31.9899020Z 
2026-01-14T08:22:31.9899114Z                       
2026-01-14T08:22:31.9899444Z [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9899812Z                                                                         
2026-01-14T08:22:31.9900055Z 
2026-01-14T08:22:31.9900064Z 
2026-01-14T08:22:31.9900261Z                                                                         [A
2026-01-14T08:22:31.9900512Z 
2026-01-14T08:22:31.9900516Z 
2026-01-14T08:22:31.9900718Z                                                                         [A[A
2026-01-14T08:22:31.9900963Z 
2026-01-14T08:22:31.9900966Z 
2026-01-14T08:22:31.9900970Z 
2026-01-14T08:22:31.9901183Z                                                                         [A[A[A
2026-01-14T08:22:31.9901433Z 
2026-01-14T08:22:31.9901437Z 
2026-01-14T08:22:31.9901441Z 
2026-01-14T08:22:31.9901445Z 
2026-01-14T08:22:31.9901663Z                                                                         [A[A[A[A
2026-01-14T08:22:31.9901928Z 
2026-01-14T08:22:31.9901932Z 
2026-01-14T08:22:31.9901936Z 
2026-01-14T08:22:31.9901939Z 
2026-01-14T08:22:31.9901943Z 
2026-01-14T08:22:31.9902162Z                                                                         [A[A[A[A[A
2026-01-14T08:22:31.9902428Z 
2026-01-14T08:22:31.9902436Z 
2026-01-14T08:22:31.9902439Z 
2026-01-14T08:22:31.9902443Z 
2026-01-14T08:22:31.9902446Z 
2026-01-14T08:22:31.9902450Z 
2026-01-14T08:22:31.9902675Z                                                                         [A[A[A[A[A[A
2026-01-14T08:22:31.9902946Z 
2026-01-14T08:22:31.9902950Z 
2026-01-14T08:22:31.9902953Z 
2026-01-14T08:22:31.9902967Z 
2026-01-14T08:22:31.9902971Z 
2026-01-14T08:22:31.9902974Z 
2026-01-14T08:22:31.9902978Z 
2026-01-14T08:22:31.9903208Z                                                                         [A[A[A[A[A[A[A
2026-01-14T08:22:31.9903527Z 
2026-01-14T08:22:31.9903531Z 
2026-01-14T08:22:31.9903863Z 
2026-01-14T08:22:31.9903868Z 
2026-01-14T08:22:31.9903871Z 
2026-01-14T08:22:31.9903883Z 
2026-01-14T08:22:31.9903887Z 
2026-01-14T08:22:31.9903891Z 
2026-01-14T08:22:31.9904138Z                                                                         [A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9904411Z 
2026-01-14T08:22:31.9904415Z 
2026-01-14T08:22:31.9904620Z 
2026-01-14T08:22:31.9904623Z 
2026-01-14T08:22:31.9904627Z 
2026-01-14T08:22:31.9904631Z 
2026-01-14T08:22:31.9904634Z 
2026-01-14T08:22:31.9904646Z 
2026-01-14T08:22:31.9904650Z 
2026-01-14T08:22:31.9904896Z                                                                         [A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9905172Z 
2026-01-14T08:22:31.9905175Z 
2026-01-14T08:22:31.9905179Z 
2026-01-14T08:22:31.9905182Z 
2026-01-14T08:22:31.9905186Z 
2026-01-14T08:22:31.9905190Z 
2026-01-14T08:22:31.9905193Z 
2026-01-14T08:22:31.9905205Z 
2026-01-14T08:22:31.9905208Z 
2026-01-14T08:22:31.9905212Z 
2026-01-14T08:22:31.9905476Z                                                                         [A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9905760Z 
2026-01-14T08:22:31.9905764Z 
2026-01-14T08:22:31.9905767Z 
2026-01-14T08:22:31.9905771Z 
2026-01-14T08:22:31.9905775Z 
2026-01-14T08:22:31.9905778Z 
2026-01-14T08:22:31.9905782Z 
2026-01-14T08:22:31.9905794Z 
2026-01-14T08:22:31.9905802Z 
2026-01-14T08:22:31.9905806Z 
2026-01-14T08:22:31.9905809Z 
2026-01-14T08:22:31.9906072Z                                                                         [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9906357Z 
2026-01-14T08:22:31.9906361Z 
2026-01-14T08:22:31.9906364Z 
2026-01-14T08:22:31.9906368Z 
2026-01-14T08:22:31.9906372Z 
2026-01-14T08:22:31.9906384Z 
2026-01-14T08:22:31.9906388Z 
2026-01-14T08:22:31.9906392Z 
2026-01-14T08:22:31.9906395Z 
2026-01-14T08:22:31.9906399Z 
2026-01-14T08:22:31.9906402Z 
2026-01-14T08:22:31.9906406Z 
2026-01-14T08:22:31.9906679Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9906966Z 
2026-01-14T08:22:31.9906969Z 
2026-01-14T08:22:31.9906973Z 
2026-01-14T08:22:31.9906985Z 
2026-01-14T08:22:31.9906989Z 
2026-01-14T08:22:31.9906992Z 
2026-01-14T08:22:31.9906996Z 
2026-01-14T08:22:31.9907000Z 
2026-01-14T08:22:31.9907003Z 
2026-01-14T08:22:31.9907007Z 
2026-01-14T08:22:31.9907016Z 
2026-01-14T08:22:31.9907019Z 
2026-01-14T08:22:31.9907023Z 
2026-01-14T08:22:31.9907295Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9907601Z 
2026-01-14T08:22:31.9907605Z 
2026-01-14T08:22:31.9907609Z 
2026-01-14T08:22:31.9907612Z 
2026-01-14T08:22:31.9907616Z 
2026-01-14T08:22:31.9907620Z 
2026-01-14T08:22:31.9907623Z 
2026-01-14T08:22:31.9907627Z 
2026-01-14T08:22:31.9907631Z 
2026-01-14T08:22:31.9907634Z 
2026-01-14T08:22:31.9907638Z 
2026-01-14T08:22:31.9907642Z 
2026-01-14T08:22:31.9907645Z 
2026-01-14T08:22:31.9907649Z 
2026-01-14T08:22:31.9907934Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9908243Z 
2026-01-14T08:22:31.9908247Z 
2026-01-14T08:22:31.9908250Z 
2026-01-14T08:22:31.9908254Z 
2026-01-14T08:22:31.9908258Z 
2026-01-14T08:22:31.9908261Z 
2026-01-14T08:22:31.9908265Z 
2026-01-14T08:22:31.9908269Z 
2026-01-14T08:22:31.9908276Z 
2026-01-14T08:22:31.9908279Z 
2026-01-14T08:22:31.9908283Z 
2026-01-14T08:22:31.9908287Z 
2026-01-14T08:22:31.9908291Z 
2026-01-14T08:22:31.9908294Z 
2026-01-14T08:22:31.9908298Z 
2026-01-14T08:22:31.9908590Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9908890Z 
2026-01-14T08:22:31.9908894Z 
2026-01-14T08:22:31.9908897Z 
2026-01-14T08:22:31.9908901Z 
2026-01-14T08:22:31.9908905Z 
2026-01-14T08:22:31.9908908Z 
2026-01-14T08:22:31.9908912Z 
2026-01-14T08:22:31.9908916Z 
2026-01-14T08:22:31.9908919Z 
2026-01-14T08:22:31.9908923Z 
2026-01-14T08:22:31.9909015Z 
2026-01-14T08:22:31.9909019Z 
2026-01-14T08:22:31.9909022Z 
2026-01-14T08:22:31.9909034Z 
2026-01-14T08:22:31.9909038Z 
2026-01-14T08:22:31.9909041Z 
2026-01-14T08:22:31.9909333Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9909640Z 
2026-01-14T08:22:31.9909716Z 
2026-01-14T08:22:31.9909720Z 
2026-01-14T08:22:31.9909724Z 
2026-01-14T08:22:31.9909728Z 
2026-01-14T08:22:31.9909731Z 
2026-01-14T08:22:31.9909743Z 
2026-01-14T08:22:31.9909746Z 
2026-01-14T08:22:31.9909750Z 
2026-01-14T08:22:31.9909754Z 
2026-01-14T08:22:31.9909757Z 
2026-01-14T08:22:31.9909761Z 
2026-01-14T08:22:31.9909764Z 
2026-01-14T08:22:31.9909768Z 
2026-01-14T08:22:31.9909772Z 
2026-01-14T08:22:31.9909775Z 
2026-01-14T08:22:31.9909779Z 
2026-01-14T08:22:31.9910078Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9910400Z 
2026-01-14T08:22:31.9910412Z 
2026-01-14T08:22:31.9910416Z 
2026-01-14T08:22:31.9910420Z 
2026-01-14T08:22:31.9910423Z 
2026-01-14T08:22:31.9910427Z 
2026-01-14T08:22:31.9910430Z 
2026-01-14T08:22:31.9910434Z 
2026-01-14T08:22:31.9910438Z 
2026-01-14T08:22:31.9910441Z 
2026-01-14T08:22:31.9910445Z 
2026-01-14T08:22:31.9910449Z 
2026-01-14T08:22:31.9910452Z 
2026-01-14T08:22:31.9910460Z 
2026-01-14T08:22:31.9910464Z 
2026-01-14T08:22:31.9910468Z 
2026-01-14T08:22:31.9910471Z 
2026-01-14T08:22:31.9910475Z 
2026-01-14T08:22:31.9910799Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:31.9911117Z 
2026-01-14T08:22:31.9911121Z 
2026-01-14T08:22:31.9911124Z 
2026-01-14T08:22:31.9911229Z [A
2026-01-14T08:22:31.9911341Z 
2026-01-14T08:22:31.9911345Z 
2026-01-14T08:22:31.9911447Z [A[A
2026-01-14T08:22:31.9911559Z 
2026-01-14T08:22:31.9911731Z Preparing transaction: / - \ done
2026-01-14T08:22:31.9912230Z Verifying transaction: / - \ | / - \ | / - \ | / - \ done
2026-01-14T08:22:31.9912893Z Executing transaction: / - \ | / - \ | / - \ | / - \ | / - \ | / - \ done
2026-01-14T08:22:31.9913341Z #
2026-01-14T08:22:31.9913547Z # To activate this environment, use
2026-01-14T08:22:31.9913816Z #
2026-01-14T08:22:31.9914019Z #     $ conda activate venv
2026-01-14T08:22:31.9914258Z #
2026-01-14T08:22:31.9914484Z # To deactivate an active environment, use
2026-01-14T08:22:31.9914767Z #
2026-01-14T08:22:31.9914959Z #     $ conda deactivate
2026-01-14T08:22:31.9915116Z 
2026-01-14T08:22:31.9915217Z + conda activate venv
2026-01-14T08:22:31.9915444Z + local cmd=activate
2026-01-14T08:22:31.9915668Z + case "$cmd" in
2026-01-14T08:22:31.9915892Z + __conda_activate activate venv
2026-01-14T08:22:31.9916164Z + '[' -n '' ']'
2026-01-14T08:22:31.9916371Z + local ask_conda
2026-01-14T08:22:31.9916596Z ++ PS1='(base) '
2026-01-14T08:22:31.9916835Z ++ __conda_exe shell.posix activate venv
2026-01-14T08:22:31.9917187Z ++ /opt/conda/bin/conda shell.posix activate venv
2026-01-14T08:22:31.9917525Z + ask_conda='PS1='\''(venv) '\''
2026-01-14T08:22:31.9918542Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:22:31.9919623Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:22:31.9919952Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:22:31.9920241Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:22:31.9920562Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:22:31.9920903Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:22:31.9921240Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:22:31.9921548Z export _CE_M='\'''\''
2026-01-14T08:22:31.9921801Z export _CE_CONDA='\'''\''
2026-01-14T08:22:31.9922123Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:22:31.9922588Z + eval 'PS1='\''(venv) '\''
2026-01-14T08:22:31.9923635Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:22:31.9924696Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:22:31.9925119Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:22:31.9925404Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:22:31.9925757Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:22:31.9926097Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:22:31.9926442Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:22:31.9926757Z export _CE_M='\'''\''
2026-01-14T08:22:31.9927021Z export _CE_CONDA='\'''\''
2026-01-14T08:22:31.9927352Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:22:31.9927709Z ++ PS1='(venv) '
2026-01-14T08:22:31.9928656Z ++ export PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:22:31.9930326Z ++ PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:22:31.9931343Z ++ export CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:22:31.9931663Z ++ CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:22:31.9931960Z ++ export CONDA_SHLVL=2
2026-01-14T08:22:31.9932201Z ++ CONDA_SHLVL=2
2026-01-14T08:22:31.9932430Z ++ export CONDA_DEFAULT_ENV=venv
2026-01-14T08:22:31.9932714Z ++ CONDA_DEFAULT_ENV=venv
2026-01-14T08:22:31.9932996Z ++ export 'CONDA_PROMPT_MODIFIER=(venv) '
2026-01-14T08:22:31.9933332Z ++ CONDA_PROMPT_MODIFIER='(venv) '
2026-01-14T08:22:31.9933642Z ++ export CONDA_PREFIX_1=/opt/conda
2026-01-14T08:22:31.9933955Z ++ CONDA_PREFIX_1=/opt/conda
2026-01-14T08:22:31.9934244Z ++ export CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:22:31.9934569Z ++ CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:22:31.9934841Z ++ export _CE_M=
2026-01-14T08:22:31.9935066Z ++ _CE_M=
2026-01-14T08:22:31.9935270Z ++ export _CE_CONDA=
2026-01-14T08:22:31.9935522Z ++ _CE_CONDA=
2026-01-14T08:22:31.9935791Z ++ export CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:22:31.9936147Z ++ CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:22:31.9936458Z + __conda_hashr
2026-01-14T08:22:31.9936674Z + '[' -n '' ']'
2026-01-14T08:22:31.9936900Z + '[' -n '' ']'
2026-01-14T08:22:31.9937107Z + hash -r
2026-01-14T08:22:31.9937354Z + python -m pip install --upgrade pip
2026-01-14T08:22:31.9937887Z Requirement already satisfied: pip in /opt/conda/envs/venv/lib/python3.10/site-packages (25.3)
2026-01-14T08:22:31.9940169Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:22:31.9941825Z [0m+ pip install torch==2.8.0
2026-01-14T08:22:31.9942115Z Collecting torch==2.8.0
2026-01-14T08:22:31.9942523Z   Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)
2026-01-14T08:22:31.9942998Z Collecting filelock (from torch==2.8.0)
2026-01-14T08:22:31.9943422Z   Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)
2026-01-14T08:22:31.9943887Z Collecting typing-extensions>=4.10.0 (from torch==2.8.0)
2026-01-14T08:22:31.9944385Z   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:22:31.9944839Z Collecting sympy>=1.13.3 (from torch==2.8.0)
2026-01-14T08:22:31.9945248Z   Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:22:31.9945776Z Collecting networkx (from torch==2.8.0)
2026-01-14T08:22:31.9946188Z   Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:22:31.9946599Z Collecting jinja2 (from torch==2.8.0)
2026-01-14T08:22:31.9946988Z   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
2026-01-14T08:22:31.9947385Z Collecting fsspec (from torch==2.8.0)
2026-01-14T08:22:31.9947913Z   Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:22:31.9948402Z Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.8.0)
2026-01-14T08:22:31.9949074Z   Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:31.9949774Z Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.8.0)
2026-01-14T08:22:31.9950460Z   Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:31.9951169Z Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.8.0)
2026-01-14T08:22:31.9951843Z   Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:31.9952502Z Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.8.0)
2026-01-14T08:22:31.9953068Z   Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
2026-01-14T08:22:31.9953638Z Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.8.0)
2026-01-14T08:22:31.9954205Z   Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:31.9954776Z Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.8.0)
2026-01-14T08:22:31.9955421Z   Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:31.9956091Z Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.8.0)
2026-01-14T08:22:31.9956650Z   Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:31.9957229Z Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.8.0)
2026-01-14T08:22:31.9957798Z   Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
2026-01-14T08:22:31.9958400Z Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.8.0)
2026-01-14T08:22:38.4843900Z   Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
2026-01-14T08:22:38.4844854Z Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.8.0)
2026-01-14T08:22:38.4845463Z   Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)
2026-01-14T08:22:38.4846039Z Collecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0)
2026-01-14T08:22:38.4846680Z   Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)
2026-01-14T08:22:38.4847316Z Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.8.0)
2026-01-14T08:22:38.4847983Z   Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
2026-01-14T08:22:38.4848654Z Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.8.0)
2026-01-14T08:22:38.4849330Z   Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:38.4850017Z Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.8.0)
2026-01-14T08:22:38.4850662Z   Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:38.4851271Z Collecting triton==3.4.0 (from torch==2.8.0)
2026-01-14T08:22:38.4851824Z   Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:38.4852793Z Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from triton==3.4.0->torch==2.8.0) (80.9.0)
2026-01-14T08:22:38.4853988Z Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.8.0)
2026-01-14T08:22:38.4854477Z   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
2026-01-14T08:22:38.4854930Z Collecting MarkupSafe>=2.0 (from jinja2->torch==2.8.0)
2026-01-14T08:22:38.4855624Z   Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)
2026-01-14T08:22:38.4856600Z Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)
2026-01-14T08:22:38.4857830Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/888.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:38.4858717Z [2K   [91m━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m60.3/888.0 MB[0m [31m301.6 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:38.4859692Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m117.4/888.0 MB[0m [31m293.5 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:38.4860639Z [2K   [91m━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m167.8/888.0 MB[0m [31m278.8 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:38.4861562Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m223.1/888.0 MB[0m [31m277.2 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:38.4862483Z [2K   [91m━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m276.3/888.0 MB[0m [31m275.0 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:38.4863431Z [2K   [91m━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m339.5/888.0 MB[0m [31m275.3 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:38.4864352Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m402.4/888.0 MB[0m [31m285.1 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:38.4865282Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m463.5/888.0 MB[0m [31m301.7 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:38.4866221Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━[0m [32m519.3/888.0 MB[0m [31m300.4 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:38.4867153Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━[0m [32m579.9/888.0 MB[0m [31m296.9 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:38.4868081Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━[0m [32m642.0/888.0 MB[0m [31m298.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4869032Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m702.5/888.0 MB[0m [31m297.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4869965Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m762.3/888.0 MB[0m [31m303.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4870901Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m824.2/888.0 MB[0m [31m302.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4871914Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m879.8/888.0 MB[0m [31m296.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4872846Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4873713Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4874678Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4875546Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4876414Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4877291Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4878174Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4879033Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4879901Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4880780Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4881660Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4882530Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4883595Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:38.4884580Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8754526Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8755608Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8756483Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8757342Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8758454Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8759326Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8760183Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8763545Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8764447Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8765363Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8766230Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8767116Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8767970Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8768859Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8769739Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8770598Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8771461Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8772338Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m887.9/888.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8773162Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m888.0/888.0 MB[0m [31m35.2 MB/s[0m  [33m0:00:09[0m
2026-01-14T08:22:45.8773940Z [?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)
2026-01-14T08:22:45.8774721Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/594.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:45.8775596Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m79.4/594.3 MB[0m [31m397.7 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:45.8776534Z [2K   [91m━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m161.7/594.3 MB[0m [31m402.6 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:45.8777465Z [2K   [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m248.0/594.3 MB[0m [31m411.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8778522Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m336.1/594.3 MB[0m [31m423.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8779449Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━[0m [32m423.6/594.3 MB[0m [31m433.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8780385Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m512.0/594.3 MB[0m [31m437.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8781379Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8782251Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8783124Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8784007Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8784869Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8785731Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8786614Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8787473Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8788345Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8789210Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8790178Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.8791043Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8697719Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8699087Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8699960Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8700821Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8701712Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8702574Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8703454Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8704343Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8705201Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8706047Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m594.3/594.3 MB[0m [31m56.2 MB/s[0m  [33m0:00:05[0m
2026-01-14T08:22:51.8706924Z [?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)
2026-01-14T08:22:51.8707802Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/10.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:51.8708587Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m10.2/10.2 MB[0m [31m191.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:51.8709454Z [?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)
2026-01-14T08:22:51.8710329Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/88.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:51.8711150Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m443.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8712008Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m443.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8712873Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m443.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8713894Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m443.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8714758Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m443.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8715660Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m443.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8716583Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m88.0/88.0 MB[0m [31m70.0 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:22:51.8717471Z [?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)
2026-01-14T08:22:51.8718356Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/954.8 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:51.8719159Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m954.8/954.8 kB[0m [31m62.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:51.8719944Z [?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)
2026-01-14T08:22:51.8720718Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/706.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:51.8721597Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m89.1/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:51.8722556Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m178.8/706.8 MB[0m [31m445.5 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:51.8723597Z [2K   [91m━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m268.7/706.8 MB[0m [31m446.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8724556Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m358.9/706.8 MB[0m [31m447.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8725509Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m449.1/706.8 MB[0m [31m448.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8726455Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━[0m [32m539.0/706.8 MB[0m [31m448.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8727403Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m629.1/706.8 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8728337Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8729246Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8730153Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8731145Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8732046Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8732924Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:51.8733904Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3017910Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3018851Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3019921Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3020834Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3021690Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3022555Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3023439Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3024302Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3025168Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3026039Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3026902Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3027776Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3028652Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3029515Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3030377Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3031237Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3032504Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3033373Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3034241Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m446.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3035263Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m706.8/706.8 MB[0m [31m46.3 MB/s[0m  [33m0:00:06[0m
2026-01-14T08:22:58.3036138Z [?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)
2026-01-14T08:22:58.3037000Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/193.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:58.3037875Z [2K   [91m━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m80.5/193.1 MB[0m [31m403.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3038875Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m162.3/193.1 MB[0m [31m404.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3039998Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m404.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3040883Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m404.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3041748Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m404.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3042673Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m404.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3043538Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m404.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3044560Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m404.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3045428Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m404.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3046301Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m404.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3047260Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m193.1/193.1 MB[0m [31m88.6 MB/s[0m  [33m0:00:02[0m
2026-01-14T08:22:58.3048101Z [?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)
2026-01-14T08:22:58.3048941Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:58.3049687Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m35.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:58.3050455Z [?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)
2026-01-14T08:22:58.3051229Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/63.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:58.3052042Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m63.4/63.6 MB[0m [31m443.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3052932Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m63.4/63.6 MB[0m [31m443.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:58.3053786Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m63.4/63.6 MB[0m [31m443.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1076554Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m63.6/63.6 MB[0m [31m81.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:05.1077515Z [?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)
2026-01-14T08:23:05.1078573Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/267.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:05.1079706Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m88.9/267.5 MB[0m [31m444.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1080644Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m178.8/267.5 MB[0m [31m445.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1081558Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1082435Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1083412Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1084541Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1085424Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1086295Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1087371Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1088238Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1089105Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1089983Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1090868Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m446.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1091689Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m267.5/267.5 MB[0m [31m96.5 MB/s[0m  [33m0:00:02[0m
2026-01-14T08:23:05.1092572Z [?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)
2026-01-14T08:23:05.1093461Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/288.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:05.1094320Z [2K   [91m━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m89.9/288.2 MB[0m [31m450.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1095260Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━[0m [32m180.6/288.2 MB[0m [31m449.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1096218Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m271.6/288.2 MB[0m [31m451.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1097120Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m450.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1097995Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m450.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1098890Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m450.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1099764Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m450.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1100685Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m450.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1101562Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m450.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1102539Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m450.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1103410Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m450.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1104244Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m288.2/288.2 MB[0m [31m119.6 MB/s[0m  [33m0:00:02[0m
2026-01-14T08:23:05.1105103Z [?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)
2026-01-14T08:23:05.1105891Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/287.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:05.1106757Z [2K   [91m━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m89.7/287.2 MB[0m [31m449.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1107700Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m180.6/287.2 MB[0m [31m448.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1108645Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m271.3/287.2 MB[0m [31m449.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1109559Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1110451Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1111335Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:05.1112215Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5255234Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5264948Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5265937Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5266816Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5267922Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5268793Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5269659Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5270657Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5271530Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5272430Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5273305Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5274175Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5275034Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5275908Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5276788Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5277617Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m287.2/287.2 MB[0m [31m57.7 MB/s[0m  [33m0:00:04[0m
2026-01-14T08:23:12.5278487Z [?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)
2026-01-14T08:23:12.5279339Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/322.4 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:12.5280187Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m89.7/322.4 MB[0m [31m448.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5281128Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━[0m [32m180.1/322.4 MB[0m [31m449.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5282152Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m270.8/322.4 MB[0m [31m449.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5283113Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5283974Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5284943Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5285823Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5286677Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5287543Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5288420Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5289284Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5290162Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5291040Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5291903Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5292775Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5293653Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5294518Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5295385Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5296266Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5297142Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:12.5298004Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1859127Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1860125Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1860996Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1862049Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1862928Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.4 MB[0m [31m450.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1863763Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m322.4/322.4 MB[0m [31m50.5 MB/s[0m  [33m0:00:05[0m
2026-01-14T08:23:21.1864639Z [?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)
2026-01-14T08:23:21.1865544Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/39.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:21.1866370Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m39.1/39.3 MB[0m [31m449.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1867245Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m39.1/39.3 MB[0m [31m449.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1868131Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m39.1/39.3 MB[0m [31m449.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1868936Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m39.3/39.3 MB[0m [31m61.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:21.1869771Z [?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)
2026-01-14T08:23:21.1870554Z Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)
2026-01-14T08:23:21.1871370Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/155.4 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:21.1872232Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m79.2/155.4 MB[0m [31m397.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1873168Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m142.3/155.4 MB[0m [31m354.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1874100Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.2/155.4 MB[0m [31m348.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1875042Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.2/155.4 MB[0m [31m348.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1875920Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.2/155.4 MB[0m [31m348.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1876932Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.2/155.4 MB[0m [31m348.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1877810Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.2/155.4 MB[0m [31m348.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1878685Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.2/155.4 MB[0m [31m348.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1879653Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.2/155.4 MB[0m [31m348.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1880518Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.2/155.4 MB[0m [31m348.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1881389Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.2/155.4 MB[0m [31m348.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:21.1882215Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m155.4/155.4 MB[0m [31m69.7 MB/s[0m  [33m0:00:02[0m
2026-01-14T08:23:21.1882955Z [?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)
2026-01-14T08:23:21.1883608Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:21.1884353Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.3/6.3 MB[0m [31m36.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:21.1884958Z [?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)
2026-01-14T08:23:21.1885613Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/536.2 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:21.1886385Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m536.2/536.2 kB[0m [31m3.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:21.1887052Z [?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)
2026-01-14T08:23:21.1887522Z Downloading filelock-3.20.3-py3-none-any.whl (16 kB)
2026-01-14T08:23:21.1887946Z Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)
2026-01-14T08:23:21.1888341Z Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)
2026-01-14T08:23:21.1889008Z Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)
2026-01-14T08:23:21.1889681Z Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)
2026-01-14T08:23:21.1890308Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:21.1891075Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m13.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:21.1893445Z [?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch
2026-01-14T08:23:21.1895392Z [?25l
2026-01-14T08:23:21.1895942Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:21.1896616Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:21.1897277Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:21.1898025Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8332393Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8333197Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8333844Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8334498Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8335183Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8335843Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8336491Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8337154Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8337802Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8338445Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:28.8339414Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 1/24[0m [mpmath]
2026-01-14T08:23:28.8340086Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 1/24[0m [mpmath]
2026-01-14T08:23:28.8341080Z [2K   [91m━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 2/24[0m [typing-extensions]
2026-01-14T08:23:28.8341794Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8342460Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8343290Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8343946Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8344602Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8345258Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8345914Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8346585Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8347239Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8347904Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8348574Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8349221Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8349879Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8350536Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8351183Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:23:28.8351859Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8352503Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8353154Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8353828Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8354476Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8355126Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8355774Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8356424Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8357179Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8357831Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8358484Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8359218Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8359867Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8360523Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8361168Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8361813Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:28.8362472Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0688001Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0689156Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0689835Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0690536Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0691194Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0691845Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0692503Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0693458Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0694122Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0694786Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:36.0695485Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 5/24[0m [nvidia-nvtx-cu12]
2026-01-14T08:23:36.0696487Z [2K   [91m━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/24[0m [nvidia-nvjitlink-cu12]
2026-01-14T08:23:36.0697275Z [2K   [91m━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/24[0m [nvidia-nvjitlink-cu12]
2026-01-14T08:23:36.0698049Z [2K   [91m━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/24[0m [nvidia-nvjitlink-cu12]
2026-01-14T08:23:36.0698861Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0699624Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0700364Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0701108Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0701864Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0702602Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0703341Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0704082Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0704840Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0705581Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0706318Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0707069Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0707806Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0708542Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0709283Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0710125Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0710859Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:36.0711612Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/24[0m [nvidia-curand-cu12]
2026-01-14T08:23:36.0712374Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/24[0m [nvidia-curand-cu12]
2026-01-14T08:23:36.0713222Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/24[0m [nvidia-curand-cu12]
2026-01-14T08:23:36.0713997Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m11/24[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:36.0714789Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m11/24[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:36.0715590Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m11/24[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:36.0716404Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m11/24[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:36.0717196Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m11/24[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:36.0717988Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m11/24[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:36.0718792Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m11/24[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:36.0719590Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m12/24[0m [nvidia-cuda-cupti-cu12]
2026-01-14T08:23:36.0720373Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2818368Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2819684Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2820469Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2821237Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2822175Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2822928Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2823676Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2824431Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2825201Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2825949Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2826729Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2827505Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2828252Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2829001Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2829750Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2830517Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2831322Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2832065Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2832817Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2833581Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2834335Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2835086Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:43.2835791Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:43.2836580Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:43.2837253Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:43.2837924Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:43.2838688Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:43.2839558Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:43.2840231Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:43.2840897Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━[0m [32m16/24[0m [fsspec]
2026-01-14T08:23:43.2841567Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━[0m [32m16/24[0m [fsspec]
2026-01-14T08:23:43.2842308Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2843134Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2843908Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2844697Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2845465Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2846237Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2846991Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2847910Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2848672Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2849437Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2850369Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:43.2851132Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:50.4846688Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:50.4847811Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:50.4848835Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:50.4849619Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:50.4850369Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4851137Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4851887Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4852631Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4853379Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4854123Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4854898Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4855640Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4856387Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4857154Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:50.4857894Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4858642Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4859397Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4860505Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4861262Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4862010Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4862920Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4863723Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4864466Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4865215Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4865976Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4866735Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4867487Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4868231Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4868985Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4869725Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4870466Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4871207Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4872049Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4872794Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4873527Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4874366Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4875111Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4875848Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4876596Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4877351Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4878099Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4878839Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:50.4879595Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7004919Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7005997Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7006873Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7007950Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7008851Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7009592Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7010342Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7011125Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7011877Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7012613Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:57.7013377Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7014453Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7015256Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7016039Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7016983Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7017754Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7018521Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7019290Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7020081Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7020847Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7021619Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7022401Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7023174Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7023947Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7024713Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7025554Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7026321Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:57.7027032Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7027846Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7028490Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7029136Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7029770Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7030411Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7031157Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7031797Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7032444Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7033080Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7033743Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7034382Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7035023Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7035669Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7036324Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:57.7036960Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4062300Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4064014Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4065357Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4066630Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4067539Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4068177Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4069134Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4069790Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4070426Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4071062Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4071882Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4072517Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4073160Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4073804Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4074459Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4075101Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4075728Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4076370Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4077034Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4077667Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4078310Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4078944Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4079683Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4080321Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4080958Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4081600Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4082325Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4083076Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4083710Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4084336Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4084992Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4085620Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4086259Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4086894Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4087553Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4088188Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4088816Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4089466Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4090122Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4090761Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4091400Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4092040Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4092701Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4093326Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4093974Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:05.4094615Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3576109Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3577063Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3577712Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3578340Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3579176Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3579807Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3580435Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3581078Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3581710Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3582362Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3582995Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3583631Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3584291Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3584920Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3585563Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3586188Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3586829Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3587577Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3588214Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3588856Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3589583Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3590229Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3590859Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3591495Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3592145Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3592797Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3593438Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3594066Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3594723Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3595364Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3595994Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3596636Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:24:14.3597222Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m24/24[0m [torch]
2026-01-14T08:24:14.3597623Z [?25h
2026-01-14T08:24:14.3600486Z [1A[2KSuccessfully installed MarkupSafe-3.0.3 filelock-3.20.3 fsspec-2026.1.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.8.0 triton-3.4.0 typing-extensions-4.15.0
2026-01-14T08:24:14.3604835Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:24:14.3606586Z [0m+ sed -i '' dev-requirements.txt
2026-01-14T08:24:14.3606968Z + pip install -r dev-requirements.txt
2026-01-14T08:24:14.3607379Z Collecting pytest==8.4.2 (from -r dev-requirements.txt (line 2))
2026-01-14T08:24:14.3607887Z   Downloading pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)
2026-01-14T08:24:14.3608437Z Collecting unittest-xml-reporting (from -r dev-requirements.txt (line 3))
2026-01-14T08:24:14.3609136Z   Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl.metadata (11 kB)
2026-01-14T08:24:14.3609718Z Collecting parameterized (from -r dev-requirements.txt (line 4))
2026-01-14T08:24:14.3610277Z   Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)
2026-01-14T08:24:14.3610821Z Collecting packaging (from -r dev-requirements.txt (line 5))
2026-01-14T08:24:14.3611316Z   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:24:14.3611822Z Collecting transformers (from -r dev-requirements.txt (line 6))
2026-01-14T08:24:14.3612355Z   Downloading transformers-4.57.5-py3-none-any.whl.metadata (43 kB)
2026-01-14T08:24:14.3612868Z Collecting hypothesis (from -r dev-requirements.txt (line 7))
2026-01-14T08:24:14.3613386Z   Downloading hypothesis-6.150.2-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:24:14.3613909Z Collecting sentencepiece (from -r dev-requirements.txt (line 8))
2026-01-14T08:24:14.3614612Z   Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)
2026-01-14T08:24:14.3615304Z Collecting expecttest (from -r dev-requirements.txt (line 9))
2026-01-14T08:24:14.3615802Z   Downloading expecttest-0.3.0-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:24:14.3616307Z Collecting pyyaml (from -r dev-requirements.txt (line 10))
2026-01-14T08:24:22.3381961Z   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
2026-01-14T08:24:22.3383011Z Collecting bitsandbytes (from -r dev-requirements.txt (line 13))
2026-01-14T08:24:22.3383718Z   Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)
2026-01-14T08:24:22.3384326Z Collecting matplotlib (from -r dev-requirements.txt (line 14))
2026-01-14T08:24:22.3385040Z   Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)
2026-01-14T08:24:22.3385730Z Collecting pandas (from -r dev-requirements.txt (line 15))
2026-01-14T08:24:22.3386352Z   Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)
2026-01-14T08:24:22.3386998Z Collecting fire (from -r dev-requirements.txt (line 16))
2026-01-14T08:24:22.3387465Z   Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)
2026-01-14T08:24:22.3387967Z Collecting tabulate (from -r dev-requirements.txt (line 17))
2026-01-14T08:24:22.3388478Z   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
2026-01-14T08:24:22.3388970Z Collecting tiktoken (from -r dev-requirements.txt (line 18))
2026-01-14T08:24:22.3389553Z   Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.7 kB)
2026-01-14T08:24:22.3390118Z Collecting blobfile (from -r dev-requirements.txt (line 19))
2026-01-14T08:24:22.3390611Z   Downloading blobfile-3.1.0-py3-none-any.whl.metadata (15 kB)
2026-01-14T08:24:22.3391093Z Collecting lm_eval (from -r dev-requirements.txt (line 20))
2026-01-14T08:24:22.3391582Z   Downloading lm_eval-0.4.9.2-py3-none-any.whl.metadata (53 kB)
2026-01-14T08:24:22.3392084Z Collecting diskcache (from -r dev-requirements.txt (line 22))
2026-01-14T08:24:22.3392576Z   Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
2026-01-14T08:24:22.3393084Z Collecting pycocotools (from -r dev-requirements.txt (line 23))
2026-01-14T08:24:22.3393845Z   Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.3 kB)
2026-01-14T08:24:22.3394594Z Collecting tqdm (from -r dev-requirements.txt (line 24))
2026-01-14T08:24:22.3395312Z   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
2026-01-14T08:24:22.3395837Z Collecting importlib_metadata (from -r dev-requirements.txt (line 25))
2026-01-14T08:24:22.3396421Z   Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:24:22.3396945Z Collecting ninja (from -r dev-requirements.txt (line 28))
2026-01-14T08:24:22.3397725Z   Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)
2026-01-14T08:24:22.3398380Z Collecting cmake<4.0.0,>=3.19.0 (from -r dev-requirements.txt (line 31))
2026-01-14T08:24:22.3399032Z   Downloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:24:22.3399677Z Collecting ruff==0.11.6 (from -r dev-requirements.txt (line 34))
2026-01-14T08:24:22.3400278Z   Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)
2026-01-14T08:24:22.3400904Z Collecting pre-commit (from -r dev-requirements.txt (line 35))
2026-01-14T08:24:22.3401425Z   Downloading pre_commit-4.5.1-py2.py3-none-any.whl.metadata (1.2 kB)
2026-01-14T08:24:22.3402030Z Collecting exceptiongroup>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:22.3402718Z   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)
2026-01-14T08:24:22.3403297Z Collecting iniconfig>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:22.3403864Z   Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:24:22.3404402Z Collecting pluggy<2,>=1.5 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:22.3404948Z   Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)
2026-01-14T08:24:22.3405486Z Collecting pygments>=2.7.2 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:22.3406054Z   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:24:22.3406582Z Collecting tomli>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:22.3407117Z   Downloading tomli-2.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:22.3407673Z Collecting lxml (from unittest-xml-reporting->-r dev-requirements.txt (line 3))
2026-01-14T08:24:22.3408362Z   Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)
2026-01-14T08:24:22.3409363Z Requirement already satisfied: filelock in /opt/conda/envs/venv/lib/python3.10/site-packages (from transformers->-r dev-requirements.txt (line 6)) (3.20.3)
2026-01-14T08:24:22.3410336Z Collecting huggingface-hub<1.0,>=0.34.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:22.3410951Z   Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:24:22.3411518Z Collecting numpy>=1.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:22.3412226Z   Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
2026-01-14T08:24:22.3412911Z Collecting regex!=2019.12.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:22.3413679Z   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
2026-01-14T08:24:22.3414445Z Collecting requests (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:22.3414994Z   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
2026-01-14T08:24:22.3415581Z Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:22.3416329Z   Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
2026-01-14T08:24:22.3417041Z Collecting safetensors>=0.4.3 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:22.3417756Z   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
2026-01-14T08:24:22.3418995Z Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (2026.1.0)
2026-01-14T08:24:22.3420500Z Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (4.15.0)
2026-01-14T08:24:22.3421764Z Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:22.3422553Z   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
2026-01-14T08:24:22.3423271Z Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis->-r dev-requirements.txt (line 7))
2026-01-14T08:24:22.3423941Z   Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:22.3424863Z Requirement already satisfied: torch<3,>=2.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from bitsandbytes->-r dev-requirements.txt (line 13)) (2.8.0)
2026-01-14T08:24:22.3426128Z Requirement already satisfied: sympy>=1.13.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.14.0)
2026-01-14T08:24:22.3427428Z Requirement already satisfied: networkx in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.4.2)
2026-01-14T08:24:22.3428708Z Requirement already satisfied: jinja2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.1.6)
2026-01-14T08:24:22.3430072Z Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.93)
2026-01-14T08:24:22.3431560Z Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.90)
2026-01-14T08:24:22.3433032Z Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.90)
2026-01-14T08:24:22.3434492Z Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (9.10.2.21)
2026-01-14T08:24:22.3435940Z Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.4.1)
2026-01-14T08:24:22.3437371Z Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (11.3.3.83)
2026-01-14T08:24:22.3438819Z Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (10.3.9.90)
2026-01-14T08:24:22.3440532Z Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (11.7.3.90)
2026-01-14T08:24:22.3442004Z Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.5.8.93)
2026-01-14T08:24:22.3443559Z Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (0.7.1)
2026-01-14T08:24:38.2375237Z Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (2.27.3)
2026-01-14T08:24:38.2376754Z Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.90)
2026-01-14T08:24:38.2378214Z Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.93)
2026-01-14T08:24:38.2381132Z Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.13.1.3)
2026-01-14T08:24:38.2382528Z Requirement already satisfied: triton==3.4.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.4.0)
2026-01-14T08:24:38.2383939Z Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from triton==3.4.0->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (80.9.0)
2026-01-14T08:24:38.2384985Z Collecting contourpy>=1.0.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:38.2385713Z   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)
2026-01-14T08:24:38.2386435Z Collecting cycler>=0.10 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:38.2387044Z   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:24:38.2387609Z Collecting fonttools>=4.22.0 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:38.2388350Z   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)
2026-01-14T08:24:38.2389084Z Collecting kiwisolver>=1.3.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:38.2389825Z   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:24:38.2390538Z Collecting pillow>=8 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:38.2391225Z   Downloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)
2026-01-14T08:24:38.2391924Z Collecting pyparsing>=3 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:38.2392502Z   Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:24:38.2393102Z Collecting python-dateutil>=2.7 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:38.2393765Z   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:24:38.2394382Z Collecting pytz>=2020.1 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:24:38.2394918Z   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
2026-01-14T08:24:38.2395463Z Collecting tzdata>=2022.7 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:24:38.2396023Z   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)
2026-01-14T08:24:38.2396563Z Collecting termcolor (from fire->-r dev-requirements.txt (line 16))
2026-01-14T08:24:38.2397106Z   Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)
2026-01-14T08:24:38.2397683Z Collecting pycryptodomex>=3.8 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:24:38.2398439Z   Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)
2026-01-14T08:24:38.2399162Z Collecting urllib3<3,>=1.25.3 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:24:38.2399719Z   Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)
2026-01-14T08:24:38.2400269Z Collecting accelerate>=0.26.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2400843Z   Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:24:38.2401397Z Collecting evaluate (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2402076Z   Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)
2026-01-14T08:24:38.2402708Z Collecting datasets>=2.16.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2403259Z   Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:24:38.2403792Z Collecting jsonlines (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2404430Z   Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)
2026-01-14T08:24:38.2404959Z Collecting numexpr (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2405644Z   Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)
2026-01-14T08:24:38.2406324Z Collecting peft>=0.2.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2406856Z   Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:24:38.2407387Z Collecting pybind11>=2.6.2 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2407974Z   Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)
2026-01-14T08:24:38.2408532Z Collecting pytablewriter (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2409126Z   Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)
2026-01-14T08:24:38.2409712Z Collecting rouge-score>=0.0.4 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2410225Z   Downloading rouge_score-0.1.2.tar.gz (17 kB)
2026-01-14T08:24:38.2410925Z   Installing build dependencies ... [?25l- \ | / done
2026-01-14T08:24:38.2411476Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:24:38.2412006Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:24:38.2412626Z [?25hCollecting sacrebleu>=1.5.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2413219Z   Downloading sacrebleu-2.6.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:24:38.2413790Z Collecting scikit-learn>=0.24.1 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2414543Z   Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
2026-01-14T08:24:38.2415241Z Collecting sqlitedict (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2415716Z   Downloading sqlitedict-2.1.0.tar.gz (21 kB)
2026-01-14T08:24:38.2416170Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:24:38.2416666Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:24:38.2417199Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:24:38.2417819Z [?25hCollecting tqdm-multiprocess (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2418477Z   Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)
2026-01-14T08:24:38.2419058Z Collecting zstandard (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2419782Z   Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)
2026-01-14T08:24:38.2420493Z Collecting dill (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2421001Z   Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:38.2421550Z Collecting word2number (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2422032Z   Downloading word2number-1.1.zip (9.7 kB)
2026-01-14T08:24:38.2422491Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:24:38.2422991Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:24:38.2423521Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:24:38.2424143Z [?25hCollecting more_itertools (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2424754Z   Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:24:38.2425369Z Collecting zipp>=3.20 (from importlib_metadata->-r dev-requirements.txt (line 25))
2026-01-14T08:24:38.2426104Z   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)
2026-01-14T08:24:38.2426650Z Collecting cfgv>=2.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:38.2427218Z   Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)
2026-01-14T08:24:38.2427799Z Collecting identify>=1.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:38.2428475Z   Downloading identify-2.6.16-py2.py3-none-any.whl.metadata (4.4 kB)
2026-01-14T08:24:38.2429056Z Collecting nodeenv>=0.11.1 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:38.2429659Z   Downloading nodeenv-1.10.0-py2.py3-none-any.whl.metadata (24 kB)
2026-01-14T08:24:38.2430243Z Collecting virtualenv>=20.10.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:38.2430864Z   Downloading virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:24:38.2431497Z Collecting psutil (from accelerate>=0.26.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2432321Z   Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)
2026-01-14T08:24:38.2433164Z Collecting pyarrow>=21.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2433839Z   Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)
2026-01-14T08:24:38.2434522Z Collecting httpx<1.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2435115Z   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
2026-01-14T08:24:38.2435692Z Collecting xxhash (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2436518Z   Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:24:38.2437373Z Collecting multiprocess<0.70.19 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:38.2438067Z   Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)
2026-01-14T08:24:38.2438780Z Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:38.2439657Z   Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:38.2440430Z Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5032203Z   Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
2026-01-14T08:24:46.5033108Z Collecting anyio (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5033716Z   Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:24:46.5034326Z Collecting certifi (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5034950Z   Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:24:46.5035591Z Collecting httpcore==1.* (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5036217Z   Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
2026-01-14T08:24:46.5036807Z Collecting idna (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5037405Z   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:24:46.5038045Z Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5038689Z   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
2026-01-14T08:24:46.5039750Z Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5040636Z   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
2026-01-14T08:24:46.5041796Z Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5042679Z   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:24:46.5043503Z Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5044507Z   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)
2026-01-14T08:24:46.5045316Z Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5046093Z   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:46.5046878Z Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5047924Z   Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)
2026-01-14T08:24:46.5048997Z Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5050036Z   Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)
2026-01-14T08:24:46.5051074Z Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5052099Z   Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:24:46.5053149Z Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5054159Z   Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)
2026-01-14T08:24:46.5054967Z Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:46.5055577Z   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
2026-01-14T08:24:46.5056202Z Collecting charset_normalizer<4,>=2 (from requests->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:46.5057097Z   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
2026-01-14T08:24:46.5057948Z Collecting absl-py (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5058518Z   Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:24:46.5059064Z Collecting nltk (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5059615Z   Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)
2026-01-14T08:24:46.5060180Z Collecting portalocker (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5060799Z   Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)
2026-01-14T08:24:46.5061380Z Collecting colorama (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5061979Z   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
2026-01-14T08:24:46.5062579Z Collecting scipy>=1.8.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5063318Z   Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
2026-01-14T08:24:46.5064051Z Collecting joblib>=1.2.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5064645Z   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)
2026-01-14T08:24:46.5065351Z Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5066010Z   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
2026-01-14T08:24:46.5067010Z Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.3.0)
2026-01-14T08:24:46.5068172Z Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:46.5068806Z   Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)
2026-01-14T08:24:46.5069455Z Collecting platformdirs<5,>=3.9.1 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:46.5070111Z   Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:24:46.5071079Z Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.0.3)
2026-01-14T08:24:46.5072120Z Collecting click (from nltk->rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5072704Z   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
2026-01-14T08:24:46.5073300Z Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5073946Z   Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)
2026-01-14T08:24:46.5074575Z Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5075212Z   Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:24:46.5075849Z Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5076492Z   Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:24:46.5077106Z Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5077722Z   Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:24:46.5078320Z Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5078981Z   Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:24:46.5079674Z Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5080364Z   Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)
2026-01-14T08:24:46.5081040Z Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:46.5081722Z   Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)
2026-01-14T08:24:46.5082172Z Downloading pytest-8.4.2-py3-none-any.whl (365 kB)
2026-01-14T08:24:46.5082762Z Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)
2026-01-14T08:24:46.5083774Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/11.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:46.5084620Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m11.3/11.5 MB[0m [31m309.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:46.5085439Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m11.5/11.5 MB[0m [31m35.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:46.5086244Z [?25hDownloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)
2026-01-14T08:24:46.5087035Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/27.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:46.5087856Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m27.8/27.8 MB[0m [31m358.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:46.5088725Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m27.8/27.8 MB[0m [31m358.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:48.8994084Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27.8/27.8 MB[0m [31m51.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.8994794Z [?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)
2026-01-14T08:24:48.8995303Z Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:24:48.8995849Z Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:24:48.8996494Z Downloading packaging-25.0-py3-none-any.whl (66 kB)
2026-01-14T08:24:48.8996941Z Downloading transformers-4.57.5-py3-none-any.whl (12.0 MB)
2026-01-14T08:24:48.8997622Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.8998456Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m11.8/12.0 MB[0m [31m450.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:48.8999279Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.0/12.0 MB[0m [31m45.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.8999955Z [?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
2026-01-14T08:24:48.9000645Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/566.1 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9001423Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m566.1/566.1 kB[0m [31m3.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9002230Z [?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:24:48.9003080Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9003836Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m20.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9004639Z [?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:24:48.9005476Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9006237Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m21.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9006870Z [?25hDownloading hypothesis-6.150.2-py3-none-any.whl (542 kB)
2026-01-14T08:24:48.9007546Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/542.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9008328Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m542.7/542.7 kB[0m [31m3.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9009022Z [?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
2026-01-14T08:24:48.9009755Z Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)
2026-01-14T08:24:48.9010579Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.4 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9011438Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.4/1.4 MB[0m [31m9.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9012061Z [?25hDownloading expecttest-0.3.0-py3-none-any.whl (8.2 kB)
2026-01-14T08:24:48.9012745Z Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)
2026-01-14T08:24:48.9013619Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/770.3 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9014487Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m770.3/770.3 kB[0m [31m5.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9015229Z [?25hDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)
2026-01-14T08:24:48.9015975Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/59.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9016839Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━[0m [32m43.0/59.1 MB[0m [31m218.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:48.9017756Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m59.0/59.1 MB[0m [31m189.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:48.9018576Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m59.1/59.1 MB[0m [31m125.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9019415Z [?25hDownloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)
2026-01-14T08:24:48.9020254Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9021013Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.7/8.7 MB[0m [31m124.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9021814Z [?25hDownloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)
2026-01-14T08:24:48.9022622Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9023412Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.8/12.8 MB[0m [31m177.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9024013Z [?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)
2026-01-14T08:24:48.9024479Z Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)
2026-01-14T08:24:48.9025073Z Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.2 MB)
2026-01-14T08:24:48.9025805Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9026563Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m105.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9027179Z [?25hDownloading blobfile-3.1.0-py3-none-any.whl (75 kB)
2026-01-14T08:24:48.9027608Z Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)
2026-01-14T08:24:48.9028017Z Downloading lm_eval-0.4.9.2-py3-none-any.whl (8.2 MB)
2026-01-14T08:24:48.9028647Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:48.9029527Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.2/8.2 MB[0m [31m167.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:48.9030158Z [?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)
2026-01-14T08:24:48.9030867Z Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (472 kB)
2026-01-14T08:24:48.9031635Z Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
2026-01-14T08:24:48.9032078Z Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)
2026-01-14T08:24:48.9032669Z Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)
2026-01-14T08:24:48.9033249Z Downloading pre_commit-4.5.1-py2.py3-none-any.whl (226 kB)
2026-01-14T08:24:48.9033722Z Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)
2026-01-14T08:24:48.9046988Z Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)
2026-01-14T08:24:48.9047643Z Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
2026-01-14T08:24:48.9048230Z Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
2026-01-14T08:24:48.9048637Z Downloading datasets-4.4.2-py3-none-any.whl (512 kB)
2026-01-14T08:24:48.9049035Z Downloading dill-0.4.0-py3-none-any.whl (119 kB)
2026-01-14T08:24:48.9049445Z Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)
2026-01-14T08:24:48.9049857Z Downloading httpx-0.28.1-py3-none-any.whl (73 kB)
2026-01-14T08:24:48.9050254Z Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)
2026-01-14T08:24:48.9050692Z Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)
2026-01-14T08:24:49.9016691Z Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)
2026-01-14T08:24:49.9017891Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9018671Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m144.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9019350Z [?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)
2026-01-14T08:24:49.9020074Z Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)
2026-01-14T08:24:49.9020974Z Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)
2026-01-14T08:24:49.9021691Z Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
2026-01-14T08:24:49.9022162Z Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:24:49.9022569Z Downloading attrs-25.4.0-py3-none-any.whl (67 kB)
2026-01-14T08:24:49.9022973Z Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)
2026-01-14T08:24:49.9023413Z Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)
2026-01-14T08:24:49.9024029Z Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)
2026-01-14T08:24:49.9025115Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/4.9 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9025889Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m4.9/4.9 MB[0m [31m122.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9026813Z [?25hDownloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)
2026-01-14T08:24:49.9027625Z Downloading h11-0.16.0-py3-none-any.whl (37 kB)
2026-01-14T08:24:49.9028044Z Downloading identify-2.6.16-py2.py3-none-any.whl (99 kB)
2026-01-14T08:24:49.9028456Z Downloading idna-3.11-py3-none-any.whl (71 kB)
2026-01-14T08:24:49.9028860Z Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:24:49.9029442Z Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
2026-01-14T08:24:49.9030315Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9031100Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m136.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9031890Z [?25hDownloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)
2026-01-14T08:24:49.9032695Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9033451Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.3/5.3 MB[0m [31m200.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9034117Z [?25hDownloading nodeenv-1.10.0-py2.py3-none-any.whl (23 kB)
2026-01-14T08:24:49.9034722Z Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)
2026-01-14T08:24:49.9035505Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/16.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9036274Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m16.8/16.8 MB[0m [31m230.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9036904Z [?25hDownloading peft-0.18.1-py3-none-any.whl (556 kB)
2026-01-14T08:24:49.9037544Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/557.0 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9038332Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m557.0/557.0 kB[0m [31m52.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9039397Z [?25hDownloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)
2026-01-14T08:24:49.9040241Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/7.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9041000Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m7.0/7.0 MB[0m [31m212.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9041927Z [?25hDownloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)
2026-01-14T08:24:49.9042779Z Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)
2026-01-14T08:24:49.9043648Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/47.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9044489Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m47.4/47.6 MB[0m [31m237.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:49.9045325Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m47.6/47.6 MB[0m [31m157.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9046089Z [?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)
2026-01-14T08:24:49.9046709Z Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)
2026-01-14T08:24:49.9047532Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/2.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9048293Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2.3/2.3 MB[0m [31m155.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9048917Z [?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)
2026-01-14T08:24:49.9049593Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9050362Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m109.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9050983Z [?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)
2026-01-14T08:24:49.9051524Z Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
2026-01-14T08:24:49.9052027Z Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)
2026-01-14T08:24:49.9052697Z Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)
2026-01-14T08:24:49.9053593Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/791.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9054375Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m791.7/791.7 kB[0m [31m80.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9055025Z [?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)
2026-01-14T08:24:49.9055748Z Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)
2026-01-14T08:24:49.9056488Z Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)
2026-01-14T08:24:49.9056920Z Downloading sacrebleu-2.6.0-py3-none-any.whl (100 kB)
2026-01-14T08:24:49.9057528Z Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)
2026-01-14T08:24:49.9058302Z Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)
2026-01-14T08:24:49.9059116Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/9.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:49.9059879Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m9.7/9.7 MB[0m [31m193.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:49.9060490Z [?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)
2026-01-14T08:24:49.9061703Z Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)
2026-01-14T08:24:49.9062508Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/37.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:54.7913458Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m37.7/37.7 MB[0m [31m228.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:54.7915484Z [?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)
2026-01-14T08:24:54.7916383Z Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
2026-01-14T08:24:54.7917219Z Downloading tomli-2.4.0-py3-none-any.whl (14 kB)
2026-01-14T08:24:54.7918025Z Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)
2026-01-14T08:24:54.7918872Z Downloading virtualenv-20.36.1-py3-none-any.whl (6.0 MB)
2026-01-14T08:24:54.7920139Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:54.7921513Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.0/6.0 MB[0m [31m196.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:54.7922171Z [?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)
2026-01-14T08:24:54.7922703Z Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)
2026-01-14T08:24:54.7923116Z Downloading zipp-3.23.0-py3-none-any.whl (10 kB)
2026-01-14T08:24:54.7923499Z Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)
2026-01-14T08:24:54.7923890Z Downloading anyio-4.12.1-py3-none-any.whl (113 kB)
2026-01-14T08:24:54.7924299Z Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
2026-01-14T08:24:54.7924712Z Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)
2026-01-14T08:24:54.7925143Z Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)
2026-01-14T08:24:54.7925557Z Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)
2026-01-14T08:24:54.7926170Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:54.7926940Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.5/1.5 MB[0m [31m131.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:54.7927528Z [?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)
2026-01-14T08:24:54.7928106Z Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (440 kB)
2026-01-14T08:24:54.7928699Z Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)
2026-01-14T08:24:54.7929366Z Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)
2026-01-14T08:24:54.7930032Z Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)
2026-01-14T08:24:54.7930493Z Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)
2026-01-14T08:24:54.7930943Z Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)
2026-01-14T08:24:54.7931363Z Downloading chardet-5.2.0-py3-none-any.whl (199 kB)
2026-01-14T08:24:54.7931802Z Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)
2026-01-14T08:24:54.7932229Z Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)
2026-01-14T08:24:54.7932651Z Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)
2026-01-14T08:24:54.7933042Z Downloading typepy-1.3.4-py3-none-any.whl (31 kB)
2026-01-14T08:24:54.7933451Z Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)
2026-01-14T08:24:54.7933902Z Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)
2026-01-14T08:24:54.7934592Z Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)
2026-01-14T08:24:54.7935402Z Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)
2026-01-14T08:24:54.7936191Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:54.7936941Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.6/5.6 MB[0m [31m193.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:54.7937647Z [?25hBuilding wheels for collected packages: rouge-score, sqlitedict, word2number
2026-01-14T08:24:54.7938462Z   Building wheel for rouge-score (pyproject.toml) ... [?25l- done
2026-01-14T08:24:54.7939782Z [?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=166a66442ba58d6075badca9ed2cbf6d67c175e8124a1176ef125140416c5fc1
2026-01-14T08:24:54.7940809Z   Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4
2026-01-14T08:24:54.7941684Z   Building wheel for sqlitedict (pyproject.toml) ... [?25l- done
2026-01-14T08:24:54.7942682Z [?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16957 sha256=bcb170d40f7eac232f17691b36824cfb7a395877a30be5f6935384462010d601
2026-01-14T08:24:54.7943705Z   Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd
2026-01-14T08:24:54.7944426Z   Building wheel for word2number (pyproject.toml) ... [?25l- done
2026-01-14T08:24:54.7945411Z [?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5659 sha256=b819a57977142982641a7619c18422a20b76679fba2169987260346ebd089ab2
2026-01-14T08:24:54.7946422Z   Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b
2026-01-14T08:24:54.7947037Z Successfully built rouge-score sqlitedict word2number
2026-01-14T08:24:54.7951987Z Installing collected packages: word2number, sqlitedict, sortedcontainers, pytz, distlib, zstandard, zipp, xxhash, urllib3, tzdata, tqdm, tomli, threadpoolctl, termcolor, tcolorpy, tabulate, six, sentencepiece, safetensors, ruff, regex, pyyaml, pyparsing, pygments, pycryptodomex, pybind11, pyarrow, psutil, propcache, portalocker, pluggy, platformdirs, pillow, pathvalidate, parameterized, packaging, numpy, nodeenv, ninja, multidict, more_itertools, lxml, kiwisolver, joblib, iniconfig, idna, identify, hf-xet, h11, fsspec, frozenlist, fonttools, expecttest, exceptiongroup, diskcache, dill, cycler, colorama, cmake, click, charset_normalizer, chardet, cfgv, certifi, attrs, async-timeout, aiohappyeyeballs, absl-py, yarl, virtualenv, unittest-xml-reporting, tqdm-multiprocess, scipy, sacrebleu, requests, python-dateutil, pytest, pycocotools, numexpr, nltk, multiprocess, mbstrdecoder, jsonlines, importlib_metadata, hypothesis, httpcore, fire, contourpy, blobfile, anyio, aiosignal, typepy, tiktoken, scikit-learn, rouge-score, pre-commit, pandas, matplotlib, huggingface-hub, httpx, aiohttp, tokenizers, bitsandbytes, accelerate, transformers, datasets, DataProperty, tabledata, peft, evaluate, pytablewriter, lm_eval
2026-01-14T08:24:54.7957117Z [?25l
2026-01-14T08:24:54.7957578Z [2K   [91m━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  4/112[0m [distlib]
2026-01-14T08:24:54.7958270Z [2K   [91m━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  7/112[0m [xxhash]
2026-01-14T08:24:54.7958942Z [2K   [91m━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  9/112[0m [tzdata]
2026-01-14T08:24:54.7959663Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 18/112[0m [safetensors]
2026-01-14T08:24:54.7960357Z [2K   [91m━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 20/112[0m [regex]
2026-01-14T08:24:54.7961044Z [2K   [91m━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 22/112[0m [pyparsing]
2026-01-14T08:24:54.7961784Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:54.7962636Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:54.7963328Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:54.7964047Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/112[0m [pycryptodomex]
2026-01-14T08:24:54.7964769Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/112[0m [pycryptodomex]
2026-01-14T08:24:54.7965619Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:54.7966301Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:54.7966981Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:25:01.6192580Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:25:01.6193328Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:25:01.6194014Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:25:01.6194702Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:25:01.6195387Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/112[0m [pillow]
2026-01-14T08:25:01.6196095Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/112[0m [pillow]
2026-01-14T08:25:01.6196783Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 35/112[0m [packaging]
2026-01-14T08:25:01.6197462Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:25:01.6198157Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:25:01.6198825Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:25:01.6199489Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:25:01.6200163Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:25:01.6200823Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:25:01.6201745Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:25:01.6202426Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:25:01.6203173Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:25:01.6204024Z [2K   [91m━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 41/112[0m [lxml]
2026-01-14T08:25:01.6204688Z [2K   [91m━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 43/112[0m [joblib]
2026-01-14T08:25:01.6205357Z [2K   [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:25:01.6205850Z [2K  Attempting uninstall: fsspec
2026-01-14T08:25:01.6206382Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:25:01.6206929Z [2K    Found existing installation: fsspec 2026.1.0
2026-01-14T08:25:01.6207508Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:25:01.6208010Z [2K    Uninstalling fsspec-2026.1.0:
2026-01-14T08:25:01.6208532Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:25:01.6209062Z [2K      Successfully uninstalled fsspec-2026.1.0
2026-01-14T08:25:01.6209645Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:25:01.6210303Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m 49/112[0m [fsspec]
2026-01-14T08:25:01.6210991Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:25:01.6211681Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:25:01.6212396Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:25:01.6213083Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:25:01.6213820Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m 55/112[0m [dill]
2026-01-14T08:25:01.6214484Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:25:01.6215277Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:25:01.6215934Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:25:01.6216586Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:25:01.6217247Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:25:01.6218043Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:25:01.6218695Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m 59/112[0m [click]
2026-01-14T08:25:01.6219370Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m 61/112[0m [chardet]
2026-01-14T08:25:01.6220052Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━[0m [32m 69/112[0m [virtualenv]
2026-01-14T08:25:01.6220769Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:01.6221433Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:01.6222096Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:01.6222754Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:01.6223446Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:01.6224096Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1853615Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1854513Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1855442Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1856127Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1856786Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1857441Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1858434Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1859104Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1859759Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1860417Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1861225Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1861880Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:25:09.1862549Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m 76/112[0m [pytest]
2026-01-14T08:25:09.1863234Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━[0m [32m 77/112[0m [pycocotools]
2026-01-14T08:25:09.1863941Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:25:09.1864589Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:25:09.1865242Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:25:09.1865967Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:25:09.1866637Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m 84/112[0m [hypothesis]
2026-01-14T08:25:09.1867335Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m 84/112[0m [hypothesis]
2026-01-14T08:25:09.1868016Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m 88/112[0m [blobfile]
2026-01-14T08:25:09.1868693Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m 92/112[0m [tiktoken]
2026-01-14T08:25:09.1869425Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:25:09.1870129Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:25:09.1870841Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:25:09.1871652Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:25:09.1872356Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:25:09.1873059Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:25:09.1873759Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:25:09.1874604Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:25:09.1875321Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:25:09.1876014Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m 95/112[0m [pre-commit]
2026-01-14T08:25:09.1876693Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1877376Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1878034Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1878693Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1879347Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1880032Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1880749Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1881405Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1882059Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1882814Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1883469Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:09.1884117Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:16.6502998Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:16.6504854Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:16.6506193Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:16.6507505Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:16.6508382Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:16.6509064Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:16.6509717Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:16.6510385Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:25:16.6511071Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:25:16.6511783Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:25:16.6512472Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:25:16.6513159Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:25:16.6513869Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:25:16.6514560Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:25:16.6515239Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:25:16.6515948Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m 98/112[0m [huggingface-hub]
2026-01-14T08:25:16.6516661Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m100/112[0m [aiohttp]
2026-01-14T08:25:16.6517351Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m101/112[0m [tokenizers]
2026-01-14T08:25:16.6518050Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:25:16.6518754Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:25:16.6519637Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:25:16.6520337Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:25:16.6521035Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:25:16.6521729Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m103/112[0m [accelerate]
2026-01-14T08:25:16.6522519Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6523328Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6524023Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6524752Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6525456Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6526151Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6526853Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6527553Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6528325Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6529025Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6529724Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6530445Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6531139Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6531840Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6532546Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6533348Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6534051Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6534748Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6535543Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:16.6536246Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3649216Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3649991Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3650696Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3651434Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3652138Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3652836Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3653564Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3654260Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3654962Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3655667Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3656387Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3657096Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:25:22.3657778Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m105/112[0m [datasets]
2026-01-14T08:25:22.3658457Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m105/112[0m [datasets]
2026-01-14T08:25:22.3659393Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m108/112[0m [peft]
2026-01-14T08:25:22.3660060Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m109/112[0m [evaluate]
2026-01-14T08:25:22.3660709Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3661325Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3662107Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3662717Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3663333Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3663948Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3664571Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3665180Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3665785Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3666394Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3667027Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3667627Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3668240Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3668848Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3669527Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3670142Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3670740Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3671349Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3671955Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:25:22.3672645Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m112/112[0m [lm_eval]
2026-01-14T08:25:22.3673045Z [?25h
2026-01-14T08:32:47.5731974Z [1A[2KSuccessfully installed DataProperty-1.1.0 absl-py-2.3.1 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 anyio-4.12.1 async-timeout-5.0.1 attrs-25.4.0 bitsandbytes-0.49.1 blobfile-3.1.0 certifi-2026.1.4 cfgv-3.5.0 chardet-5.2.0 charset_normalizer-3.4.4 click-8.3.1 cmake-3.31.10 colorama-0.4.6 contourpy-1.3.2 cycler-0.12.1 datasets-4.4.2 dill-0.4.0 diskcache-5.6.3 distlib-0.4.0 evaluate-0.4.6 exceptiongroup-1.3.1 expecttest-0.3.0 fire-0.7.1 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 hypothesis-6.150.2 identify-2.6.16 idna-3.11 importlib_metadata-8.7.1 iniconfig-2.3.0 joblib-1.5.3 jsonlines-4.0.0 kiwisolver-1.4.9 lm_eval-0.4.9.2 lxml-6.0.2 matplotlib-3.10.8 mbstrdecoder-1.1.4 more_itertools-10.8.0 multidict-6.7.0 multiprocess-0.70.18 ninja-1.13.0 nltk-3.9.2 nodeenv-1.10.0 numexpr-2.14.1 numpy-2.2.6 packaging-25.0 pandas-2.3.3 parameterized-0.9.0 pathvalidate-3.3.1 peft-0.18.1 pillow-12.1.0 platformdirs-4.5.1 pluggy-1.6.0 portalocker-3.2.0 pre-commit-4.5.1 propcache-0.4.1 psutil-7.2.1 pyarrow-22.0.0 pybind11-3.0.1 pycocotools-2.0.11 pycryptodomex-3.23.0 pygments-2.19.2 pyparsing-3.3.1 pytablewriter-1.2.1 pytest-8.4.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 rouge-score-0.1.2 ruff-0.11.6 sacrebleu-2.6.0 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentencepiece-0.2.1 six-1.17.0 sortedcontainers-2.4.0 sqlitedict-2.1.0 tabledata-1.3.4 tabulate-0.9.0 tcolorpy-0.1.7 termcolor-3.3.0 threadpoolctl-3.6.0 tiktoken-0.12.0 tokenizers-0.22.2 tomli-2.4.0 tqdm-4.67.1 tqdm-multiprocess-0.0.11 transformers-4.57.5 typepy-1.3.4 tzdata-2025.3 unittest-xml-reporting-4.0.0 urllib3-2.6.3 virtualenv-20.36.1 word2number-1.1 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0 zstandard-0.25.0
2026-01-14T08:32:47.5742355Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:32:47.5744015Z [0m+ pip install . --no-build-isolation
2026-01-14T08:32:47.5744324Z Processing /pytorch/ao
2026-01-14T08:32:47.5744694Z   Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:32:47.5745160Z [?25hBuilding wheels for collected packages: torchao
2026-01-14T08:32:47.5745846Z   Building wheel for torchao (pyproject.toml) ... [?25l- \ | / - \ | / - \ | / - \ | / - \ done
2026-01-14T08:32:47.5747109Z [?25h  Created wheel for torchao: filename=torchao-0.16.0+gitb34f898-cp310-abi3-linux_x86_64.whl size=4848968 sha256=24e46b146bd763aa39a2cd191581e888dbadc150bbd8be8808b653bb22519d3a
2026-01-14T08:32:47.5748315Z   Stored in directory: /tmp/pip-ephem-wheel-cache-y64xxhn5/wheels/d2/8b/29/aa26bc7679794c5ecae292c3b064b585980cbedb836e694414
2026-01-14T08:32:47.5748960Z Successfully built torchao
2026-01-14T08:32:47.5749245Z Installing collected packages: torchao
2026-01-14T08:32:47.5749585Z Successfully installed torchao-0.16.0+gitb34f898
2026-01-14T08:32:47.5751455Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:32:47.5753057Z [0m++++ which conda
2026-01-14T08:32:47.5753301Z +++ dirname /opt/conda/condabin/conda
2026-01-14T08:32:47.5753599Z ++ dirname /opt/conda/condabin
2026-01-14T08:32:47.5753862Z + export CONDA=/opt/conda
2026-01-14T08:32:47.5754103Z + CONDA=/opt/conda
2026-01-14T08:32:47.5754814Z + export LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:32:47.5755632Z + LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:32:47.5756193Z + pytest test --verbose -s
2026-01-14T08:32:47.5756729Z [1m============================= test session starts ==============================[0m
2026-01-14T08:32:47.5757334Z platform linux -- Python 3.10.19, pytest-8.4.2, pluggy-1.6.0 -- /opt/conda/envs/venv/bin/python3.10
2026-01-14T08:32:47.5757835Z cachedir: .pytest_cache
2026-01-14T08:32:47.5758445Z hypothesis profile 'ci' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=(HealthCheck.too_slow,)
2026-01-14T08:32:47.5759110Z rootdir: /pytorch/ao
2026-01-14T08:32:47.5759357Z configfile: pyproject.toml
2026-01-14T08:32:47.5759648Z plugins: hypothesis-6.150.2, anyio-4.12.1
2026-01-14T08:32:47.5759999Z [1mcollecting ... [0m[1m
2026-01-14T08:32:47.5760436Z collecting 0 items                                                             [0m[1m
2026-01-14T08:32:47.5761006Z collecting 28 items                                                            [0m[1m
2026-01-14T08:32:47.5761575Z collecting 28 items                                                            [0m[1m
2026-01-14T08:32:47.5762153Z collecting 177 items                                                           [0m[1m
2026-01-14T08:32:47.5762817Z collecting 872 items / 3 skipped                                               [0m[1m
2026-01-14T08:32:47.5763439Z collecting 927 items / 5 skipped                                               [0m[1m
2026-01-14T08:32:47.5764059Z collecting 5155 items / 17 skipped                                             [0m[1m
2026-01-14T08:32:47.5764692Z collecting 5770 items / 17 skipped                                             [0m[1m
2026-01-14T08:32:47.5765312Z collecting 7848 items / 17 skipped                                             [0m[1m
2026-01-14T08:32:47.5765936Z collected 8953 items / 17 skipped                                              [0m
2026-01-14T08:32:47.5766265Z 
2026-01-14T08:32:47.5766667Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config0] [32mPASSED[0m
2026-01-14T08:32:47.5767434Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config1] [32mPASSED[0m
2026-01-14T08:32:47.5768206Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config2] [32mPASSED[0m
2026-01-14T08:32:47.5768957Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config3] [32mPASSED[0m
2026-01-14T08:32:47.5769726Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config4] [32mPASSED[0m
2026-01-14T08:32:47.5770478Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config5] [32mPASSED[0m
2026-01-14T08:32:47.5771247Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config6] [32mPASSED[0m
2026-01-14T08:32:47.5772005Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7] [32mPASSED[0m
2026-01-14T08:32:47.5772755Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config8] [32mPASSED[0m
2026-01-14T08:32:47.5773521Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config9] [32mPASSED[0m
2026-01-14T08:32:47.5774285Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config10] [32mPASSED[0m
2026-01-14T08:32:47.5775058Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config11] [32mPASSED[0m
2026-01-14T08:32:47.5775831Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config12] [32mPASSED[0m
2026-01-14T08:32:47.5776590Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config13] [32mPASSED[0m
2026-01-14T08:32:47.5777359Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14] [32mPASSED[0m
2026-01-14T08:32:47.5778214Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config15] [32mPASSED[0m
2026-01-14T08:32:47.5778987Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config16] [32mPASSED[0m
2026-01-14T08:32:47.5779750Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config17] [32mPASSED[0m
2026-01-14T08:32:47.5780597Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config18] [32mPASSED[0m
2026-01-14T08:32:47.5781368Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config19] [32mPASSED[0m
2026-01-14T08:32:47.5782130Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config20] [32mPASSED[0m
2026-01-14T08:32:47.5782898Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config21] [32mPASSED[0m
2026-01-14T08:32:47.5783643Z test/core/test_config.py::test_granularity_serialization[granularity0] [33mSKIPPED[0m
2026-01-14T08:32:47.5784374Z test/core/test_config.py::test_granularity_serialization[granularity1] [33mSKIPPED[0m
2026-01-14T08:32:47.5785101Z test/core/test_config.py::test_granularity_serialization[granularity2] [33mSKIPPED[0m
2026-01-14T08:32:47.5785737Z test/core/test_config.py::test_disallowed_modules [32mPASSED[0m
2026-01-14T08:32:47.5786284Z test/core/test_config.py::test_version_mismatch [32mPASSED[0m
2026-01-14T08:32:47.5786812Z test/core/test_config.py::test_default_version [32mPASSED[0m
2026-01-14T08:32:47.5787585Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant0 [32mPASSED[0m
2026-01-14T08:32:47.5788735Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant1 [32mPASSED[0m
2026-01-14T08:32:47.5789710Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant2 [32mPASSED[0m
2026-01-14T08:32:47.5790693Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant3 [32mPASSED[0m
2026-01-14T08:32:47.5791673Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant4 [32mPASSED[0m
2026-01-14T08:32:48.2646861Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_print_quantized_module [32mPASSED[0m
2026-01-14T08:32:48.2647795Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_register_new_dispatch [32mPASSED[0m
2026-01-14T08:32:48.2648741Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_tensor_core_layout_transpose [32mPASSED[0m
2026-01-14T08:32:48.2650045Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant0 [32mPASSED[0m
2026-01-14T08:32:48.2650992Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant1 [32mPASSED[0m
2026-01-14T08:32:48.2651921Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant2 [32mPASSED[0m
2026-01-14T08:32:48.2652865Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant3 [32mPASSED[0m
2026-01-14T08:32:48.2653855Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant4 [32mPASSED[0m
2026-01-14T08:32:48.2654953Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_affine_quantized_intx_static [32mPASSED[0m
2026-01-14T08:32:48.2655876Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant0 [32mPASSED[0m
2026-01-14T08:32:48.2657113Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant1 [32mPASSED[0m
2026-01-14T08:32:48.2658355Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant2 [32mPASSED[0m
2026-01-14T08:32:48.2659241Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant3 [32mPASSED[0m
2026-01-14T08:32:48.2660059Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_weights_only [32mPASSED[0m
2026-01-14T08:32:48.2661168Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_alias_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2662138Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_alias_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2663389Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2664774Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2665771Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_matmul_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2666693Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_mm_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2667674Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_and_copy_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2668690Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_cuda_bfloat16 [33mSKIPPED[0m
2026-01-14T08:32:48.2669668Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_cuda_float16 [33mSKIPPED[0m
2026-01-14T08:32:48.2670626Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2671788Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2673088Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_float32 [32mPASSED[0m
2026-01-14T08:32:48.2674359Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_bfloat16 [32mPASSED[0m
2026-01-14T08:32:48.2675635Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_float32 [32mPASSED[0m
2026-01-14T08:32:48.2677003Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size0 [32mPASSED[0m
2026-01-14T08:32:48.2678376Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size1 [32mPASSED[0m
2026-01-14T08:32:48.2679757Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size2 [32mPASSED[0m
2026-01-14T08:32:48.2681119Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size3 [32mPASSED[0m
2026-01-14T08:32:48.2682486Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size0 [32mPASSED[0m
2026-01-14T08:32:48.2683948Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size1 [32mPASSED[0m
2026-01-14T08:32:48.2685307Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size2 [32mPASSED[0m
2026-01-14T08:32:48.2686680Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size3 [32mPASSED[0m
2026-01-14T08:32:48.2688069Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size0 [32mPASSED[0m
2026-01-14T08:32:48.2689422Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size1 [32mPASSED[0m
2026-01-14T08:32:48.2690881Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size2 [32mPASSED[0m
2026-01-14T08:32:48.2692250Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size3 [32mPASSED[0m
2026-01-14T08:32:48.2693601Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size0 [32mPASSED[0m
2026-01-14T08:32:48.2695087Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size1 [32mPASSED[0m
2026-01-14T08:32:48.2696460Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size2 [32mPASSED[0m
2026-01-14T08:32:48.2697813Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size3 [32mPASSED[0m
2026-01-14T08:32:48.2699120Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_scale_broadcasting [32mPASSED[0m
2026-01-14T08:32:48.2700358Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity0 [33mSKIPPED[0m
2026-01-14T08:32:48.2701557Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity1 [33mSKIPPED[0m
2026-01-14T08:32:48.2702938Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:48.2704459Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:48.2705991Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:48.2707510Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:48.2709019Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:48.2710534Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:48.2712045Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:48.2713548Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:48.2715051Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:48.2716563Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:48.2718061Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:33:29.1215190Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:33:29.1218887Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:33:29.1221191Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:33:29.1223417Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:33:29.1226030Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:33:29.1228027Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_invalid_granularity [32mPASSED[0m
2026-01-14T08:33:29.1229690Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_mismatched_granularity [32mPASSED[0m
2026-01-14T08:33:29.1231392Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_per_row_with_float32 [33mSKIPPED[0m
2026-01-14T08:33:29.1233007Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_preprocess_scale_3d_reshape [32mPASSED[0m
2026-01-14T08:33:29.1234714Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:33:29.1236001Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:33:29.1236578Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:33:29.1237331Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:33:29.1238016Z graph_break []
2026-01-14T08:33:29.1238388Z [32mPASSED[0m
2026-01-14T08:33:29.1239898Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:33:29.1241197Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:33:29.1241947Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:33:29.1242846Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:33:29.1243336Z graph_break []
2026-01-14T08:33:29.1243707Z [32mPASSED[0m
2026-01-14T08:33:29.1244815Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:33:29.1246094Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:33:29.1246826Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:33:29.1247620Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:33:29.1248122Z graph_break []
2026-01-14T08:33:29.1248471Z [32mPASSED[0m
2026-01-14T08:33:29.1249606Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:33:29.1250873Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:33:29.1251611Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:33:29.1252407Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:33:29.1252909Z graph_break []
2026-01-14T08:33:29.1253263Z [32mPASSED[0m
2026-01-14T08:33:29.1254256Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_serialization_mode_static [33mSKIPPED[0m
2026-01-14T08:33:29.1255913Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_unsupported_granularity [32mPASSED[0m
2026-01-14T08:33:29.1258363Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_bfloat16 I0114 08:32:56.944000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 1363
2026-01-14T08:33:29.1260506Z I0114 08:32:56.945000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 1364
2026-01-14T08:33:29.1261871Z I0114 08:32:56.946000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 2 with pid 1365
2026-01-14T08:33:29.1263397Z I0114 08:32:56.947000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 3 with pid 1366
2026-01-14T08:33:29.1265659Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1267444Z   warnings.warn(
2026-01-14T08:33:29.1269164Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1270941Z   warnings.warn(
2026-01-14T08:33:29.1272595Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1274370Z   warnings.warn(
2026-01-14T08:33:29.1276041Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1277802Z   warnings.warn(
2026-01-14T08:33:29.1278172Z [32mPASSED[0m
2026-01-14T08:33:29.1279744Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float16 I0114 08:33:11.575000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 3740
2026-01-14T08:33:29.1281828Z I0114 08:33:11.576000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 3741
2026-01-14T08:33:29.1283259Z I0114 08:33:11.577000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 2 with pid 3742
2026-01-14T08:33:29.1284533Z I0114 08:33:11.578000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 3 with pid 3743
2026-01-14T08:33:29.1286642Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1288311Z   warnings.warn(
2026-01-14T08:33:29.1289858Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1291517Z   warnings.warn(
2026-01-14T08:33:29.1293092Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1294772Z   warnings.warn(
2026-01-14T08:33:29.1296336Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1298009Z   warnings.warn(
2026-01-14T08:33:29.1298492Z [32mPASSED[0m
2026-01-14T08:33:29.1299935Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float32 I0114 08:33:25.105000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 6084
2026-01-14T08:33:29.1301917Z I0114 08:33:25.106000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 6085
2026-01-14T08:33:29.1303328Z I0114 08:33:25.107000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 2 with pid 6086
2026-01-14T08:33:29.1304628Z I0114 08:33:25.108000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 3 with pid 6087
2026-01-14T08:33:29.1306749Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1308416Z   warnings.warn(
2026-01-14T08:33:29.1309976Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:29.1311670Z   warnings.warn(
2026-01-14T08:33:53.1176139Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:53.1177677Z   warnings.warn(
2026-01-14T08:33:53.1178890Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:53.1180086Z   warnings.warn(
2026-01-14T08:33:53.1180526Z [32mPASSED[0m
2026-01-14T08:33:53.1181284Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt4woAffineQuantizedTensorParallel::test_tp_bfloat16 [33mSKIPPED[0m
2026-01-14T08:33:53.1182430Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestGemliteLayoutTensorParallel::test_tp_gemlite_float16 [33mSKIPPED[0m
2026-01-14T08:33:53.1183883Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8dqAffineQuantizedTensorParallel::test_tp_bfloat16 I0114 08:33:38.938000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 8489
2026-01-14T08:33:53.1185268Z I0114 08:33:38.939000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 8490
2026-01-14T08:33:53.1186179Z I0114 08:33:38.941000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 2 with pid 8491
2026-01-14T08:33:53.1187085Z I0114 08:33:38.942000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 3 with pid 8492
2026-01-14T08:33:53.1187703Z [32mPASSED[0m
2026-01-14T08:33:53.1188086Z test/dtypes/test_bitpacking.py::test_CPU[0-1] [32mPASSED[0m
2026-01-14T08:33:53.1188609Z test/dtypes/test_bitpacking.py::test_CPU[0-2] [32mPASSED[0m
2026-01-14T08:33:53.1189140Z test/dtypes/test_bitpacking.py::test_CPU[0-3] [32mPASSED[0m
2026-01-14T08:33:53.1189654Z test/dtypes/test_bitpacking.py::test_CPU[0-4] [32mPASSED[0m
2026-01-14T08:33:53.1190173Z test/dtypes/test_bitpacking.py::test_CPU[0-5] [32mPASSED[0m
2026-01-14T08:33:53.1190690Z test/dtypes/test_bitpacking.py::test_CPU[0-6] [32mPASSED[0m
2026-01-14T08:33:53.1191209Z test/dtypes/test_bitpacking.py::test_CPU[0-7] [32mPASSED[0m
2026-01-14T08:33:53.1191734Z test/dtypes/test_bitpacking.py::test_CPU[-1-1] [32mPASSED[0m
2026-01-14T08:33:53.1192260Z test/dtypes/test_bitpacking.py::test_CPU[-1-2] [32mPASSED[0m
2026-01-14T08:33:53.1193289Z test/dtypes/test_bitpacking.py::test_CPU[-1-3] [32mPASSED[0m
2026-01-14T08:33:53.1193818Z test/dtypes/test_bitpacking.py::test_CPU[-1-4] [32mPASSED[0m
2026-01-14T08:33:53.1194340Z test/dtypes/test_bitpacking.py::test_CPU[-1-5] [32mPASSED[0m
2026-01-14T08:33:53.1194863Z test/dtypes/test_bitpacking.py::test_CPU[-1-6] [32mPASSED[0m
2026-01-14T08:33:53.1195565Z test/dtypes/test_bitpacking.py::test_CPU[-1-7] [32mPASSED[0m
2026-01-14T08:33:53.1196185Z test/dtypes/test_bitpacking.py::test_CPU[1-1] [32mPASSED[0m
2026-01-14T08:33:53.1196827Z test/dtypes/test_bitpacking.py::test_CPU[1-2] [32mPASSED[0m
2026-01-14T08:33:53.1197463Z test/dtypes/test_bitpacking.py::test_CPU[1-3] [32mPASSED[0m
2026-01-14T08:33:53.1198093Z test/dtypes/test_bitpacking.py::test_CPU[1-4] [32mPASSED[0m
2026-01-14T08:33:53.1198731Z test/dtypes/test_bitpacking.py::test_CPU[1-5] [32mPASSED[0m
2026-01-14T08:33:53.1199368Z test/dtypes/test_bitpacking.py::test_CPU[1-6] [32mPASSED[0m
2026-01-14T08:33:53.1200006Z test/dtypes/test_bitpacking.py::test_CPU[1-7] [32mPASSED[0m
2026-01-14T08:33:53.1200635Z test/dtypes/test_bitpacking.py::test_GPU[0-1] [32mPASSED[0m
2026-01-14T08:33:53.1201261Z test/dtypes/test_bitpacking.py::test_GPU[0-2] [32mPASSED[0m
2026-01-14T08:33:53.1201890Z test/dtypes/test_bitpacking.py::test_GPU[0-3] [32mPASSED[0m
2026-01-14T08:33:53.1202633Z test/dtypes/test_bitpacking.py::test_GPU[0-4] [32mPASSED[0m
2026-01-14T08:33:53.1203283Z test/dtypes/test_bitpacking.py::test_GPU[0-5] [32mPASSED[0m
2026-01-14T08:33:53.1203917Z test/dtypes/test_bitpacking.py::test_GPU[0-6] [32mPASSED[0m
2026-01-14T08:33:53.1204538Z test/dtypes/test_bitpacking.py::test_GPU[0-7] [32mPASSED[0m
2026-01-14T08:33:53.1205178Z test/dtypes/test_bitpacking.py::test_GPU[-1-1] [32mPASSED[0m
2026-01-14T08:33:53.1205813Z test/dtypes/test_bitpacking.py::test_GPU[-1-2] [32mPASSED[0m
2026-01-14T08:33:53.1206462Z test/dtypes/test_bitpacking.py::test_GPU[-1-3] [32mPASSED[0m
2026-01-14T08:33:53.1207102Z test/dtypes/test_bitpacking.py::test_GPU[-1-4] [32mPASSED[0m
2026-01-14T08:33:53.1207749Z test/dtypes/test_bitpacking.py::test_GPU[-1-5] [32mPASSED[0m
2026-01-14T08:33:53.1208384Z test/dtypes/test_bitpacking.py::test_GPU[-1-6] [32mPASSED[0m
2026-01-14T08:33:53.1209026Z test/dtypes/test_bitpacking.py::test_GPU[-1-7] [32mPASSED[0m
2026-01-14T08:33:53.1209667Z test/dtypes/test_bitpacking.py::test_GPU[1-1] [32mPASSED[0m
2026-01-14T08:33:53.1210301Z test/dtypes/test_bitpacking.py::test_GPU[1-2] [32mPASSED[0m
2026-01-14T08:33:53.1210932Z test/dtypes/test_bitpacking.py::test_GPU[1-3] [32mPASSED[0m
2026-01-14T08:33:53.1211556Z test/dtypes/test_bitpacking.py::test_GPU[1-4] [32mPASSED[0m
2026-01-14T08:33:53.1212186Z test/dtypes/test_bitpacking.py::test_GPU[1-5] [32mPASSED[0m
2026-01-14T08:33:53.1212806Z test/dtypes/test_bitpacking.py::test_GPU[1-6] [32mPASSED[0m
2026-01-14T08:33:53.1213435Z test/dtypes/test_bitpacking.py::test_GPU[1-7] [32mPASSED[0m
2026-01-14T08:33:53.1214093Z test/dtypes/test_bitpacking.py::test_compile[0-1] [32mPASSED[0m
2026-01-14T08:33:53.1214774Z test/dtypes/test_bitpacking.py::test_compile[0-2] [32mPASSED[0m
2026-01-14T08:33:53.1215458Z test/dtypes/test_bitpacking.py::test_compile[0-3] [32mPASSED[0m
2026-01-14T08:33:53.1216127Z test/dtypes/test_bitpacking.py::test_compile[0-4] [32mPASSED[0m
2026-01-14T08:33:53.1216809Z test/dtypes/test_bitpacking.py::test_compile[0-5] [32mPASSED[0m
2026-01-14T08:33:53.1217485Z test/dtypes/test_bitpacking.py::test_compile[0-6] [32mPASSED[0m
2026-01-14T08:33:53.1218162Z test/dtypes/test_bitpacking.py::test_compile[0-7] [32mPASSED[0m
2026-01-14T08:33:53.1218851Z test/dtypes/test_bitpacking.py::test_compile[-1-1] [32mPASSED[0m
2026-01-14T08:33:53.1219534Z test/dtypes/test_bitpacking.py::test_compile[-1-2] [32mPASSED[0m
2026-01-14T08:33:53.1220221Z test/dtypes/test_bitpacking.py::test_compile[-1-3] [32mPASSED[0m
2026-01-14T08:33:53.1220902Z test/dtypes/test_bitpacking.py::test_compile[-1-4] [32mPASSED[0m
2026-01-14T08:33:53.1221743Z test/dtypes/test_bitpacking.py::test_compile[-1-5] [32mPASSED[0m
2026-01-14T08:33:53.1222431Z test/dtypes/test_bitpacking.py::test_compile[-1-6] [32mPASSED[0m
2026-01-14T08:33:53.1223119Z test/dtypes/test_bitpacking.py::test_compile[-1-7] [32mPASSED[0m
2026-01-14T08:33:53.1223813Z test/dtypes/test_bitpacking.py::test_compile[1-1] [32mPASSED[0m
2026-01-14T08:33:53.1224499Z test/dtypes/test_bitpacking.py::test_compile[1-2] [32mPASSED[0m
2026-01-14T08:33:53.1225392Z test/dtypes/test_bitpacking.py::test_compile[1-3] [32mPASSED[0m
2026-01-14T08:33:53.1226063Z test/dtypes/test_bitpacking.py::test_compile[1-4] [32mPASSED[0m
2026-01-14T08:33:53.1226745Z test/dtypes/test_bitpacking.py::test_compile[1-5] [32mPASSED[0m
2026-01-14T08:33:53.1227415Z test/dtypes/test_bitpacking.py::test_compile[1-6] [32mPASSED[0m
2026-01-14T08:33:53.1228100Z test/dtypes/test_bitpacking.py::test_compile[1-7] [32mPASSED[0m
2026-01-14T08:33:53.1229150Z test/dtypes/test_bitpacking.py::test_pack_example tensor([  0, 105, 151,  37], device='cuda:0', dtype=torch.uint8) tensor([ 39, 146], device='cuda:0', dtype=torch.uint8)
2026-01-14T08:33:53.1230097Z [32mPASSED[0m
2026-01-14T08:33:53.1230800Z test/dtypes/test_bitpacking.py::test_pack_example_CPU tensor([  0, 105, 151,  37], dtype=torch.uint8) tensor([ 39, 146], dtype=torch.uint8)
2026-01-14T08:33:53.1231621Z [32mPASSED[0m
2026-01-14T08:33:53.1232225Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:33:53.1240931Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:33:53.1241953Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:33:53.1243109Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:53.1244296Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:53.1245487Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:53.1246672Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:53.1247849Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:53.1249043Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:53.1250210Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:53.1251381Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:53.1252550Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:53.1253715Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:53.1254886Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:53.1256045Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:53.1257221Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:53.1258396Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:53.1259552Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:53.1260722Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:53.1262116Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:53.1263296Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:34:02.7141446Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size0 [32mPASSED[0m
2026-01-14T08:34:02.7142204Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size1 [32mPASSED[0m
2026-01-14T08:34:02.7143263Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:34:02.7144044Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float16 [32mPASSED[0m
2026-01-14T08:34:02.7144821Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float32 [32mPASSED[0m
2026-01-14T08:34:02.7145589Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:34:02.7146362Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float16 [32mPASSED[0m
2026-01-14T08:34:02.7147126Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float32 [32mPASSED[0m
2026-01-14T08:34:02.7147891Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_bfloat16 [32mPASSED[0m
2026-01-14T08:34:02.7148643Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float16 [32mPASSED[0m
2026-01-14T08:34:02.7149400Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float32 [32mPASSED[0m
2026-01-14T08:34:02.7150135Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_bfloat16 [33mSKIPPED[0m
2026-01-14T08:34:02.7150846Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float16 [33mSKIPPED[0m
2026-01-14T08:34:02.7151555Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float32 [33mSKIPPED[0m
2026-01-14T08:34:02.7152269Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:34:02.7153012Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:34:02.7153742Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:34:02.7154463Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_False [32mPASSED[0m
2026-01-14T08:34:02.7155190Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_True [32mPASSED[0m
2026-01-14T08:34:02.7155981Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_bfloat16 [33mSKIPPED[0m
2026-01-14T08:34:02.7156811Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float16 [33mSKIPPED[0m
2026-01-14T08:34:02.7157646Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float32 [33mSKIPPED[0m
2026-01-14T08:34:02.7158427Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_bfloat16 [32mPASSED[0m
2026-01-14T08:34:02.7159188Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float16 [32mPASSED[0m
2026-01-14T08:34:02.7159939Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float32 [32mPASSED[0m
2026-01-14T08:34:02.7160681Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_bfloat16 [32mPASSED[0m
2026-01-14T08:34:02.7161405Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_bfloat16 AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:34:02.7161959Z strides: [32, 1], [1, 32]
2026-01-14T08:34:02.7162244Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:34:02.7163071Z   triton_mm_10 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:34:02.7164258Z   triton_mm_11 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:34:02.7165593Z   triton_mm_0 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:34:02.7166749Z   triton_mm_1 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:34:02.7167904Z   triton_mm_2 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:34:02.7169141Z   triton_mm_3 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:34:02.7170290Z   triton_mm_4 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:34:02.7171451Z   triton_mm_5 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:34:02.7172607Z   triton_mm_6 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:34:02.7173755Z   triton_mm_7 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:34:02.7174746Z SingleProcess AUTOTUNE benchmarking takes 0.1586 seconds and 0.3683 seconds precompiling for 13 choices
2026-01-14T08:34:02.7175334Z [32mPASSED[0m
2026-01-14T08:34:02.7175811Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float16 AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:34:02.7176357Z strides: [32, 1], [1, 32]
2026-01-14T08:34:02.7176634Z dtypes: torch.float16, torch.float16
2026-01-14T08:34:02.7177392Z   triton_mm_16 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:34:02.7178630Z   triton_mm_19 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:34:02.7179809Z   triton_mm_20 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:34:02.7180982Z   triton_mm_17 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:34:02.7182143Z   triton_mm_18 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:34:02.7183321Z   triton_mm_21 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:34:02.7184490Z   triton_mm_22 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:34:02.7185651Z   triton_mm_23 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:34:02.7186816Z   triton_mm_15 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:34:02.7187979Z   triton_mm_12 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:34:02.7189041Z SingleProcess AUTOTUNE benchmarking takes 0.2835 seconds and 0.2776 seconds precompiling for 13 choices
2026-01-14T08:34:02.7189629Z [32mPASSED[0m
2026-01-14T08:34:02.7190090Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float32 AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:34:02.7190630Z strides: [32, 1], [1, 32]
2026-01-14T08:34:02.7190898Z dtypes: torch.float32, torch.float32
2026-01-14T08:34:02.7191724Z   triton_mm_25 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:34:02.7192915Z   triton_mm_29 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:34:02.7194099Z   triton_mm_30 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:34:02.7195295Z   triton_mm_32 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:34:02.7196482Z   triton_mm_33 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:34:02.7197668Z   triton_mm_34 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:34:02.7198848Z   triton_mm_35 0.0245 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:34:02.7200030Z   triton_mm_28 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:34:29.8858420Z   triton_mm_24 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:34:29.8861189Z   triton_mm_26 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:34:29.8862530Z SingleProcess AUTOTUNE benchmarking takes 0.1557 seconds and 0.1916 seconds precompiling for 13 choices
2026-01-14T08:34:29.8863452Z [32mPASSED[0m
2026-01-14T08:34:29.8864054Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float16 [32mPASSED[0m
2026-01-14T08:34:29.8864932Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float32 [32mPASSED[0m
2026-01-14T08:34:29.8865762Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16 [32mPASSED[0m
2026-01-14T08:34:29.8866538Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_device [32mPASSED[0m
2026-01-14T08:34:29.8867313Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16 [32mPASSED[0m
2026-01-14T08:34:29.8868096Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32 [32mPASSED[0m
2026-01-14T08:34:29.8868883Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_bfloat16 [32mPASSED[0m
2026-01-14T08:34:29.8869664Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float16 [32mPASSED[0m
2026-01-14T08:34:29.8870465Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float32 [32mPASSED[0m
2026-01-14T08:34:29.8871216Z test/dtypes/test_nf4.py::TestFSDPOps::test_pin_memory [32mPASSED[0m
2026-01-14T08:34:29.8872048Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_2d_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:34:29.8873019Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:34:29.8873998Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:34:29.8876708Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size1 [32mPASSED[0m
2026-01-14T08:34:29.8877690Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size2 [32mPASSED[0m
2026-01-14T08:34:29.8878693Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:34:29.8879815Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size1 [32mPASSED[0m
2026-01-14T08:34:29.8880698Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size2 [32mPASSED[0m
2026-01-14T08:34:29.8881618Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size_262144 [32mPASSED[0m
2026-01-14T08:34:29.8882662Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:34:29.8883640Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size2 [32mPASSED[0m
2026-01-14T08:34:29.8884647Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size_262144 [32mPASSED[0m
2026-01-14T08:34:29.8885642Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size1 [32mPASSED[0m
2026-01-14T08:34:29.8886593Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size2 [32mPASSED[0m
2026-01-14T08:34:29.8887569Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:34:29.8888502Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_1d_invalid [32mPASSED[0m
2026-01-14T08:34:29.8889334Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_2d_invalid [32mPASSED[0m
2026-01-14T08:34:29.8890204Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size1 [32mPASSED[0m
2026-01-14T08:34:29.8891111Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size2 [32mPASSED[0m
2026-01-14T08:34:29.8892043Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:34:29.8892995Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:34:29.8893894Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:34:29.8894793Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size1 [32mPASSED[0m
2026-01-14T08:34:29.8895590Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cpu [32mPASSED[0m
2026-01-14T08:34:29.8896267Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cuda [32mPASSED[0m
2026-01-14T08:34:29.8896961Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_module [32mPASSED[0m
2026-01-14T08:34:29.8897783Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_3d_input_size0 [32mPASSED[0m
2026-01-14T08:34:29.8898757Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size1 [32mPASSED[0m
2026-01-14T08:34:29.8899746Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size2 [32mPASSED[0m
2026-01-14T08:34:29.8900789Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size_261632 [32mPASSED[0m
2026-01-14T08:34:29.8901771Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size1 [32mPASSED[0m
2026-01-14T08:34:29.8902664Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size2 [32mPASSED[0m
2026-01-14T08:34:29.8903599Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:34:29.8904879Z test/dtypes/test_nf4.py::TestQLoRA::test_qlora_fsdp2 I0114 08:34:05.306000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 12113
2026-01-14T08:34:29.8906389Z I0114 08:34:05.308000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 12114
2026-01-14T08:34:29.8907004Z dist init r=1, world=2
2026-01-14T08:34:29.8907240Z dist init r=0, world=2
2026-01-14T08:34:29.8908264Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:34:29.8909239Z   warnings.warn(  # warn only once
2026-01-14T08:34:29.8910189Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:34:29.8911631Z   warnings.warn(  # warn only once
2026-01-14T08:34:29.8912030Z [32mPASSED[0m
2026-01-14T08:34:29.8912994Z test/dtypes/test_nf4.py::TestComm::test_comm I0114 08:34:16.629000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 12528
2026-01-14T08:34:29.8914365Z I0114 08:34:16.630000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 12529
2026-01-14T08:34:29.8915129Z dist init r=0, world=2
2026-01-14T08:34:29.8915421Z dist init r=1, world=2
2026-01-14T08:34:29.8916560Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:34:29.8917842Z   warnings.warn(  # warn only once
2026-01-14T08:34:29.8919040Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:34:29.8920264Z   warnings.warn(  # warn only once
2026-01-14T08:34:29.8920636Z [32mPASSED[0m
2026-01-14T08:34:29.8921261Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype0] [32mPASSED[0m
2026-01-14T08:34:29.8922246Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype1] [32mPASSED[0m
2026-01-14T08:34:29.8923341Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype2] [32mPASSED[0m
2026-01-14T08:34:29.8924310Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype3] [32mPASSED[0m
2026-01-14T08:34:29.8925269Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype4] [32mPASSED[0m
2026-01-14T08:34:29.8926285Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype5] [32mPASSED[0m
2026-01-14T08:34:29.8927252Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype6] [32mPASSED[0m
2026-01-14T08:34:29.8928206Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype0] [32mPASSED[0m
2026-01-14T08:34:29.8929166Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype1] [32mPASSED[0m
2026-01-14T08:34:29.8930120Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype2] [32mPASSED[0m
2026-01-14T08:34:29.8931088Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype3] [32mPASSED[0m
2026-01-14T08:34:29.8932109Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype4] [32mPASSED[0m
2026-01-14T08:34:29.8933103Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype5] [32mPASSED[0m
2026-01-14T08:34:29.8934070Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype6] [32mPASSED[0m
2026-01-14T08:34:29.8935054Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype0] [32mPASSED[0m
2026-01-14T08:34:29.8936038Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype1] [32mPASSED[0m
2026-01-14T08:34:29.8937014Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype2] [32mPASSED[0m
2026-01-14T08:34:29.8937978Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype3] [32mPASSED[0m
2026-01-14T08:34:29.8939168Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype4] [32mPASSED[0m
2026-01-14T08:34:29.8940330Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype5] [32mPASSED[0m
2026-01-14T08:34:29.8941317Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype6] [32mPASSED[0m
2026-01-14T08:34:29.8942278Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0908869Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0911040Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0911851Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0912619Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0913368Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0914153Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0914909Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0915660Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0916414Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0917175Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0917928Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0918756Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0919504Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0920272Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0921033Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0921797Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0922560Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0923433Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0924195Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0924952Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0925735Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0926533Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0927323Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0928111Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0928889Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0929686Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0930477Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0931257Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0932048Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0932833Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0933933Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0934719Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0935501Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0936450Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0937226Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0938020Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0938799Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0939968Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0940772Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0941555Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0942348Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0943095Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0943802Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0944500Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0945190Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0945887Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0946586Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0947285Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0948004Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0948728Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0949429Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0950124Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0950821Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0951510Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0952211Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0952919Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0953620Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0954329Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0955022Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0955732Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0956442Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0957143Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0957866Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0958601Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0959468Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0960203Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0960935Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0961661Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0962552Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0963350Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0964084Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0964821Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0965562Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0966287Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0967021Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0967750Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0968495Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0969245Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0969985Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0970729Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0971465Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0972212Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0972956Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype6] [32mPASSED[0m
2026-01-14T08:36:23.0973627Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype0] [32mPASSED[0m
2026-01-14T08:36:23.0974240Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype1] [32mPASSED[0m
2026-01-14T08:36:23.0974849Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype2] [32mPASSED[0m
2026-01-14T08:36:23.0975456Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype3] [32mPASSED[0m
2026-01-14T08:36:23.0976055Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype4] [32mPASSED[0m
2026-01-14T08:36:23.0976658Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype5] [32mPASSED[0m
2026-01-14T08:36:23.0977267Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype6] [32mPASSED[0m
2026-01-14T08:37:14.8001722Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype0] [32mPASSED[0m
2026-01-14T08:37:14.8004284Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype1] [32mPASSED[0m
2026-01-14T08:37:14.8005048Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype2] [32mPASSED[0m
2026-01-14T08:37:14.8005742Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype3] [32mPASSED[0m
2026-01-14T08:37:14.8006439Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype4] [32mPASSED[0m
2026-01-14T08:37:14.8007121Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype5] [32mPASSED[0m
2026-01-14T08:37:14.8007796Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype6] [32mPASSED[0m
2026-01-14T08:37:14.8008461Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype0] [32mPASSED[0m
2026-01-14T08:37:14.8009064Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype1] [32mPASSED[0m
2026-01-14T08:37:14.8009678Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype2] [32mPASSED[0m
2026-01-14T08:37:14.8010653Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype3] [32mPASSED[0m
2026-01-14T08:37:14.8011268Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype4] [32mPASSED[0m
2026-01-14T08:37:14.8011882Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype5] [32mPASSED[0m
2026-01-14T08:37:14.8012491Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype6] [32mPASSED[0m
2026-01-14T08:37:14.8013265Z test/dtypes/test_uintx.py::test_uintx_api_deprecation [32mPASSED[0m
2026-01-14T08:37:14.8014138Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims0-valid.layer-filter_fqns0-True] [32mPASSED[0m
2026-01-14T08:37:14.8015280Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims1-skip_layer.linear-filter_fqns1-False] [32mPASSED[0m
2026-01-14T08:37:14.8016417Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims2-valid.layer-filter_fqns2-False] [32mPASSED[0m
2026-01-14T08:37:14.8017517Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims3-valid.layer-filter_fqns3-True] [32mPASSED[0m
2026-01-14T08:37:14.8018620Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims4-skip_layer.linear-filter_fqns4-False] [32mPASSED[0m
2026-01-14T08:37:14.8019734Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims5-valid.layer-filter_fqns5-False] [32mPASSED[0m
2026-01-14T08:37:14.8020636Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_rowwise [32mPASSED[0m
2026-01-14T08:37:14.8021388Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_tensorwise [32mPASSED[0m
2026-01-14T08:37:14.8022074Z test/float8/test_auto_filter.py::test_partial_fqn_matching [32mPASSED[0m
2026-01-14T08:37:14.8022776Z test/float8/test_base.py::TestFloat8TrainingTensor::test_preserves_dtype [32mPASSED[0m
2026-01-14T08:37:14.8023559Z test/float8/test_base.py::TestFloat8TrainingTensor::test_differentiable_casts [32mPASSED[0m
2026-01-14T08:37:14.8024323Z test/float8/test_base.py::TestFloat8TrainingTensor::test_split_cat [32mPASSED[0m
2026-01-14T08:37:14.8025032Z test/float8/test_base.py::TestFloat8TrainingTensor::test_index_put [32mPASSED[0m
2026-01-14T08:37:14.8025722Z test/float8/test_base.py::TestFloat8TrainingTensor::test_copy_ [32mPASSED[0m
2026-01-14T08:37:14.8026409Z test/float8/test_base.py::TestFloat8TrainingTensor::test_transpose [32mPASSED[0m
2026-01-14T08:37:14.8027247Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape0] [32mPASSED[0m
2026-01-14T08:37:14.8028185Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape1] [32mPASSED[0m
2026-01-14T08:37:14.8029122Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape2] [32mPASSED[0m
2026-01-14T08:37:14.8030068Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape0] [32mPASSED[0m
2026-01-14T08:37:14.8031019Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape1] [32mPASSED[0m
2026-01-14T08:37:14.8031956Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape2] [32mPASSED[0m
2026-01-14T08:37:14.8032899Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape0] [32mPASSED[0m
2026-01-14T08:37:14.8033843Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape1] [32mPASSED[0m
2026-01-14T08:37:14.8034779Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape2] [32mPASSED[0m
2026-01-14T08:37:14.8035729Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape0] [32mPASSED[0m
2026-01-14T08:37:14.8036678Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape1] [32mPASSED[0m
2026-01-14T08:37:14.8037718Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape2] [32mPASSED[0m
2026-01-14T08:37:14.8038581Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_reshape [32mPASSED[0m
2026-01-14T08:37:14.8040073Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:37:14.8041632Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:37:14.8043156Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:37:14.8044570Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:37:14.8046014Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:37:14.8047445Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:37:14.8055836Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:37:14.8057296Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:37:14.8058737Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:37:14.8059799Z test/float8/test_base.py::TestFloat8TrainingTensor::test_fp8_dtype [32mPASSED[0m
2026-01-14T08:37:14.8061105Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:14.8062872Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:14.8064653Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:14.8066416Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:14.8068171Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:14.8069933Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:14.8071680Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:14.8073482Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:14.8075225Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:14.8077180Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:14.8078944Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:14.8080699Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:14.8082529Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:15.0190560Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:15.0192355Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:15.0194097Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:15.0195858Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:15.0197614Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:15.0199365Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:15.0201154Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:15.0202985Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:15.0204748Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:15.0206511Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:15.0208287Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:15.0209795Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0211142Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0212474Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0213800Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0215135Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0216633Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0217972Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0219329Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0220780Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0222125Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0223525Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0224868Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0226204Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0227545Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0228872Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0230213Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0231555Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0232890Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0234232Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0235578Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0236921Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0238273Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0239785Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0241134Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0242469Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0243835Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0245162Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0246497Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0247953Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0249299Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0250732Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0252082Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0253478Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0254821Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0256164Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:15.0257518Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:15.0258830Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:37:15.0260060Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:37:15.0261274Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:37:15.0262483Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:37:21.2462230Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:37:21.2463654Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:37:21.2464911Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:37:21.2466152Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:37:21.2467394Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:37:21.2468291Z test/float8/test_base.py::TestFloat8Linear::test_repr [32mPASSED[0m
2026-01-14T08:37:21.2468960Z test/float8/test_base.py::TestFloat8Linear::test_inference_mode [33mSKIPPED[0m
2026-01-14T08:37:21.2469654Z test/float8/test_base.py::TestFloat8Linear::test_quantize [33mSKIPPED[0m (C...)
2026-01-14T08:37:21.2470419Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:37:21.2471271Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:37:21.2472114Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:37:21.2472960Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:37:21.2473813Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:37:21.2474669Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:37:21.2475711Z test/float8/test_base.py::TestScaledMM::test_different_configs_error [33mSKIPPED[0m
2026-01-14T08:37:21.2476478Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:37:21.2477263Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:37:21.2478046Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:37:21.2478964Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:37:21.2479751Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:37:21.2480527Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:37:21.2481307Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype0] [32mPASSED[0m
2026-01-14T08:37:21.2482084Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype1] [32mPASSED[0m
2026-01-14T08:37:21.2482944Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype2] [32mPASSED[0m
2026-01-14T08:37:21.2483729Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype3] [32mPASSED[0m
2026-01-14T08:37:21.2484509Z test/float8/test_base.py::TestFloat8LinearUtils::test_fp8_tensor_statistics [32mPASSED[0m
2026-01-14T08:37:21.2485326Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_linears_with_filters [32mPASSED[0m
2026-01-14T08:37:21.2486093Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear [32mPASSED[0m
2026-01-14T08:37:21.2486936Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear_with_children_raises [32mPASSED[0m
2026-01-14T08:37:21.2487784Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears [32mPASSED[0m
2026-01-14T08:37:21.2488618Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears_with_skip [32mPASSED[0m
2026-01-14T08:37:21.2489733Z test/float8/test_compile.py::test_eager_only[dtype0-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [32mPASSED[0m
2026-01-14T08:37:21.2491064Z test/float8/test_compile.py::test_eager_only[dtype1-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [32mPASSED[0m
2026-01-14T08:37:21.2492380Z test/float8/test_compile.py::test_aot_eager[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [32mPASSED[0m
2026-01-14T08:37:21.2493688Z test/float8/test_compile.py::test_aot_eager[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [32mPASSED[0m
2026-01-14T08:37:21.2495102Z test/float8/test_compile.py::test_inductor_from_config_params[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:37:21.2496607Z test/float8/test_compile.py::test_inductor_from_config_params[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:37:21.2497784Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:21.2498735Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:21.2499594Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_input [33mSKIPPED[0m
2026-01-14T08:37:21.2500342Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_output [33mSKIPPED[0m
2026-01-14T08:37:21.2501170Z test/float8/test_compile.py::TestGraphBreaks::test_float8_with_graph_break_in_the_middle [33mSKIPPED[0m
2026-01-14T08:37:21.2501990Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype0] [33mSKIPPED[0m
2026-01-14T08:37:21.2502764Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype1] [33mSKIPPED[0m
2026-01-14T08:37:21.2503528Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype2] [33mSKIPPED[0m
2026-01-14T08:37:21.2504399Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype0] [33mSKIPPED[0m
2026-01-14T08:37:21.2505214Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype1] [33mSKIPPED[0m
2026-01-14T08:37:21.2506011Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype2] [33mSKIPPED[0m
2026-01-14T08:37:21.2506943Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case0] [32mPASSED[0m
2026-01-14T08:37:21.2507833Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case1] [32mPASSED[0m
2026-01-14T08:37:21.2508737Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case2] [32mPASSED[0m
2026-01-14T08:37:21.2509629Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case3] [32mPASSED[0m
2026-01-14T08:37:21.2510525Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case4] [32mPASSED[0m
2026-01-14T08:37:21.2511421Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case5] [32mPASSED[0m
2026-01-14T08:37:21.2512306Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case6] [32mPASSED[0m
2026-01-14T08:37:21.2513202Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case7] [32mPASSED[0m
2026-01-14T08:37:21.2514011Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype0] [32mPASSED[0m
2026-01-14T08:37:21.2514735Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype1] [32mPASSED[0m
2026-01-14T08:37:21.2515462Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype2] [32mPASSED[0m
2026-01-14T08:37:21.2516182Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype3] [32mPASSED[0m
2026-01-14T08:37:21.2516913Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype4] [32mPASSED[0m
2026-01-14T08:37:21.2517625Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype5] [32mPASSED[0m
2026-01-14T08:37:21.2518352Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype6] [32mPASSED[0m
2026-01-14T08:37:21.2519073Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype7] [32mPASSED[0m
2026-01-14T08:37:21.2520365Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_config_params[ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC] [33mSKIPPED[0m
2026-01-14T08:37:21.2521947Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:21.2523466Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:21.2524496Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_2bit [32mPASSED[0m
2026-01-14T08:37:21.2525114Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_3bit [32mPASSED[0m
2026-01-14T08:37:21.2525721Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_4bit [32mPASSED[0m
2026-01-14T08:37:21.2526331Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_5bit [32mPASSED[0m
2026-01-14T08:37:21.2526946Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_6bit [32mPASSED[0m
2026-01-14T08:37:21.2527553Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_7bit [32mPASSED[0m
2026-01-14T08:37:21.2528159Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_8bit [32mPASSED[0m
2026-01-14T08:37:21.2528855Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm AUTOTUNE int_mm(32x32, 32x16)
2026-01-14T08:37:21.2529434Z strides: [32, 1], [16, 1]
2026-01-14T08:37:21.2529692Z dtypes: torch.int8, torch.int8
2026-01-14T08:37:21.2530530Z   triton_mm_37 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=2
2026-01-14T08:37:32.5737686Z   triton_mm_38 0.0246 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2
2026-01-14T08:37:32.5738915Z   triton_mm_39 0.0246 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:37:32.5740594Z   triton_mm_36 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:37:32.5741332Z   _int_mm 0.0358 ms 68.6% 
2026-01-14T08:37:32.5741836Z SingleProcess AUTOTUNE benchmarking takes 0.0631 seconds and 0.1701 seconds precompiling for 5 choices
2026-01-14T08:37:32.5742604Z [32mPASSED[0m
2026-01-14T08:37:32.5743282Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm_eager_and_torch_compile_numerics AUTOTUNE int_mm(17x1536, 1536x1536)
2026-01-14T08:37:32.5743999Z strides: [s15, 1], [s21, 1]
2026-01-14T08:37:32.5744272Z dtypes: torch.int8, torch.int8
2026-01-14T08:37:32.5744979Z   triton_mm_49 0.0707 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:37:32.5746150Z   triton_mm_52 0.0809 ms 87.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:37:32.5747303Z   triton_mm_48 0.0932 ms 75.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:37:32.5748499Z   triton_mm_50 0.0932 ms 75.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:37:32.5749641Z   triton_mm_44 0.1075 ms 65.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:37:32.5750782Z   triton_mm_46 0.1075 ms 65.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:37:32.5751504Z   _int_mm 0.1219 ms 58.0% 
2026-01-14T08:37:32.5752192Z   triton_mm_54 0.1454 ms 48.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:37:32.5753342Z   triton_mm_47 0.1608 ms 43.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:37:32.5754500Z   triton_mm_51 0.1608 ms 43.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:37:32.5755477Z SingleProcess AUTOTUNE benchmarking takes 0.2516 seconds and 1.0530 seconds precompiling for 12 choices
2026-01-14T08:37:32.5756021Z AUTOTUNE int_mm(136x4096, 4096x1536)
2026-01-14T08:37:32.5756309Z strides: [s15, 1], [s21, 1]
2026-01-14T08:37:32.5756578Z dtypes: torch.int8, torch.int8
2026-01-14T08:37:32.5757284Z   triton_mm_60 0.2181 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:37:32.5758438Z   triton_mm_63 0.2314 ms 94.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:37:32.5759737Z   triton_mm_55 0.2703 ms 80.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:37:32.5760910Z   triton_mm_59 0.2939 ms 74.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:37:32.5762097Z   triton_mm_57 0.3062 ms 71.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:37:32.5762989Z   _int_mm 0.3144 ms 69.4% 
2026-01-14T08:37:32.5763672Z   triton_mm_61 0.3513 ms 62.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:37:32.5764840Z   triton_mm_58 0.4393 ms 49.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:37:32.5766022Z   triton_mm_56 0.4444 ms 49.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:37:32.5767191Z   triton_mm_62 0.4977 ms 43.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:37:32.5768185Z SingleProcess AUTOTUNE benchmarking takes 0.4371 seconds and 2.0623 seconds precompiling for 12 choices
2026-01-14T08:37:32.5768773Z [32mPASSED[0m
2026-01-14T08:37:32.5769464Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cpu [32mPASSED[0m
2026-01-14T08:37:32.5770592Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cuda [33mSKIPPED[0m
2026-01-14T08:37:32.5771616Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cpu [32mPASSED[0m
2026-01-14T08:37:32.5772568Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cuda [32mPASSED[0m
2026-01-14T08:37:32.5773521Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cpu [32mPASSED[0m
2026-01-14T08:37:32.5774481Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cuda [32mPASSED[0m
2026-01-14T08:37:32.5775517Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:37:32.5776610Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:37:32.5777700Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:37:32.5778816Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:37:32.5779877Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:37:32.5780933Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:37:32.5782017Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:37:32.5783136Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:37:32.5784248Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:37:32.5785340Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:37:32.5786424Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:37:32.5787589Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:37:32.5788645Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:37:32.5789633Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:37:32.5790692Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:37:32.5791671Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:37:32.5792612Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:37:32.5793563Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:37:32.5794510Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_0_cpu [32mPASSED[0m
2026-01-14T08:37:32.5795594Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_1_cpu [32mPASSED[0m
2026-01-14T08:37:32.5796525Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_2_cpu [32mPASSED[0m
2026-01-14T08:37:32.5797409Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_3 AUTOTUNE int_mm(32x64, 64x32)
2026-01-14T08:37:32.5798022Z strides: [64, 1], [1, 64]
2026-01-14T08:37:32.5798291Z dtypes: torch.int8, torch.int8
2026-01-14T08:37:32.5799011Z   triton_mm_70 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4246822Z   triton_mm_69 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:02.4248015Z   triton_mm_66 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4249166Z   triton_mm_67 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4250324Z   triton_mm_68 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:02.4251054Z   _int_mm 0.0369 ms 63.9% 
2026-01-14T08:38:02.4251556Z SingleProcess AUTOTUNE benchmarking takes 0.0801 seconds and 0.1736 seconds precompiling for 6 choices
2026-01-14T08:38:02.4252321Z [32mPASSED[0m
2026-01-14T08:38:02.4252921Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_4 [32mPASSED[0m
2026-01-14T08:38:02.4253817Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_5 [32mPASSED[0m
2026-01-14T08:38:02.4254757Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_0_cpu [32mPASSED[0m
2026-01-14T08:38:02.4255726Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_1_cpu [32mPASSED[0m
2026-01-14T08:38:02.4256703Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_2_cpu [32mPASSED[0m
2026-01-14T08:38:02.4257662Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_3 [32mPASSED[0m
2026-01-14T08:38:02.4258592Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_4 [32mPASSED[0m
2026-01-14T08:38:02.4259530Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_5 [32mPASSED[0m
2026-01-14T08:38:02.4260911Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_0_cpu [32mPASSED[0m
2026-01-14T08:38:02.4261899Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_1_cpu [32mPASSED[0m
2026-01-14T08:38:02.4262869Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_2_cpu [32mPASSED[0m
2026-01-14T08:38:02.4264006Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_3 AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:38:02.4264671Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:38:02.4265010Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:38:02.4265809Z   triton_mm_86 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4267007Z   triton_mm_82 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4268181Z   triton_mm_84 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:02.4269362Z   triton_mm_87 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4270538Z   triton_mm_88 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4271705Z   triton_mm_90 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:02.4272887Z   triton_mm_83 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:02.4274064Z   triton_mm_89 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:02.4275239Z   triton_mm_81 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:02.4276412Z   triton_mm_85 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4277409Z SingleProcess AUTOTUNE benchmarking takes 0.1536 seconds and 0.2463 seconds precompiling for 12 choices
2026-01-14T08:38:02.4277988Z [32mPASSED[0m
2026-01-14T08:38:02.4278569Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_4 AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:38:02.4279219Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:38:02.4279550Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:38:02.4280348Z   triton_mm_92 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4281537Z   triton_mm_100 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:02.4282802Z   triton_mm_95 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4284073Z   triton_mm_96 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4285244Z   triton_mm_91 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:02.4286419Z   triton_mm_93 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:02.4287668Z   triton_mm_94 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:02.4288842Z   triton_mm_97 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4290032Z   triton_mm_98 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4291202Z   triton_mm_99 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:02.4292184Z SingleProcess AUTOTUNE benchmarking takes 0.1535 seconds and 0.2065 seconds precompiling for 12 choices
2026-01-14T08:38:02.4292778Z [32mPASSED[0m
2026-01-14T08:38:02.4293346Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_5 AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:38:02.4294001Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:38:02.4294341Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:02.4295152Z   triton_mm_107 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4296349Z   triton_mm_101 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:02.4297576Z   triton_mm_102 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4298765Z   triton_mm_103 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:02.4299944Z   triton_mm_104 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:02.4301118Z   triton_mm_105 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4302299Z   triton_mm_106 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4303481Z   triton_mm_108 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:18.1617215Z   triton_mm_109 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:18.1618472Z   triton_mm_110 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:18.1619470Z SingleProcess AUTOTUNE benchmarking takes 0.1542 seconds and 0.2052 seconds precompiling for 12 choices
2026-01-14T08:38:18.1620237Z [32mPASSED[0m
2026-01-14T08:38:18.1621219Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1622208Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1623174Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1624283Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:38:18.1625224Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:38:18.1626153Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:38:18.1627073Z test/integration/test_integration.py::TestSubclass::test_autoquantizable_flatten_unflatten [32mPASSED[0m
2026-01-14T08:38:18.1627942Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1628739Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1629544Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_2_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1630329Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_3 [33mSKIPPED[0m
2026-01-14T08:38:18.1631106Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_4 [33mSKIPPED[0m
2026-01-14T08:38:18.1631881Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_5 [33mSKIPPED[0m
2026-01-14T08:38:18.1632783Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1633798Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1634802Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:38:18.1635785Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:38:18.1636758Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:38:18.1637707Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_5 AUTOTUNE addmm(16x16, 16x16, 16x16)
2026-01-14T08:38:18.1638373Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:38:18.1638712Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:18.1639778Z   triton_mm_114 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:38:18.1640973Z   triton_mm_112 0.0246 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:38:18.1642143Z   triton_mm_115 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:38:18.1643390Z   triton_mm_111 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:38:18.1644565Z   triton_mm_113 0.0267 ms 92.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:38:18.1645293Z   addmm 0.0502 ms 49.0% 
2026-01-14T08:38:18.1645549Z   bias_addmm 0.0707 ms 34.8% 
2026-01-14T08:38:18.1646055Z SingleProcess AUTOTUNE benchmarking takes 0.0914 seconds and 0.1845 seconds precompiling for 7 choices
2026-01-14T08:38:18.1646635Z [32mPASSED[0m
2026-01-14T08:38:18.1647385Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1648373Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1649345Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:38:18.1650422Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:38:18.1651420Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:38:18.1652345Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_5 [32mPASSED[0m
2026-01-14T08:38:18.1653337Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1654389Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:18.1655425Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_2_cpu [32mPASSED[0m
2026-01-14T08:38:18.1656445Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_3 [33mSKIPPED[0m
2026-01-14T08:38:18.1657454Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_4 [33mSKIPPED[0m
2026-01-14T08:38:18.1658439Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_5 AUTOTUNE addmm(256x16, 256x16, 16x16)
2026-01-14T08:38:18.1659125Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:38:18.1659458Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:18.1660274Z   triton_mm_121 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:18.1661461Z   triton_mm_122 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:18.1662645Z   triton_mm_120 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:18.1663827Z   triton_mm_117 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:38:18.1664999Z   triton_mm_116 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:18.1666185Z   triton_mm_118 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:38:18.1667362Z   triton_mm_119 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:18.1668542Z   triton_mm_123 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:18.1669736Z   triton_mm_124 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:38:18.1670925Z   triton_mm_125 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:38:18.1672002Z SingleProcess AUTOTUNE benchmarking takes 0.1650 seconds and 0.1868 seconds precompiling for 13 choices
2026-01-14T08:38:18.1672563Z AUTOTUNE addmm(256x8, 256x8, 8x8)
2026-01-14T08:38:18.1672842Z strides: [0, 1], [8, 1], [1, 8]
2026-01-14T08:38:18.1673177Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:18.1673992Z   triton_mm_160 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:18.1676044Z   triton_mm_164 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:18.1677239Z   triton_mm_165 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:18.1678443Z   triton_mm_168 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:38:18.1679796Z   triton_mm_161 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:38:30.8209374Z   triton_mm_162 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:38:30.8217619Z   triton_mm_163 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:30.8218841Z   triton_mm_166 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:30.8220060Z   triton_mm_167 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:30.8221268Z   triton_mm_169 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:38:30.8222274Z SingleProcess AUTOTUNE benchmarking takes 0.1678 seconds and 0.2728 seconds precompiling for 13 choices
2026-01-14T08:38:30.8223046Z [32mPASSED[0m
2026-01-14T08:38:30.8223672Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_00_cpu [33mSKIPPED[0m
2026-01-14T08:38:30.8224631Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_01_cpu [33mSKIPPED[0m
2026-01-14T08:38:30.8225586Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_02_cpu [33mSKIPPED[0m
2026-01-14T08:38:30.8226535Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_03_cpu [33mSKIPPED[0m
2026-01-14T08:38:30.8227494Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_04_cpu [33mSKIPPED[0m
2026-01-14T08:38:30.8228448Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_05_cpu [33mSKIPPED[0m
2026-01-14T08:38:30.8229379Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_06 [33mSKIPPED[0m
2026-01-14T08:38:30.8230485Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_07 [33mSKIPPED[0m
2026-01-14T08:38:30.8231411Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_08 [33mSKIPPED[0m
2026-01-14T08:38:30.8232340Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_09 [33mSKIPPED[0m
2026-01-14T08:38:30.8233264Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_10 [33mSKIPPED[0m
2026-01-14T08:38:30.8234418Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_11 [33mSKIPPED[0m
2026-01-14T08:38:30.8235384Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_0_cpu [32mPASSED[0m
2026-01-14T08:38:30.8236356Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_1_cpu [32mPASSED[0m
2026-01-14T08:38:30.8237471Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:38:30.8238396Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_3 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:30.8240386Z strides: [64, 1], [32, 1]
2026-01-14T08:38:30.8240689Z dtypes: torch.float32, torch.float32
2026-01-14T08:38:30.8241460Z   triton_mm_213 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:30.8242765Z   triton_mm_205 0.0256 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:30.8243978Z   triton_mm_204 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:30.8245184Z   triton_mm_206 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:30.8246391Z   triton_mm_207 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:30.8247601Z   triton_mm_208 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:30.8248798Z   triton_mm_210 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:30.8250000Z   triton_mm_211 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:30.8251202Z   triton_mm_209 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:30.8252409Z   triton_mm_212 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:30.8253416Z SingleProcess AUTOTUNE benchmarking takes 0.1397 seconds and 0.2134 seconds precompiling for 11 choices
2026-01-14T08:38:30.8253974Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:30.8254242Z strides: [32, 1], [32, 1]
2026-01-14T08:38:30.8254509Z dtypes: torch.float32, torch.float32
2026-01-14T08:38:30.8255273Z   triton_mm_215 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:30.8256500Z   triton_mm_214 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:30.8257697Z   triton_mm_219 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:30.8258900Z   triton_mm_217 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:30.8260273Z   triton_mm_218 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:30.8261467Z   triton_mm_216 0.0276 ms 85.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:30.8262368Z   mm 0.0379 ms 62.2% 
2026-01-14T08:38:30.8262851Z SingleProcess AUTOTUNE benchmarking takes 0.0872 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:38:30.8263459Z [32mPASSED[0m
2026-01-14T08:38:30.8264008Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_4 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:30.8264616Z strides: [64, 1], [32, 1]
2026-01-14T08:38:30.8264887Z dtypes: torch.float16, torch.float16
2026-01-14T08:38:30.8265649Z   triton_mm_228 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:30.8266866Z   triton_mm_222 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:30.8268068Z   triton_mm_223 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:30.8269266Z   triton_mm_224 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:30.8270463Z   triton_mm_226 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:30.8271664Z   triton_mm_227 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:30.8272859Z   triton_mm_229 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:30.8274061Z   triton_mm_220 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:30.8275324Z   triton_mm_221 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:30.8276515Z   triton_mm_225 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3438749Z SingleProcess AUTOTUNE benchmarking takes 0.1389 seconds and 0.1011 seconds precompiling for 11 choices
2026-01-14T08:39:01.3440791Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:01.3441420Z strides: [32, 1], [32, 1]
2026-01-14T08:39:01.3441777Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:01.3442630Z   triton_mm_231 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3443913Z   triton_mm_232 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:01.3445108Z   triton_mm_233 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3446552Z   triton_mm_234 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:01.3447753Z   triton_mm_235 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:01.3448934Z   triton_mm_230 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:01.3449832Z   mm 0.0389 ms 65.8% 
2026-01-14T08:39:01.3450324Z SingleProcess AUTOTUNE benchmarking takes 0.0864 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:01.3451089Z [32mPASSED[0m
2026-01-14T08:39:01.3451649Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_5 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:01.3452264Z strides: [64, 1], [32, 1]
2026-01-14T08:39:01.3452550Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:01.3453315Z   triton_mm_238 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:01.3454521Z   triton_mm_239 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:01.3455725Z   triton_mm_240 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3456909Z   triton_mm_241 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3458105Z   triton_mm_242 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:01.3459307Z   triton_mm_243 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:01.3460491Z   triton_mm_244 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:01.3461691Z   triton_mm_236 0.0257 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:01.3462883Z   triton_mm_237 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3464059Z   triton_mm_245 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:01.3465057Z SingleProcess AUTOTUNE benchmarking takes 0.1388 seconds and 0.1128 seconds precompiling for 11 choices
2026-01-14T08:39:01.3465615Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:01.3465870Z strides: [32, 1], [32, 1]
2026-01-14T08:39:01.3466153Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:01.3466925Z   triton_mm_251 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:01.3468135Z   triton_mm_248 0.0236 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:01.3469317Z   triton_mm_246 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:01.3470589Z   triton_mm_247 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3471767Z   triton_mm_249 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3472947Z   triton_mm_250 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:01.3473762Z   mm 0.0389 ms 60.5% 
2026-01-14T08:39:01.3474235Z SingleProcess AUTOTUNE benchmarking takes 0.0855 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:01.3474815Z [32mPASSED[0m
2026-01-14T08:39:01.3475436Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_0_cpu AUTOTUNE packed_linear(32x64, 1459233x1, 32x64)
2026-01-14T08:39:01.3476147Z strides: [64, 1], [1, 0], [64, 1]
2026-01-14T08:39:01.3476485Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:39:01.3476858Z   cpp_CppMicroGemmFP32Vec_0 0.0072 ms 100.0% 
2026-01-14T08:39:01.3477182Z   _mkl_linear 0.0286 ms 25.2% 
2026-01-14T08:39:01.3477689Z SingleProcess AUTOTUNE benchmarking takes 0.2475 seconds and 2.2044 seconds precompiling for 2 choices
2026-01-14T08:39:01.3478269Z AUTOTUNE packed_linear(32x32, 1459233x1, 32x32)
2026-01-14T08:39:01.3478597Z strides: [32, 1], [1, 0], [32, 1]
2026-01-14T08:39:01.3478922Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:39:01.3479312Z   cpp_CppMicroGemmFP32Vec_1 0.0062 ms 100.0% 
2026-01-14T08:39:01.3479625Z   _mkl_linear 0.0285 ms 21.8% 
2026-01-14T08:39:01.3480130Z SingleProcess AUTOTUNE benchmarking takes 0.2466 seconds and 2.1931 seconds precompiling for 2 choices
2026-01-14T08:39:01.3480690Z [32mPASSED[0m
2026-01-14T08:39:01.3481251Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_1_cpu AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:01.3481874Z strides: [64, 1], [1, 64]
2026-01-14T08:39:01.3482150Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:01.3482479Z   cpp_CppMicroGemmFP32Vec_2 0.0067 ms 100.0% 
2026-01-14T08:39:01.3482850Z   mm 0.0319 ms 21.0% 
2026-01-14T08:39:01.3483375Z SingleProcess AUTOTUNE benchmarking takes 0.2468 seconds and 2.3311 seconds precompiling for 2 choices
2026-01-14T08:39:01.3483933Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:01.3484197Z strides: [32, 1], [1, 32]
2026-01-14T08:39:01.3484462Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:01.3484790Z   cpp_CppMicroGemmFP32Vec_3 0.0073 ms 100.0% 
2026-01-14T08:39:01.3485091Z   mm 0.0377 ms 19.4% 
2026-01-14T08:39:01.3485576Z SingleProcess AUTOTUNE benchmarking takes 0.2467 seconds and 2.3221 seconds precompiling for 2 choices
2026-01-14T08:39:01.3486141Z [32mPASSED[0m
2026-01-14T08:39:01.3486765Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_2_cpu AUTOTUNE _weight_int8pack_mm(32x64, 32x64, 32)
2026-01-14T08:39:01.3487470Z strides: [64, 1], [64, 1], [1]
2026-01-14T08:39:01.3487784Z dtypes: torch.bfloat16, torch.int8, torch.bfloat16
2026-01-14T08:39:01.3488156Z   cpp_CppMicroGemmFP32Vec_4 0.0071 ms 100.0% 
2026-01-14T08:39:01.3488477Z   _weight_int8pack_mm 0.0176 ms 40.3% 
2026-01-14T08:39:01.3489014Z SingleProcess AUTOTUNE benchmarking takes 0.2480 seconds and 2.3201 seconds precompiling for 2 choices
2026-01-14T08:39:01.3489586Z AUTOTUNE _weight_int8pack_mm(32x32, 32x32, 32)
2026-01-14T08:39:01.3489902Z strides: [32, 1], [32, 1], [1]
2026-01-14T08:39:01.3490212Z dtypes: torch.bfloat16, torch.int8, torch.bfloat16
2026-01-14T08:39:01.3490575Z   cpp_CppMicroGemmFP32Vec_5 0.0070 ms 100.0% 
2026-01-14T08:39:01.3490902Z   _weight_int8pack_mm 0.0177 ms 39.5% 
2026-01-14T08:39:01.3491423Z SingleProcess AUTOTUNE benchmarking takes 0.2478 seconds and 2.3077 seconds precompiling for 2 choices
2026-01-14T08:39:01.3491991Z [32mPASSED[0m
2026-01-14T08:39:01.3492611Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_3 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:01.3493214Z strides: [64, 1], [1, 64]
2026-01-14T08:39:01.3493492Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:01.3494245Z   triton_mm_253 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3495525Z   triton_mm_258 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:01.3496716Z   triton_mm_252 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:01.3497904Z   triton_mm_256 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:01.3499088Z   triton_mm_259 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:09.6825489Z   triton_mm_260 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:09.6826730Z   triton_mm_261 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:09.6827909Z   triton_mm_254 0.0257 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:09.6829091Z   triton_mm_255 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:09.6830255Z   triton_mm_257 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6831246Z SingleProcess AUTOTUNE benchmarking takes 0.1359 seconds and 0.2852 seconds precompiling for 11 choices
2026-01-14T08:39:09.6831798Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:09.6832053Z strides: [32, 1], [1, 32]
2026-01-14T08:39:09.6832322Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:09.6833067Z   triton_mm_266 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:09.6834254Z   triton_mm_262 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:09.6835424Z   triton_mm_263 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6836601Z   triton_mm_265 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6837776Z   triton_mm_267 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:09.6838938Z   triton_mm_264 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:09.6839897Z   mm 0.0369 ms 66.7% 
2026-01-14T08:39:09.6840381Z SingleProcess AUTOTUNE benchmarking takes 0.0941 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:09.6841134Z [32mPASSED[0m
2026-01-14T08:39:09.6842011Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_4 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:09.6842690Z strides: [64, 1], [1, 64]
2026-01-14T08:39:09.6842963Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:09.6843703Z   triton_mm_268 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:09.6845223Z   triton_mm_269 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6846694Z   triton_mm_270 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:09.6848146Z   triton_mm_273 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6849596Z   triton_mm_276 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:09.6851037Z   triton_mm_271 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:09.6852473Z   triton_mm_272 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6853897Z   triton_mm_275 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:09.6855335Z   triton_mm_277 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:09.6856771Z   triton_mm_274 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:09.6857949Z SingleProcess AUTOTUNE benchmarking takes 0.1438 seconds and 0.1337 seconds precompiling for 11 choices
2026-01-14T08:39:09.6858595Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:09.6858858Z strides: [32, 1], [1, 32]
2026-01-14T08:39:09.6859141Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:09.6860014Z   triton_mm_281 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6861463Z   triton_mm_282 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:09.6862907Z   triton_mm_283 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:09.6864339Z   triton_mm_279 0.0256 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6865775Z   triton_mm_278 0.0266 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:09.6867205Z   triton_mm_280 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:09.6867948Z   mm 0.0389 ms 65.8% 
2026-01-14T08:39:09.6868521Z SingleProcess AUTOTUNE benchmarking takes 0.0939 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:09.6869100Z [32mPASSED[0m
2026-01-14T08:39:09.6869633Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_5 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:09.6870228Z strides: [64, 1], [32, 1]
2026-01-14T08:39:09.6870489Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:09.6871325Z   triton_mm_292 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:09.6872518Z   triton_mm_291 0.0266 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:09.6873708Z   triton_mm_285 0.0266 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6874902Z   triton_mm_290 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:09.6876137Z   triton_mm_293 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:09.6877330Z   triton_mm_287 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:09.6878524Z   triton_mm_288 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6879707Z   triton_mm_284 0.0277 ms 92.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:09.6880900Z   triton_mm_286 0.0287 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:09.6882089Z   triton_mm_289 0.0287 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:09.6883133Z SingleProcess AUTOTUNE benchmarking takes 0.1487 seconds and 0.1125 seconds precompiling for 11 choices
2026-01-14T08:39:09.6883690Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:09.6883935Z strides: [32, 1], [32, 1]
2026-01-14T08:39:09.6884203Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:09.6884957Z   triton_mm_294 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:23.1670441Z   triton_mm_295 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:23.1671693Z   triton_mm_297 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:23.1672886Z   triton_mm_298 0.0257 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:23.1674128Z   triton_mm_296 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:23.1675332Z   triton_mm_299 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:23.1676077Z   mm 0.0389 ms 65.8% 
2026-01-14T08:39:23.1676890Z SingleProcess AUTOTUNE benchmarking takes 0.0869 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:23.1677671Z [32mPASSED[0m
2026-01-14T08:39:23.1678199Z test/integration/test_integration.py::TestDynamicQuant::test_dynamic_quant [32mPASSED[0m
2026-01-14T08:39:23.1679153Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_embedding_quant [32mPASSED[0m
2026-01-14T08:39:23.1680333Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_quant [32mPASSED[0m
2026-01-14T08:39:23.1681271Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant [32mPASSED[0m
2026-01-14T08:39:23.1682268Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:39:23.1683400Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:39:23.1684477Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:39:23.1685446Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_3 AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:39:23.1686085Z strides: [4, 1], [5, 1]
2026-01-14T08:39:23.1686363Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:23.1687123Z   triton_mm_302 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:23.1688343Z   triton_mm_300 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:23.1689548Z   triton_mm_301 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:23.1690749Z   triton_mm_303 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:23.1691949Z   triton_mm_304 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:23.1692693Z   mm 0.0358 ms 65.7% 
2026-01-14T08:39:23.1693182Z SingleProcess AUTOTUNE benchmarking takes 0.0744 seconds and 0.1884 seconds precompiling for 6 choices
2026-01-14T08:39:23.1693725Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:39:23.1693970Z strides: [4, 1], [5, 1]
2026-01-14T08:39:23.1694227Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:23.1694976Z   triton_mm_306 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:39:23.1696207Z   triton_mm_307 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:39:23.1697427Z   triton_mm_313 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:39:23.1698650Z   triton_mm_314 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:39:23.1699894Z   triton_mm_308 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:23.1701225Z   triton_mm_311 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:23.1702437Z   triton_mm_312 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:23.1703653Z   triton_mm_315 0.0266 ms 92.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:39:23.1704931Z   triton_mm_305 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:23.1706132Z   triton_mm_309 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:23.1707136Z SingleProcess AUTOTUNE benchmarking takes 0.1494 seconds and 0.2598 seconds precompiling for 12 choices
2026-01-14T08:39:23.1707681Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:39:23.1707928Z strides: [4, 1], [5, 1]
2026-01-14T08:39:23.1708179Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:23.1708935Z   triton_mm_318 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:23.1710206Z   triton_mm_317 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:23.1711405Z   triton_mm_316 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:23.1712606Z   triton_mm_319 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:23.1713816Z   triton_mm_320 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:23.1714558Z   mm 0.0369 ms 63.9% 
2026-01-14T08:39:23.1715042Z SingleProcess AUTOTUNE benchmarking takes 0.0755 seconds and 0.1970 seconds precompiling for 6 choices
2026-01-14T08:39:23.1715624Z [32mPASSED[0m
2026-01-14T08:39:23.1716201Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_4 AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:39:23.1716839Z strides: [4, 1], [5, 1]
2026-01-14T08:39:23.1717111Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:23.1717871Z   triton_mm_322 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:23.1719086Z   triton_mm_323 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:23.1720299Z   triton_mm_325 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:23.1721508Z   triton_mm_321 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:23.1722766Z   triton_mm_324 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:23.1723515Z   mm 0.0430 ms 57.1% 
2026-01-14T08:39:23.1723995Z SingleProcess AUTOTUNE benchmarking takes 0.0756 seconds and 0.1797 seconds precompiling for 6 choices
2026-01-14T08:39:23.1724549Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:39:23.1724797Z strides: [4, 1], [5, 1]
2026-01-14T08:39:23.1725139Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:23.1725905Z   triton_mm_333 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:23.1727126Z   triton_mm_335 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:39:23.1728427Z   triton_mm_326 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:49.4219457Z   triton_mm_328 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:39:49.4220732Z   triton_mm_329 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:49.4221953Z   triton_mm_336 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:39:49.4223287Z   triton_mm_327 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:39:49.4224500Z   triton_mm_330 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:49.4225695Z   triton_mm_331 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:49.4226887Z   triton_mm_332 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:49.4227891Z SingleProcess AUTOTUNE benchmarking takes 0.1542 seconds and 0.2024 seconds precompiling for 12 choices
2026-01-14T08:39:49.4228458Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:39:49.4228694Z strides: [4, 1], [5, 1]
2026-01-14T08:39:49.4228965Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:49.4229728Z   triton_mm_338 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:49.4230964Z   triton_mm_340 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:49.4232190Z   triton_mm_341 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:49.4233402Z   triton_mm_339 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:49.4234612Z   triton_mm_337 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:49.4235366Z   mm 0.0451 ms 54.5% 
2026-01-14T08:39:49.4235841Z SingleProcess AUTOTUNE benchmarking takes 0.0788 seconds and 0.1801 seconds precompiling for 6 choices
2026-01-14T08:39:49.4236601Z [32mPASSED[0m
2026-01-14T08:39:49.4237194Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_5 AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:39:49.4237845Z strides: [4, 1], [5, 1]
2026-01-14T08:39:49.4238107Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:49.4239378Z   triton_mm_343 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:49.4240758Z   triton_mm_344 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:49.4242141Z   triton_mm_346 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:49.4243445Z   triton_mm_342 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:49.4244649Z   triton_mm_345 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:49.4245401Z   mm 0.0359 ms 68.4% 
2026-01-14T08:39:49.4245887Z SingleProcess AUTOTUNE benchmarking takes 0.0767 seconds and 0.1977 seconds precompiling for 6 choices
2026-01-14T08:39:49.4246435Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:39:49.4246682Z strides: [4, 1], [5, 1]
2026-01-14T08:39:49.4246942Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:49.4247715Z   triton_mm_357 0.0245 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:39:49.4248955Z   triton_mm_351 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:49.4250167Z   triton_mm_353 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:49.4251395Z   triton_mm_354 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:49.4252623Z   triton_mm_355 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:39:49.4253846Z   triton_mm_356 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:39:49.4255070Z   triton_mm_347 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:49.4256291Z   triton_mm_349 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:39:49.4257554Z   triton_mm_350 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:49.4258768Z   triton_mm_352 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:49.4259780Z SingleProcess AUTOTUNE benchmarking takes 0.1507 seconds and 0.2148 seconds precompiling for 12 choices
2026-01-14T08:39:49.4260329Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:39:49.4260574Z strides: [4, 1], [5, 1]
2026-01-14T08:39:49.4260839Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:49.4261608Z   triton_mm_358 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:49.4262952Z   triton_mm_359 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:49.4264176Z   triton_mm_360 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:49.4265395Z   triton_mm_361 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:49.4266689Z   triton_mm_362 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:49.4267495Z   mm 0.0358 ms 68.6% 
2026-01-14T08:39:49.4267981Z SingleProcess AUTOTUNE benchmarking takes 0.0746 seconds and 0.1790 seconds precompiling for 6 choices
2026-01-14T08:39:49.4268579Z [32mPASSED[0m
2026-01-14T08:39:49.4269266Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:39:49.4270339Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:39:49.4271408Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:39:49.4272462Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_3 [32mPASSED[0m
2026-01-14T08:39:49.4273486Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_4 [32mPASSED[0m
2026-01-14T08:39:49.4274508Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_5 [32mPASSED[0m
2026-01-14T08:39:49.4275468Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:39:49.4276377Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:39:49.4277280Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_2_cpu [33mSKIPPED[0m
2026-01-14T08:39:49.4278114Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_3 AUTOTUNE int_mm(32x32, 32x32)
2026-01-14T08:39:49.4278706Z strides: [32, 1], [1, 32]
2026-01-14T08:39:49.4278970Z dtypes: torch.int8, torch.int8
2026-01-14T08:40:05.6074042Z   triton_mm_433 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:05.6075290Z   triton_mm_434 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:05.6076519Z   triton_mm_431 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6077707Z   triton_mm_432 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:05.6078463Z   _int_mm 0.0369 ms 66.7% 
2026-01-14T08:40:05.6078977Z SingleProcess AUTOTUNE benchmarking takes 0.0631 seconds and 0.1185 seconds precompiling for 5 choices
2026-01-14T08:40:05.6079562Z AUTOTUNE int_mm(32x64, 64x32)
2026-01-14T08:40:05.6079850Z strides: [64, 1], [1, 64]
2026-01-14T08:40:05.6080118Z dtypes: torch.int8, torch.int8
2026-01-14T08:40:05.6080862Z   triton_mm_426 0.0256 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6082459Z   triton_mm_427 0.0256 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:05.6083790Z   triton_mm_428 0.0266 ms 96.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:05.6084988Z   triton_mm_429 0.0266 ms 96.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:05.6086348Z   triton_mm_430 0.0266 ms 96.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:05.6087101Z   _int_mm 0.0369 ms 69.4% 
2026-01-14T08:40:05.6087618Z SingleProcess AUTOTUNE benchmarking takes 0.0779 seconds and 0.0002 seconds precompiling for 6 choices
2026-01-14T08:40:05.6088395Z [32mPASSED[0m
2026-01-14T08:40:05.6088998Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_4 [32mPASSED[0m
2026-01-14T08:40:05.6089867Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_5 [32mPASSED[0m
2026-01-14T08:40:05.6090780Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:05.6091717Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:05.6092663Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_2_cpu [32mPASSED[0m
2026-01-14T08:40:05.6093589Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_3 [33mSKIPPED[0m
2026-01-14T08:40:05.6094501Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_4 [33mSKIPPED[0m
2026-01-14T08:40:05.6095362Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_5 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:40:05.6095955Z strides: [64, 1], [1, 64]
2026-01-14T08:40:05.6096249Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:40:05.6097028Z   triton_mm_460 0.0245 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:05.6098246Z   triton_mm_453 0.0256 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:05.6099469Z   triton_mm_454 0.0256 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6100682Z   triton_mm_455 0.0256 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:05.6101895Z   triton_mm_456 0.0256 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:05.6103109Z   triton_mm_457 0.0256 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6104342Z   triton_mm_458 0.0256 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6105552Z   triton_mm_459 0.0256 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:05.6106769Z   triton_mm_461 0.0256 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:05.6108080Z   triton_mm_462 0.0256 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:05.6109086Z SingleProcess AUTOTUNE benchmarking takes 0.1393 seconds and 0.1355 seconds precompiling for 11 choices
2026-01-14T08:40:05.6109656Z AUTOTUNE addmm(32x32, 32x32, 32x32)
2026-01-14T08:40:05.6109947Z strides: [0, 1], [32, 1], [1, 32]
2026-01-14T08:40:05.6110378Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:40:05.6111205Z   triton_mm_468 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:05.6112432Z   triton_mm_463 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:05.6113659Z   triton_mm_464 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6114861Z   triton_mm_465 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:05.6116063Z   triton_mm_466 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6117289Z   triton_mm_467 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:05.6118044Z   addmm 0.0502 ms 51.0% 
2026-01-14T08:40:05.6118318Z   bias_addmm 0.0707 ms 36.2% 
2026-01-14T08:40:05.6118836Z SingleProcess AUTOTUNE benchmarking takes 0.1083 seconds and 0.0002 seconds precompiling for 8 choices
2026-01-14T08:40:05.6119432Z [32mPASSED[0m
2026-01-14T08:40:05.6120038Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_0_cpu [32mPASSED[0m
2026-01-14T08:40:05.6120970Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_1_cpu [32mPASSED[0m
2026-01-14T08:40:05.6121907Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_2_cpu [32mPASSED[0m
2026-01-14T08:40:05.6122829Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_3 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:40:05.6123431Z strides: [64, 1], [32, 1]
2026-01-14T08:40:05.6123711Z dtypes: torch.float32, torch.float32
2026-01-14T08:40:05.6124483Z   triton_mm_477 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:05.6125708Z   triton_mm_470 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6126923Z   triton_mm_472 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:05.6128137Z   triton_mm_473 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6129352Z   triton_mm_474 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:05.6130561Z   triton_mm_476 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:05.6131862Z   triton_mm_478 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:05.6133078Z   triton_mm_475 0.0266 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:13.0068893Z   triton_mm_469 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:13.0071017Z   triton_mm_471 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:13.0072390Z SingleProcess AUTOTUNE benchmarking takes 0.1370 seconds and 0.2453 seconds precompiling for 11 choices
2026-01-14T08:40:13.0072960Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:40:13.0073216Z strides: [32, 1], [32, 1]
2026-01-14T08:40:13.0073490Z dtypes: torch.float32, torch.float32
2026-01-14T08:40:13.0074261Z   triton_mm_483 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:13.0075468Z   triton_mm_482 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:13.0076666Z   triton_mm_480 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:13.0077843Z   triton_mm_484 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:13.0079032Z   triton_mm_481 0.0286 ms 89.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:13.0080232Z   triton_mm_479 0.0287 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:13.0080968Z   mm 0.0399 ms 64.2% 
2026-01-14T08:40:13.0081460Z SingleProcess AUTOTUNE benchmarking takes 0.0908 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:40:13.0082223Z [32mPASSED[0m
2026-01-14T08:40:13.0082870Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_4 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:40:13.0083474Z strides: [64, 1], [32, 1]
2026-01-14T08:40:13.0083741Z dtypes: torch.float16, torch.float16
2026-01-14T08:40:13.0084496Z   triton_mm_485 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:13.0085696Z   triton_mm_486 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:13.0086887Z   triton_mm_487 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:13.0088076Z   triton_mm_488 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:13.0089262Z   triton_mm_489 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:13.0090451Z   triton_mm_490 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:13.0091820Z   triton_mm_492 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:13.0093017Z   triton_mm_493 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:13.0094253Z   triton_mm_491 0.0287 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:13.0095537Z   triton_mm_494 0.0287 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:13.0096526Z SingleProcess AUTOTUNE benchmarking takes 0.1478 seconds and 0.1028 seconds precompiling for 11 choices
2026-01-14T08:40:13.0097085Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:40:13.0097338Z strides: [32, 1], [32, 1]
2026-01-14T08:40:13.0097636Z dtypes: torch.float16, torch.float16
2026-01-14T08:40:13.0098382Z   triton_mm_496 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:13.0099578Z   triton_mm_497 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:13.0100782Z   triton_mm_498 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:13.0101967Z   triton_mm_499 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:13.0103167Z   triton_mm_500 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:13.0104350Z   triton_mm_495 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:13.0105079Z   mm 0.0410 ms 62.5% 
2026-01-14T08:40:13.0105566Z SingleProcess AUTOTUNE benchmarking takes 0.0897 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:40:13.0106152Z [32mPASSED[0m
2026-01-14T08:40:13.0106735Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_5 [32mPASSED[0m
2026-01-14T08:40:13.0107560Z test/integration/test_integration.py::UtilsUnitTest::test_shape_logger [32mPASSED[0m
2026-01-14T08:40:13.0108369Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_00_cpu [33mSKIPPED[0m
2026-01-14T08:40:13.0109230Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_01_cpu [33mSKIPPED[0m
2026-01-14T08:40:13.0110082Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_02_cpu [33mSKIPPED[0m
2026-01-14T08:40:13.0110942Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_03_cpu [33mSKIPPED[0m
2026-01-14T08:40:13.0111796Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_04_cpu [33mSKIPPED[0m
2026-01-14T08:40:13.0112654Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_05_cpu [33mSKIPPED[0m
2026-01-14T08:40:13.0113514Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_06_cpu [33mSKIPPED[0m
2026-01-14T08:40:13.0114365Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_07_cpu [33mSKIPPED[0m
2026-01-14T08:40:13.0115222Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_08_cpu [33mSKIPPED[0m
2026-01-14T08:40:13.0116052Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_09 [33mSKIPPED[0m
2026-01-14T08:40:13.0116968Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_10 [33mSKIPPED[0m
2026-01-14T08:40:13.0117863Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_11 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:40:13.0118701Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:13.0119271Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:40:13.0119568Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:13.0119906Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:40:13.0120729Z   triton_mm_521 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:13.0121948Z   triton_mm_517 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:13.0123210Z   triton_mm_518 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:13.0124413Z   triton_mm_520 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:13.0125606Z   triton_mm_530 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:13.0126795Z   triton_mm_519 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:13.0127984Z   triton_mm_524 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:33.1443709Z   triton_mm_531 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:33.1444946Z   triton_mm_523 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:33.1446188Z   triton_mm_528 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:33.1447191Z SingleProcess AUTOTUNE benchmarking takes 0.2529 seconds and 3.9698 seconds precompiling for 19 choices
2026-01-14T08:40:33.1447989Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:33.1448548Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:40:33.1448806Z strides: [128, 1], [128, 1]
2026-01-14T08:40:33.1449089Z dtypes: torch.float32, torch.float32
2026-01-14T08:40:33.1449841Z   triton_mm_542 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:33.1451062Z   triton_mm_543 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:33.1452273Z   triton_mm_535 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:33.1453488Z   triton_mm_538 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:33.1454960Z   triton_mm_540 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:33.1456155Z   triton_mm_547 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:33.1457338Z   triton_mm_548 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:33.1458666Z   triton_mm_541 0.0256 ms 92.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:33.1459850Z   triton_mm_534 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:33.1461044Z   triton_mm_536 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:33.1462039Z SingleProcess AUTOTUNE benchmarking takes 0.2131 seconds and 1.7200 seconds precompiling for 18 choices
2026-01-14T08:40:33.1462939Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.009ms 
2026-01-14T08:40:33.1463940Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.008ms 
2026-01-14T08:40:33.1464599Z AUTOTUNE int_mm(32x128, 128x128)
2026-01-14T08:40:33.1464864Z strides: [128, 1], [1, 128]
2026-01-14T08:40:33.1465132Z dtypes: torch.int8, torch.int8
2026-01-14T08:40:33.1465848Z   triton_mm_554 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:33.1467058Z   triton_mm_557 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:33.1468246Z   triton_mm_559 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:33.1469427Z   triton_mm_555 0.0236 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:33.1470604Z   triton_mm_556 0.0236 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:33.1471793Z   triton_mm_560 0.0236 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:33.1472978Z   triton_mm_551 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:33.1474158Z   triton_mm_558 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:33.1475343Z   triton_mm_552 0.0256 ms 88.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:33.1476514Z   triton_mm_553 0.0256 ms 88.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:33.1477505Z SingleProcess AUTOTUNE benchmarking takes 0.1379 seconds and 0.2293 seconds precompiling for 11 choices
2026-01-14T08:40:33.1478521Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:40:33.1479467Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:40:33.1479955Z 
2026-01-14T08:40:33.1480266Z [32mPASSED[0m
2026-01-14T08:40:33.1480835Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_12 [33mSKIPPED[0m
2026-01-14T08:40:33.1481754Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_13 [33mSKIPPED[0m
2026-01-14T08:40:33.1482707Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_14 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:40:33.1483544Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:40:33.1484030Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:40:33.1484322Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:33.1484647Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:40:33.1485462Z   triton_mm_571 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:33.1486666Z   triton_mm_564 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:33.1487882Z   triton_mm_573 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:33.1489090Z   triton_mm_561 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:33.1490283Z   triton_mm_562 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:33.1491486Z   triton_mm_563 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:33.1492679Z   triton_mm_566 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:33.1493881Z   triton_mm_567 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:33.1495087Z   triton_mm_569 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:33.1496289Z   triton_mm_570 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:33.1497290Z SingleProcess AUTOTUNE benchmarking takes 0.2385 seconds and 0.3433 seconds precompiling for 19 choices
2026-01-14T08:40:33.1498085Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:33.1498629Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:40:33.1498891Z strides: [128, 1], [128, 1]
2026-01-14T08:40:33.1499153Z dtypes: torch.float16, torch.float16
2026-01-14T08:40:33.1499907Z   triton_mm_578 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:55.0280678Z   triton_mm_579 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:55.0283899Z   triton_mm_581 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:55.0286086Z   triton_mm_582 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:55.0287328Z   triton_mm_583 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:55.0288723Z   triton_mm_584 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:55.0289968Z   triton_mm_585 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:55.0291203Z   triton_mm_586 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:55.0292444Z   triton_mm_588 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:55.0293688Z   triton_mm_589 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:55.0294724Z SingleProcess AUTOTUNE benchmarking takes 0.2143 seconds and 0.2711 seconds precompiling for 18 choices
2026-01-14T08:40:55.0295655Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.006ms 
2026-01-14T08:40:55.0296679Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.006ms 
2026-01-14T08:40:55.0297731Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:40:55.0298679Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:40:55.0299142Z 
2026-01-14T08:40:55.0299450Z [32mPASSED[0m
2026-01-14T08:40:55.0300021Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_15 [33mSKIPPED[0m
2026-01-14T08:40:55.0300850Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_16 [33mSKIPPED[0m
2026-01-14T08:40:55.0301742Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_17 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:40:55.0302593Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:40:55.0303082Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:40:55.0303381Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:55.0303723Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:40:55.0304556Z   triton_mm_618 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:55.0305778Z   triton_mm_610 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:55.0306980Z   triton_mm_619 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:55.0308187Z   triton_mm_612 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:55.0309481Z   triton_mm_611 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:55.0310686Z   triton_mm_613 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:55.0311898Z   triton_mm_614 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:55.0313204Z   triton_mm_615 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:55.0314409Z   triton_mm_616 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:55.0315629Z   triton_mm_617 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:55.0316702Z SingleProcess AUTOTUNE benchmarking takes 0.2433 seconds and 0.3215 seconds precompiling for 19 choices
2026-01-14T08:40:55.0317505Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:55.0318064Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:40:55.0318333Z strides: [128, 1], [128, 1]
2026-01-14T08:40:55.0318613Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:40:55.0319384Z   triton_mm_625 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:55.0320603Z   triton_mm_627 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:55.0321818Z   triton_mm_629 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:55.0323087Z   triton_mm_634 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:55.0324317Z   triton_mm_637 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:55.0325533Z   triton_mm_638 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:55.0326740Z   triton_mm_630 0.0226 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:55.0327954Z   triton_mm_633 0.0226 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:55.0329156Z   triton_mm_628 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:55.0330360Z   triton_mm_631 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:55.0331359Z SingleProcess AUTOTUNE benchmarking takes 0.2189 seconds and 0.3029 seconds precompiling for 18 choices
2026-01-14T08:40:55.0332264Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.005ms 
2026-01-14T08:40:55.0333271Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.004ms 
2026-01-14T08:40:55.0334398Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:40:55.0335319Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:40:55.0335784Z 
2026-01-14T08:40:55.0335910Z [32mPASSED[0m
2026-01-14T08:40:55.0336485Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:55.0337466Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:55.0338364Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_2_cpu [33mSKIPPED[0m
2026-01-14T08:40:55.0339486Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_3 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:40:55.0340347Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:55.0340837Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:40:55.0341129Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:55.0341462Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:40:55.0342273Z   triton_mm_657 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:08.2464314Z   triton_mm_652 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:08.2465639Z   triton_mm_653 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:08.2467327Z   triton_mm_663 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:08.2468570Z   triton_mm_649 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:08.2469767Z   triton_mm_650 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:08.2471004Z   triton_mm_651 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:08.2472193Z   triton_mm_654 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:08.2473394Z   triton_mm_655 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:08.2474590Z   triton_mm_656 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:08.2475591Z SingleProcess AUTOTUNE benchmarking takes 0.2317 seconds and 1.8715 seconds precompiling for 19 choices
2026-01-14T08:41:08.2476404Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:08.2476956Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:41:08.2477226Z strides: [128, 1], [128, 1]
2026-01-14T08:41:08.2477523Z dtypes: torch.float32, torch.float32
2026-01-14T08:41:08.2478280Z   triton_mm_667 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:08.2479759Z   triton_mm_674 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:08.2480981Z   triton_mm_679 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:08.2482195Z   triton_mm_675 0.0236 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:08.2483648Z   triton_mm_669 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:08.2484831Z   triton_mm_680 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:08.2486019Z   triton_mm_666 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:08.2487203Z   triton_mm_668 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:08.2488399Z   triton_mm_670 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:08.2489587Z   triton_mm_671 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:08.2490581Z SingleProcess AUTOTUNE benchmarking takes 0.2115 seconds and 0.9424 seconds precompiling for 18 choices
2026-01-14T08:41:08.2491486Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.009ms 
2026-01-14T08:41:08.2492489Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.007ms 
2026-01-14T08:41:08.2493151Z AUTOTUNE int_mm(16x128, 128x128)
2026-01-14T08:41:08.2493420Z strides: [128, 1], [1, 128]
2026-01-14T08:41:08.2493688Z dtypes: torch.int8, torch.int8
2026-01-14T08:41:08.2494405Z   triton_mm_688 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:08.2495608Z   triton_mm_691 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:08.2496795Z   triton_mm_689 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:08.2497975Z   triton_mm_684 0.0246 ms 95.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:08.2499157Z   triton_mm_683 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:08.2500339Z   triton_mm_685 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:08.2501507Z   triton_mm_686 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:08.2502683Z   triton_mm_687 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:08.2503939Z   triton_mm_690 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:08.2505138Z   triton_mm_692 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:08.2506239Z SingleProcess AUTOTUNE benchmarking takes 0.1252 seconds and 0.2141 seconds precompiling for 11 choices
2026-01-14T08:41:08.2507190Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:41:08.2508116Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:41:08.2508575Z 
2026-01-14T08:41:08.2508894Z [32mPASSED[0m
2026-01-14T08:41:08.2509529Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_4 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:41:08.2510397Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:41:08.2510882Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:41:08.2511186Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:41:08.2511511Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:41:08.2512331Z   triton_mm_703 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:08.2513558Z   triton_mm_709 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:08.2514766Z   triton_mm_702 0.0236 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:08.2515976Z   triton_mm_693 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:08.2517179Z   triton_mm_696 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:08.2518380Z   triton_mm_694 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:08.2519588Z   triton_mm_697 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:08.2520791Z   triton_mm_698 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.0911550Z   triton_mm_699 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.0912772Z   triton_mm_700 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.0913775Z SingleProcess AUTOTUNE benchmarking takes 0.2387 seconds and 0.2671 seconds precompiling for 19 choices
2026-01-14T08:41:25.0914563Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:25.0915156Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:41:25.0915414Z strides: [128, 1], [128, 1]
2026-01-14T08:41:25.0915679Z dtypes: torch.float16, torch.float16
2026-01-14T08:41:25.0916783Z   triton_mm_718 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:25.0917990Z   triton_mm_721 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.0919179Z   triton_mm_722 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:25.0920505Z   triton_mm_723 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.0921665Z   triton_mm_724 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:25.0922929Z   triton_mm_710 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:25.0924103Z   triton_mm_711 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:25.0925269Z   triton_mm_712 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:25.0926446Z   triton_mm_714 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:25.0927615Z   triton_mm_715 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.0928591Z SingleProcess AUTOTUNE benchmarking takes 0.2194 seconds and 0.2622 seconds precompiling for 18 choices
2026-01-14T08:41:25.0929474Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.005ms 
2026-01-14T08:41:25.0930459Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.004ms 
2026-01-14T08:41:25.0931470Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:41:25.0932387Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:41:25.0932835Z 
2026-01-14T08:41:25.0933151Z [32mPASSED[0m
2026-01-14T08:41:25.0940746Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_5 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:41:25.0941645Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:41:25.0942129Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:41:25.0942427Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:41:25.0942754Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:41:25.0943568Z   triton_mm_741 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:25.0944773Z   triton_mm_749 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:25.0945960Z   triton_mm_738 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:25.0947132Z   triton_mm_742 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.0948475Z   triton_mm_752 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:25.0949667Z   triton_mm_748 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.0950967Z   triton_mm_751 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:25.0952136Z   triton_mm_744 0.0257 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.0953312Z   triton_mm_750 0.0266 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.0954496Z   triton_mm_739 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:25.0955474Z SingleProcess AUTOTUNE benchmarking takes 0.2413 seconds and 0.2675 seconds precompiling for 19 choices
2026-01-14T08:41:25.0956283Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:25.0956826Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:41:25.0957095Z strides: [128, 1], [128, 1]
2026-01-14T08:41:25.0957380Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:41:25.0958145Z   triton_mm_765 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.0959350Z   triton_mm_770 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:25.0960527Z   triton_mm_754 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:25.0961727Z   triton_mm_755 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:25.0962978Z   triton_mm_756 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:25.0964158Z   triton_mm_759 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.0965355Z   triton_mm_761 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.0966558Z   triton_mm_763 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.0967755Z   triton_mm_764 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:25.0968967Z   triton_mm_766 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:25.0969974Z SingleProcess AUTOTUNE benchmarking takes 0.2186 seconds and 0.2393 seconds precompiling for 18 choices
2026-01-14T08:41:25.0970861Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.004ms 
2026-01-14T08:41:25.0971948Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.004ms 
2026-01-14T08:41:25.0972974Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:41:25.0973898Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:41:25.0974436Z 
2026-01-14T08:41:25.0974600Z [32mPASSED[0m
2026-01-14T08:41:25.0975140Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_0_cpu [33mSKIPPED[0m
2026-01-14T08:41:25.0975988Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_1_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0845790Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_2_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0847542Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_3 [33mSKIPPED[0m
2026-01-14T08:41:40.0849032Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_4 [33mSKIPPED[0m
2026-01-14T08:41:40.0849825Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_5 [33mSKIPPED[0m
2026-01-14T08:41:40.0850717Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_hp_float activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:41:40.0851585Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:40.0852317Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQFloat32LinearWeight'>, to_beat: infms 
2026-01-14T08:41:40.0853035Z best_cls=<class 'torchao.quantization.autoquant.AQFloat32LinearWeight'>
2026-01-14T08:41:40.0853401Z 
2026-01-14T08:41:40.0853573Z activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:41:40.0854105Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:40.0854835Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQBFloat16LinearWeight'>, to_beat: infms 
2026-01-14T08:41:40.0855546Z best_cls=<class 'torchao.quantization.autoquant.AQBFloat16LinearWeight'>
2026-01-14T08:41:40.0855917Z 
2026-01-14T08:41:40.0856083Z activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:41:40.0856600Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:40.0857328Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQFloat16LinearWeight'>, to_beat: infms 
2026-01-14T08:41:40.0858035Z best_cls=<class 'torchao.quantization.autoquant.AQFloat16LinearWeight'>
2026-01-14T08:41:40.0858427Z 
2026-01-14T08:41:40.0858576Z [32mPASSED[0m
2026-01-14T08:41:40.0859138Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_0_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0859989Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_1_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0860848Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_2_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0861682Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_3 [33mSKIPPED[0m
2026-01-14T08:41:40.0862491Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_4 [33mSKIPPED[0m
2026-01-14T08:41:40.0863305Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_5 [33mSKIPPED[0m
2026-01-14T08:41:40.0864143Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_00_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0865010Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_01_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0865864Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_02_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0866725Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_03_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0867856Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_04_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0868717Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_05_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0869568Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_06_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0870422Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_07_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0871445Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_08_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0872286Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_09 [33mSKIPPED[0m
2026-01-14T08:41:40.0873103Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_10 [33mSKIPPED[0m
2026-01-14T08:41:40.0873920Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_11 [32mPASSED[0m
2026-01-14T08:41:40.0874725Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_12 [33mSKIPPED[0m
2026-01-14T08:41:40.0875547Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_13 [33mSKIPPED[0m
2026-01-14T08:41:40.0876367Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_14 [32mPASSED[0m
2026-01-14T08:41:40.0877172Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_15 [33mSKIPPED[0m
2026-01-14T08:41:40.0877994Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_16 [33mSKIPPED[0m
2026-01-14T08:41:40.0878799Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_17 [32mPASSED[0m
2026-01-14T08:41:40.0879623Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_0_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0880469Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_1_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0881307Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_2_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0882138Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_3 [32mPASSED[0m
2026-01-14T08:41:40.0883007Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_4 [32mPASSED[0m
2026-01-14T08:41:40.0883805Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_5 [32mPASSED[0m
2026-01-14T08:41:40.0884617Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_0_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0885426Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_1_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0886244Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_2_cpu [33mSKIPPED[0m
2026-01-14T08:41:40.0887106Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_3 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:41:40.0887939Z weight_shape: torch.Size([4096, 4096]), dtype: torch.float32, bias_shape: torch.Size([4096])
2026-01-14T08:41:40.0888446Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:41:40.0888748Z strides: [0, 1], [4096, 1], [1, 4096]
2026-01-14T08:41:40.0889093Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:41:40.0889440Z   bias_addmm 0.1444 ms 100.0% 
2026-01-14T08:41:40.0889710Z   addmm 0.1485 ms 97.2% 
2026-01-14T08:41:40.0890419Z   triton_mm_788 0.1864 ms 77.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.0891636Z   triton_mm_783 0.1884 ms 76.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:40.0892840Z   triton_mm_795 0.1894 ms 76.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:40.0894132Z   triton_mm_794 0.1925 ms 75.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.0895340Z   triton_mm_784 0.2028 ms 71.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:40.0896628Z   triton_mm_785 0.2058 ms 70.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:40.0897824Z   triton_mm_782 0.2232 ms 64.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:40.0899091Z   triton_mm_787 0.2580 ms 56.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:40.0900097Z SingleProcess AUTOTUNE benchmarking takes 0.4794 seconds and 1.3084 seconds precompiling for 19 choices
2026-01-14T08:41:40.0900895Z >>time: 0.144ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:40.0901790Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.144ms 
2026-01-14T08:41:40.0902808Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.037ms 
2026-01-14T08:41:40.0903487Z AUTOTUNE int_mm(1x4096, 4096x4096)
2026-01-14T08:41:40.0903759Z strides: [4096, 1], [1, 4096]
2026-01-14T08:41:40.0904033Z dtypes: torch.int8, torch.int8
2026-01-14T08:41:40.0904760Z   triton_mm_807 0.0481 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:40.0905980Z   triton_mm_808 0.0481 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:40.0907175Z   triton_mm_806 0.0532 ms 90.4% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.0908351Z   triton_mm_803 0.0553 ms 87.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:40.0909534Z   triton_mm_804 0.0563 ms 85.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:40.0910706Z   triton_mm_802 0.0614 ms 78.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:02.8616136Z   triton_mm_800 0.0768 ms 62.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:02.8617352Z   triton_mm_799 0.0788 ms 61.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:02.8618526Z   triton_mm_801 0.1341 ms 35.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:02.8619710Z   triton_mm_798 0.1351 ms 35.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:02.8620704Z SingleProcess AUTOTUNE benchmarking takes 0.1718 seconds and 0.3502 seconds precompiling for 12 choices
2026-01-14T08:42:02.8621642Z >>time: 0.048ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.037ms
2026-01-14T08:42:02.8622830Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:42:02.8623288Z 
2026-01-14T08:42:02.8623611Z [32mPASSED[0m
2026-01-14T08:42:02.8624219Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_4 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:42:02.8625200Z weight_shape: torch.Size([4096, 4096]), dtype: torch.float16, bias_shape: torch.Size([4096])
2026-01-14T08:42:02.8625696Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:42:02.8626005Z strides: [0, 1], [4096, 1], [1, 4096]
2026-01-14T08:42:02.8626342Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:42:02.8627152Z   triton_mm_817 0.0799 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:02.8628364Z   triton_mm_825 0.0840 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:02.8629562Z   triton_mm_820 0.0850 ms 94.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:02.8630749Z   triton_mm_816 0.0860 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:02.8631495Z   addmm 0.0881 ms 90.7% 
2026-01-14T08:42:02.8632188Z   triton_mm_811 0.0881 ms 90.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:02.8633379Z   triton_mm_813 0.0881 ms 90.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:02.8634559Z   triton_mm_823 0.0942 ms 84.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:02.8635301Z   bias_addmm 0.0952 ms 83.9% 
2026-01-14T08:42:02.8636004Z   triton_mm_819 0.0973 ms 82.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:02.8637002Z SingleProcess AUTOTUNE benchmarking takes 0.3469 seconds and 0.4980 seconds precompiling for 19 choices
2026-01-14T08:42:02.8637789Z >>time: 0.081ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:02.8638672Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.081ms 
2026-01-14T08:42:02.8639842Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.037ms 
2026-01-14T08:42:02.8640872Z >>time: 0.048ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.037ms
2026-01-14T08:42:02.8641773Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:42:02.8642220Z 
2026-01-14T08:42:02.8642372Z [32mPASSED[0m
2026-01-14T08:42:02.8642995Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_5 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:42:02.8643827Z weight_shape: torch.Size([4096, 4096]), dtype: torch.bfloat16, bias_shape: torch.Size([4096])
2026-01-14T08:42:02.8644322Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:42:02.8644615Z strides: [0, 1], [4096, 1], [1, 4096]
2026-01-14T08:42:02.8644961Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:42:02.8645765Z   triton_mm_845 0.0799 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:02.8647112Z   triton_mm_853 0.0829 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:02.8648466Z   triton_mm_848 0.0840 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:02.8649772Z   triton_mm_839 0.0850 ms 94.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:02.8650951Z   triton_mm_844 0.0860 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:02.8651688Z   addmm 0.0881 ms 90.7% 
2026-01-14T08:42:02.8652382Z   triton_mm_841 0.0881 ms 90.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:02.8653567Z   triton_mm_851 0.0901 ms 88.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:02.8654304Z   bias_addmm 0.0922 ms 86.7% 
2026-01-14T08:42:02.8655024Z   triton_mm_847 0.0932 ms 85.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:02.8656065Z SingleProcess AUTOTUNE benchmarking takes 0.3410 seconds and 0.4823 seconds precompiling for 19 choices
2026-01-14T08:42:02.8656842Z >>time: 0.081ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:02.8657731Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.081ms 
2026-01-14T08:42:02.8658722Z >>time: 0.036ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.037ms 
2026-01-14T08:42:02.8659748Z >>time: 0.048ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.036ms
2026-01-14T08:42:02.8660662Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:42:02.8661118Z 
2026-01-14T08:42:02.8661245Z [32mPASSED[0m
2026-01-14T08:42:02.8661835Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_0 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:42:02.8662651Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:42:02.8663129Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:42:02.8663422Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:42:02.8663743Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:42:02.8664542Z   triton_mm_867 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:02.8665722Z   triton_mm_874 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:02.8666922Z   triton_mm_879 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:02.8668094Z   triton_mm_865 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:02.8669260Z   triton_mm_866 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:02.8670528Z   triton_mm_868 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:02.8671710Z   triton_mm_869 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:02.8672956Z   triton_mm_870 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:02.8674122Z   triton_mm_871 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:09.5562479Z   triton_mm_872 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:09.5563623Z SingleProcess AUTOTUNE benchmarking takes 0.2341 seconds and 0.8192 seconds precompiling for 21 choices
2026-01-14T08:42:09.5564428Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:09.5565550Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 53.31756591796875
2026-01-14T08:42:09.5567038Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 54.40925216674805
2026-01-14T08:42:09.5568495Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 48.288150787353516
2026-01-14T08:42:09.5569539Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:42:09.5569905Z 
2026-01-14T08:42:09.5570219Z [32mPASSED[0m
2026-01-14T08:42:09.5570865Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_1 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:42:09.5571703Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:42:09.5572199Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:42:09.5572506Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:42:09.5572829Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:42:09.5573637Z   triton_mm_900 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:09.5574859Z   triton_mm_901 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:09.5576070Z   triton_mm_885 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:09.5577317Z   triton_mm_888 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:09.5578501Z   triton_mm_889 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:09.5579695Z   triton_mm_891 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:09.5580881Z   triton_mm_894 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:09.5582375Z   triton_mm_897 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:09.5583574Z   triton_mm_895 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:09.5584923Z   triton_mm_898 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:09.5585910Z SingleProcess AUTOTUNE benchmarking takes 0.2521 seconds and 0.6315 seconds precompiling for 21 choices
2026-01-14T08:42:09.5586706Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:09.5587792Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 53.3125
2026-01-14T08:42:09.5589178Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 54.0
2026-01-14T08:42:09.5590560Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 48.15625
2026-01-14T08:42:09.5591573Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:42:09.5591942Z 
2026-01-14T08:42:09.5592076Z [32mPASSED[0m
2026-01-14T08:42:09.5592672Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_2 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:42:09.5593508Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:42:09.5593991Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:42:09.5594282Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:42:09.5594625Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:42:09.5595420Z   triton_mm_903 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:09.5596621Z   triton_mm_907 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:09.5597818Z   triton_mm_908 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:09.5599001Z   triton_mm_912 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:09.5600198Z   triton_mm_913 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:09.5601397Z   triton_mm_915 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:09.5602644Z   triton_mm_916 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:09.5603852Z   triton_mm_919 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:09.5605045Z   triton_mm_914 0.0236 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:09.5606326Z   triton_mm_910 0.0245 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:09.5607330Z SingleProcess AUTOTUNE benchmarking takes 0.2509 seconds and 0.6401 seconds precompiling for 21 choices
2026-01-14T08:42:09.5608121Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:09.5609277Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 49.0
2026-01-14T08:42:09.5610646Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 49.0
2026-01-14T08:42:09.5612015Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 46.25
2026-01-14T08:42:09.5613005Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:42:09.5613366Z 
2026-01-14T08:42:09.5613499Z [32mPASSED[0m
2026-01-14T08:42:09.5613996Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_00_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:42:09.5614610Z [33mSKIPPED[0m
2026-01-14T08:42:09.5615098Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_01_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:42:09.5615710Z [33mSKIPPED[0m
2026-01-14T08:42:09.5616194Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_02_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:42:09.5616789Z [33mSKIPPED[0m
2026-01-14T08:42:09.5617324Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_03_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:42:09.5617923Z [33mSKIPPED[0m
2026-01-14T08:42:09.5618416Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_04_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:42:09.5619001Z [33mSKIPPED[0m
2026-01-14T08:42:09.5619500Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_05_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:42:09.5620087Z [33mSKIPPED[0m
2026-01-14T08:42:09.5620582Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_06_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:42:09.5621171Z [33mSKIPPED[0m
2026-01-14T08:42:09.5621665Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_07_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:42:09.5622260Z [33mSKIPPED[0m
2026-01-14T08:42:09.5622742Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_08_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:42:09.5623329Z [33mSKIPPED[0m
2026-01-14T08:42:09.5623812Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_09_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:42:37.3045500Z [33mSKIPPED[0m
2026-01-14T08:42:37.3047907Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_10_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:42:37.3048633Z [33mSKIPPED[0m
2026-01-14T08:42:37.3049161Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_11_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:42:37.3049767Z [33mSKIPPED[0m
2026-01-14T08:42:37.3050269Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_12_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:42:37.3050880Z [33mSKIPPED[0m
2026-01-14T08:42:37.3051380Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_13_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:42:37.3051973Z [33mSKIPPED[0m
2026-01-14T08:42:37.3052470Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_14_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:42:37.3053064Z [33mSKIPPED[0m
2026-01-14T08:42:37.3053541Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_15 (m, k, n):  (16, 128, 128)
2026-01-14T08:42:37.3054123Z [32mPASSED[0m
2026-01-14T08:42:37.3054897Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_16 (m, k, n):  (64, 128, 128)
2026-01-14T08:42:37.3055524Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:42:37.3056047Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:42:37.3056703Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:42:37.3057005Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:42:37.3057339Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:42:37.3058163Z   triton_mm_922 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:37.3059381Z   triton_mm_923 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:37.3060590Z   triton_mm_924 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:37.3061792Z   triton_mm_925 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:37.3062976Z   triton_mm_935 0.0287 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:37.3064164Z   triton_mm_928 0.0297 ms 86.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:37.3065350Z   triton_mm_927 0.0327 ms 78.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:37.3066540Z   triton_mm_931 0.0328 ms 78.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:37.3067733Z   triton_mm_929 0.0369 ms 69.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:37.3068931Z   triton_mm_933 0.0369 ms 69.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:37.3069924Z SingleProcess AUTOTUNE benchmarking takes 0.2748 seconds and 10.7296 seconds precompiling for 19 choices
2026-01-14T08:42:37.3070725Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:37.3071279Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:42:37.3071550Z strides: [128, 1], [128, 1]
2026-01-14T08:42:37.3071825Z dtypes: torch.float32, torch.float32
2026-01-14T08:42:37.3072580Z   triton_mm_939 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:37.3073784Z   triton_mm_940 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:37.3074985Z   triton_mm_941 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:37.3076173Z   triton_mm_942 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:37.3077456Z   triton_mm_945 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:37.3078650Z   triton_mm_948 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:37.3079841Z   triton_mm_953 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:37.3081113Z   triton_mm_954 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:42:37.3082297Z   triton_mm_952 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:37.3083584Z   triton_mm_943 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:37.3084581Z SingleProcess AUTOTUNE benchmarking takes 0.2305 seconds and 5.0265 seconds precompiling for 18 choices
2026-01-14T08:42:37.3085530Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.013ms 
2026-01-14T08:42:37.3086200Z AUTOTUNE int_mm(64x128, 128x128)
2026-01-14T08:42:37.3086473Z strides: [128, 1], [1, 128]
2026-01-14T08:42:37.3086746Z dtypes: torch.int8, torch.int8
2026-01-14T08:42:37.3087463Z   triton_mm_960 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:37.3088642Z   triton_mm_959 0.0226 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:37.3089818Z   triton_mm_963 0.0236 ms 95.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:42:37.3090971Z   triton_mm_962 0.0236 ms 95.4% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:37.3092132Z   triton_mm_956 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:37.3093297Z   triton_mm_957 0.0256 ms 88.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:37.3094452Z   triton_mm_958 0.0256 ms 88.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:37.3095620Z   triton_mm_965 0.0256 ms 88.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:37.3096785Z   triton_mm_961 0.0266 ms 84.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:37.3097937Z   triton_mm_964 0.0266 ms 84.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:37.3098911Z SingleProcess AUTOTUNE benchmarking takes 0.1369 seconds and 0.2595 seconds precompiling for 11 choices
2026-01-14T08:42:37.3099837Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.013ms
2026-01-14T08:42:37.3100860Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.048ms 
2026-01-14T08:42:37.3102043Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 5.45
2026-01-14T08:42:37.3103030Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:42:37.3103498Z 
2026-01-14T08:42:37.3103634Z [32mPASSED[0m
2026-01-14T08:42:37.3104202Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_17 (m, k, n):  (16, 128, 256)
2026-01-14T08:42:37.3104824Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:42:37.3105345Z weight_shape: torch.Size([256, 128]), dtype: torch.float32, bias_shape: torch.Size([256])
2026-01-14T08:42:37.3105826Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:42:37.3106128Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:42:37.3106454Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:42:50.0988257Z   triton_mm_977 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:42:50.0989544Z   triton_mm_980 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:50.0990746Z   triton_mm_983 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:50.0992302Z   triton_mm_990 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:50.0993648Z   triton_mm_978 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:50.0994830Z   triton_mm_976 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:50.0996009Z   triton_mm_979 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:50.0997197Z   triton_mm_981 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:50.0998395Z   triton_mm_982 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:50.0999593Z   triton_mm_984 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:50.1000594Z SingleProcess AUTOTUNE benchmarking takes 0.2317 seconds and 1.8914 seconds precompiling for 19 choices
2026-01-14T08:42:50.1001403Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:50.1001970Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:42:50.1002233Z strides: [128, 1], [256, 1]
2026-01-14T08:42:50.1002512Z dtypes: torch.float32, torch.float32
2026-01-14T08:42:50.1003396Z   triton_mm_994 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:42:50.1011783Z   triton_mm_1006 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:50.1013058Z   triton_mm_993 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:50.1015854Z   triton_mm_995 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:50.1017070Z   triton_mm_998 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:50.1018425Z   triton_mm_999 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:50.1019633Z   triton_mm_1002 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:50.1020857Z   triton_mm_1004 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:50.1022078Z   triton_mm_1005 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:50.1023301Z   triton_mm_1007 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:50.1024309Z SingleProcess AUTOTUNE benchmarking takes 0.2089 seconds and 0.7406 seconds precompiling for 18 choices
2026-01-14T08:42:50.1025226Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:42:50.1026241Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.007ms 
2026-01-14T08:42:50.1026902Z AUTOTUNE int_mm(16x128, 128x256)
2026-01-14T08:42:50.1027184Z strides: [128, 1], [1, 128]
2026-01-14T08:42:50.1027454Z dtypes: torch.int8, torch.int8
2026-01-14T08:42:50.1028196Z   triton_mm_1013 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:50.1029397Z   triton_mm_1014 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:50.1030605Z   triton_mm_1017 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:42:50.1031804Z   triton_mm_1018 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:50.1033007Z   triton_mm_1019 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:50.1034221Z   triton_mm_1020 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:50.1035423Z   triton_mm_1016 0.0226 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:50.1036610Z   triton_mm_1010 0.0236 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:50.1037800Z   triton_mm_1011 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:50.1039527Z   triton_mm_1012 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:50.1040537Z SingleProcess AUTOTUNE benchmarking takes 0.1368 seconds and 0.2141 seconds precompiling for 12 choices
2026-01-14T08:42:50.1041473Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:42:50.1042525Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:42:50.1043069Z 
2026-01-14T08:42:50.1043378Z [32mPASSED[0m
2026-01-14T08:42:50.1043899Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_18 (m, k, n):  (16, 256, 128)
2026-01-14T08:42:50.1044523Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:42:50.1045048Z weight_shape: torch.Size([128, 256]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:42:50.1045531Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:42:50.1045837Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:42:50.1046174Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:42:50.1046984Z   triton_mm_1025 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:50.1048212Z   triton_mm_1022 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:42:50.1049465Z   triton_mm_1024 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:50.1050675Z   triton_mm_1034 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:50.1051888Z   triton_mm_1023 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:50.1053085Z   triton_mm_1028 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:50.1054292Z   triton_mm_1035 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:43:11.5125940Z   triton_mm_1021 0.0287 ms 85.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:43:11.5127190Z   triton_mm_1027 0.0307 ms 80.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:11.5128420Z   triton_mm_1026 0.0338 ms 72.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:11.5129443Z SingleProcess AUTOTUNE benchmarking takes 0.2081 seconds and 1.3038 seconds precompiling for 19 choices
2026-01-14T08:43:11.5130249Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:11.5130826Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:43:11.5131094Z strides: [256, 1], [128, 1]
2026-01-14T08:43:11.5131369Z dtypes: torch.float32, torch.float32
2026-01-14T08:43:11.5132136Z   triton_mm_1051 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:11.5133653Z   triton_mm_1044 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:11.5134872Z   triton_mm_1052 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:43:11.5136088Z   triton_mm_1040 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:11.5137446Z   triton_mm_1041 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:11.5138660Z   triton_mm_1042 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:11.5140296Z   triton_mm_1043 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:11.5141511Z   triton_mm_1047 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:11.5142730Z   triton_mm_1048 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:11.5143950Z   triton_mm_1049 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:11.5144963Z SingleProcess AUTOTUNE benchmarking takes 0.1890 seconds and 1.0169 seconds precompiling for 18 choices
2026-01-14T08:43:11.5145868Z >>time: 0.018ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.010ms 
2026-01-14T08:43:11.5146875Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.010ms 
2026-01-14T08:43:11.5147538Z AUTOTUNE int_mm(16x256, 256x128)
2026-01-14T08:43:11.5147814Z strides: [256, 1], [1, 256]
2026-01-14T08:43:11.5148089Z dtypes: torch.int8, torch.int8
2026-01-14T08:43:11.5148821Z   triton_mm_1059 0.0216 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:43:11.5150022Z   triton_mm_1062 0.0225 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:43:11.5151217Z   triton_mm_1063 0.0225 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:11.5152422Z   triton_mm_1064 0.0225 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:11.5153613Z   triton_mm_1055 0.0236 ms 91.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:11.5154813Z   triton_mm_1056 0.0246 ms 87.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:11.5156010Z   triton_mm_1057 0.0246 ms 87.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:11.5157193Z   triton_mm_1058 0.0246 ms 87.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:11.5158531Z   triton_mm_1060 0.0246 ms 87.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:11.5159742Z   triton_mm_1061 0.0246 ms 87.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:11.5160733Z SingleProcess AUTOTUNE benchmarking takes 0.1236 seconds and 0.2101 seconds precompiling for 11 choices
2026-01-14T08:43:11.5161825Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:43:11.5162859Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:43:11.5163328Z 
2026-01-14T08:43:11.5163637Z [32mPASSED[0m
2026-01-14T08:43:11.5164150Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_19 (m, k, n):  (64, 256, 128)
2026-01-14T08:43:11.5164774Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:43:11.5165300Z weight_shape: torch.Size([128, 256]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:43:11.5165781Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:43:11.5166079Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:43:11.5166402Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:43:11.5167216Z   triton_mm_1066 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:11.5168455Z   triton_mm_1065 0.0358 ms 77.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:43:11.5169659Z   triton_mm_1067 0.0388 ms 71.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:11.5170875Z   triton_mm_1068 0.0389 ms 71.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:11.5172082Z   triton_mm_1078 0.0420 ms 65.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:11.5173286Z   triton_mm_1071 0.0430 ms 64.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:11.5174497Z   triton_mm_1070 0.0461 ms 60.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:11.5175703Z   triton_mm_1074 0.0461 ms 60.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:11.5176915Z   triton_mm_1076 0.0461 ms 60.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:11.5178120Z   triton_mm_1079 0.0471 ms 58.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:11.5179135Z SingleProcess AUTOTUNE benchmarking takes 0.2076 seconds and 4.4705 seconds precompiling for 19 choices
2026-01-14T08:43:11.5179927Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:11.5180472Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:43:11.5180737Z strides: [256, 1], [128, 1]
2026-01-14T08:43:11.5181000Z dtypes: torch.float32, torch.float32
2026-01-14T08:43:11.5181862Z   triton_mm_1083 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:11.5183088Z   triton_mm_1084 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:21.0085793Z   triton_mm_1096 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:21.0087349Z   triton_mm_1095 0.0255 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:21.0088559Z   triton_mm_1085 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:21.0089761Z   triton_mm_1089 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:21.0090966Z   triton_mm_1082 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:43:21.0092165Z   triton_mm_1088 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:21.0093366Z   triton_mm_1087 0.0317 ms 77.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:21.0094570Z   triton_mm_1091 0.0328 ms 75.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:21.0095586Z SingleProcess AUTOTUNE benchmarking takes 0.1892 seconds and 3.6461 seconds precompiling for 18 choices
2026-01-14T08:43:21.0096503Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.016ms 
2026-01-14T08:43:21.0097173Z AUTOTUNE int_mm(64x256, 256x128)
2026-01-14T08:43:21.0097447Z strides: [256, 1], [1, 256]
2026-01-14T08:43:21.0097723Z dtypes: torch.int8, torch.int8
2026-01-14T08:43:21.0098466Z   triton_mm_1106 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:43:21.0099667Z   triton_mm_1099 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:21.0100858Z   triton_mm_1100 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:21.0102044Z   triton_mm_1101 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:21.0103232Z   triton_mm_1102 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:21.0104424Z   triton_mm_1103 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:21.0105602Z   triton_mm_1104 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:21.0106788Z   triton_mm_1105 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:21.0108134Z   triton_mm_1107 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:21.0109318Z   triton_mm_1108 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:21.0110410Z SingleProcess AUTOTUNE benchmarking takes 0.1362 seconds and 0.2782 seconds precompiling for 11 choices
2026-01-14T08:43:21.0111344Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.011ms
2026-01-14T08:43:21.0112374Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.012ms 
2026-01-14T08:43:21.0113468Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 0.01
2026-01-14T08:43:21.0114449Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:43:21.0114911Z 
2026-01-14T08:43:21.0115227Z [32mPASSED[0m
2026-01-14T08:43:21.0115733Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_20 (m, k, n):  (16, 128, 128)
2026-01-14T08:43:21.0116315Z [32mPASSED[0m
2026-01-14T08:43:21.0116793Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_21 (m, k, n):  (64, 128, 128)
2026-01-14T08:43:21.0117404Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:43:21.0117918Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:43:21.0118395Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:43:21.0118679Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:43:21.0119003Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:43:21.0119812Z   triton_mm_1127 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:21.0121038Z   triton_mm_1131 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:43:21.0122252Z   triton_mm_1132 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:21.0123559Z   triton_mm_1128 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:21.0124754Z   triton_mm_1120 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:21.0125941Z   triton_mm_1121 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:21.0127129Z   triton_mm_1123 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:21.0128324Z   triton_mm_1124 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:21.0129511Z   triton_mm_1125 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:21.0130700Z   triton_mm_1126 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:21.0131787Z SingleProcess AUTOTUNE benchmarking takes 0.2364 seconds and 0.4744 seconds precompiling for 19 choices
2026-01-14T08:43:21.0132574Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:21.0133129Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:43:21.0133386Z strides: [128, 1], [128, 1]
2026-01-14T08:43:21.0133663Z dtypes: torch.float16, torch.float16
2026-01-14T08:43:21.0134512Z   triton_mm_1147 0.0226 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:21.0135723Z   triton_mm_1148 0.0236 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:43:21.0136943Z   triton_mm_1136 0.0246 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:43:21.0138152Z   triton_mm_1137 0.0246 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:21.0139586Z   triton_mm_1139 0.0246 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:21.0140793Z   triton_mm_1140 0.0246 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:21.0141988Z   triton_mm_1141 0.0246 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:34.3056990Z   triton_mm_1143 0.0246 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:34.3058271Z   triton_mm_1144 0.0246 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:34.3059509Z   triton_mm_1145 0.0246 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:34.3060529Z SingleProcess AUTOTUNE benchmarking takes 0.2183 seconds and 0.3796 seconds precompiling for 18 choices
2026-01-14T08:43:34.3061449Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.006ms 
2026-01-14T08:43:34.3062481Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.006ms
2026-01-14T08:43:34.3063410Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:43:34.3063874Z 
2026-01-14T08:43:34.3064203Z [32mPASSED[0m
2026-01-14T08:43:34.3064711Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_22 (m, k, n):  (16, 128, 256)
2026-01-14T08:43:34.3065343Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:43:34.3065861Z weight_shape: torch.Size([256, 128]), dtype: torch.float16, bias_shape: torch.Size([256])
2026-01-14T08:43:34.3066353Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:43:34.3066654Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:43:34.3066986Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:43:34.3067803Z   triton_mm_1164 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:43:34.3069311Z   triton_mm_1169 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:34.3070546Z   triton_mm_1167 0.0245 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:34.3071761Z   triton_mm_1163 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:43:34.3073108Z   triton_mm_1166 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:34.3074314Z   triton_mm_1168 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:34.3075517Z   triton_mm_1170 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:34.3076714Z   triton_mm_1171 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:34.3077917Z   triton_mm_1172 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:34.3079126Z   triton_mm_1173 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:34.3080118Z SingleProcess AUTOTUNE benchmarking takes 0.2400 seconds and 0.3063 seconds precompiling for 19 choices
2026-01-14T08:43:34.3080914Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:34.3081456Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:43:34.3081720Z strides: [128, 1], [256, 1]
2026-01-14T08:43:34.3081983Z dtypes: torch.float16, torch.float16
2026-01-14T08:43:34.3082867Z   triton_mm_1181 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:43:34.3084082Z   triton_mm_1182 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:34.3085284Z   triton_mm_1183 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:34.3086491Z   triton_mm_1184 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:34.3087705Z   triton_mm_1186 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:34.3088904Z   triton_mm_1187 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:34.3090120Z   triton_mm_1188 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:34.3091331Z   triton_mm_1189 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:34.3092535Z   triton_mm_1190 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:34.3093831Z   triton_mm_1191 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:34.3094837Z SingleProcess AUTOTUNE benchmarking takes 0.2128 seconds and 0.3180 seconds precompiling for 18 choices
2026-01-14T08:43:34.3095727Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.005ms 
2026-01-14T08:43:34.3096811Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.005ms 
2026-01-14T08:43:34.3097844Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:43:34.3098766Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:43:34.3099220Z 
2026-01-14T08:43:34.3099366Z [32mPASSED[0m
2026-01-14T08:43:34.3099851Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_23 (m, k, n):  (16, 256, 128)
2026-01-14T08:43:34.3100475Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:43:34.3100981Z weight_shape: torch.Size([128, 256]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:43:34.3101465Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:43:34.3101758Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:43:34.3102081Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:43:34.3102889Z   triton_mm_1212 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:34.3104100Z   triton_mm_1221 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:34.3105321Z   triton_mm_1223 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:43:34.3106531Z   triton_mm_1211 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:34.3107730Z   triton_mm_1218 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:34.3108938Z   triton_mm_1222 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:43:34.3110142Z   triton_mm_1209 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:43:34.3111344Z   triton_mm_1224 0.0256 ms 92.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:34.3112547Z   triton_mm_1208 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:43:34.3113753Z   triton_mm_1210 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:50.1548331Z SingleProcess AUTOTUNE benchmarking takes 0.2280 seconds and 0.3251 seconds precompiling for 19 choices
2026-01-14T08:43:50.1549412Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:50.1549974Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:43:50.1550239Z strides: [256, 1], [128, 1]
2026-01-14T08:43:50.1550517Z dtypes: torch.float16, torch.float16
2026-01-14T08:43:50.1551869Z   triton_mm_1229 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:50.1553554Z   triton_mm_1233 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:50.1555005Z   triton_mm_1236 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:50.1556193Z   triton_mm_1239 0.0236 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:43:50.1557381Z   triton_mm_1225 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:43:50.1558593Z   triton_mm_1226 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:43:50.1559795Z   triton_mm_1227 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:50.1561007Z   triton_mm_1228 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:50.1562213Z   triton_mm_1230 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:50.1563538Z   triton_mm_1231 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:50.1564540Z SingleProcess AUTOTUNE benchmarking takes 0.2100 seconds and 0.3421 seconds precompiling for 18 choices
2026-01-14T08:43:50.1565456Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.005ms 
2026-01-14T08:43:50.1566461Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.005ms 
2026-01-14T08:43:50.1567498Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:43:50.1568416Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:43:50.1568880Z 
2026-01-14T08:43:50.1569191Z [32mPASSED[0m
2026-01-14T08:43:50.1569710Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_24 (m, k, n):  (64, 256, 128)
2026-01-14T08:43:50.1570346Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:43:50.1570877Z weight_shape: torch.Size([128, 256]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:43:50.1571358Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:43:50.1571659Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:43:50.1571985Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:43:50.1572804Z   triton_mm_1265 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:50.1574020Z   triton_mm_1266 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:50.1575220Z   triton_mm_1252 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:43:50.1576576Z   triton_mm_1254 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:50.1577786Z   triton_mm_1255 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:50.1579069Z   triton_mm_1256 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:50.1580286Z   triton_mm_1257 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:50.1581496Z   triton_mm_1258 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:50.1582704Z   triton_mm_1259 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:50.1583919Z   triton_mm_1261 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:50.1584927Z SingleProcess AUTOTUNE benchmarking takes 0.2215 seconds and 0.5389 seconds precompiling for 19 choices
2026-01-14T08:43:50.1585754Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:50.1586451Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:43:50.1586780Z strides: [256, 1], [128, 1]
2026-01-14T08:43:50.1587124Z dtypes: torch.float16, torch.float16
2026-01-14T08:43:50.1588094Z   triton_mm_1280 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:50.1589331Z   triton_mm_1282 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:50.1590556Z   triton_mm_1278 0.0235 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:50.1591771Z   triton_mm_1283 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:50.1592988Z   triton_mm_1270 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:50.1594203Z   triton_mm_1271 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:50.1595475Z   triton_mm_1273 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:50.1596988Z   triton_mm_1274 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:50.1598259Z   triton_mm_1275 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:50.1599465Z   triton_mm_1279 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:50.1600564Z SingleProcess AUTOTUNE benchmarking takes 0.2004 seconds and 0.5174 seconds precompiling for 18 choices
2026-01-14T08:43:50.1601460Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:43:50.1602709Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.007ms
2026-01-14T08:43:50.1603665Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:43:50.1604024Z 
2026-01-14T08:43:50.1604166Z [32mPASSED[0m
2026-01-14T08:43:50.1604655Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_25 (m, k, n):  (16, 128, 128)
2026-01-14T08:43:50.1605234Z [32mPASSED[0m
2026-01-14T08:43:50.1605710Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_26 (m, k, n):  (64, 128, 128)
2026-01-14T08:43:50.1606330Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:43:50.1606847Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:43:50.1607334Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:43:50.1607622Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:43:50.1607962Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:43:50.1608779Z   triton_mm_1306 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:01.5791924Z   triton_mm_1299 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:01.5793175Z   triton_mm_1300 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:01.5794433Z   triton_mm_1304 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:01.5795664Z   triton_mm_1305 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:01.5796870Z   triton_mm_1311 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:44:01.5798086Z   triton_mm_1296 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:01.5799290Z   triton_mm_1297 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:01.5800491Z   triton_mm_1298 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:01.5801688Z   triton_mm_1301 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:01.5802795Z SingleProcess AUTOTUNE benchmarking takes 0.2366 seconds and 0.4648 seconds precompiling for 19 choices
2026-01-14T08:44:01.5803600Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:44:01.5804159Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:44:01.5804424Z strides: [128, 1], [128, 1]
2026-01-14T08:44:01.5804705Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:44:01.5805475Z   triton_mm_1326 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:01.5806996Z   triton_mm_1323 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:01.5808237Z   triton_mm_1313 0.0236 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:01.5809607Z   triton_mm_1314 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:01.5810810Z   triton_mm_1318 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:01.5812019Z   triton_mm_1319 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:01.5813237Z   triton_mm_1322 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:01.5814445Z   triton_mm_1324 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:01.5815672Z   triton_mm_1325 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:01.5816890Z   triton_mm_1327 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:01.5817890Z SingleProcess AUTOTUNE benchmarking takes 0.2218 seconds and 0.4153 seconds precompiling for 18 choices
2026-01-14T08:44:01.5818804Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:44:01.5819835Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.007ms
2026-01-14T08:44:01.5820876Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.013ms 
2026-01-14T08:44:01.5821982Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 0.50
2026-01-14T08:44:01.5822973Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:44:01.5823440Z 
2026-01-14T08:44:01.5823750Z [32mPASSED[0m
2026-01-14T08:44:01.5824261Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_27 (m, k, n):  (16, 128, 256)
2026-01-14T08:44:01.5824901Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:44:01.5825442Z weight_shape: torch.Size([256, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([256])
2026-01-14T08:44:01.5825930Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:44:01.5826231Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:44:01.5826577Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:01.5827417Z   triton_mm_1360 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:01.5828657Z   triton_mm_1361 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:01.5829881Z   triton_mm_1363 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:01.5831188Z   triton_mm_1350 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:01.5832403Z   triton_mm_1351 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:44:01.5833620Z   triton_mm_1352 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:01.5834956Z   triton_mm_1353 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:44:01.5836163Z   triton_mm_1354 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:44:01.5837382Z   triton_mm_1355 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:01.5838592Z   triton_mm_1356 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:01.5839870Z SingleProcess AUTOTUNE benchmarking takes 0.2388 seconds and 0.2983 seconds precompiling for 19 choices
2026-01-14T08:44:01.5840673Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:44:01.5841234Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:44:01.5841494Z strides: [128, 1], [256, 1]
2026-01-14T08:44:01.5841774Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:44:01.5850484Z   triton_mm_1382 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:44:01.5851788Z   triton_mm_1383 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:01.5853013Z   triton_mm_1371 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:44:01.5854226Z   triton_mm_1367 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:01.5855437Z   triton_mm_1368 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:44:01.5856649Z   triton_mm_1369 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:20.4774274Z   triton_mm_1370 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:44:20.4775531Z   triton_mm_1372 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:20.4776751Z   triton_mm_1373 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:20.4777974Z   triton_mm_1374 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:20.4778988Z SingleProcess AUTOTUNE benchmarking takes 0.2180 seconds and 0.2536 seconds precompiling for 18 choices
2026-01-14T08:44:20.4780253Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.005ms 
2026-01-14T08:44:20.4781262Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.005ms 
2026-01-14T08:44:20.4782295Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:44:20.4783383Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:44:20.4783842Z 
2026-01-14T08:44:20.4784156Z [32mPASSED[0m
2026-01-14T08:44:20.4784695Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_28 (m, k, n):  (16, 256, 128)
2026-01-14T08:44:20.4785361Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:44:20.4785884Z weight_shape: torch.Size([128, 256]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:44:20.4786380Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:44:20.4786686Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:44:20.4787025Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:20.4787856Z   triton_mm_1401 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:20.4789089Z   triton_mm_1403 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:20.4790324Z   triton_mm_1406 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:20.4791546Z   triton_mm_1408 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:20.4792765Z   triton_mm_1409 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:20.4793987Z   triton_mm_1411 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:20.4795267Z   triton_mm_1410 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:44:20.4796475Z   triton_mm_1405 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:20.4797683Z   triton_mm_1395 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:20.4798894Z   triton_mm_1397 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:20.4799893Z SingleProcess AUTOTUNE benchmarking takes 0.2307 seconds and 0.3375 seconds precompiling for 19 choices
2026-01-14T08:44:20.4800715Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:44:20.4801274Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:44:20.4801536Z strides: [256, 1], [128, 1]
2026-01-14T08:44:20.4801817Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:44:20.4802671Z   triton_mm_1427 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:44:20.4803999Z   triton_mm_1428 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:20.4805218Z   triton_mm_1413 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:44:20.4806421Z   triton_mm_1415 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:44:20.4807718Z   triton_mm_1416 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:44:20.4808929Z   triton_mm_1419 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:20.4810143Z   triton_mm_1420 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:20.4811363Z   triton_mm_1421 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:20.4812578Z   triton_mm_1422 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:20.4813797Z   triton_mm_1423 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:20.4814811Z SingleProcess AUTOTUNE benchmarking takes 0.2101 seconds and 0.3390 seconds precompiling for 18 choices
2026-01-14T08:44:20.4815706Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.008ms 
2026-01-14T08:44:20.4816718Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.008ms 
2026-01-14T08:44:20.4817757Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.005ms
2026-01-14T08:44:20.4818673Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:44:20.4819141Z 
2026-01-14T08:44:20.4819272Z [32mPASSED[0m
2026-01-14T08:44:20.4819751Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_29 (m, k, n):  (64, 256, 128)
2026-01-14T08:44:20.4820381Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:44:20.4820902Z weight_shape: torch.Size([128, 256]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:44:20.4821383Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:44:20.4821679Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:44:20.4822022Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:20.4822859Z   triton_mm_1452 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:20.4824088Z   triton_mm_1455 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:20.4825360Z   triton_mm_1442 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:20.4826574Z   triton_mm_1450 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:20.4827867Z   triton_mm_1439 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:20.4829086Z   triton_mm_1440 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:20.4830298Z   triton_mm_1441 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:20.4831582Z   triton_mm_1443 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:30.9482215Z   triton_mm_1448 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:30.9483570Z   triton_mm_1453 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:30.9484594Z SingleProcess AUTOTUNE benchmarking takes 0.2239 seconds and 0.5785 seconds precompiling for 19 choices
2026-01-14T08:44:30.9485402Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:44:30.9485982Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:44:30.9486250Z strides: [256, 1], [128, 1]
2026-01-14T08:44:30.9486542Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:44:30.9487315Z   triton_mm_1469 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:30.9488545Z   triton_mm_1467 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:30.9489774Z   triton_mm_1470 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:30.9490990Z   triton_mm_1471 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:44:30.9492225Z   triton_mm_1457 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:30.9493444Z   triton_mm_1459 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:30.9494657Z   triton_mm_1466 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:30.9495882Z   triton_mm_1472 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:30.9497098Z   triton_mm_1456 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:30.9498310Z   triton_mm_1458 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:30.9499326Z SingleProcess AUTOTUNE benchmarking takes 0.2005 seconds and 0.5036 seconds precompiling for 18 choices
2026-01-14T08:44:30.9500240Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:44:30.9501270Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.007ms
2026-01-14T08:44:30.9502384Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:44:30.9502753Z 
2026-01-14T08:44:30.9503075Z [32mPASSED[0m
2026-01-14T08:44:30.9503561Z test/integration/test_integration.py::TestAOTI::test_aoti_00 [33mSKIPPED[0m
2026-01-14T08:44:30.9504243Z test/integration/test_integration.py::TestAOTI::test_aoti_01 [33mSKIPPED[0m
2026-01-14T08:44:30.9505085Z test/integration/test_integration.py::TestAOTI::test_aoti_02 [33mSKIPPED[0m
2026-01-14T08:44:30.9505760Z test/integration/test_integration.py::TestAOTI::test_aoti_03 [33mSKIPPED[0m
2026-01-14T08:44:30.9506426Z test/integration/test_integration.py::TestAOTI::test_aoti_04 [33mSKIPPED[0m
2026-01-14T08:44:30.9507084Z test/integration/test_integration.py::TestAOTI::test_aoti_05 [33mSKIPPED[0m
2026-01-14T08:44:30.9507762Z test/integration/test_integration.py::TestAOTI::test_aoti_06 [33mSKIPPED[0m
2026-01-14T08:44:30.9508429Z test/integration/test_integration.py::TestAOTI::test_aoti_07 [33mSKIPPED[0m
2026-01-14T08:44:30.9509096Z test/integration/test_integration.py::TestAOTI::test_aoti_08 [33mSKIPPED[0m
2026-01-14T08:44:30.9509763Z test/integration/test_integration.py::TestAOTI::test_aoti_09 [33mSKIPPED[0m
2026-01-14T08:44:30.9510422Z test/integration/test_integration.py::TestAOTI::test_aoti_10 [33mSKIPPED[0m
2026-01-14T08:44:30.9511100Z test/integration/test_integration.py::TestAOTI::test_aoti_11 [33mSKIPPED[0m
2026-01-14T08:44:30.9511763Z test/integration/test_integration.py::TestAOTI::test_aoti_12 [33mSKIPPED[0m
2026-01-14T08:44:30.9512428Z test/integration/test_integration.py::TestAOTI::test_aoti_13 [33mSKIPPED[0m
2026-01-14T08:44:30.9513089Z test/integration/test_integration.py::TestAOTI::test_aoti_14 [33mSKIPPED[0m
2026-01-14T08:44:30.9513759Z test/integration/test_integration.py::TestAOTI::test_aoti_15 [33mSKIPPED[0m
2026-01-14T08:44:30.9514429Z test/integration/test_integration.py::TestAOTI::test_aoti_16 [33mSKIPPED[0m
2026-01-14T08:44:30.9515100Z test/integration/test_integration.py::TestAOTI::test_aoti_17 [33mSKIPPED[0m
2026-01-14T08:44:30.9515784Z test/integration/test_integration.py::TestExport::test_export_00 [32mPASSED[0m
2026-01-14T08:44:30.9516476Z test/integration/test_integration.py::TestExport::test_export_01 [32mPASSED[0m
2026-01-14T08:44:30.9517175Z test/integration/test_integration.py::TestExport::test_export_02 [32mPASSED[0m
2026-01-14T08:44:30.9517876Z test/integration/test_integration.py::TestExport::test_export_03 [32mPASSED[0m
2026-01-14T08:44:30.9518568Z test/integration/test_integration.py::TestExport::test_export_04 [32mPASSED[0m
2026-01-14T08:44:30.9519260Z test/integration/test_integration.py::TestExport::test_export_05 [32mPASSED[0m
2026-01-14T08:44:30.9519946Z test/integration/test_integration.py::TestExport::test_export_06 [32mPASSED[0m
2026-01-14T08:44:30.9520637Z test/integration/test_integration.py::TestExport::test_export_07 [32mPASSED[0m
2026-01-14T08:44:30.9521340Z test/integration/test_integration.py::TestExport::test_export_08 [32mPASSED[0m
2026-01-14T08:44:30.9522031Z test/integration/test_integration.py::TestExport::test_export_09 [32mPASSED[0m
2026-01-14T08:44:30.9522795Z test/integration/test_integration.py::TestExport::test_export_10 [32mPASSED[0m
2026-01-14T08:44:30.9523485Z test/integration/test_integration.py::TestExport::test_export_11 [32mPASSED[0m
2026-01-14T08:44:30.9524188Z test/integration/test_integration.py::TestExport::test_export_12 [32mPASSED[0m
2026-01-14T08:44:30.9524877Z test/integration/test_integration.py::TestExport::test_export_13 [32mPASSED[0m
2026-01-14T08:44:30.9525571Z test/integration/test_integration.py::TestExport::test_export_14 [32mPASSED[0m
2026-01-14T08:44:30.9526268Z test/integration/test_integration.py::TestExport::test_export_15 [32mPASSED[0m
2026-01-14T08:44:30.9526956Z test/integration/test_integration.py::TestExport::test_export_16 [32mPASSED[0m
2026-01-14T08:44:30.9527652Z test/integration/test_integration.py::TestExport::test_export_17 [32mPASSED[0m
2026-01-14T08:44:30.9528437Z test/integration/test_integration.py::TestExport::test_export_18 [32mPASSED[0m
2026-01-14T08:44:30.9529134Z test/integration/test_integration.py::TestExport::test_export_19 [32mPASSED[0m
2026-01-14T08:44:30.9529821Z test/integration/test_integration.py::TestExport::test_export_20 [32mPASSED[0m
2026-01-14T08:44:30.9530514Z test/integration/test_integration.py::TestExport::test_export_21 [32mPASSED[0m
2026-01-14T08:44:30.9533331Z test/integration/test_integration.py::TestExport::test_export_22 [32mPASSED[0m
2026-01-14T08:44:30.9534029Z test/integration/test_integration.py::TestExport::test_export_23 [32mPASSED[0m
2026-01-14T08:44:30.9534751Z test/integration/test_integration.py::TestExport::test_export_float8 [33mSKIPPED[0m
2026-01-14T08:44:30.9535526Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_00 [33mSKIPPED[0m
2026-01-14T08:44:30.9536313Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_01 [33mSKIPPED[0m
2026-01-14T08:44:30.9537105Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_02 [33mSKIPPED[0m
2026-01-14T08:44:30.9537947Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_03 [33mSKIPPED[0m
2026-01-14T08:44:30.9538733Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_04 [33mSKIPPED[0m
2026-01-14T08:44:30.9539731Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_05 [32mPASSED[0m
2026-01-14T08:44:30.9540511Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_06 [33mSKIPPED[0m
2026-01-14T08:44:30.9541286Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_07 [33mSKIPPED[0m
2026-01-14T08:44:30.9542067Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_08 [33mSKIPPED[0m
2026-01-14T08:44:30.9542847Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_09 [33mSKIPPED[0m
2026-01-14T08:44:30.9543629Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_10 [33mSKIPPED[0m
2026-01-14T08:44:30.9544408Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_11 [32mPASSED[0m
2026-01-14T08:44:30.9545181Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_12 [33mSKIPPED[0m
2026-01-14T08:44:30.9545967Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_13 [33mSKIPPED[0m
2026-01-14T08:44:30.9546757Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_14 [33mSKIPPED[0m
2026-01-14T08:44:30.9547533Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_15 [33mSKIPPED[0m
2026-01-14T08:44:30.9548313Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_16 [33mSKIPPED[0m
2026-01-14T08:44:30.9549089Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_17 [32mPASSED[0m
2026-01-14T08:44:30.9549924Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cpu [32mPASSED[0m
2026-01-14T08:46:26.9586575Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cuda [32mPASSED[0m
2026-01-14T08:46:26.9587915Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_hf_models_model_info0 [33mSKIPPED[0m
2026-01-14T08:46:26.9589378Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:46:26.9590827Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:46:26.9592182Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info1 [33mSKIPPED[0m
2026-01-14T08:46:26.9593527Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info2 [33mSKIPPED[0m
2026-01-14T08:46:26.9595251Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info3 [33mSKIPPED[0m
2026-01-14T08:46:26.9596616Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info4 [33mSKIPPED[0m
2026-01-14T08:46:26.9597728Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_0_cuda [32mPASSED[0m
2026-01-14T08:46:26.9598584Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_1_cuda [32mPASSED[0m
2026-01-14T08:46:26.9599677Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_0_cuda [33mSKIPPED[0m
2026-01-14T08:46:26.9600619Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_1_cuda [33mSKIPPED[0m
2026-01-14T08:46:26.9601536Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_0_cuda [32mPASSED[0m
2026-01-14T08:46:26.9602451Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu [32mPASSED[0m
2026-01-14T08:46:26.9603447Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_2_cuda [32mPASSED[0m
2026-01-14T08:46:26.9604385Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu [32mPASSED[0m
2026-01-14T08:46:26.9605323Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-2-512-128] Relative Error: 0.052789
2026-01-14T08:46:26.9606064Z [32mPASSED[0m
2026-01-14T08:46:26.9606683Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-3-2048-2048] Relative Error: 0.052619
2026-01-14T08:46:26.9607424Z [32mPASSED[0m
2026-01-14T08:46:26.9608036Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-4-3584-640] Relative Error: 0.052605
2026-01-14T08:46:26.9608770Z [32mPASSED[0m
2026-01-14T08:46:26.9609402Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-13-8704-8576] Relative Error: 0.052641
2026-01-14T08:46:26.9610152Z [32mPASSED[0m
2026-01-14T08:46:26.9610811Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-26-18944-1664] Relative Error: 0.052629
2026-01-14T08:46:26.9611582Z [32mPASSED[0m
2026-01-14T08:46:26.9612193Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-67-6656-1408] Relative Error: 0.052626
2026-01-14T08:46:26.9612942Z [32mPASSED[0m
2026-01-14T08:46:26.9613512Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-2-512-128] Relative Error: 0.076733
2026-01-14T08:46:26.9614226Z [32mPASSED[0m
2026-01-14T08:46:26.9614816Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-3-2048-2048] Relative Error: 0.073021
2026-01-14T08:46:26.9615532Z [32mPASSED[0m
2026-01-14T08:46:26.9616118Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-4-3584-640] Relative Error: 0.073371
2026-01-14T08:46:26.9616817Z [32mPASSED[0m
2026-01-14T08:46:26.9617412Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-13-8704-8576] Relative Error: 0.073475
2026-01-14T08:46:26.9618125Z [32mPASSED[0m
2026-01-14T08:46:26.9618718Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-26-18944-1664] Relative Error: 0.073329
2026-01-14T08:46:26.9619445Z [32mPASSED[0m
2026-01-14T08:46:26.9620022Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-67-6656-1408] Relative Error: 0.073540
2026-01-14T08:46:26.9620734Z [32mPASSED[0m
2026-01-14T08:46:26.9621599Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-2-512-128] [33mSKIPPED[0m
2026-01-14T08:46:26.9623049Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-2-5120-1280] [33mSKIPPED[0m
2026-01-14T08:46:26.9624490Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-3-2048-2048] [33mSKIPPED[0m
2026-01-14T08:46:26.9625912Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-4-3584-640] [33mSKIPPED[0m
2026-01-14T08:46:26.9627458Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-13-8704-8576] [33mSKIPPED[0m
2026-01-14T08:46:26.9628927Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-26-18944-1664] [33mSKIPPED[0m
2026-01-14T08:46:26.9630377Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-67-6656-1408] [33mSKIPPED[0m
2026-01-14T08:46:26.9631902Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-2-512-128] [33mSKIPPED[0m
2026-01-14T08:46:26.9633311Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-2-5120-1280] [33mSKIPPED[0m
2026-01-14T08:46:26.9634736Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-3-2048-2048] [33mSKIPPED[0m
2026-01-14T08:46:26.9636160Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-4-3584-640] [33mSKIPPED[0m
2026-01-14T08:46:26.9637580Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-13-8704-8576] [33mSKIPPED[0m
2026-01-14T08:46:26.9639203Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-26-18944-1664] [33mSKIPPED[0m
2026-01-14T08:46:26.9640660Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-67-6656-1408] [33mSKIPPED[0m
2026-01-14T08:46:26.9642044Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_lhs[128] [33mSKIPPED[0m
2026-01-14T08:46:26.9643481Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_lhs[256] [33mSKIPPED[0m
2026-01-14T08:46:26.9644814Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_rhs[128] [33mSKIPPED[0m
2026-01-14T08:46:26.9646170Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_rhs[256] [33mSKIPPED[0m
2026-01-14T08:46:26.9647633Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-1024-128] [33mSKIPPED[0m
2026-01-14T08:46:26.9649185Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-1024-256] [33mSKIPPED[0m
2026-01-14T08:46:26.9650753Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-16384-128] [33mSKIPPED[0m
2026-01-14T08:46:26.9652314Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-16384-256] [33mSKIPPED[0m
2026-01-14T08:46:26.9653834Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-1024-128] [33mSKIPPED[0m
2026-01-14T08:46:26.9655314Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-1024-256] [33mSKIPPED[0m
2026-01-14T08:46:26.9656800Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-16384-128] [33mSKIPPED[0m
2026-01-14T08:46:26.9658287Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-16384-256] [33mSKIPPED[0m
2026-01-14T08:46:26.9659789Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_transposed_rhs[128] [33mSKIPPED[0m
2026-01-14T08:46:26.9661275Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_transposed_rhs[256] [33mSKIPPED[0m
2026-01-14T08:46:26.9662681Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_fp8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:46:26.9664150Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_int8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:46:26.9665504Z test/prototype/module_swap_quantization/test_kmeans_codebook.py::TestKmeansCodebook::test_kmeans_codebook [33mSKIPPED[0m
2026-01-14T08:46:26.9666837Z test/prototype/module_swap_quantization/test_llm_ptq_data_getter.py::TestPTQDataGetter::test_data_getter [33mSKIPPED[0m
2026-01-14T08:46:26.9668233Z test/prototype/module_swap_quantization/test_module_swap.py::TestEmbeddingSwap::test_embedding_swap [32mPASSED[0m
2026-01-14T08:46:26.9669709Z test/prototype/module_swap_quantization/test_module_swap_quantization_utils.py::TestQuantizedModuleUtils::test_set_bit_widths_by_name [32mPASSED[0m
2026-01-14T08:46:26.9671258Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic [32mPASSED[0m
2026-01-14T08:46:26.9672710Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic_vectorized [32mPASSED[0m
2026-01-14T08:46:26.9674140Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear [32mPASSED[0m
2026-01-14T08:46:27.3340402Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_init [32mPASSED[0m
2026-01-14T08:46:27.3342251Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients [32mPASSED[0m
2026-01-14T08:46:27.3344944Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_activation_scale [32mPASSED[0m
2026-01-14T08:46:27.3347723Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_weight_scale [32mPASSED[0m
2026-01-14T08:46:27.3350402Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_all_options [32mPASSED[0m
2026-01-14T08:46:27.3352192Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_correct [32mPASSED[0m
2026-01-14T08:46:27.3353416Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedEmbedding::test_quantized_embedding [32mPASSED[0m
2026-01-14T08:46:27.3354485Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_qmin_qmax [32mPASSED[0m
2026-01-14T08:46:27.3355523Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max [32mPASSED[0m
2026-01-14T08:46:27.3356634Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max_vectorized [32mPASSED[0m
2026-01-14T08:46:27.3357745Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_asymmetric [32mPASSED[0m
2026-01-14T08:46:27.3358864Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max [32mPASSED[0m
2026-01-14T08:46:27.3360020Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max_tensorized [32mPASSED[0m
2026-01-14T08:46:27.3361177Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_symmetric [32mPASSED[0m
2026-01-14T08:46:27.3362305Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_param_size [32mPASSED[0m
2026-01-14T08:46:27.3363412Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward [32mPASSED[0m
2026-01-14T08:46:27.3364515Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_asymmetric_clipping [32mPASSED[0m
2026-01-14T08:46:27.3365847Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric [32mPASSED[0m
2026-01-14T08:46:27.3366992Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric_clipping [32mPASSED[0m
2026-01-14T08:46:27.3368130Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_codebook_quantizer [32mPASSED[0m
2026-01-14T08:46:27.3369311Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_vector_quantizer [32mPASSED[0m
2026-01-14T08:46:27.3370413Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max [32mPASSED[0m
2026-01-14T08:46:27.3371590Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max_grouped [32mPASSED[0m
2026-01-14T08:46:27.3372722Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse [32mPASSED[0m
2026-01-14T08:46:27.3373847Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse_grouped [32mPASSED[0m
2026-01-14T08:46:27.3375123Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss [32mPASSED[0m
2026-01-14T08:46:27.3376587Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss_progressive [32mPASSED[0m
2026-01-14T08:46:27.3378034Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting [32mPASSED[0m
2026-01-14T08:46:27.3379458Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting_no_input [32mPASSED[0m
2026-01-14T08:46:27.3380838Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales [32mPASSED[0m
2026-01-14T08:46:27.3382226Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales_dont_change_per_channel [32mPASSED[0m
2026-01-14T08:46:27.3383522Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3384679Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.3385814Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3386957Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.3388109Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3389243Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:27.3390388Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3391600Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:27.3392739Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3393886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.3395027Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3396282Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.3397436Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3398587Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.3399822Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3400995Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.3402142Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3403339Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.3404480Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3405640Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.3406796Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3407941Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:27.3409095Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3410253Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:27.3411410Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3412575Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.3413731Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.3414898Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4027520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4029877Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4031825Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4033018Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4034172Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4035308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4036467Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4037608Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4038902Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4040261Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:27.4041405Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4042735Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:27.4043868Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4045004Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4046146Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4047292Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4048433Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4049584Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4050726Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4051934Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4053076Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4054215Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4055356Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4056499Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4057655Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4058790Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:27.4059945Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4061100Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:27.4062237Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4063385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4064531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4065683Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4066842Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4068119Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4069289Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:27.4070457Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:27.4071827Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4073247Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4074653Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4083105Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4084559Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4085999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4087435Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4088870Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4090287Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4091682Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4093082Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4094488Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4095908Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4097340Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4098777Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4100215Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4101633Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4103037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4104562Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4105986Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4683187Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4686250Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4687693Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.4689145Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.4690567Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4691964Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4693391Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4694808Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4696233Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4697677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4699117Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.4700559Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.4701980Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4703379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4704800Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4706223Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4707648Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4709096Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4710536Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4712148Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4713587Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4715008Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4716550Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4717968Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4719402Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4720857Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4722316Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4723829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4725269Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4726695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4728121Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4729556Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4730999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4732455Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4733910Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.4735376Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.4736806Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4738224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4739809Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4741294Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4742870Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4744327Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4745790Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.4747380Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.4748815Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4750227Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4751646Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.4753063Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.4754497Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5295267Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5298181Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5300939Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5302375Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5303778Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5305195Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5306615Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5308037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5309485Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5310960Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5312438Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5313876Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5315293Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5316844Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5318284Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5319823Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5321276Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5322793Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.5324233Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.5325652Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5327073Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5328475Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5329894Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5331344Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5332788Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5334233Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.5335681Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.5337100Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5338514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5340082Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5341494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5342936Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5344378Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5345831Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5347406Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5348846Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5350363Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5351783Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5353200Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5354641Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5356089Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5357543Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5359002Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5360441Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5361872Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5363372Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5364820Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5366287Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5367750Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5927601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.5929329Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.5930797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5932380Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5933847Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5935401Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5937132Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5938625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5940633Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.5942204Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.5943660Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5945088Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5946598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5948043Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5949497Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5950997Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5952494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5954058Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5955505Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5956998Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5958443Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5959888Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5961352Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5962909Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5964470Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5965939Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5967470Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5970024Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5971478Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5973033Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5974576Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5976046Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5977614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.5979075Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.5980520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5982008Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5983514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5984983Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5986507Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5987986Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5989468Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.5990928Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.5992369Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5993886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5995321Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5996840Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.5998295Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.5999755Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6001331Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6542114Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6543774Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6545211Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6546642Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6548096Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6549578Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6551053Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6552545Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6554021Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6555480Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6556915Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6558363Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6559809Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6561271Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6562819Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6564301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.6565767Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.6567208Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6568638Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6570079Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6571726Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6573181Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6574651Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6576191Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.6577667Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.6579109Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6580509Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6581984Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6583414Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6584855Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6586317Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6587754Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6589202Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6590643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6592043Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6593464Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6594901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6596323Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6597774Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6599225Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6600664Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6602188Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6603700Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6605127Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6606648Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6608091Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.6609554Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.6611010Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.6612456Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.7153360Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7154987Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7156434Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7157901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7159375Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7160851Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7162379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.7163948Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.7165398Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7166816Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7168247Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7169679Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7171138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7172772Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7174238Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7175714Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7177252Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7178686Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7180124Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7181601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7183062Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7184535Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7185999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7187459Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7188921Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7190357Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7191804Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7193249Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7194712Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7196203Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7197676Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.7199143Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.7200605Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7202026Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7203643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7205101Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7206560Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7208138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7209607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.7211117Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.7212564Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7214001Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7215430Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7216867Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7218301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7219762Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7221223Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7222684Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7224134Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7770847Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7772333Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7773767Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7775220Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7776685Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7778145Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7779790Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7781300Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7782754Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7784311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7785752Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7787213Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7788698Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7790156Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.7791646Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.7793089Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7794515Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7795968Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7797413Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7798878Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7800364Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7801827Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.7803403Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.7804846Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7806260Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7807695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7809135Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7810668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7812120Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7813580Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7815119Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7816559Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7817976Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7819412Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7820847Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7822343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7823798Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7825257Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7826713Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7828155Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7829592Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7831014Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7832468Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7833931Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7835394Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.7836866Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.7838340Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.7839969Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.7841545Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8382259Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8383763Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8385406Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8386990Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8388460Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.8390020Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.8391465Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8392860Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8394271Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8395677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8397102Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8398543Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8399976Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8401429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8402936Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8404337Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8405728Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8407132Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8408542Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8409966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8411399Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8412972Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8414395Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8415891Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8417297Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8418708Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8420138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8421576Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8423014Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.8424448Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.8425866Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8427272Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8428673Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8430084Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8431514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8432955Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8434395Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.8435827Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.8437253Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8438655Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8440240Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8441647Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8443256Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8444696Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8446246Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8447693Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8449105Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8450509Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8451965Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8992608Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.8994132Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.8995620Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9006173Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9007639Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9009066Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9010490Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9011907Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9013354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9014802Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9016247Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9017708Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.9019169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.9020595Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9022182Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9023622Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9025053Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9026614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9028062Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9029530Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.9030997Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.9032424Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9033851Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9035278Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9036698Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9038145Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9040238Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9041772Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9043312Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9044750Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9046169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9047594Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9049020Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9050454Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9051904Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9053487Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9054953Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9056397Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9057922Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9059357Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9060802Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9062242Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9063703Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9065170Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.9066622Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.9068065Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9069489Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9070937Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9072419Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9599893Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9601416Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9602951Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.9604428Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.9605877Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9607328Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9608773Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9610401Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9611870Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9613339Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9614921Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9616399Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9617852Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9619270Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9620714Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9622164Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9623614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9625090Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9626558Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9628053Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9629519Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9630969Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9632416Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9633883Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9635343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9636816Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9638295Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.9640022Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.9641673Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9643167Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9644601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9646169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9647634Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9649101Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9650576Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:27.9652050Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:27.9653483Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9654889Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9656288Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9657704Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9659127Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9660556Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9661992Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9663434Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9664849Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9666252Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9667660Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:27.9669068Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:27.9670493Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0174601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0176069Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0177527Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0179081Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0180496Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0181929Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0183376Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0184812Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0186280Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0187726Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:28.0189186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:28.0190624Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0192040Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0193463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0194891Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0196331Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0197792Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0199244Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0200715Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0202166Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0203646Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0205065Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0206628Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0208069Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0209609Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0211107Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0212585Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0214036Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0215445Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0216869Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0218311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0219741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0221265Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0222724Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0224184Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0225644Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0227076Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0228518Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0229960Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0231411Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0232886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0234357Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:28.0235814Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:28.0237351Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0238784Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0240531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0242037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0243556Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0245021Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0678837Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0680527Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0682048Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0683529Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0684978Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0686426Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0687875Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0689345Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0690819Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0692279Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0693723Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0695145Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0696565Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0697999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0699433Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0701052Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0702516Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0703970Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0705530Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0706958Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0708392Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0709838Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0711292Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0712762Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0714220Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0715690Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0717136Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0718570Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0720008Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0721517Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0723049Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0724513Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0725986Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0727463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0728916Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0730360Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0733213Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0734668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0736126Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0737714Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0739367Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0740884Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0742343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0743794Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0745243Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0746684Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0748146Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.0749611Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.0751130Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1182729Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1184198Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1185655Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1187115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1188583Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1190083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1191588Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1193075Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1194734Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1196207Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1197642Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1199207Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1200678Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1202146Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1203707Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1205211Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1206716Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1208179Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1209610Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1211053Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1212472Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1213924Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1215385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1216846Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1218305Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1219740Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1221198Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1222620Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1224057Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1225614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1227061Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1228519Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1230052Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1231505Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1232936Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1234366Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1235800Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1237267Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1238718Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1240349Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1241828Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1243311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1244737Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1246180Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1247607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1249060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1250511Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1252028Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1253499Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1672859Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1674450Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1676057Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1677510Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1679070Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1680544Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1682030Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1683600Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1685046Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1686453Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1687896Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1689344Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1690797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1692313Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1693794Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1695271Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1696723Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1698176Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1699622Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1701075Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1702550Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1704011Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1705497Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1707076Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1708543Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1710087Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1711533Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1712997Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1714474Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1715942Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1717429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1718929Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1720366Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1721848Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1723355Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1724770Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1726221Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1727670Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1729137Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1730614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1732060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1733493Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1734922Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1736354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1737899Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1739512Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1740966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.1742561Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.1744002Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2158209Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2160097Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2161540Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2163063Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2164526Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2165989Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2167464Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2168922Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2170349Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2171790Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2173224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2174690Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2176152Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2177636Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2179114Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2180562Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2182144Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2183588Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2185031Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2186594Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2188065Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2189540Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2191028Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2192473Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2193910Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2195334Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2196783Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2198245Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2199695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2201229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2202762Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2204208Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2205661Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2207117Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2208577Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2210065Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2211540Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2213127Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2214617Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2216070Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2217602Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2219051Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2220505Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2221976Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2223453Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2224939Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2226425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2227887Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2229322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2651389Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2652876Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2654327Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2655786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2657255Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2658714Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2660162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2661597Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2663021Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2664463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2666085Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2667560Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2669121Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2670600Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2672116Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2673578Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2682521Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2684058Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2685499Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2686942Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2688408Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2689865Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2691304Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2692723Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2694139Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2695572Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2697013Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2698463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2699933Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2701454Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2702892Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2704429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2705856Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2707354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2708801Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2710251Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2711723Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2713198Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2714626Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2716055Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2717482Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2718905Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2720343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2721786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2723300Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2724756Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2726191Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.2727620Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.2729050Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3163054Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3164675Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3166138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3167760Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3169231Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3170792Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3172261Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3173695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3175167Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3176610Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3178071Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3179546Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3181000Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3182422Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3183828Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3185210Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3186626Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3188038Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3189451Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3190895Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3192325Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3193736Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3195133Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3196511Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3198003Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3199423Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3200834Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3202347Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3203854Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3205278Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3206688Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3208090Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3209504Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3210954Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3212381Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3213808Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3215260Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3216676Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3218083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3219479Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3220888Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3222311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3223755Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3225201Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3226632Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3228147Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3229546Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3230952Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3232472Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3233911Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3665521Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3667224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3668673Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3670108Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3671520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3672928Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3674356Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3675768Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3677218Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3678671Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3680104Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3681576Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3683055Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3684472Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3685924Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3687373Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3688830Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3690461Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3691931Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3693474Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3694889Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3696318Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3697742Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3699188Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3700639Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3702094Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3703545Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3704984Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3706400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3707801Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3709245Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3710677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3712159Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3713615Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3715062Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3716483Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3717899Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3719314Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3720812Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3722250Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3723740Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3725267Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3726716Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3728141Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3729555Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3730974Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3732395Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.3733831Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.3735277Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4167661Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4169199Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4170645Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4172058Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4173497Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4174937Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4176384Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4177850Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4179321Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4180789Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4182400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4183811Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4185216Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4186746Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4188184Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4189649Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4191122Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4192581Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4194015Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4195429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4196852Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4198290Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4199739Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4201186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4202714Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4204181Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4205650Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4207095Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4208529Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4209993Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4211509Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4213091Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4214578Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4216066Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4217672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4219112Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4220562Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4222006Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4223462Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4224934Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4226405Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4227881Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4229316Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4230728Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4232158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4233579Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4235012Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4236469Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4237912Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4741494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4742984Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4744399Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4745967Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4747397Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4748829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4750384Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4751883Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4753341Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4754790Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4756219Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4757659Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4759105Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4760571Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4762047Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4763595Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:28.4765060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:28.4766495Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4767913Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4769353Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4770790Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4772259Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4773726Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4775205Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4776943Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4778390Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4779816Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4781340Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4782778Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4784240Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4785708Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4787156Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4788623Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4790058Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4791472Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4792902Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4794328Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4795768Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4797223Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4798670Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4800138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4801589Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4803075Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4804524Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4805967Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4807412Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.4808970Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.4810434Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:28.4812019Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:28.5241453Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5242987Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5244429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5245879Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5247341Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5248805Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5250278Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5251773Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5253219Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5254652Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5256100Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5257534Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5259000Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5260463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5261983Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5263471Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5264913Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5266343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5267973Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5269406Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5270981Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5272464Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5273936Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5275423Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5276892Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5278338Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5279787Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5281246Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5282787Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5284265Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5285739Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5287229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5288701Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5290144Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5291650Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5293119Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5294586Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5296217Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5297711Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5299289Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5300921Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5302458Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5303928Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5305403Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5306971Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5308454Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5310031Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5311514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5312980Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5742765Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5744275Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5745745Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5747321Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5748807Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5750365Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5751855Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5753326Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5754779Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5756301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5757773Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5759463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5760985Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5762674Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5764169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5765657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5767230Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5768689Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5770250Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5771754Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5773259Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5774768Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5776351Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5777843Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5779298Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5780807Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5782274Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5783758Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5785235Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5786725Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5788287Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5789736Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5791421Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5792878Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5794420Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5795891Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5797422Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5798928Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5800470Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5801932Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5803476Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5804928Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5806394Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5807956Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5809443Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5811010Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5812505Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.5813989Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.5815447Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6240121Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6241630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6243164Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6244628Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6246272Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6247743Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6249308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6250751Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6252196Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6253650Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6255095Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6256563Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6258037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6259514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6260983Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6262419Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6263851Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6265304Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6266770Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6268238Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6269717Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6271210Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6272677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6281165Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6282683Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6284245Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6285703Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6287170Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6288719Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6290197Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6291660Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6293093Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6294531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6295973Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6297424Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6298894Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6300351Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6301877Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6303317Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6304710Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6306121Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6307553Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6308974Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6310428Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6311881Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6313330Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6314842Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6316254Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6317663Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6740998Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6742538Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6744027Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6745730Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6747523Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6749200Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6750836Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6752274Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6753741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6755404Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6756896Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6758352Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6760024Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6761494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6763010Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6764475Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6766076Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6767638Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6769480Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6770985Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6772476Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6774062Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6775499Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6777181Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6778632Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6780294Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6781788Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6783267Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6784750Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6786402Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6787843Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6789480Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6790956Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6792406Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6793892Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6795369Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6797037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6798519Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6800157Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6801736Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6803293Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6804751Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6806553Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6808085Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6809762Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6811239Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6812686Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.6814142Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.6815607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7245770Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7247293Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7248776Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7250507Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7251989Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7253430Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7255095Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7256532Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7258005Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7259509Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7261187Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7262863Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7264534Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7266180Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7267822Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7269278Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7270788Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7272468Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7273946Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7275643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7277129Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7278575Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7280041Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7281694Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7283264Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7284959Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7286475Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7287983Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7289469Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7290912Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7292599Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7294056Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7295853Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7297350Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7298838Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7300418Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7302086Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7303543Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7305188Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7306675Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7308158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7309653Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7311196Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7312886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7314358Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7315914Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7317476Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7318945Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7320414Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7740566Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7742091Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7743590Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7745057Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7746676Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7748134Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7749598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7751229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7752744Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7754228Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7755736Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7757201Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7758657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7760113Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7761566Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7763143Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7764635Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7766131Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7767632Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7769103Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7770527Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7772003Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7773431Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7774886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7776355Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7777905Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7779371Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7780824Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7782322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7783749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7785183Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7786625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7788088Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7789567Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7791040Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7792492Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7793928Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7795366Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7796807Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7798271Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7799749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7801239Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7802783Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7804245Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7805700Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7807128Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7808585Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.7810128Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.7811945Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8230781Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8232301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8233737Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8235169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8236612Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8238034Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8239656Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8241089Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8242684Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8244162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8245596Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8247041Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8248464Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8249899Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8251409Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8252880Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8254350Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8255826Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8257288Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8258872Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8260318Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8261878Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8263344Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8264823Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8266308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8267798Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8269269Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8270723Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8272178Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8273637Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8275097Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8276562Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8278049Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8279524Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8280986Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8282429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8283943Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8285391Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8286842Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8288292Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8291643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8293141Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8294588Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8296138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8297587Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8299015Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8300471Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8301919Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8303390Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8733252Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8734987Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8736409Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8737839Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8739455Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8740910Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8742379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8743845Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8745318Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8746778Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8748202Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8749627Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8751257Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8752730Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8754192Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8755942Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8757425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8758900Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8760335Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8761777Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8763327Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8764778Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8766253Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8767727Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8769204Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8770666Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8772106Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8773548Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8775011Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8776480Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8777949Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8779427Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8780919Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8782519Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8783982Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8785430Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8786977Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8788451Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8789941Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8791432Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8792932Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8794397Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8795862Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8797326Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8798782Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8800271Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8801819Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.8803393Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.8804891Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9283635Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9285070Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9286506Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9287924Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9289352Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9290973Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9292440Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9293890Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9295429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9296827Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9298236Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9299661Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9301080Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9302530Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9303993Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9305435Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9306872Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9308291Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9309713Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9311156Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9312607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9314057Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9315529Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:28.9316972Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:28.9318399Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9319821Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9321452Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9322982Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9324426Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9325946Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9327563Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9329035Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9330470Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9331891Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9333319Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9334725Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9336153Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9337594Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9339310Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9340808Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9342244Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9343675Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9345100Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9346511Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9347942Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9349386Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9350821Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9352417Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9353855Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9355270Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9816453Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9817903Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9819330Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9820781Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9822227Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:46:28.9823677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:46:28.9825125Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9826548Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9827977Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9829409Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9830836Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9832293Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9833741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9835207Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9836647Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9838076Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9839794Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9841226Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9842715Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9844302Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9845759Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9847333Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9848767Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9850171Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9851657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9853077Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9854510Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9855960Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9857420Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9858886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9860309Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9861737Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9863165Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9864590Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9866038Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9867499Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9868946Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9870416Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9871842Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9873270Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9874796Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9876214Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9877669Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9879203Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9880651Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9882115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9883628Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:28.9885023Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:28.9886440Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0316045Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0317528Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0318999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0320458Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0321952Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0323470Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0332409Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0333934Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0335375Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0336814Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0338258Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0340282Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0342016Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0343463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0344900Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0346451Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0347900Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0349369Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0350828Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0352292Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0353767Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0355215Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0356660Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0358114Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0359560Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0361029Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0362548Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0364123Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0365970Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0367418Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0368817Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0370218Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0371643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0373342Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0375037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0376481Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0378031Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0379453Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0380967Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0382571Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0384113Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0385673Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0387291Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0388914Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0390542Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0392192Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0393732Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0395297Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0396900Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0813857Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0815340Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0816795Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0818249Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0819683Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0821255Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0822664Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0824086Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0825628Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0827061Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0828509Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0829980Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0831415Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0832865Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0834268Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0835690Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0837125Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0838563Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0840340Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0841865Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0843355Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0844766Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0846192Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0847607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0849052Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0850495Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0851948Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0853545Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0854979Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0856538Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0857973Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0859390Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0860844Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0862346Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0863807Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0865281Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0866710Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0868151Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0869576Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0871005Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0872460Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0873932Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0875394Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0876872Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0878289Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0879689Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0881094Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.0882494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.0884101Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1294639Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1296412Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1297864Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1299284Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1300684Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1302146Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1303563Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1304987Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1306425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1307881Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1309314Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1310743Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1312160Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1313569Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1314993Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1316425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1317875Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1319333Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1320780Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1322202Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1323828Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1325236Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1326668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1328195Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1329639Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1331102Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1332629Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1334064Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1335501Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1336904Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1338328Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1339968Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1341424Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1342921Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1344377Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1345803Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1347229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1348648Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1350059Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1351505Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1352959Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1354529Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1355997Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1357433Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1358967Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1360396Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1361818Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1363356Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1364819Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1775702Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1777214Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1778672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1780106Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1781540Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1783003Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1784460Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1785931Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1787414Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1788900Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1790345Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1791833Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1793254Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1794871Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1796322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1797790Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1799348Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1800831Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1802266Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1803799Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1805353Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1806793Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1808246Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1809711Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1811175Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1812688Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1814151Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1815587Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1817040Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1818490Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1819958Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1821421Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1822910Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1824400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1825858Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1827387Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1828837Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1830363Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1831858Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1833333Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1834819Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1836296Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1837752Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1839435Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1841190Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1842762Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1844215Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.1845686Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.1847162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2264149Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2265661Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2267125Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2268881Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2270362Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2272119Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2273606Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2275285Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2276781Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2278662Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2280116Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2281992Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2283568Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2285041Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2286520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2288140Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2289719Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2291387Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2292884Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2294323Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2295785Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2297413Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2298948Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2300615Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2302141Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2303599Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2305002Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2306448Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2308160Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2309598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2311239Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2312884Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2314348Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2315797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2317206Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2318831Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2320280Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2321962Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2323513Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2324971Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2326411Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2328072Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2329503Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2331143Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2332610Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2334060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2335528Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2337181Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2338670Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2754276Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2755771Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2757208Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2759064Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2760523Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2762248Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2763830Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2765279Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2766733Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2768248Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2769802Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2771364Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2772948Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2774426Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2775882Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2777433Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2778993Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2780417Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2781932Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2783556Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2784999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2786582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2788070Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2789730Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2791404Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2793001Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2794465Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2795918Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2797385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2799036Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2800561Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2802201Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2803756Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2805177Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2806597Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2808268Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2809723Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2811410Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2812871Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2814325Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2815760Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2817343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2818783Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2820515Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2822033Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2823565Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2825031Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2826578Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.2828147Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.2829657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3235072Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3236566Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3238013Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3240015Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3241510Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3243313Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3244797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3246232Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3247677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3249211Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3250792Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3252276Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3253953Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3255464Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3257116Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3258563Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3260198Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3261902Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3263618Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3265119Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3266603Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3268097Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3269744Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3271186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3272874Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3274346Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3275804Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3277275Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3278747Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3280220Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3281681Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3283192Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3284630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3286072Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3287515Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3289102Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3290582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3292099Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3293637Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3295295Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3296749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3298443Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3299917Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3301390Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3302860Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3304339Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3305795Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:46:29.3307226Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:46:29.3308660Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:46:30.4660991Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:46:30.4663676Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:46:30.4666624Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:46:30.4669547Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:46:30.4672174Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:46:30.4673432Z test/prototype/mx_formats/test_inference_workflow.py::VLLMIntegrationTestCase::test_narrow_similar_to_vllm [32mPASSED[0m
2026-01-14T08:46:30.4674578Z test/prototype/mx_formats/test_inference_workflow.py::VLLMIntegrationTestCase::test_nvfp4_quantize_3d_param_similar_to_vllm [32mPASSED[0m
2026-01-14T08:46:30.4676010Z test/prototype/mx_formats/test_inference_workflow.py::VLLMIntegrationTestCase::test_slice_and_copy_similar_to_vllm [32mPASSED[0m
2026-01-14T08:46:30.4676908Z test/prototype/mx_formats/test_kernels.py::test_fp32 [33mSKIPPED[0m (TODO d...)
2026-01-14T08:46:30.4677601Z test/prototype/mx_formats/test_kernels.py::test_bf16 [33mSKIPPED[0m (TODO d...)
2026-01-14T08:46:30.4678231Z test/prototype/mx_formats/test_kernels.py::test_fp16 [32mPASSED[0m
2026-01-14T08:46:30.4679001Z test/prototype/mx_formats/test_kernels.py::test_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:46:30.4679658Z test/prototype/mx_formats/test_kernels.py::test_float8_e5m2 [32mPASSED[0m
2026-01-14T08:46:30.4680318Z test/prototype/mx_formats/test_kernels.py::test_float4_e2m1_table [32mPASSED[0m
2026-01-14T08:46:30.4681004Z test/prototype/mx_formats/test_kernels.py::test_float6_e3m2_table [32mPASSED[0m
2026-01-14T08:46:30.4681678Z test/prototype/mx_formats/test_kernels.py::test_float6_e2m3_table [32mPASSED[0m
2026-01-14T08:46:30.4682339Z test/prototype/mx_formats/test_kernels.py::test_fp4_0_0 [32mPASSED[0m
2026-01-14T08:46:30.4683041Z test/prototype/mx_formats/test_kernels.py::test_fp4_0_5 [32mPASSED[0m
2026-01-14T08:46:30.4683647Z test/prototype/mx_formats/test_kernels.py::test_fp4_1_0 [32mPASSED[0m
2026-01-14T08:46:30.4684254Z test/prototype/mx_formats/test_kernels.py::test_fp4_1_5 [32mPASSED[0m
2026-01-14T08:46:30.4684855Z test/prototype/mx_formats/test_kernels.py::test_fp4_2_0 [32mPASSED[0m
2026-01-14T08:46:30.4685471Z test/prototype/mx_formats/test_kernels.py::test_fp4_3_0 [32mPASSED[0m
2026-01-14T08:46:30.4686067Z test/prototype/mx_formats/test_kernels.py::test_fp4_4_0 [32mPASSED[0m
2026-01-14T08:46:30.4686678Z test/prototype/mx_formats/test_kernels.py::test_fp4_6_0 [32mPASSED[0m
2026-01-14T08:46:30.4687316Z test/prototype/mx_formats/test_kernels.py::test_fp4_pack_unpack [32mPASSED[0m
2026-01-14T08:46:30.4688017Z test/prototype/mx_formats/test_kernels.py::test_fp6_values[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:30.4688727Z test/prototype/mx_formats/test_kernels.py::test_fp6_values[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:30.4689492Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[29.0-31-cpu] [32mPASSED[0m
2026-01-14T08:46:30.4690287Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[29.0-31-cuda] [32mPASSED[0m
2026-01-14T08:46:30.4691076Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[26.0-30-cpu] [32mPASSED[0m
2026-01-14T08:46:30.4691875Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[26.0-30-cuda] [32mPASSED[0m
2026-01-14T08:46:30.4692667Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.1251-2-cpu] [32mPASSED[0m
2026-01-14T08:46:30.4693458Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.1251-2-cuda] [32mPASSED[0m
2026-01-14T08:46:30.4694256Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.0314-1-cpu] [32mPASSED[0m
2026-01-14T08:46:30.4695047Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.0314-1-cuda] [32mPASSED[0m
2026-01-14T08:46:30.4695842Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.03-0-cpu] [32mPASSED[0m
2026-01-14T08:46:30.4696624Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.03-0-cuda] [32mPASSED[0m
2026-01-14T08:46:30.4697552Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-128-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4698631Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-128-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4699697Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-256-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4700769Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4701836Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-128-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4703033Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-128-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4704112Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-256-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4705179Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4706326Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-128-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4707400Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-128-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4708457Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-256-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4709527Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4710605Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-128-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4711664Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-128-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4712737Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-256-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4713801Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4714830Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_zeros[ScaleCalculationMode.FLOOR] [33mSKIPPED[0m
2026-01-14T08:46:30.4715833Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_zeros[ScaleCalculationMode.RCEIL] [33mSKIPPED[0m
2026-01-14T08:46:30.4716800Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-128-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4717737Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-128-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4718660Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-256-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4719594Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4720527Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-128-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4721449Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-128-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4722411Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-256-128] [33mSKIPPED[0m
2026-01-14T08:46:30.4723403Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4724209Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape0] [32mPASSED[0m
2026-01-14T08:46:30.4724904Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape1] [32mPASSED[0m
2026-01-14T08:46:30.4725588Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape2] [32mPASSED[0m
2026-01-14T08:46:30.4726288Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape3] [32mPASSED[0m
2026-01-14T08:46:30.4726974Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape4] [32mPASSED[0m
2026-01-14T08:46:30.4727664Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape5] [32mPASSED[0m
2026-01-14T08:46:30.4728355Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape6] [32mPASSED[0m
2026-01-14T08:46:30.4729035Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape7] [32mPASSED[0m
2026-01-14T08:46:30.4730068Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-32-32] [33mSKIPPED[0m
2026-01-14T08:46:30.4731225Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-32-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4732394Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-256-32] [33mSKIPPED[0m
2026-01-14T08:46:30.4733654Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.4734802Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-32-32] [33mSKIPPED[0m
2026-01-14T08:46:30.7340873Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-32-256] [33mSKIPPED[0m
2026-01-14T08:46:30.7342661Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-256-32] [33mSKIPPED[0m
2026-01-14T08:46:30.7343853Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.7345019Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-32-32] [33mSKIPPED[0m
2026-01-14T08:46:30.7346190Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-32-256] [33mSKIPPED[0m
2026-01-14T08:46:30.7347355Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-256-32] [33mSKIPPED[0m
2026-01-14T08:46:30.7348533Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.7349714Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-32-32] [33mSKIPPED[0m
2026-01-14T08:46:30.7350883Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-32-256] [33mSKIPPED[0m
2026-01-14T08:46:30.7352061Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-256-32] [33mSKIPPED[0m
2026-01-14T08:46:30.7353232Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-256-256] [33mSKIPPED[0m
2026-01-14T08:46:30.7354204Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim0_not_supported [33mSKIPPED[0m
2026-01-14T08:46:30.7355443Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:30.7357047Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:30.7358652Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:30.7360260Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:30.7361878Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:30.7363591Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:30.7365211Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:30.7367010Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:30.7368742Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:30.7370474Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:30.7372085Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:30.7373732Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:30.7375343Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:30.7376943Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:30.7378553Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:30.7380160Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:30.7381768Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:30.7383383Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:30.7385000Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:30.7386612Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:30.7388223Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:30.7389829Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:30.7391438Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:30.7393049Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:30.7394652Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:30.7396258Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:30.7397875Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:30.7399572Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:30.7401179Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:30.7402933Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:30.7404554Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7406163Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7407789Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7409397Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7411018Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7412643Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7414262Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7758210Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7759870Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7761506Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7763180Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7764804Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7766434Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7768046Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7769667Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7771464Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7773084Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7774956Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7776578Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7778314Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7779926Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7781534Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7783161Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7784773Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7786382Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7788001Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7789621Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7791248Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7792873Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7794502Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7796105Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7797703Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7799310Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7800896Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7802501Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7804180Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7805776Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7807468Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7809082Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7810760Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7812359Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7813953Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7815550Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7817144Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7818724Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7820325Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7821923Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7823524Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:30.7825123Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:30.7826727Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:30.7828315Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:30.7829905Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:30.7831499Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0468302Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0471543Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0473537Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0475142Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0476908Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0478515Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0480218Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0481810Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.0483491Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.0485074Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.0486660Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.0488253Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.0489832Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.0491425Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.0493060Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.0494646Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.0496232Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.0497808Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.0499384Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.0500965Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.0502540Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.0504130Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.0505720Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.0507300Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.0508971Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.0510568Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.0512303Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.0513890Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.0515464Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.0517037Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.0518614Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.0520192Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.0521769Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.0523455Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.0525038Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.0526621Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.0528214Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.0529801Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0531401Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0532999Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0534589Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0536191Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0537815Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0539690Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0541454Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0543074Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0861726Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0864602Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0867817Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0871027Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0873285Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0874896Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0876501Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0878135Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0879757Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0881374Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0883111Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0884727Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0886328Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0887940Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0889547Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0891149Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0892762Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0894384Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0896147Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0897764Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0899730Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0901332Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0902955Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0904525Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0906100Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0907682Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0909252Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0910841Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0912426Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0913999Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0915586Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0917158Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0918726Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0920299Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0921872Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0923509Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0925091Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0926671Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0928350Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0929948Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0931537Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.0933190Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.0934766Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.0936340Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.0937918Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.0939755Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.3766456Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.3769441Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.3772343Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.3773959Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.3775548Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.3777148Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.3778740Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.3780325Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.3781908Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.3783506Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.3785097Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.3786689Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.3788463Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.3790076Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.3791665Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.3793385Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.3794964Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.3796552Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.3798130Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.3799717Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.3801311Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.3803143Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.3804736Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.3806324Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.3807903Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.3809499Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.3811074Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.3812649Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.3814225Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.3815804Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.3817385Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.3818972Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.3820658Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.3822255Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.3823839Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.3825514Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.3827116Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.3828718Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.3830309Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.3831909Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.3833529Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.3835124Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.3836742Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.3838346Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.3840124Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.3841739Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4160886Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.4162508Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.4164192Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.4165797Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.4167391Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4168995Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.4170772Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.4172378Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.4173989Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.4175700Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4177293Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.4178899Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.4180496Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.4182089Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.4183696Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4185302Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.4186905Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.4188506Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.4190112Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.4191698Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4193322Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.4194893Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.4196469Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.4198039Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.4199619Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4201207Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.4202950Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.4204528Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.4206115Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.4207782Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4209344Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.4210932Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.4212562Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.4214130Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.4215723Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4217305Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.4218881Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.4220463Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.4222042Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.4223620Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4225188Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.4226765Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.4228333Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.4229903Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.4231478Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.4233054Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.6822398Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.6824041Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.6825638Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.6827331Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.6828921Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.6830525Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.6832106Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.6833695Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.6835296Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.6836890Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.6838493Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.6840248Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.6841838Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.6843476Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.6845055Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.6846646Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.6848234Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.6849812Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.6851401Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.6852991Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.6854699Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.6856298Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.6857896Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.6859590Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.6861177Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.6862779Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.6864355Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.6865936Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.6867529Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.6869117Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.6870711Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:46:31.6872299Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:46:31.6873887Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.6875492Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.6877086Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.6878703Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.6880303Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.6881900Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.6883598Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.6885235Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.6886951Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.6888579Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.6890207Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.6891903Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.6893568Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.6895195Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7224751Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7226385Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7228003Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7229612Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7231245Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7232867Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7234478Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7236102Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7237705Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7239465Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7241071Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7242738Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7244347Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7245961Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7247723Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7249340Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7250956Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7252704Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7254279Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7255871Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7257457Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7259039Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7260632Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7262217Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7263813Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7265400Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7266976Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7268568Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7270148Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7271731Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7273321Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7274901Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7276489Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7278085Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7279756Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7281338Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7282994Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7285949Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7287530Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7289124Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7290707Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7292291Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7293891Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7295489Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7297072Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:46:31.7298665Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:46:31.7732975Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:31.7734394Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn0-MXLinearRecipeName.MXFP8_CUBLAS] [33mSKIPPED[0m
2026-01-14T08:46:31.7735580Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn0-MXLinearRecipeName.MXFP4_CUTLASS] [33mSKIPPED[0m
2026-01-14T08:46:31.7736767Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn1-MXLinearRecipeName.MXFP8_CUBLAS] [33mSKIPPED[0m
2026-01-14T08:46:31.7737944Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn1-MXLinearRecipeName.MXFP4_CUTLASS] [33mSKIPPED[0m
2026-01-14T08:46:31.7739272Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn2-MXLinearRecipeName.MXFP8_CUBLAS] [33mSKIPPED[0m
2026-01-14T08:46:31.7740449Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn2-MXLinearRecipeName.MXFP4_CUTLASS] [33mSKIPPED[0m
2026-01-14T08:46:31.7741410Z test/prototype/mx_formats/test_mx_linear.py::test_activation_checkpointing [32mPASSED[0m
2026-01-14T08:46:31.7742669Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7744283Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7746024Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7747618Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7749427Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7751012Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7752587Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7754161Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7755769Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7757397Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7759003Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7760611Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7762216Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7763881Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7765486Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7767074Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7768661Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7770275Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7771863Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7773436Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7775013Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7776589Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7778256Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7779826Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7781407Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7783085Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7784671Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7786253Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7787843Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7789441Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7791025Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7792592Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7794192Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7795797Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7797410Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7799020Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7800616Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7802465Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7804360Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.7805933Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.7807524Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.8645690Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.8649313Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.8652159Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.8653723Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.8655412Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.8656982Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:31.8658534Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:31.8659611Z test/prototype/mx_formats/test_mx_linear.py::test_filter_fn [32mPASSED[0m
2026-01-14T08:46:31.8660291Z test/prototype/mx_formats/test_mx_linear.py::test_training_print_str [32mPASSED[0m
2026-01-14T08:46:31.8661077Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-128x128x128] [33mSKIPPED[0m
2026-01-14T08:46:31.8661922Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-256x256x256] [33mSKIPPED[0m
2026-01-14T08:46:31.8662804Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-384x384x384] [33mSKIPPED[0m
2026-01-14T08:46:31.8663627Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-512x512x512] [33mSKIPPED[0m
2026-01-14T08:46:31.8664461Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-768x768x768] [33mSKIPPED[0m
2026-01-14T08:46:31.8665301Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-1024x1024x1024] [33mSKIPPED[0m
2026-01-14T08:46:31.8666176Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-8192x8192x8192] [33mSKIPPED[0m
2026-01-14T08:46:31.8667023Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-128x256x384] [33mSKIPPED[0m
2026-01-14T08:46:31.8667854Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-256x384x512] [33mSKIPPED[0m
2026-01-14T08:46:31.8668695Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-129x256x384] [33mSKIPPED[0m
2026-01-14T08:46:31.8669530Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-133x512x528] [33mSKIPPED[0m
2026-01-14T08:46:31.8670364Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-128x128x128] [33mSKIPPED[0m
2026-01-14T08:46:31.8671206Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-256x256x256] [33mSKIPPED[0m
2026-01-14T08:46:31.8672039Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-384x384x384] [33mSKIPPED[0m
2026-01-14T08:46:31.8672875Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-512x512x512] [33mSKIPPED[0m
2026-01-14T08:46:31.8673701Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-768x768x768] [33mSKIPPED[0m
2026-01-14T08:46:31.8674552Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-1024x1024x1024] [33mSKIPPED[0m
2026-01-14T08:46:31.8675411Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-8192x8192x8192] [33mSKIPPED[0m
2026-01-14T08:46:31.8676250Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-128x256x384] [33mSKIPPED[0m
2026-01-14T08:46:31.8677086Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-256x384x512] [33mSKIPPED[0m
2026-01-14T08:46:31.8677909Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-129x256x384] [33mSKIPPED[0m
2026-01-14T08:46:31.8678833Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-133x512x528] [33mSKIPPED[0m
2026-01-14T08:46:31.8679660Z test/prototype/mx_formats/test_mx_serialization.py::test_serialization[mxfp8] [33mSKIPPED[0m
2026-01-14T08:46:31.8680462Z test/prototype/mx_formats/test_mx_serialization.py::test_serialization[nvfp4] [33mSKIPPED[0m
2026-01-14T08:46:31.8681236Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.8682059Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.8682886Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:31.8683608Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:31.8684338Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.8685258Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:46:31.8686326Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:46:31.8687377Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:46:31.8688425Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:46:31.8689487Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:46:31.8690537Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:46:31.8691588Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:46:31.8692689Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:46:31.8693724Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:46:31.8694751Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:46:31.8695769Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:46:31.8696781Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:46:31.8697790Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:46:31.8698817Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:46:31.8699853Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:46:31.8700869Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:46:31.8701914Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:46:31.8702979Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:46:31.8704052Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:46:31.8705121Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:46:31.8706010Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.8706851Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.8707573Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:31.8708288Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:31.8709019Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.8709847Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.8710614Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.8711344Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:31.8712064Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:31.8712804Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:31.8713520Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_rceil [32mPASSED[0m
2026-01-14T08:46:31.8714270Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:31.8715064Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:31.8715866Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:31.8716646Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:31.8717425Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:45.9972582Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:45.9973428Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:45.9974241Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:45.9975008Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:45.9975776Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:45.9976537Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:45.9977256Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:45.9977941Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:45.9978625Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:45.9979310Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:45.9980045Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:45.9980821Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:45.9981587Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-fp6_e2m3] [33mSKIPPED[0m
2026-01-14T08:46:45.9982348Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-fp6_e3m2] [33mSKIPPED[0m
2026-01-14T08:46:45.9983117Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:46:45.9983905Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:45.9984674Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:45.9985435Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:45.9986178Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:45.9987305Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:45.9988095Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:45.9988874Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:45.9989644Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:45.9990552Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:45.9991320Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:45.9992096Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:45.9992836Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:45.9993577Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:45.9994299Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:45.9995028Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:45.9995751Z test/prototype/mx_formats/test_mx_tensor.py::test_view[elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:45.9996446Z test/prototype/mx_formats/test_mx_tensor.py::test_view[elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:45.9997143Z test/prototype/mx_formats/test_mx_tensor.py::test_view[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:45.9997820Z test/prototype/mx_formats/test_mx_tensor.py::test_view[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:45.9998509Z test/prototype/mx_formats/test_mx_tensor.py::test_view[elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:45.9999155Z test/prototype/mx_formats/test_mx_tensor.py::test_clone [32mPASSED[0m
2026-01-14T08:46:46.0000004Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:46.0001070Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:46.0002092Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:46.0003214Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:46.0004249Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:46.0005297Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:46.0006349Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:46.0007370Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:46.0008367Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:46.0009376Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:46.0010404Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:46.0011433Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:46.0012434Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:46.0013423Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:46.0014521Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:46.0015545Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:46.0016626Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:46.0018662Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:46:46.0019657Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:46:46.0020664Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-elem_dtype4] [32mPASSED[0m
2026-01-14T08:46:46.0021551Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_inductor_single_kernel [33mSKIPPED[0m
2026-01-14T08:46:46.0022287Z test/prototype/mx_formats/test_mx_tensor.py::test_index_select [32mPASSED[0m
2026-01-14T08:46:46.0023079Z test/prototype/mx_formats/test_mx_tensor.py::test_cast_to_float8_e4m3fn_saturation_behavior [33mSKIPPED[0m
2026-01-14T08:46:46.0024005Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape0] [32mPASSED[0m
2026-01-14T08:46:46.0024957Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape1] [32mPASSED[0m
2026-01-14T08:46:46.0025894Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape2] [32mPASSED[0m
2026-01-14T08:46:46.0026833Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape3] [32mPASSED[0m
2026-01-14T08:46:46.0027760Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape4] [32mPASSED[0m
2026-01-14T08:46:46.0028703Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape5] [32mPASSED[0m
2026-01-14T08:46:46.0029635Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape0] [32mPASSED[0m
2026-01-14T08:46:46.0030557Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape1] [32mPASSED[0m
2026-01-14T08:46:46.0031484Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape2] [32mPASSED[0m
2026-01-14T08:46:46.0032411Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape3] [32mPASSED[0m
2026-01-14T08:46:46.0033334Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape4] [32mPASSED[0m
2026-01-14T08:46:46.0034259Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape5] [32mPASSED[0m
2026-01-14T08:46:46.0035148Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape0-False] [32mPASSED[0m
2026-01-14T08:46:46.0036023Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape0-True] [32mPASSED[0m
2026-01-14T08:46:46.0036897Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape1-False] [32mPASSED[0m
2026-01-14T08:46:46.0037761Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape1-True] [33mSKIPPED[0m
2026-01-14T08:46:46.0038615Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:46.0039685Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:46.0040510Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:46.0041330Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:46.0890897Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:46:46.0891774Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:46:46.0892610Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:46:46.0893435Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:46:46.0894448Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype0-shape0-False] [32mPASSED[0m
2026-01-14T08:46:46.0895376Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype1-shape1-False] [32mPASSED[0m
2026-01-14T08:46:46.0896306Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype2-shape2-False] [32mPASSED[0m
2026-01-14T08:46:46.0897223Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype3-shape3-True] [32mPASSED[0m
2026-01-14T08:46:46.0898150Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype4-shape4-False] [32mPASSED[0m
2026-01-14T08:46:46.0899109Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape0-False] [32mPASSED[0m
2026-01-14T08:46:46.0900090Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape0-True] [32mPASSED[0m
2026-01-14T08:46:46.0901069Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape1-False] [32mPASSED[0m
2026-01-14T08:46:46.0902055Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape1-True] [32mPASSED[0m
2026-01-14T08:46:46.0903024Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape2-False] [32mPASSED[0m
2026-01-14T08:46:46.0903997Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape2-True] [32mPASSED[0m
2026-01-14T08:46:46.0904980Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape3-False] [32mPASSED[0m
2026-01-14T08:46:46.0905944Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape3-True] [32mPASSED[0m
2026-01-14T08:46:46.0906923Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape4-False] [32mPASSED[0m
2026-01-14T08:46:46.0907894Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape4-True] [32mPASSED[0m
2026-01-14T08:46:46.0908866Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_rows[0:128]] [32mPASSED[0m
2026-01-14T08:46:46.0909840Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_rows[128:256]] [32mPASSED[0m
2026-01-14T08:46:46.0910801Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:64]] [32mPASSED[0m
2026-01-14T08:46:46.0911777Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[64:128]] [32mPASSED[0m
2026-01-14T08:46:46.0912789Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:128]_full_width] [32mPASSED[0m
2026-01-14T08:46:46.0913864Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:2048]_tp_first_half] [32mPASSED[0m
2026-01-14T08:46:46.0914986Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[2048:4096]_tp_second_half] [32mPASSED[0m
2026-01-14T08:46:46.0916060Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:1024]_quarter] [32mPASSED[0m
2026-01-14T08:46:46.0917109Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[1024:2048]_quarter] [32mPASSED[0m
2026-01-14T08:46:46.0918250Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_row_end] [32mPASSED[0m
2026-01-14T08:46:46.0919317Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_row_start] [32mPASSED[0m
2026-01-14T08:46:46.0920369Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_col_32] [32mPASSED[0m
2026-01-14T08:46:46.0921410Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_col_start] [32mPASSED[0m
2026-01-14T08:46:46.0922544Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_col_end] [32mPASSED[0m
2026-01-14T08:46:46.0923610Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[odd_start] [32mPASSED[0m
2026-01-14T08:46:46.0924569Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[odd_end] [32mPASSED[0m
2026-01-14T08:46:46.0925496Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_view_semantics [32mPASSED[0m
2026-01-14T08:46:46.0926398Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_serialization [32mPASSED[0m
2026-01-14T08:46:46.0927317Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_get_scales_method [32mPASSED[0m
2026-01-14T08:46:46.0928328Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.0929424Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.0930523Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.0931623Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.0932728Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.0933819Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.0934910Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.0936016Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.0937127Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.0938230Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.0939511Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.0940623Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.0941728Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.0942841Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.0943945Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.0945061Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.0946169Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.0947420Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.0948542Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.0949641Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.0950861Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.0951975Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.0953090Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.0954209Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.0955317Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.0956442Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.0957565Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.0958662Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1169752Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1170875Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1179584Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1180696Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1181803Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1182896Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1183972Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1185065Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1186165Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1187243Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1188338Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1189430Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1190522Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1191617Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1192867Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1193970Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1195061Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1196258Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1197363Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1198451Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1199548Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1200655Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1201747Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1202942Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1204046Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1205157Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1206260Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1207366Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1208480Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1209592Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1210696Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1211828Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1212959Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1214083Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1215199Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1216316Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1217437Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1218561Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1219676Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1220800Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1222005Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1223130Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1224243Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1225428Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1226539Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1227651Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1228777Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1229893Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1231001Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1232126Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1233240Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1234345Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1235468Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1236571Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1237678Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1238791Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1240156Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1241263Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1242369Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1243521Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1244617Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1456780Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1457928Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1459047Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1460171Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1461450Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1462582Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1463703Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1464935Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1466058Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1467168Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1468271Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1469358Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1470470Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1471583Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1472672Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1473772Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1474867Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1475994Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1477112Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1478226Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1479356Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1480474Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1481580Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1482754Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1483857Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1484962Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1486080Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1487175Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1488285Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1489482Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1490575Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1491676Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1492874Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1493985Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1495106Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1496209Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1497331Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1498475Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1499573Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1500671Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1501761Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1502862Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1503956Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1505038Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1506125Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1507204Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1508279Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1509380Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1510469Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1511552Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1512626Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1513716Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1514806Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1515891Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1516996Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1518191Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1519287Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1520382Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1521565Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1522711Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1523820Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1524922Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1720858Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1721994Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1723157Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1724281Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1725395Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1726504Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1727633Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1728764Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1729874Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1731004Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1732108Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1733226Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1734349Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1735467Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1736589Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1737698Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1738816Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1740112Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1741431Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1742547Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1743667Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1744875Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1745974Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1747121Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1748226Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1749329Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1750417Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1751527Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1752639Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1753729Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1754826Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1755920Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1757017Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1758111Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1759212Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1760309Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1761398Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1762501Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1763653Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:46:46.1764752Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:46:46.1765858Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:46:46.1766976Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:46:46.1768081Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:46:46.1769186Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:46:46.1770383Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:46:46.1771570Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1772902Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1774164Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1775449Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1776773Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1778022Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1779303Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1780592Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1781863Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1783118Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1784384Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1785664Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1786928Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1788188Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1968550Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1969866Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1971133Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1972387Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1973652Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1974935Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1976203Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1977472Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1978916Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1980213Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1981597Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1982837Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1984104Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1985403Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1986669Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1987939Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1989217Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1990520Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1991801Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1993062Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1994331Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1995620Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1996951Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.1998221Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.1999510Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2000809Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2002082Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2003401Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2004675Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2005964Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2007325Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2008593Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2009878Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2011246Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2012532Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2013794Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2015084Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2016372Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2017649Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2018931Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2020228Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2021528Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2022819Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2024081Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2025349Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2026650Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2027928Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2029204Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2030502Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2031806Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2033083Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2034330Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2035583Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2037006Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2212999Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2214271Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2215683Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2216972Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2218228Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2219488Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2220746Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2222021Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2223292Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2224541Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2225824Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2227115Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2228383Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2229649Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2230934Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2232211Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2233480Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2234751Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2236034Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2237347Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2238613Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2240024Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2241433Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2242782Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2244065Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2245441Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2246736Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2248044Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2249317Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2250569Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2251840Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2253132Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2254407Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2255671Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2257008Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2258305Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2259573Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2260835Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2262103Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2263384Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2264653Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2265917Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2267203Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2268502Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2269779Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2271166Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2272448Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2273736Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2275099Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2276380Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2277668Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2278981Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2280275Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2281545Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2458112Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2459421Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2460697Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2461971Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2463260Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2464559Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2465844Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2467105Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2468387Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2469683Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2470965Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2472237Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2473531Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2474831Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2476248Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2477508Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2478787Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2480185Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2481460Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2482802Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2484088Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2485380Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2486664Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2487937Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2489219Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2490519Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2491809Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2493085Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2494394Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2495701Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2496992Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2498265Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2499544Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2500842Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2502123Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2503408Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2504703Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2506095Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2507426Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2508672Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2510001Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2511275Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2512543Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2513795Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2515085Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2516371Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2517645Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2518900Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2520162Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2521448Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2522762Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2524015Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2525296Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2526575Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2775868Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2777160Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2778450Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2779741Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2781025Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2782289Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2783718Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2785019Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2786282Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2787739Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2789012Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2790289Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2791574Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2792845Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2794115Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2795419Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2796684Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2797956Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2799238Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2800516Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2801798Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2803137Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2804417Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2805722Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2806990Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2808241Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2809515Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2810785Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2812054Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2813403Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2814675Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2815975Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2817327Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2818576Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2819853Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2821140Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2822427Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2823701Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2824979Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2832614Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2834003Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2835263Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2836531Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2837814Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2839339Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2840604Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2841895Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2843260Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2844233Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_to_copy [32mPASSED[0m
2026-01-14T08:46:46.2845101Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-False-False] [32mPASSED[0m
2026-01-14T08:46:46.2846096Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-False-True] [32mPASSED[0m
2026-01-14T08:46:46.2847094Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.2848085Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.2849229Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-False-False] [32mPASSED[0m
2026-01-14T08:46:46.2850218Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-False-True] [32mPASSED[0m
2026-01-14T08:46:46.2851195Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.3394221Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.3395251Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-False-False] [32mPASSED[0m
2026-01-14T08:46:46.3396255Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-False-True] [32mPASSED[0m
2026-01-14T08:46:46.3397930Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.3399937Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.3401922Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-False-False] [32mPASSED[0m
2026-01-14T08:46:46.3403987Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-False-True] [32mPASSED[0m
2026-01-14T08:46:46.3405976Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.3407396Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.3408392Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-False-False] [32mPASSED[0m
2026-01-14T08:46:46.3409391Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-False-True] [32mPASSED[0m
2026-01-14T08:46:46.3410400Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.3411407Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.3412406Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-False-False] [32mPASSED[0m
2026-01-14T08:46:46.3413401Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-False-True] [32mPASSED[0m
2026-01-14T08:46:46.3414397Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.3415392Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.3416390Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-False-False] [32mPASSED[0m
2026-01-14T08:46:46.3417446Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-False-True] [32mPASSED[0m
2026-01-14T08:46:46.3418447Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.3419445Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.3420445Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-False-False] [32mPASSED[0m
2026-01-14T08:46:46.3421450Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-False-True] [32mPASSED[0m
2026-01-14T08:46:46.3422445Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.3423585Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.3424593Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-False-False] [32mPASSED[0m
2026-01-14T08:46:46.3425585Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-False-True] [32mPASSED[0m
2026-01-14T08:46:46.3426698Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.3427704Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.3428700Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-False-False] [32mPASSED[0m
2026-01-14T08:46:46.3429694Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-False-True] [32mPASSED[0m
2026-01-14T08:46:46.3430691Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-True-False] [33mSKIPPED[0m
2026-01-14T08:46:46.3431690Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-True-True] [33mSKIPPED[0m
2026-01-14T08:46:46.3432576Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims0] [32mPASSED[0m
2026-01-14T08:46:46.3433361Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims1] [32mPASSED[0m
2026-01-14T08:46:46.3434154Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims2] [32mPASSED[0m
2026-01-14T08:46:46.3434940Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims3] [32mPASSED[0m
2026-01-14T08:46:46.3435732Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims0] [32mPASSED[0m
2026-01-14T08:46:46.3436539Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims1] [32mPASSED[0m
2026-01-14T08:46:46.3437335Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims2] [32mPASSED[0m
2026-01-14T08:46:46.3438126Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims3] [32mPASSED[0m
2026-01-14T08:46:46.3439337Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3440496Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3441638Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:46:46.3442818Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3443960Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3445102Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3446289Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3447436Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3448578Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3449756Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3450969Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3452301Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:46:46.3453527Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3454728Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3456043Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3457252Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3458461Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3459682Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:46.3460774Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_metadata_torchao [33mSKIPPED[0m
2026-01-14T08:46:46.3461823Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata0 [33mSKIPPED[0m
2026-01-14T08:46:46.3462931Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata1 [33mSKIPPED[0m
2026-01-14T08:46:46.3464032Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata2 [33mSKIPPED[0m
2026-01-14T08:46:46.3465133Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata3 [33mSKIPPED[0m
2026-01-14T08:46:46.3466235Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata4 [33mSKIPPED[0m
2026-01-14T08:46:46.3467332Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata5 [33mSKIPPED[0m
2026-01-14T08:46:51.8443065Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata6 [33mSKIPPED[0m
2026-01-14T08:46:51.8445436Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata7 [33mSKIPPED[0m
2026-01-14T08:46:51.8447651Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata8 [33mSKIPPED[0m
2026-01-14T08:46:51.8448821Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata9 [33mSKIPPED[0m
2026-01-14T08:46:51.8449687Z test/prototype/test_awq.py::TestAWQ::test_awq_config [32mPASSED[0m
2026-01-14T08:46:51.8450421Z test/prototype/test_awq.py::TestAWQ::test_awq_functionality_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:46:51.8451223Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:46:51.8452007Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_vllm_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:46:51.8452892Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook [33mSKIPPED[0m
2026-01-14T08:46:51.8453925Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook_row_grouping [33mSKIPPED[0m
2026-01-14T08:46:51.8454987Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [33mSKIPPED[0m
2026-01-14T08:46:51.8456063Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [33mSKIPPED[0m
2026-01-14T08:46:51.8457661Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float_row_grouping [33mSKIPPED[0m
2026-01-14T08:46:51.8458650Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_export [33mSKIPPED[0m
2026-01-14T08:46:51.8459492Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_quantize_api [33mSKIPPED[0m
2026-01-14T08:46:51.8460398Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook [32mPASSED[0m
2026-01-14T08:46:51.8461560Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:46:51.8462621Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [32mPASSED[0m
2026-01-14T08:46:51.8463560Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:46:51.8464363Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_accuracy [33mSKIPPED[0m
2026-01-14T08:46:51.8465180Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T08:46:51.8466631Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8468597Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8470521Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8472433Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8474368Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8476269Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8478191Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8480109Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8482014Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8484033Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8486157Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8488250Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8490255Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8492257Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8494412Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8496417Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8498477Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8500470Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8502474Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8504474Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8506478Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8508477Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8510467Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8512452Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8514447Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8612051Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8614058Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8616481Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8619027Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8621664Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8624189Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8626709Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8629225Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8631747Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8634262Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8636777Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8639551Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8642064Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8644631Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8647133Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8649760Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8652260Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8654869Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8657384Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8659879Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8662444Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8665051Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8667666Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8670271Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8672867Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8675449Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8678040Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8777447Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8780419Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8784699Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8787290Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8789866Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8792453Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8795032Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8797600Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8800174Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8802808Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8805389Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8807977Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8810741Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8813338Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8815997Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8818594Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8821167Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8823757Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8826328Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8828916Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8831502Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8834083Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8836668Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8839455Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8842031Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8844866Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8948224Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8950957Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8953534Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8956087Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8958616Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8961141Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8963716Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8966229Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8968740Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8971248Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8973771Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8976402Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8978911Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8981512Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8984013Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8986521Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8989016Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8991506Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.8994014Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.8996516Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.8999013Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9001588Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9004248Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9006847Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9009523Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9012122Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9014794Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9111098Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9113699Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9116281Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9118868Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9121449Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9124085Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9126656Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9129228Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9131787Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9134513Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9137083Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9139920Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9142504Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9145098Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9147702Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9150290Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9152866Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9155439Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9158023Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9160604Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9163225Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9165926Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9168515Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9171195Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9173768Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9176344Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9279700Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9282297Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9284933Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9287489Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9290048Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9292584Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9295106Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9297627Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9300303Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9302817Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9305438Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9307946Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9310462Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9312979Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9315496Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9318011Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9320527Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9323083Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9325575Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9328084Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9330672Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9333171Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9335834Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9338442Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9341209Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9343795Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9346376Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9441879Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9444557Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9447150Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9449731Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9452317Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9454901Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9457625Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9460210Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9462897Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9465489Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9468074Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9470654Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9473245Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9475832Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9478429Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9481015Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9483664Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9486254Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9488934Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9491513Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9494175Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9496765Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9499355Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9501947Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9504535Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9507109Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9609614Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9612203Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9614765Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9617344Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9620040Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9622589Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9625219Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9627753Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9630294Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9632802Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9635313Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9637843Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9640512Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9643071Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9645598Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9648109Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9650620Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9653247Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9655750Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9658435Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9660940Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9663442Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9665949Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9668511Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9671126Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9673720Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9676335Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9771169Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9773763Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9776466Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9779037Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9781702Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9784270Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9786838Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9789456Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9792026Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9794582Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9797134Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9799694Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9802250Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9804850Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9807409Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9810072Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9812647Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9815303Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9817859Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9820482Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9823065Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9825639Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9828186Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9830767Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9833357Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9846438Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9939351Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9942111Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9944664Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9947321Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9949875Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9952409Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9954947Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9957450Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9959938Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9962433Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9964970Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9967439Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9969920Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9972392Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9974957Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9977447Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9980011Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9982489Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9984961Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9987431Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9989894Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9992365Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:51.9994833Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:51.9997300Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:51.9999826Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0002404Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0005105Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0099377Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0102155Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0104719Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0107276Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0109845Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0112402Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0114955Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0117518Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0120060Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0122669Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0125213Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0127873Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0130421Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0133074Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0135612Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0138228Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0140948Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0143509Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0146056Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0148594Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0151134Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0153679Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0156220Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0158758Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0161416Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0164007Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0265530Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0268103Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0270639Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0273183Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0275727Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0278260Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0280789Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0283362Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0285859Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0288352Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0290969Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0293469Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0296058Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0298554Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0301042Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0303529Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0306012Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0308497Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0310971Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0313449Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0315924Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0318416Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0320916Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0323530Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0326003Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0328661Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0331259Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0424975Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0427580Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0430221Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0432786Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0435363Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0437944Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0440728Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0443352Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0446085Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0448670Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0451328Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0453903Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0456474Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0459055Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0461625Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0464182Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0466760Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0469341Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0471906Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0474483Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0477049Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0479707Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0482338Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0484945Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0487505Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0490062Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0592953Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0598159Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0600902Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0603529Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0606077Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0608627Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0611182Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0613880Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0616406Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0619024Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0621527Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0624019Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0626511Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0629002Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0631503Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0634028Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0636536Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0639279Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0641812Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0644516Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0647040Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0649648Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0652144Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0654646Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0657158Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0659665Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0662243Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0751820Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0754428Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0757019Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0759650Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0762236Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0764994Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0767571Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0770254Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0772829Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0775403Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0777970Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0780530Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0783080Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0785635Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0788196Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0790761Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0793320Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0795967Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0798561Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0801258Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0803902Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0806465Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0809022Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0811596Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0814161Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0816736Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0920912Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0926125Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0929549Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0932108Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0934805Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0937375Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0940192Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0942748Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0945279Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0947816Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0950329Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0952828Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0955325Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0957824Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0960311Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0962866Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0965481Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0967985Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0970645Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0973146Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0975637Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0978134Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0980675Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0983166Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.0985653Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.0988138Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.0990681Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1080275Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1082940Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1085687Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1088282Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1090965Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1093544Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1096127Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1098769Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1101352Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1103927Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1106507Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1109136Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1111715Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1114276Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1116954Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1119524Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1122235Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1124876Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1127457Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1130099Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1132675Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1135242Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1137814Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1140617Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1143207Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1145805Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1264397Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1266996Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1269732Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1272330Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1274905Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1277483Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1280063Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1282692Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:52.1285276Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:52.1287849Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1290200Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1292318Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1294477Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1296766Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1298998Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1301254Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1303400Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1305513Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1307665Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1309909Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1312100Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1314282Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1316429Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1318544Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1320711Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1322958Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1325151Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1327328Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1329611Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1331733Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1477148Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1479350Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1481519Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1483749Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1485879Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1487972Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1490118Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1492309Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1494483Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1496648Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1498780Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1500897Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1503218Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1505419Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1507716Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1509903Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1512054Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1514177Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1516346Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1518552Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1520742Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1522977Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1525125Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1527239Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1529396Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1531589Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1533857Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1536048Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:52.1537597Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_shared_embedding [33mSKIPPED[0m
2026-01-14T08:46:52.1538813Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1540557Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1542067Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1543561Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1545064Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1791564Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1794629Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1797617Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1799648Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1801134Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1802827Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1804321Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1805807Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1807281Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1808762Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1810253Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1811732Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1813406Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1814903Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1816397Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1818009Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1819498Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1821002Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1822497Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1823987Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1825491Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1826987Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1828463Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1829941Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1831430Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1832905Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1834396Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1835880Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1837354Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1838890Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1840544Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1842018Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1843662Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1845152Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1846632Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1848222Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1849697Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1851181Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1852665Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1854133Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1855619Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.1857101Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.1858580Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.1860067Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.1861552Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.1863040Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2103560Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2105089Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2106572Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2108071Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2109575Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2111065Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2112702Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2114194Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2115685Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2117279Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2118775Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2120264Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2128772Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2130359Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2131850Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2133329Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2134809Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2136289Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2137766Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2139495Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2140984Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2142466Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2143936Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2145419Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2146883Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2148401Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2150022Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2151485Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2153050Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2154516Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2155975Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2157445Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2158916Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2160381Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2161847Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2163368Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2164832Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2166294Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2167763Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2169223Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2170699Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2172179Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2173637Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2175106Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2176574Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2178039Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2414037Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2415497Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2416947Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2418525Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2420000Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2421483Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2422963Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2424443Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2425924Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2427406Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2428885Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2430362Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2431844Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2433319Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2434792Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2436275Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2437749Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2439401Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2440899Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2442372Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2444020Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2445508Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2447087Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2448568Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2450047Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2451525Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2453002Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2454481Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2455950Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2457421Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2458894Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2460357Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2461836Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2463303Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2464762Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2466225Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2467689Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2469212Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2470675Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2472138Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2473698Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2475170Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2476738Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2478213Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2479682Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2481150Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2724929Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2727922Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2729849Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2731326Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2732801Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2734265Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2735747Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2737224Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2738715Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2740340Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2741818Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2743301Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2744772Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2746246Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2747888Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2749394Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2750975Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2752459Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2753929Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2755409Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2756883Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2758373Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2759855Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2761335Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2762877Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2764345Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2765819Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2767286Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2768758Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2770225Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2771698Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2773173Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2774633Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2776088Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2777643Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2779159Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2780698Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2782163Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2783622Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2785095Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2786556Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.2788032Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.2789496Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.2790950Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.2792419Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.2793888Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3050578Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3052045Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3053503Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3054995Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3056455Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3057956Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3059436Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3060894Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3062496Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3063959Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3066458Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3067867Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3069223Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3070590Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3071939Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3073295Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3074642Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3075988Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3077335Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3078684Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3080027Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3081379Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3082786Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3084127Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3085479Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3086817Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3088152Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3089491Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3090831Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3092283Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3093630Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3094976Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3096404Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3097747Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:52.3099079Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:52.3100494Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3101975Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3103447Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3104923Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3106395Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3107860Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3109331Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3110812Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3112280Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3113754Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3115220Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3116684Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3118149Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3360203Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3361818Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3363334Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3364793Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3366363Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3367838Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3369337Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3370802Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3372274Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3373755Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3375231Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3376702Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3378177Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3379635Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3381101Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3382554Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3384014Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3385468Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3386926Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3388380Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3389833Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3391374Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3392825Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3394284Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3395815Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3397261Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3398722Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3400178Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3401626Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3403143Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3404609Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3406067Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3407525Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3409036Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3410496Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3411954Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3413409Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3414872Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3416329Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3417785Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3419247Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3420796Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3422249Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3423709Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3425242Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3426696Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3669856Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3671312Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3672769Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3674261Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3675731Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3677205Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3678678Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3680151Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3681620Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3683143Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3684605Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3686059Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3687522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3688995Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3690454Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3692089Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3693724Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3695177Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3696745Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3698203Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3699713Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3701166Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3702616Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3704075Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3705525Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3706972Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3708428Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3709883Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3711334Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3712983Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3714438Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3715892Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3717347Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3718806Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3720260Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3721706Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3723293Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3724740Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3726273Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3727734Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3729245Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3730724Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3732190Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3733666Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3735143Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3736608Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3983407Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3984881Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3986354Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3987855Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3989333Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3990809Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3992280Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.3993750Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.3995221Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.3996688Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.3998298Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.3999767Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4001347Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4002871Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4004333Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4005812Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4007286Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4008809Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4010284Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4011755Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4013219Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4014682Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4016144Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4017593Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4019050Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4020518Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4021973Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4023433Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4024895Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4026344Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4027886Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4029346Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4030909Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4032361Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4033810Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4035270Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4036730Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4038246Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4039882Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4041331Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4042836Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4044298Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4045760Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4047205Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4048668Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4050139Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4293083Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4294554Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4296019Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4297456Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4299072Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4300542Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4302093Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4303546Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4305003Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4306453Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4307909Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4309383Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4310829Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4312278Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4313737Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4315181Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4316641Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4318081Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4319536Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4320994Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4322440Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4323961Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4325412Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4326858Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4328391Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4329887Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4331395Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4332840Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4334284Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4335731Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4337168Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4338613Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4340212Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4341649Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4343100Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4344537Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4345984Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4347418Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4348858Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4350299Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4351739Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4353189Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4354628Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4356056Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4357621Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4359118Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4605346Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4608249Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4609918Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4611386Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4612874Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4614352Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4615821Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4617295Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4618775Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4620243Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4621720Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4623197Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4624664Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4626148Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4627618Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4629095Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4630580Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4632052Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4641582Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4643209Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4644792Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4646247Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4647695Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4649152Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4650602Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4652056Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4653507Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4654959Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4656408Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4657848Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4659291Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4660729Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4662169Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4663608Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4665050Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4666494Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4667934Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4669425Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4670952Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4672400Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4673936Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4675387Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4676834Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4678284Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4679735Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4681189Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4927307Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4929832Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4933376Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4936949Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4939560Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4941009Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4942451Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4943910Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4945350Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4946802Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4948254Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4949699Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4951300Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4952760Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4954314Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4955770Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4957222Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4958729Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4960184Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4961650Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4963161Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4964612Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4966060Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4967508Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4968964Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4970404Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4971863Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4973317Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4974768Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4976220Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4977676Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4979123Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4980646Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4982092Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4983637Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4985085Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4986526Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4987973Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4989464Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4990902Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4992340Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.4993778Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.4995218Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.4996665Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.4998109Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.4999551Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5249236Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5250727Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5252176Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5253623Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5255068Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5256500Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5258093Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5259554Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5261092Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5262528Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5263968Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5265426Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5266890Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5268362Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5269871Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5271332Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5272804Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5274266Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5275731Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5277193Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5278652Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5280116Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5281583Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5283126Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5284590Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5286044Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5287611Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5289086Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5290620Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5292079Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5293545Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5295012Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5296479Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5297945Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5299464Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5300932Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5302391Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5303843Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5305296Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5306753Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5308205Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5309659Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5311111Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5312567Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5314012Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5315457Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5569217Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5570726Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5572291Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5573757Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5575205Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5576649Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5578100Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5579558Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5581011Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5582466Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5583916Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5585372Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5586828Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5588324Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5589778Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5591247Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5592722Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5594188Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5595651Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5597110Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5598682Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5600149Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5601682Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5603225Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5604698Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5606165Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5607624Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5609089Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5610560Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5612032Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5613501Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5614967Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5616442Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5617907Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5619429Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5620903Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5622362Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5623835Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5625300Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5626759Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5628304Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5629763Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5631282Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5632735Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5634183Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5635635Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5949143Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5950621Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5952064Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5953505Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5954960Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5956394Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5957836Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5959282Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5960715Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5962161Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5963663Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5965278Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5967129Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5968961Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5970946Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:52.5972786Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:52.5974608Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:52.5976561Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:52.5978389Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:52.5979876Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_bfloat16 [33mSKIPPED[0m
2026-01-14T08:46:52.5981068Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float16 [33mSKIPPED[0m
2026-01-14T08:46:52.5982251Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float32 [33mSKIPPED[0m
2026-01-14T08:46:52.5983348Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_choose_qparams_gguf [32mPASSED[0m
2026-01-14T08:46:52.5984476Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_gguf_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:46:52.5985529Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:46:52.5986811Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_00 [33mSKIPPED[0m
2026-01-14T08:46:52.5988390Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_01 [33mSKIPPED[0m
2026-01-14T08:46:52.5989946Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_02 [33mSKIPPED[0m
2026-01-14T08:46:52.5991509Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_03 [33mSKIPPED[0m
2026-01-14T08:46:52.5993087Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_04 [33mSKIPPED[0m
2026-01-14T08:46:52.5994647Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_05 [33mSKIPPED[0m
2026-01-14T08:46:52.5996203Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_06 [33mSKIPPED[0m
2026-01-14T08:46:52.5997759Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_07 [33mSKIPPED[0m
2026-01-14T08:46:52.5999398Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_08 [33mSKIPPED[0m
2026-01-14T08:46:52.6000956Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_09 [33mSKIPPED[0m
2026-01-14T08:46:52.6002511Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_10 [33mSKIPPED[0m
2026-01-14T08:46:52.6004210Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_11 [33mSKIPPED[0m
2026-01-14T08:46:52.6005776Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_12 [33mSKIPPED[0m
2026-01-14T08:46:52.6007427Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_13 [33mSKIPPED[0m
2026-01-14T08:46:52.6009014Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_14 [33mSKIPPED[0m
2026-01-14T08:46:52.6010566Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_15 [33mSKIPPED[0m
2026-01-14T08:46:52.6012187Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_00 [33mSKIPPED[0m
2026-01-14T08:46:52.6013728Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_01 [33mSKIPPED[0m
2026-01-14T08:46:52.6015224Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_02 [33mSKIPPED[0m
2026-01-14T08:46:52.6016723Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_03 [33mSKIPPED[0m
2026-01-14T08:46:52.6018253Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_04 [33mSKIPPED[0m
2026-01-14T08:46:52.6019739Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_05 [33mSKIPPED[0m
2026-01-14T08:46:52.6021249Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_06 [33mSKIPPED[0m
2026-01-14T08:46:52.6022745Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_07 [33mSKIPPED[0m
2026-01-14T08:46:52.6024252Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_08 [33mSKIPPED[0m
2026-01-14T08:46:52.6025760Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_09 [33mSKIPPED[0m
2026-01-14T08:46:52.6027265Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_10 [33mSKIPPED[0m
2026-01-14T08:46:52.6028767Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_11 [33mSKIPPED[0m
2026-01-14T08:46:52.6030265Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_12 [33mSKIPPED[0m
2026-01-14T08:46:52.6031769Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_13 [33mSKIPPED[0m
2026-01-14T08:47:01.9428489Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_14 [33mSKIPPED[0m
2026-01-14T08:47:01.9430087Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_15 [33mSKIPPED[0m
2026-01-14T08:47:01.9431533Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9432856Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9434253Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9435727Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9437172Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9438603Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9440687Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9442160Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9443683Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9445318Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9446750Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9448201Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9449680Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9451110Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9452559Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9454018Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9455449Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9456889Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9458320Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9459773Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9461219Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9462677Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9464132Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9465576Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9467022Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9468476Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9469914Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9471408Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9472851Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9474286Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9475721Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9477248Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9478695Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9480144Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9481661Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9483163Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9484599Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9486034Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9487511Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9488959Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9490417Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9491861Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9493293Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9494737Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9496181Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9497613Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9499051Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9500493Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9501965Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9503451Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9504965Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9506441Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9507939Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9509397Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9510870Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9512334Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:01.9513840Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:01.9515173Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:08.3492453Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:08.3493984Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:08.3494992Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_False [32mPASSED[0m
2026-01-14T08:47:08.3496005Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_True [32mPASSED[0m
2026-01-14T08:47:08.3496988Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3497952Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3498891Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3499828Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3500774Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3501708Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3502648Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3503578Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3504524Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3505468Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3506397Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3507343Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3508275Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3509217Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3510156Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3511097Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3512035Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3512967Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3513903Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3514849Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3515782Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3516717Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3517650Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3518802Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3519743Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3520667Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3521681Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3522684Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3523674Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3524607Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3525542Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3526480Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3527393Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3528258Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3529113Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3529963Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3530819Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3531684Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3540667Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3541544Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3542389Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3543242Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3544081Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3544930Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3545782Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3546621Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3547475Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3548318Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3549165Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3550017Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3550857Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3551710Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3552551Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3553614Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3554466Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3555307Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3556156Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3557110Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3557966Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3558806Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3559652Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3560505Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3561349Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:47:08.3562194Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:47:08.3563139Z test/prototype/test_mixed_precision.py::TestWeightOnlyQuantNaive::test_quantization_intNwo [32mPASSED[0m
2026-01-14T08:47:08.3563989Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace [32mPASSED[0m
2026-01-14T08:47:08.3564778Z test/prototype/test_parametrization.py::TestFakeSparsity::test_masking_logic [32mPASSED[0m
2026-01-14T08:47:08.3565598Z test/prototype/test_parametrization.py::TestFakeSparsity::test_state_dict_preserved [32mPASSED[0m
2026-01-14T08:47:08.3566459Z test/prototype/test_parametrization.py::TestFakeSparsity::test_weights_parametrized [32mPASSED[0m
2026-01-14T08:47:08.3567242Z test/prototype/test_paretoq.py::TestParetoQ::test_quantize_functions [32mPASSED[0m
2026-01-14T08:47:08.3567952Z test/prototype/test_paretoq.py::TestParetoQ::test_quantized_linear [32mPASSED[0m
2026-01-14T08:47:08.3568950Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8651158Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8652433Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8653667Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8654910Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8656151Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8657368Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8658599Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8659832Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8661060Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8662479Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8663774Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8665002Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8668136Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8669349Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8670577Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8671836Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8673082Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8674325Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8675578Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8676806Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8678047Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8679286Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8680506Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8681749Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8683068Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8684317Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8685554Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8686789Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8688028Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8689273Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:47:08.8690494Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:47:08.8691526Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_e2e [33mSKIPPED[0m
2026-01-14T08:47:08.8692426Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_256 [33mSKIPPED[0m
2026-01-14T08:47:08.8693467Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_32 [33mSKIPPED[0m
2026-01-14T08:47:08.8694414Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_32 [32mPASSED[0m
2026-01-14T08:47:08.8695373Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_512 [32mPASSED[0m
2026-01-14T08:47:08.8696417Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_32 [32mPASSED[0m
2026-01-14T08:47:08.8697365Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_512 [32mPASSED[0m
2026-01-14T08:47:08.8698323Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_32 [32mPASSED[0m
2026-01-14T08:47:08.8699283Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_512 [32mPASSED[0m
2026-01-14T08:47:08.8700238Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_32 [32mPASSED[0m
2026-01-14T08:47:08.8701199Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_512 [32mPASSED[0m
2026-01-14T08:47:08.8702109Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_2 [32mPASSED[0m
2026-01-14T08:47:08.8702992Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_3 [32mPASSED[0m
2026-01-14T08:47:08.8703883Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_4 [32mPASSED[0m
2026-01-14T08:47:08.8704753Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_8 [32mPASSED[0m
2026-01-14T08:47:08.8705653Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only [32mPASSED[0m
2026-01-14T08:47:08.8706581Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_e2e [32mPASSED[0m
2026-01-14T08:47:08.8707587Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_parq_equivalent [32mPASSED[0m
2026-01-14T08:47:08.8708654Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_tied_embed_linear [32mPASSED[0m
2026-01-14T08:47:08.8709885Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:47:08.8711261Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:47:08.8712616Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:47:08.8713965Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:47:08.8715317Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:47:08.8716661Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:47:08.8718018Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:47:08.8719381Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:47:08.8720730Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:47:08.8722171Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:47:11.8051506Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:47:11.8053291Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:47:11.8055399Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:47:11.8057082Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:47:11.8058766Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:47:11.8060458Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:47:11.8062131Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:47:11.8063804Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:47:11.8065497Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:47:11.8067170Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:47:11.8068853Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:47:11.8070532Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:47:11.8072196Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:47:11.8073878Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:47:11.8075272Z test/prototype/test_parq.py::TestTorchAoConfigIntegration::test_tied_weights_quantization [32mPASSED[0m
2026-01-14T08:47:11.8076618Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity0 [33mSKIPPED[0m
2026-01-14T08:47:11.8078095Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity1 [33mSKIPPED[0m
2026-01-14T08:47:11.8079742Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:47:11.8081551Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:47:11.8083480Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:47:11.8085267Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:47:11.8087059Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:47:11.8089031Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:47:11.8090827Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:47:11.8092608Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:47:11.8094477Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:47:11.8096269Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:47:11.8098063Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:47:11.8099841Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:47:11.8101620Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:47:11.8103431Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:47:11.8105226Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:47:11.8106994Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:47:11.8108659Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity0 [33mSKIPPED[0m
2026-01-14T08:47:11.8110210Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity1 [33mSKIPPED[0m
2026-01-14T08:47:11.8111627Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_False [33mSKIPPED[0m
2026-01-14T08:47:11.8112889Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_True [33mSKIPPED[0m
2026-01-14T08:47:11.8114385Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_False [32mPASSED[0m
2026-01-14T08:47:11.8116073Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_True [32mPASSED[0m
2026-01-14T08:47:11.8117757Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_False [32mPASSED[0m
2026-01-14T08:47:11.8119439Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_True [32mPASSED[0m
2026-01-14T08:47:11.8121130Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_False [32mPASSED[0m
2026-01-14T08:47:11.8122884Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_True [32mPASSED[0m
2026-01-14T08:47:11.8124571Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_False [32mPASSED[0m
2026-01-14T08:47:11.8126343Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_True [32mPASSED[0m
2026-01-14T08:47:11.8128027Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_False [32mPASSED[0m
2026-01-14T08:47:11.8129705Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_True [32mPASSED[0m
2026-01-14T08:47:11.8133337Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_False [32mPASSED[0m
2026-01-14T08:47:11.8135059Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_True [32mPASSED[0m
2026-01-14T08:47:11.8136737Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_False [32mPASSED[0m
2026-01-14T08:47:11.8138430Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_True [32mPASSED[0m
2026-01-14T08:47:11.8140357Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_False [32mPASSED[0m
2026-01-14T08:47:11.8142064Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_True [32mPASSED[0m
2026-01-14T08:49:10.6914933Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_stochastic_rounding_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6917212Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_stochastic_rounding_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6918746Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6920392Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6921967Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6923661Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6925238Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6926820Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6928418Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6929990Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6931575Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6933184Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6934776Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6936389Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6938530Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6940420Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6942068Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6943957Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6945596Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6947247Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6948956Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6950775Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6952427Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6954092Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6955732Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6957380Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6958947Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_False_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6960451Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_False_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6961952Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_True_device_cpu [32mPASSED[0m
2026-01-14T08:49:10.6963417Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_True_device_cuda [32mPASSED[0m
2026-01-14T08:49:10.6964742Z test/prototype/test_quantized_training.py::TestFSDP2::test_fsdp2_correctness I0114 08:48:08.047000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 48866
2026-01-14T08:49:10.6965980Z I0114 08:48:08.048000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 48867
2026-01-14T08:49:10.6966589Z dist init r=1, world=2
2026-01-14T08:49:10.6966829Z dist init r=0, world=2
2026-01-14T08:49:10.6967748Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:49:10.6968781Z   warnings.warn(  # warn only once
2026-01-14T08:49:10.6969728Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:49:10.6970694Z   warnings.warn(  # warn only once
2026-01-14T08:49:10.6971637Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:49:10.6972742Z   warnings.warn(  # warn only once
2026-01-14T08:49:10.6973693Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:49:10.6974663Z   warnings.warn(  # warn only once
2026-01-14T08:49:10.6975681Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:49:10.6976653Z   warnings.warn(  # warn only once
2026-01-14T08:49:10.6977587Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:49:10.6978609Z   warnings.warn(  # warn only once
2026-01-14T08:49:10.6979558Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:49:10.6980521Z   warnings.warn(  # warn only once
2026-01-14T08:49:10.6981466Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:49:10.6982437Z   warnings.warn(  # warn only once
2026-01-14T08:49:10.6982750Z [32mPASSED[0m
2026-01-14T08:49:10.6983628Z test/prototype/test_quantized_training.py::TestFSDP2::test_precompute_bitnet_scale I0114 08:49:05.438000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 50046
2026-01-14T08:49:10.6984885Z I0114 08:49:05.439000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 50047
2026-01-14T08:49:10.6985508Z dist init r=1, world=2
2026-01-14T08:49:10.6985740Z dist init r=0, world=2
2026-01-14T08:49:10.6986010Z [32mPASSED[0m
2026-01-14T08:49:10.6986478Z test/prototype/test_scheduler.py::TestScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:49:10.6987214Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler [32mPASSED[0m
2026-01-14T08:49:10.6987963Z test/prototype/test_scheduler.py::TestScheduler::test_order_of_steps [32mPASSED[0m
2026-01-14T08:49:10.6988705Z test/prototype/test_scheduler.py::TestScheduler::test_step [32mPASSED[0m
2026-01-14T08:49:10.6989415Z test/prototype/test_scheduler.py::TestCubicScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:49:10.6990137Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step [32mPASSED[0m
2026-01-14T08:49:10.6990963Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_observer_insertion_base_config0 [32mPASSED[0m
2026-01-14T08:49:10.6991894Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_prepare_for_loading_base_config0 [32mPASSED[0m
2026-01-14T08:49:10.6992952Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_5_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:49:10.6994134Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_5_base_config0_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:49:13.9131697Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_75_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:49:13.9132939Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_75_base_config0_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:49:13.9133916Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:49:13.9134664Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_convert [32mPASSED[0m
2026-01-14T08:49:13.9135661Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:49:13.9136493Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params1 [32mPASSED[0m
2026-01-14T08:49:13.9137376Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params2 [32mPASSED[0m
2026-01-14T08:49:13.9138267Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params3 [32mPASSED[0m
2026-01-14T08:49:13.9139480Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_prepare_config [32mPASSED[0m
2026-01-14T08:49:13.9140252Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_state_dict [32mPASSED[0m
2026-01-14T08:49:13.9140982Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_step [32mPASSED[0m
2026-01-14T08:49:13.9141757Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:49:13.9142581Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:49:13.9143392Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:49:13.9144225Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:49:13.9145027Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step [32mPASSED[0m
2026-01-14T08:49:13.9145835Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step_2_of_4 [32mPASSED[0m
2026-01-14T08:49:13.9146671Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:49:13.9147559Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:49:13.9148441Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:49:13.9149332Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:49:13.9150190Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_step [32mPASSED[0m
2026-01-14T08:49:13.9151031Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module [32mPASSED[0m
2026-01-14T08:49:13.9151949Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_fail [32mPASSED[0m
2026-01-14T08:49:13.9152914Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_for_tensors [32mPASSED[0m
2026-01-14T08:49:13.9153910Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn [32mPASSED[0m
2026-01-14T08:49:13.9154935Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn_fail [32mPASSED[0m
2026-01-14T08:49:13.9155893Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn [32mPASSED[0m
2026-01-14T08:49:13.9156810Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_fail [32mPASSED[0m
2026-01-14T08:49:13.9157728Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_root [32mPASSED[0m
2026-01-14T08:49:13.9158711Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_lstm_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:49:13.9159728Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:49:13.9160723Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_complex_conv2d [32mPASSED[0m
2026-01-14T08:49:13.9161711Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:49:13.9162752Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_conv2d [32mPASSED[0m
2026-01-14T08:49:13.9163737Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_linear [32mPASSED[0m
2026-01-14T08:49:13.9164933Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_activation_conv2d [32mPASSED[0m
2026-01-14T08:49:13.9166040Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_bias_conv2d [32mPASSED[0m
2026-01-14T08:49:13.9167099Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_conv2d [32mPASSED[0m
2026-01-14T08:49:13.9168311Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_padding_conv2d [32mPASSED[0m
2026-01-14T08:49:13.9169397Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_pool_conv2d [32mPASSED[0m
2026-01-14T08:49:13.9170499Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_activation_linear [32mPASSED[0m
2026-01-14T08:49:13.9171608Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_bias_linear [32mPASSED[0m
2026-01-14T08:49:13.9172656Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_linear [32mPASSED[0m
2026-01-14T08:49:13.9173790Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:49:13.9175006Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_single_layer [32mPASSED[0m
2026-01-14T08:49:13.9176187Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:49:13.9177319Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_single_layer [32mPASSED[0m
2026-01-14T08:49:13.9178352Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_conv2d [32mPASSED[0m
2026-01-14T08:49:13.9179323Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_linear [32mPASSED[0m
2026-01-14T08:49:13.9180226Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_compute_distance [32mPASSED[0m
2026-01-14T08:49:13.9181064Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_update_mask [32mPASSED[0m
2026-01-14T08:49:13.9181987Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9182984Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9183978Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9184958Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9185959Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9186949Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9187933Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9188985Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9189977Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9190974Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9191968Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9193044Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9194048Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9195032Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9196025Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9197109Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9198101Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9199103Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9200101Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9201098Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:13.9202091Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:13.9203136Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7499158Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7500201Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7501201Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7502214Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7503222Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7504214Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7505214Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7506213Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7507224Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7508235Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7509231Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7510242Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7511226Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7512224Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7513243Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7514231Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7515231Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7516228Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7517431Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7518430Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7519412Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7520524Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7521512Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7522494Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7523554Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:16.7524553Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:16.7525412Z test/prototype/test_tensor_conversion.py::test_int4_tensor_conversion [33mSKIPPED[0m
2026-01-14T08:49:16.7526359Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_attention_block [33mSKIPPED[0m
2026-01-14T08:49:16.7527381Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d [33mSKIPPED[0m
2026-01-14T08:49:16.7528402Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:49:16.7529458Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:49:16.7530530Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:49:16.7531642Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_filter_linear_recipe [33mSKIPPED[0m
2026-01-14T08:49:16.7532680Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear [33mSKIPPED[0m
2026-01-14T08:49:16.7533697Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary [33mSKIPPED[0m
2026-01-14T08:49:16.7534773Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic [33mSKIPPED[0m
2026-01-14T08:49:16.7535889Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic_qat [33mSKIPPED[0m
2026-01-14T08:49:16.7536996Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_qat [33mSKIPPED[0m
2026-01-14T08:49:16.7538040Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d [33mSKIPPED[0m
2026-01-14T08:49:16.7539295Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:49:16.7547451Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:49:16.7548677Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:49:16.7549931Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case1 [33mSKIPPED[0m
2026-01-14T08:49:16.7551180Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case2 [33mSKIPPED[0m
2026-01-14T08:49:16.7552474Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:49:16.7553871Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig [33mSKIPPED[0m
2026-01-14T08:49:16.7555081Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_for_dynamic_quant [33mSKIPPED[0m
2026-01-14T08:49:16.7556362Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_with_underscores [33mSKIPPED[0m
2026-01-14T08:49:16.7557703Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:49:16.7558804Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_avgpool_use_different_qconfig [32mPASSED[0m
2026-01-14T08:49:16.7559786Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_add_quant_duplicate_dq [32mPASSED[0m
2026-01-14T08:49:16.7560753Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_need_for_duplicate_dq [32mPASSED[0m
2026-01-14T08:49:16.7561694Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_simple_duplicate_dq [32mPASSED[0m
2026-01-14T08:49:16.7562559Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu [32mPASSED[0m
2026-01-14T08:49:16.7563764Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu W0114 08:49:16.571000 1006 site-packages/torch/fx/experimental/symbolic_shapes.py:3130] Failed to reduce inequalities: 1/2
2026-01-14T08:49:16.7564717Z [32mPASSED[0m
2026-01-14T08:49:16.7565639Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict W0114 08:49:16.718000 1006 site-packages/torch/fx/experimental/symbolic_shapes.py:3130] Failed to reduce inequalities: 1/2
2026-01-14T08:49:16.7566671Z [32mPASSED[0m
2026-01-14T08:49:16.7567332Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_calculate_qparams [32mPASSED[0m
2026-01-14T08:49:16.7568419Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_disable_range_learning [32mPASSED[0m
2026-01-14T08:49:16.7569503Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_observer [32mPASSED[0m
2026-01-14T08:49:16.7570569Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_range_learning [32mPASSED[0m
2026-01-14T08:49:16.7571642Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_error_conditions [32mPASSED[0m
2026-01-14T08:49:16.7572760Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_and_observer_control [32mPASSED[0m
2026-01-14T08:49:16.7573881Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_control [32mPASSED[0m
2026-01-14T08:49:16.7575000Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_fake_quant_disabled [32mPASSED[0m
2026-01-14T08:49:16.7576132Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_learning_enabled [32mPASSED[0m
2026-01-14T08:49:39.8206358Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_observer_enabled [32mPASSED[0m
2026-01-14T08:49:39.8207830Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_gradient_scaling [32mPASSED[0m
2026-01-14T08:49:39.8209210Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_channel [32mPASSED[0m
2026-01-14T08:49:39.8210656Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_tensor [32mPASSED[0m
2026-01-14T08:49:39.8212104Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_backward_per_tensor [32mPASSED[0m
2026-01-14T08:49:39.8213926Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_forward_per_tensor [32mPASSED[0m
2026-01-14T08:49:39.8215375Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_per_channel_quantization [32mPASSED[0m
2026-01-14T08:49:39.8216736Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_state_persistence [32mPASSED[0m
2026-01-14T08:49:39.8218293Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_symmetric_quantization [32mPASSED[0m
2026-01-14T08:49:39.8219773Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_device_compatibility [32mPASSED[0m
2026-01-14T08:49:39.8221344Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_integration_with_linear_layer [32mPASSED[0m
2026-01-14T08:49:39.8222965Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_multiple_fake_quant_modules [32mPASSED[0m
2026-01-14T08:49:39.8224633Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_optimizer_updates_scale_and_zero_point [32mPASSED[0m
2026-01-14T08:49:39.8226262Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_training_mode_switching [32mPASSED[0m
2026-01-14T08:49:39.8227874Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_numerical_consistency_per_tensor [32mPASSED[0m
2026-01-14T08:49:39.8229265Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_serialization [32mPASSED[0m
2026-01-14T08:49:39.8230337Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq [33mSKIPPED[0m
2026-01-14T08:49:39.8231384Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq_no_static_q [32mPASSED[0m
2026-01-14T08:49:39.8232420Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_two_dq [32mPASSED[0m
2026-01-14T08:49:39.8233502Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_with_no_quant_inbetween [32mPASSED[0m
2026-01-14T08:49:39.8234542Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting [32mPASSED[0m
2026-01-14T08:49:39.8235585Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting_through_unknown_ops [32mPASSED[0m
2026-01-14T08:49:39.8236635Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_simple_metadata_porting [32mPASSED[0m
2026-01-14T08:49:39.8237654Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_added_node_gets_unique_id [32mPASSED[0m
2026-01-14T08:49:39.8238661Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_control_flow [33mSKIPPED[0m
2026-01-14T08:49:39.8239909Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_copy_preserve_handle [32mPASSED[0m
2026-01-14T08:49:39.8240938Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_deepcopy_preserve_handle [32mPASSED[0m
2026-01-14T08:49:39.8242041Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_prepare_for_propagation_comparison [32mPASSED[0m
2026-01-14T08:49:39.8243194Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_re_export_preserve_handle [32mPASSED[0m
2026-01-14T08:49:39.8244332Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_map_handle_to_new_nodes [32mPASSED[0m
2026-01-14T08:49:39.8245503Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_same_handle_id [32mPASSED[0m
2026-01-14T08:49:39.8246647Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_simple [32mPASSED[0m
2026-01-14T08:49:39.8247623Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval [32mPASSED[0m
2026-01-14T08:49:39.8248670Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval_idempotent [32mPASSED[0m
2026-01-14T08:49:39.8249790Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing [32mPASSED[0m
2026-01-14T08:49:39.8250821Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing_with_shared_input_edge [32mPASSED[0m
2026-01-14T08:49:39.8251806Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_chunked_bn_fusion [32mPASSED[0m
2026-01-14T08:49:39.8253882Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_linear_conv [W114 08:49:39.106112437 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:39.8256783Z [W114 08:49:39.106151438 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:39.8259256Z [W114 08:49:39.106177748 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:39.8261720Z [W114 08:49:39.106192118 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:39.8264193Z [W114 08:49:39.106203669 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:39.8266710Z [W114 08:49:39.106218369 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:39.8269171Z [W114 08:49:39.106226359 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:39.8271640Z [W114 08:49:39.106234919 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:39.8274178Z [W114 08:49:39.106273140 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:39.8276648Z [W114 08:49:39.106295120 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:26.7768164Z [W114 08:49:39.106305840 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:26.7771381Z [W114 08:49:39.106325671 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:26.7774488Z [W114 08:49:39.106340231 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:26.7777612Z [W114 08:49:39.106355081 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:26.7780709Z [W114 08:49:39.106405642 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:26.7783826Z [W114 08:49:39.106428873 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:26.7785849Z [32mPASSED[0m
2026-01-14T08:50:26.7786633Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_throw [32mPASSED[0m
2026-01-14T08:50:26.7787969Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_transform_for_annotation [32mPASSED[0m
2026-01-14T08:50:26.7789246Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_folding_pass [32mPASSED[0m
2026-01-14T08:50:26.7790461Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_prop_preserve_metadata [32mPASSED[0m
2026-01-14T08:50:26.7791624Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv3d_bn_relu [32mPASSED[0m
2026-01-14T08:50:26.7792724Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_padding_bn_relu [32mPASSED[0m
2026-01-14T08:50:26.7793915Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose3d_bn_relu [32mPASSED[0m
2026-01-14T08:50:26.7795079Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:50:26.7796206Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec [32mPASSED[0m
2026-01-14T08:50:26.7797358Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec_per_channel [32mPASSED[0m
2026-01-14T08:50:26.7798900Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_disallow_eval_train [32mPASSED[0m
2026-01-14T08:50:26.7800069Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_dont_fold_other_constant [32mPASSED[0m
2026-01-14T08:50:26.7801296Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_conv_linear_quantization [32mPASSED[0m
2026-01-14T08:50:26.7802934Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_quantizer [32mPASSED[0m
2026-01-14T08:50:26.7804141Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_observer_dedup [32mPASSED[0m
2026-01-14T08:50:26.7805353Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_ptq [32mPASSED[0m
2026-01-14T08:50:26.7806523Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_qat [32mPASSED[0m
2026-01-14T08:50:26.7807712Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_all_ops_before_quantize [32mPASSED[0m
2026-01-14T08:50:26.7808838Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize [32mPASSED[0m
2026-01-14T08:50:26.7809997Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize_per_channel [32mPASSED[0m
2026-01-14T08:50:26.7811206Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_groupwise_per_channel_quant [32mPASSED[0m
2026-01-14T08:50:26.7812384Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_input_edge_sanity_check [32mPASSED[0m
2026-01-14T08:50:26.7813511Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_max_pool2d_quantizer [32mPASSED[0m
2026-01-14T08:50:26.7814611Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported [32mPASSED[0m
2026-01-14T08:50:26.7815799Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_bn_device_cpu [32mPASSED[0m
2026-01-14T08:50:26.7817052Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_bn_device_cuda [32mPASSED[0m
2026-01-14T08:50:26.7818284Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout [32mPASSED[0m
2026-01-14T08:50:26.7819527Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout_inplace [32mPASSED[0m
2026-01-14T08:50:26.7820819Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_multi_users_without_output_observer [32mPASSED[0m
2026-01-14T08:50:26.7821997Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_observer_callback [32mPASSED[0m
2026-01-14T08:50:26.7823137Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_prepare_obs_or_fq_callback [32mPASSED[0m
2026-01-14T08:50:26.7824320Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_preserve_nn_module_stack [32mPASSED[0m
2026-01-14T08:50:26.7825599Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:50:26.7826933Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e5m2 [32mPASSED[0m
2026-01-14T08:50:26.7828231Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_int16 [32mPASSED[0m
2026-01-14T08:50:26.7829535Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:50:26.7830860Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e5m2 [32mPASSED[0m
2026-01-14T08:50:26.7832141Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_int16 [32mPASSED[0m
2026-01-14T08:50:26.7833349Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantize_in_place_ops input_act1 is a node
2026-01-14T08:50:26.7834111Z [32mPASSED[0m
2026-01-14T08:50:26.7834743Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant [32mPASSED[0m
2026-01-14T08:50:26.7836417Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_save_load W0114 08:50:26.354000 1006 site-packages/torch/export/pt2_archive/_package.py:396] Expect archive file to be a file ending in .pt2, or is a buffer. Instead got {/tmp/tmpzg8nuztl}
2026-01-14T08:50:26.7838532Z W0114 08:50:26.365000 1006 site-packages/torch/export/pt2_archive/_package.py:571] Unable to load package. f must be a buffer or a file ending in .pt2. Instead got {/tmp/tmpzg8nuztl}
2026-01-14T08:50:26.7839819Z [32mPASSED[0m
2026-01-14T08:50:26.7840481Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec [32mPASSED[0m
2026-01-14T08:50:26.7841588Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity [32mPASSED[0m
2026-01-14T08:50:26.7842915Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity_case_2 [32mPASSED[0m
2026-01-14T08:50:26.7844080Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_simple_quantizer [32mPASSED[0m
2026-01-14T08:50:26.7845089Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_speed [32mPASSED[0m
2026-01-14T08:50:26.7846174Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_transform_for_annotation [32mPASSED[0m
2026-01-14T08:50:26.7847382Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_wo_annotate_conv_output_quantizer [32mPASSED[0m
2026-01-14T08:50:26.7848693Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_channel_group_quantization prepared model: GraphModule(
2026-01-14T08:50:26.7849603Z   (linear): Module()
2026-01-14T08:50:26.7850002Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:50:26.7850605Z   (activation_post_process_0): AffineQuantizedMinMaxObserver()
2026-01-14T08:50:26.7851058Z )
2026-01-14T08:50:26.7851190Z 
2026-01-14T08:50:26.7851196Z 
2026-01-14T08:50:26.7851201Z 
2026-01-14T08:50:26.7851310Z def forward(self, x):
2026-01-14T08:50:26.7851687Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:50:26.7852139Z     linear_weight = self.linear.weight
2026-01-14T08:51:10.3600214Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:51:10.3603008Z     linear_bias = self.linear.bias
2026-01-14T08:51:10.3603588Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:10.3604852Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:51:10.3606033Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:51:10.3606478Z     
2026-01-14T08:51:10.3606871Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:10.3607409Z quantized model GraphModule(
2026-01-14T08:51:10.3607731Z   (linear): Module()
2026-01-14T08:51:10.3608030Z )
2026-01-14T08:51:10.3608158Z 
2026-01-14T08:51:10.3608163Z 
2026-01-14T08:51:10.3608168Z 
2026-01-14T08:51:10.3608278Z def forward(self, x):
2026-01-14T08:51:10.3608667Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:10.3609106Z     _scale0 = self._scale0
2026-01-14T08:51:10.3609430Z     _zero_point0 = self._zero_point0
2026-01-14T08:51:10.3609822Z     quantize_affine = self._frozen_param0
2026-01-14T08:51:10.3610978Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:51:10.3612146Z     linear_bias = self.linear.bias
2026-01-14T08:51:10.3612485Z     _scale1 = self._scale1
2026-01-14T08:51:10.3613147Z     _zero_point1 = self._zero_point1
2026-01-14T08:51:10.3613868Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255);  x = None
2026-01-14T08:51:10.3615419Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine_1 = _scale1 = _zero_point1 = None
2026-01-14T08:51:10.3617322Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:51:10.3618344Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:51:10.3618806Z     
2026-01-14T08:51:10.3619176Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:10.3619879Z [32mPASSED[0m
2026-01-14T08:51:10.3620864Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_affine_act_per_channel_weights [32mPASSED[0m
2026-01-14T08:51:10.3622381Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_per_tok_act_per_group_weights prepared model: GraphModule(
2026-01-14T08:51:10.3623337Z   (linear): Module()
2026-01-14T08:51:10.3623747Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:51:10.3624381Z   (activation_post_process_0): AffineQuantizedPlaceholderObserver()
2026-01-14T08:51:10.3624879Z )
2026-01-14T08:51:10.3625005Z 
2026-01-14T08:51:10.3625010Z 
2026-01-14T08:51:10.3625015Z 
2026-01-14T08:51:10.3625123Z def forward(self, x):
2026-01-14T08:51:10.3625497Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:10.3625956Z     linear_weight = self.linear.weight
2026-01-14T08:51:10.3626593Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:51:10.3627261Z     linear_bias = self.linear.bias
2026-01-14T08:51:10.3627769Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:10.3629000Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:51:10.3630151Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:51:10.3630595Z     
2026-01-14T08:51:10.3630960Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:10.3631453Z quantized model GraphModule(
2026-01-14T08:51:10.3631771Z   (linear): Module()
2026-01-14T08:51:10.3632025Z )
2026-01-14T08:51:10.3632155Z 
2026-01-14T08:51:10.3632161Z 
2026-01-14T08:51:10.3632165Z 
2026-01-14T08:51:10.3632271Z def forward(self, x):
2026-01-14T08:51:10.3632633Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:10.3633066Z     _scale0 = self._scale0
2026-01-14T08:51:10.3633381Z     _zero_point0 = self._zero_point0
2026-01-14T08:51:10.3633748Z     quantize_affine = self._frozen_param0
2026-01-14T08:51:10.3634914Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.int8, -127, 127, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:51:10.3636070Z     linear_bias = self.linear.bias
2026-01-14T08:51:10.3636843Z     choose_qparams_affine = torch.ops.torchao.choose_qparams_affine(x, 'SYMMETRIC', (1, 128), torch.int8, -128, 127, None, None, None)
2026-01-14T08:51:10.3637645Z     getitem = choose_qparams_affine[0]
2026-01-14T08:51:10.3638152Z     getitem_1 = choose_qparams_affine[1];  choose_qparams_affine = None
2026-01-14T08:51:10.3639274Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), getitem, getitem_1, torch.int8, -128, 127);  x = None
2026-01-14T08:51:10.3640626Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), getitem, getitem_1, torch.int8, -128, 127, output_dtype = torch.float32);  quantize_affine_1 = getitem = getitem_1 = None
2026-01-14T08:51:10.3641992Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:51:10.3642851Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:51:10.3643343Z     
2026-01-14T08:51:10.3643670Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:10.3644147Z [32mPASSED[0m
2026-01-14T08:51:10.3644828Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_fold_bn_erases_bn_node [33mSKIPPED[0m
2026-01-14T08:51:10.3645947Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_bias_derived_qspec [33mSKIPPED[0m
2026-01-14T08:51:10.3647043Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion [33mSKIPPED[0m
2026-01-14T08:51:10.3648123Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:51:10.3649241Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_literal_args [33mSKIPPED[0m
2026-01-14T08:51:10.3650393Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:51:10.3651566Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_per_channel_weight_bias [33mSKIPPED[0m
2026-01-14T08:51:10.3652703Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion [33mSKIPPED[0m
2026-01-14T08:51:10.3653812Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:51:10.3654973Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:51:10.3656076Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_no_bias [33mSKIPPED[0m
2026-01-14T08:51:10.3657131Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn [33mSKIPPED[0m
2026-01-14T08:51:10.3658226Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn_relu [33mSKIPPED[0m
2026-01-14T08:51:10.3659310Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_inplace_add_relu [33mSKIPPED[0m
2026-01-14T08:51:10.3660434Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_per_channel_weight_custom_dtype [33mSKIPPED[0m
2026-01-14T08:51:10.3661595Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_preserve_source_fn_stack [33mSKIPPED[0m
2026-01-14T08:51:10.3662760Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_update_shared_qspec [33mSKIPPED[0m
2026-01-14T08:51:10.3663825Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T08:51:10.3664911Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T08:51:10.3665903Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T08:51:10.3666539Z   (conv): Module()
2026-01-14T08:51:10.3666756Z   (bn): Module()
2026-01-14T08:51:10.3667067Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:10.3668213Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:10.3669461Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:10.3670014Z   )
2026-01-14T08:51:10.3670308Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:10.3671537Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0017, 0.0019, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:10.3673000Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2148, -0.0992, -0.2048]), max_val=tensor([0.0771, 0.2459, 0.3011]))
2026-01-14T08:51:10.3673703Z   )
2026-01-14T08:51:10.3673991Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:10.3675049Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:28.4372687Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4139440059661865)
2026-01-14T08:51:28.4373505Z   )
2026-01-14T08:51:28.4373732Z )
2026-01-14T08:51:28.4373869Z 
2026-01-14T08:51:28.4373875Z 
2026-01-14T08:51:28.4373880Z 
2026-01-14T08:51:28.4373999Z def forward(self, x):
2026-01-14T08:51:28.4374389Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:28.4374844Z     conv_weight = self.conv.weight
2026-01-14T08:51:28.4375210Z     conv_bias = self.conv.bias
2026-01-14T08:51:28.4375543Z     bn_weight = self.bn.weight
2026-01-14T08:51:28.4375877Z     bn_bias = self.bn.bias
2026-01-14T08:51:28.4376211Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:51:28.4376602Z     bn_running_var = self.bn.running_var
2026-01-14T08:51:28.4377043Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:28.4377629Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:28.4378431Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:28.4379154Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:51:28.4379679Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:51:28.4380220Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:51:28.4380809Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:51:28.4381470Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:51:28.4382224Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:51:28.4383066Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:51:28.4384416Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:51:28.4385643Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:51:28.4386370Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:51:28.4387137Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:51:28.4387884Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:51:28.4389123Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:51:28.4390783Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:51:28.4391600Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:51:28.4392117Z     
2026-01-14T08:51:28.4392481Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:28.4392962Z model fx: GraphModule(
2026-01-14T08:51:28.4393523Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:28.4394843Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:28.4396428Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:28.4397176Z   )
2026-01-14T08:51:28.4397397Z   (conv): ConvBn1d(
2026-01-14T08:51:28.4397679Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:51:28.4398212Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:51:28.4398843Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:28.4400213Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0017, 0.0019, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:28.4402073Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2148, -0.0992, -0.2048]), max_val=tensor([0.0771, 0.2459, 0.3011]))
2026-01-14T08:51:28.4403063Z     )
2026-01-14T08:51:28.4403276Z   )
2026-01-14T08:51:28.4403625Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:28.4404944Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:28.4406509Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4139440059661865)
2026-01-14T08:51:28.4407207Z   )
2026-01-14T08:51:28.4407415Z )
2026-01-14T08:51:28.4407539Z 
2026-01-14T08:51:28.4407551Z 
2026-01-14T08:51:28.4407556Z 
2026-01-14T08:51:28.4407669Z def forward(self, x):
2026-01-14T08:51:28.4408117Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:28.4408827Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:51:28.4409560Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:51:28.4410121Z     return activation_post_process_1
2026-01-14T08:51:28.4410453Z     
2026-01-14T08:51:28.4410803Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:28.4411290Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:28.4411582Z          [0., 0., 0.],
2026-01-14T08:51:28.4411886Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:51:28.4412271Z converted model pt2e: GraphModule(
2026-01-14T08:51:28.4412603Z   (conv): Module()
2026-01-14T08:51:28.4412854Z   (bn): Module()
2026-01-14T08:51:28.4413096Z )
2026-01-14T08:51:28.4413216Z 
2026-01-14T08:51:28.4413222Z 
2026-01-14T08:51:28.4413226Z 
2026-01-14T08:51:28.4413348Z def forward(self, x):
2026-01-14T08:51:28.4413709Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:28.4414147Z     conv_bias = self.conv.bias
2026-01-14T08:51:28.4414550Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:28.4415331Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:28.4416785Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:28.4417928Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:28.4418448Z     _scale_0 = self._scale_0
2026-01-14T08:51:28.4418717Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:51:28.4419056Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:51:28.4420146Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:51:28.4421651Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:51:28.4422986Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011089790612459183, 0, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:51:28.4424407Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011089790612459183, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:28.4425510Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:51:28.4425964Z     
2026-01-14T08:51:28.4426264Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:28.4426703Z onverted model fx: GraphModule(
2026-01-14T08:51:28.4427120Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:51:28.4427532Z )
2026-01-14T08:51:28.4427636Z 
2026-01-14T08:51:28.4427640Z 
2026-01-14T08:51:28.4427644Z 
2026-01-14T08:51:28.4427745Z def forward(self, x):
2026-01-14T08:51:28.4428410Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:28.4429758Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:28.4430863Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:51:28.4431798Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011089790612459183, 0, -128, 127, torch.int8);  conv = None
2026-01-14T08:51:28.4433191Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011089790612459183, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:28.4434149Z     return dequantize_per_tensor_default_1
2026-01-14T08:51:28.4434441Z     
2026-01-14T08:51:28.4434734Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:28.4435137Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:28.4435390Z          [0., 0., 0.],
2026-01-14T08:51:28.4435610Z          [0., 0., 0.]]])
2026-01-14T08:51:28.4435861Z model pt2e: GraphModule(
2026-01-14T08:51:28.4436099Z   (conv): Module()
2026-01-14T08:51:28.4436329Z   (bn): Module()
2026-01-14T08:51:28.4444427Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:28.4445525Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:28.4446785Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:28.4447342Z   )
2026-01-14T08:51:28.4447647Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:28.4449675Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:51:28.4450947Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.214811772108078, max_val=0.30109599232673645)
2026-01-14T08:51:28.4451514Z   )
2026-01-14T08:51:28.4451924Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:51.9553936Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:51.9555362Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4138529300689697)
2026-01-14T08:51:51.9556018Z   )
2026-01-14T08:51:51.9556209Z )
2026-01-14T08:51:51.9556323Z 
2026-01-14T08:51:51.9556328Z 
2026-01-14T08:51:51.9556332Z 
2026-01-14T08:51:51.9556441Z def forward(self, x):
2026-01-14T08:51:51.9556843Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:51.9557221Z     conv_weight = self.conv.weight
2026-01-14T08:51:51.9557586Z     conv_bias = self.conv.bias
2026-01-14T08:51:51.9557905Z     bn_weight = self.bn.weight
2026-01-14T08:51:51.9558174Z     bn_bias = self.bn.bias
2026-01-14T08:51:51.9558551Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:51:51.9558872Z     bn_running_var = self.bn.running_var
2026-01-14T08:51:51.9559280Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:51.9559805Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:51.9560546Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:51.9561215Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:51:51.9561647Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:51:51.9562191Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:51:51.9562808Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:51:51.9563400Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:51:51.9564116Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:51:51.9564888Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:51:51.9566069Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:51:51.9567203Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:51:51.9567817Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:51:51.9568543Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:51:51.9569240Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:51:51.9570346Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:51:51.9571585Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:51:51.9572277Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:51:51.9572769Z     
2026-01-14T08:51:51.9573083Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:51.9573570Z model fx: GraphModule(
2026-01-14T08:51:51.9573924Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:51.9575393Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:51.9576816Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:51.9577404Z   )
2026-01-14T08:51:51.9577834Z   (conv): ConvBn1d(
2026-01-14T08:51:51.9578086Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:51:51.9578605Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:51:51.9579157Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:51.9580348Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:51:51.9581725Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.214811772108078, max_val=0.30109599232673645)
2026-01-14T08:51:51.9582391Z     )
2026-01-14T08:51:51.9582581Z   )
2026-01-14T08:51:51.9582926Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:51.9584116Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:51.9585509Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4138529300689697)
2026-01-14T08:51:51.9586108Z   )
2026-01-14T08:51:51.9586305Z )
2026-01-14T08:51:51.9586461Z 
2026-01-14T08:51:51.9586467Z 
2026-01-14T08:51:51.9586473Z 
2026-01-14T08:51:51.9586571Z def forward(self, x):
2026-01-14T08:51:51.9586951Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:51.9587615Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:51:51.9588303Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:51:51.9588773Z     return activation_post_process_1
2026-01-14T08:51:51.9589131Z     
2026-01-14T08:51:51.9589431Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:51.9589884Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:51.9590180Z          [0., 0., 0.],
2026-01-14T08:51:51.9590437Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:51:51.9590835Z converted model pt2e: GraphModule(
2026-01-14T08:51:51.9591121Z   (conv): Module()
2026-01-14T08:51:51.9591342Z   (bn): Module()
2026-01-14T08:51:51.9591567Z )
2026-01-14T08:51:51.9591719Z 
2026-01-14T08:51:51.9591725Z 
2026-01-14T08:51:51.9591732Z 
2026-01-14T08:51:51.9591826Z def forward(self, x):
2026-01-14T08:51:51.9592134Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:51.9592573Z     conv_bias = self.conv.bias
2026-01-14T08:51:51.9592929Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:51.9593803Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:51.9595309Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:51.9596517Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:51.9597166Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:51:51.9598048Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002370834583416581, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:51:51.9599667Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:51:51.9601018Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.01108943298459053, 0, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:51:51.9602459Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01108943298459053, 0, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:51:51.9603838Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:51:51.9604303Z     
2026-01-14T08:51:51.9604610Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:51.9605026Z onverted model fx: GraphModule(
2026-01-14T08:51:51.9605429Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:51:51.9605826Z )
2026-01-14T08:51:51.9605928Z 
2026-01-14T08:51:51.9605939Z 
2026-01-14T08:51:51.9605943Z 
2026-01-14T08:51:51.9606041Z def forward(self, x):
2026-01-14T08:51:51.9606708Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:51.9608081Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:51.9609212Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:51:51.9610228Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01108943298459053, 0, -128, 127, torch.int8);  conv = None
2026-01-14T08:51:51.9611637Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01108943298459053, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:51.9612619Z     return dequantize_per_tensor_default_1
2026-01-14T08:51:51.9612918Z     
2026-01-14T08:51:51.9613215Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:51.9613622Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:51.9613874Z          [0., 0., 0.],
2026-01-14T08:51:51.9614110Z          [0., 0., 0.]]])
2026-01-14T08:51:51.9614570Z [32mPASSED[0m
2026-01-14T08:51:51.9615196Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_cuda model pt2e: GraphModule(
2026-01-14T08:51:51.9615865Z   (conv): Module()
2026-01-14T08:51:51.9616094Z   (bn): Module()
2026-01-14T08:51:51.9616413Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:51.9617711Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:51.9619178Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:51.9619733Z   )
2026-01-14T08:51:51.9620037Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:07.3801749Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:52:07.3803747Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:52:07.3804570Z   )
2026-01-14T08:52:07.3805178Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:07.3806470Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:07.3808103Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3958139419555664, max_val=1.4123148918151855)
2026-01-14T08:52:07.3808666Z   )
2026-01-14T08:52:07.3808840Z )
2026-01-14T08:52:07.3808937Z 
2026-01-14T08:52:07.3808944Z 
2026-01-14T08:52:07.3808954Z 
2026-01-14T08:52:07.3809040Z def forward(self, x):
2026-01-14T08:52:07.3809339Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:07.3809709Z     conv_weight = self.conv.weight
2026-01-14T08:52:07.3809993Z     conv_bias = self.conv.bias
2026-01-14T08:52:07.3810258Z     bn_weight = self.bn.weight
2026-01-14T08:52:07.3810529Z     bn_bias = self.bn.bias
2026-01-14T08:52:07.3810793Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:52:07.3811112Z     bn_running_var = self.bn.running_var
2026-01-14T08:52:07.3811459Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:07.3811933Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:07.3812583Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:07.3813175Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:52:07.3813588Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:52:07.3814031Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:52:07.3814532Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:52:07.3815063Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:52:07.3815680Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:52:07.3816353Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:52:07.3817432Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:52:07.3818440Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:52:07.3819040Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:52:07.3819665Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:52:07.3820263Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:52:07.3821262Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:52:07.3822336Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:52:07.3822984Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:52:07.3823396Z     
2026-01-14T08:52:07.3823697Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:07.3824081Z model fx: GraphModule(
2026-01-14T08:52:07.3824420Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:07.3825694Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:07.3827281Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:52:07.3827834Z   )
2026-01-14T08:52:07.3828015Z   (conv): ConvBn1d(
2026-01-14T08:52:07.3828247Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:52:07.3828696Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:07.3829323Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:07.3830643Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:52:07.3832447Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:52:07.3833264Z     )
2026-01-14T08:52:07.3833431Z   )
2026-01-14T08:52:07.3833722Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:07.3834997Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:07.3836463Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3958139419555664, max_val=1.4123148918151855)
2026-01-14T08:52:07.3837016Z   )
2026-01-14T08:52:07.3837189Z )
2026-01-14T08:52:07.3837292Z 
2026-01-14T08:52:07.3837297Z 
2026-01-14T08:52:07.3837301Z 
2026-01-14T08:52:07.3837393Z def forward(self, x):
2026-01-14T08:52:07.3837764Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:07.3838338Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:52:07.3838924Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:52:07.3839577Z     return activation_post_process_1
2026-01-14T08:52:07.3839843Z     
2026-01-14T08:52:07.3840149Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:07.3840543Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:52:07.3840788Z          [0., 0., 0.],
2026-01-14T08:52:07.3841076Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:52:07.3841435Z converted model pt2e: GraphModule(
2026-01-14T08:52:07.3841708Z   (conv): Module()
2026-01-14T08:52:07.3841910Z   (bn): Module()
2026-01-14T08:52:07.3842110Z )
2026-01-14T08:52:07.3842208Z 
2026-01-14T08:52:07.3842213Z 
2026-01-14T08:52:07.3842217Z 
2026-01-14T08:52:07.3842302Z def forward(self, x):
2026-01-14T08:52:07.3842645Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:07.3843006Z     conv_bias = self.conv.bias
2026-01-14T08:52:07.3843326Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:07.3844096Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:52:07.3845453Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:07.3846609Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:07.3847123Z     _scale_0 = self._scale_0
2026-01-14T08:52:07.3847386Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:52:07.3847710Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:52:07.3848860Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:52:07.3850378Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:52:07.3851721Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011012271046638489, -1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:52:07.3853261Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011012271046638489, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:07.3854378Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:52:07.3854810Z     
2026-01-14T08:52:07.3855104Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:07.3855509Z onverted model fx: GraphModule(
2026-01-14T08:52:07.3855900Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:52:07.3856294Z )
2026-01-14T08:52:07.3856393Z 
2026-01-14T08:52:07.3856397Z 
2026-01-14T08:52:07.3856401Z 
2026-01-14T08:52:07.3856485Z def forward(self, x):
2026-01-14T08:52:07.3857147Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:52:07.3858507Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:07.3859608Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:52:07.3860543Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011012271046638489, -1, -128, 127, torch.int8);  conv = None
2026-01-14T08:52:07.3861950Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011012271046638489, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:07.3862922Z     return dequantize_per_tensor_default_1
2026-01-14T08:52:07.3863207Z     
2026-01-14T08:52:07.3863500Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:07.3863893Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:52:25.7690491Z          [0., 0., 0.],
2026-01-14T08:52:25.7691304Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:52:25.7692177Z model pt2e: GraphModule(
2026-01-14T08:52:25.7692896Z   (conv): Module()
2026-01-14T08:52:25.7693272Z   (bn): Module()
2026-01-14T08:52:25.7693740Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:25.7695662Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:25.7697327Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:52:25.7697875Z   )
2026-01-14T08:52:25.7698185Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:25.7699476Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:25.7700945Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:52:25.7701512Z   )
2026-01-14T08:52:25.7702062Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:25.7703345Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:25.7705091Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3977917432785034, max_val=1.4123148918151855)
2026-01-14T08:52:25.7705654Z   )
2026-01-14T08:52:25.7705847Z )
2026-01-14T08:52:25.7705950Z 
2026-01-14T08:52:25.7705954Z 
2026-01-14T08:52:25.7705958Z 
2026-01-14T08:52:25.7706055Z def forward(self, x):
2026-01-14T08:52:25.7706365Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:25.7706740Z     conv_weight = self.conv.weight
2026-01-14T08:52:25.7707032Z     conv_bias = self.conv.bias
2026-01-14T08:52:25.7707315Z     bn_weight = self.bn.weight
2026-01-14T08:52:25.7707581Z     bn_bias = self.bn.bias
2026-01-14T08:52:25.7707872Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:52:25.7708193Z     bn_running_var = self.bn.running_var
2026-01-14T08:52:25.7708556Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:25.7709029Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:25.7709684Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:25.7710274Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:52:25.7710696Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:52:25.7711149Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:52:25.7711625Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:52:25.7712167Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:52:25.7712792Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:52:25.7713465Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:52:25.7714557Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:52:25.7715537Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:52:25.7716135Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:52:25.7716768Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:52:25.7717375Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:52:25.7718386Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:52:25.7719449Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:52:25.7720103Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:52:25.7720528Z     
2026-01-14T08:52:25.7720825Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:25.7721233Z model fx: GraphModule(
2026-01-14T08:52:25.7721572Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:25.7722964Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:25.7724521Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:52:25.7725069Z   )
2026-01-14T08:52:25.7725257Z   (conv): ConvBn1d(
2026-01-14T08:52:25.7725484Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:52:25.7725926Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:25.7726441Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:25.7727817Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:25.7729297Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:52:25.7729855Z     )
2026-01-14T08:52:25.7730036Z   )
2026-01-14T08:52:25.7730319Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:25.7731603Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:25.7733064Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3977917432785034, max_val=1.4123148918151855)
2026-01-14T08:52:25.7733620Z   )
2026-01-14T08:52:25.7733796Z )
2026-01-14T08:52:25.7733896Z 
2026-01-14T08:52:25.7733901Z 
2026-01-14T08:52:25.7733905Z 
2026-01-14T08:52:25.7733995Z def forward(self, x):
2026-01-14T08:52:25.7734375Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:25.7734947Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:52:25.7735541Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:52:25.7736010Z     return activation_post_process_1
2026-01-14T08:52:25.7736277Z     
2026-01-14T08:52:25.7736573Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:25.7736966Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:52:25.7737221Z          [0., 0., 0.],
2026-01-14T08:52:25.7737505Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:52:25.7737886Z converted model pt2e: GraphModule(
2026-01-14T08:52:25.7738156Z   (conv): Module()
2026-01-14T08:52:25.7738371Z   (bn): Module()
2026-01-14T08:52:25.7738574Z )
2026-01-14T08:52:25.7738673Z 
2026-01-14T08:52:25.7738678Z 
2026-01-14T08:52:25.7738682Z 
2026-01-14T08:52:25.7738769Z def forward(self, x):
2026-01-14T08:52:25.7739384Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:25.7739753Z     conv_bias = self.conv.bias
2026-01-14T08:52:25.7740091Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:25.7740861Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:52:25.7742222Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:25.7743626Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:25.7744256Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:52:25.7745297Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:52:25.7746996Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:52:25.7748740Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011020027101039886, -1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:52:25.7750186Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011020027101039886, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:52:25.7751402Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:52:25.7751840Z     
2026-01-14T08:52:25.7752139Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:25.7752541Z onverted model fx: GraphModule(
2026-01-14T08:52:25.7752942Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:52:25.7753336Z )
2026-01-14T08:52:25.7753445Z 
2026-01-14T08:52:25.7753450Z 
2026-01-14T08:52:25.7753453Z 
2026-01-14T08:52:25.7753544Z def forward(self, x):
2026-01-14T08:52:25.7754215Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:52:25.7755560Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:25.7756676Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:52:49.7565938Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011020027101039886, -1, -128, 127, torch.int8);  conv = None
2026-01-14T08:52:49.7569337Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011020027101039886, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:49.7570630Z     return dequantize_per_tensor_default_1
2026-01-14T08:52:49.7571008Z     
2026-01-14T08:52:49.7571377Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:49.7571871Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:52:49.7572172Z          [0., 0., 0.],
2026-01-14T08:52:49.7572464Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:52:49.7573059Z [32mPASSED[0m
2026-01-14T08:52:49.7573872Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T08:52:49.7574745Z   (conv): Module()
2026-01-14T08:52:49.7575000Z   (bn): Module()
2026-01-14T08:52:49.7575384Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:49.7576707Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:49.7578290Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:52:49.7578987Z   )
2026-01-14T08:52:49.7579342Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:49.7580748Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:52:49.7582598Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:52:49.7583478Z   )
2026-01-14T08:52:49.7583829Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:49.7585405Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:49.7586977Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9784814715385437, max_val=2.047511577606201)
2026-01-14T08:52:49.7587671Z   )
2026-01-14T08:52:49.7587886Z )
2026-01-14T08:52:49.7588009Z 
2026-01-14T08:52:49.7588014Z 
2026-01-14T08:52:49.7588167Z 
2026-01-14T08:52:49.7588284Z def forward(self, x):
2026-01-14T08:52:49.7588651Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:49.7589100Z     conv_weight = self.conv.weight
2026-01-14T08:52:49.7589444Z     conv_bias = self.conv.bias
2026-01-14T08:52:49.7589775Z     bn_weight = self.bn.weight
2026-01-14T08:52:49.7590097Z     bn_bias = self.bn.bias
2026-01-14T08:52:49.7590418Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:52:49.7590807Z     bn_running_var = self.bn.running_var
2026-01-14T08:52:49.7591229Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:49.7591816Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:49.7592626Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:49.7601131Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:52:49.7601672Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:52:49.7602225Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:52:49.7602910Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:52:49.7603568Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:52:49.7604334Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:52:49.7605171Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:52:49.7606554Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:52:49.7607802Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:52:49.7608514Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:52:49.7609298Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:52:49.7610096Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:52:49.7611340Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:52:49.7612673Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:52:49.7613479Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:52:49.7614007Z     
2026-01-14T08:52:49.7614379Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:49.7614861Z model fx: GraphModule(
2026-01-14T08:52:49.7615279Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:49.7616607Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:49.7618194Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:52:49.7618899Z   )
2026-01-14T08:52:49.7619130Z   (conv): ConvBn1d(
2026-01-14T08:52:49.7619467Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:52:49.7620061Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:49.7620878Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:49.7622056Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:52:49.7623608Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:52:49.7624324Z     )
2026-01-14T08:52:49.7624502Z   )
2026-01-14T08:52:49.7624798Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:49.7625858Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:49.7627108Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9784814715385437, max_val=2.047511577606201)
2026-01-14T08:52:49.7627667Z   )
2026-01-14T08:52:49.7627844Z )
2026-01-14T08:52:49.7627946Z 
2026-01-14T08:52:49.7627951Z 
2026-01-14T08:52:49.7627955Z 
2026-01-14T08:52:49.7628053Z def forward(self, x):
2026-01-14T08:52:49.7628416Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:49.7628999Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:52:49.7629586Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:52:49.7630045Z     return activation_post_process_1
2026-01-14T08:52:49.7630319Z     
2026-01-14T08:52:49.7630607Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:49.7631005Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:52:49.7631286Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:52:49.7631597Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:52:49.7631942Z converted model pt2e: GraphModule(
2026-01-14T08:52:49.7632220Z   (conv): Module()
2026-01-14T08:52:49.7632425Z   (bn): Module()
2026-01-14T08:52:49.7632624Z )
2026-01-14T08:52:49.7632723Z 
2026-01-14T08:52:49.7632728Z 
2026-01-14T08:52:49.7632732Z 
2026-01-14T08:52:49.7632824Z def forward(self, x):
2026-01-14T08:52:49.7633126Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:49.7633490Z     conv_bias = self.conv.bias
2026-01-14T08:52:49.7633803Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:49.7634581Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:52:49.7635961Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:49.7637118Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:49.7637643Z     _scale_0 = self._scale_0
2026-01-14T08:52:49.7637906Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:52:49.7638234Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:52:49.7639467Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:52:49.7641055Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:52:49.7642410Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011866639368236065, -46, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:52:49.7644057Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011866639368236065, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:49.7645187Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:52:49.7645641Z     
2026-01-14T08:52:49.7646048Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:49.7646468Z onverted model fx: GraphModule(
2026-01-14T08:52:49.7646909Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:52:49.7647367Z )
2026-01-14T08:52:49.7647470Z 
2026-01-14T08:52:49.7647474Z 
2026-01-14T08:52:49.7647478Z 
2026-01-14T08:52:49.7647573Z def forward(self, x):
2026-01-14T08:53:08.1972075Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:53:08.1973847Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:08.1975320Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:08.1976515Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011866639368236065, -46, -128, 127, torch.int8);  conv = None
2026-01-14T08:53:08.1978321Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011866639368236065, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:08.1979565Z     return dequantize_per_tensor_default_1
2026-01-14T08:53:08.1979921Z     
2026-01-14T08:53:08.1980298Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:08.1980801Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:53:08.1981159Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:53:08.1981475Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:53:08.1981823Z model pt2e: GraphModule(
2026-01-14T08:53:08.1982129Z   (conv): Module()
2026-01-14T08:53:08.1982389Z   (bn): Module()
2026-01-14T08:53:08.1982784Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:08.1984121Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:08.1985702Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:53:08.1986403Z   )
2026-01-14T08:53:08.1986764Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:08.1988102Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:08.1989687Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.23078496754169464)
2026-01-14T08:53:08.1990404Z   )
2026-01-14T08:53:08.1990763Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:08.1992090Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-44], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:08.1993656Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9980934262275696, max_val=2.047511577606201)
2026-01-14T08:53:08.1994345Z   )
2026-01-14T08:53:08.1994573Z )
2026-01-14T08:53:08.1994699Z 
2026-01-14T08:53:08.1994705Z 
2026-01-14T08:53:08.1994709Z 
2026-01-14T08:53:08.1995070Z def forward(self, x):
2026-01-14T08:53:08.1995457Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:08.1995914Z     conv_weight = self.conv.weight
2026-01-14T08:53:08.1996264Z     conv_bias = self.conv.bias
2026-01-14T08:53:08.1996599Z     bn_weight = self.bn.weight
2026-01-14T08:53:08.1996914Z     bn_bias = self.bn.bias
2026-01-14T08:53:08.1997400Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:53:08.1997780Z     bn_running_var = self.bn.running_var
2026-01-14T08:53:08.1998210Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:08.1998783Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:08.1999582Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:08.2000296Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:53:08.2000805Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:08.2001353Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:53:08.2001922Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:08.2002581Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:53:08.2003431Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:53:08.2004278Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:53:08.2005666Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:53:08.2006900Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:08.2007615Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:53:08.2008384Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:53:08.2009128Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:53:08.2010394Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:53:08.2011732Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:53:08.2012539Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:53:08.2013052Z     
2026-01-14T08:53:08.2013416Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:08.2013905Z model fx: GraphModule(
2026-01-14T08:53:08.2014306Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:08.2015647Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:08.2017207Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:53:08.2017895Z   )
2026-01-14T08:53:08.2018125Z   (conv): ConvBn1d(
2026-01-14T08:53:08.2018438Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:53:08.2019022Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:08.2019650Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:08.2020961Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:08.2022666Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.23078496754169464)
2026-01-14T08:53:08.2023389Z     )
2026-01-14T08:53:08.2023611Z   )
2026-01-14T08:53:08.2023958Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:08.2025303Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-44], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:08.2027042Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9980934262275696, max_val=2.047511577606201)
2026-01-14T08:53:08.2027716Z   )
2026-01-14T08:53:08.2027900Z )
2026-01-14T08:53:08.2028003Z 
2026-01-14T08:53:08.2028007Z 
2026-01-14T08:53:08.2028012Z 
2026-01-14T08:53:08.2028100Z def forward(self, x):
2026-01-14T08:53:08.2028478Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:08.2029054Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:53:08.2029649Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:53:08.2030104Z     return activation_post_process_1
2026-01-14T08:53:08.2030376Z     
2026-01-14T08:53:08.2030676Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:08.2031083Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:53:08.2031372Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:53:08.2031688Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:53:08.2032042Z converted model pt2e: GraphModule(
2026-01-14T08:53:08.2032320Z   (conv): Module()
2026-01-14T08:53:08.2032538Z   (bn): Module()
2026-01-14T08:53:08.2032736Z )
2026-01-14T08:53:08.2032843Z 
2026-01-14T08:53:08.2032847Z 
2026-01-14T08:53:08.2032851Z 
2026-01-14T08:53:08.2032942Z def forward(self, x):
2026-01-14T08:53:08.2033252Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:08.2033612Z     conv_bias = self.conv.bias
2026-01-14T08:53:08.2033936Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:08.2034717Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:53:08.2036110Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:08.2037282Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:08.2037828Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:53:08.2038702Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0024561204481869936, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:53:08.2040358Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:53:08.2041706Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011943548917770386, -44, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:53:08.2043213Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011943548917770386, -44, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:53:08.2044339Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:53:08.2044790Z     
2026-01-14T08:53:08.2045085Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:08.2045495Z onverted model fx: GraphModule(
2026-01-14T08:53:32.2125875Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:53:32.2126540Z )
2026-01-14T08:53:32.2126679Z 
2026-01-14T08:53:32.2126683Z 
2026-01-14T08:53:32.2126687Z 
2026-01-14T08:53:32.2126781Z def forward(self, x):
2026-01-14T08:53:32.2127463Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:53:32.2129008Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:32.2130127Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:32.2131066Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011943548917770386, -44, -128, 127, torch.int8);  conv = None
2026-01-14T08:53:32.2132498Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011943548917770386, -44, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:32.2133482Z     return dequantize_per_tensor_default_1
2026-01-14T08:53:32.2133766Z     
2026-01-14T08:53:32.2134065Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:32.2134469Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:53:32.2134763Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:53:32.2135019Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:53:32.2135514Z [32mPASSED[0m
2026-01-14T08:53:32.2136162Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:53:32.2136853Z   (conv): Module()
2026-01-14T08:53:32.2137066Z   (bn): Module()
2026-01-14T08:53:32.2137375Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:32.2138445Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:32.2140024Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:32.2140592Z   )
2026-01-14T08:53:32.2140889Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:32.2142014Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:32.2143488Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618]), max_val=tensor([0.1970, 0.2308, 0.2775]))
2026-01-14T08:53:32.2144189Z   )
2026-01-14T08:53:32.2144477Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:32.2145531Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:32.2146764Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:53:32.2147318Z   )
2026-01-14T08:53:32.2147487Z )
2026-01-14T08:53:32.2147595Z 
2026-01-14T08:53:32.2147600Z 
2026-01-14T08:53:32.2147604Z 
2026-01-14T08:53:32.2147692Z def forward(self, x):
2026-01-14T08:53:32.2148000Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:32.2148361Z     conv_weight = self.conv.weight
2026-01-14T08:53:32.2148650Z     bn_weight = self.bn.weight
2026-01-14T08:53:32.2148908Z     bn_bias = self.bn.bias
2026-01-14T08:53:32.2149179Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:53:32.2149688Z     bn_running_var = self.bn.running_var
2026-01-14T08:53:32.2150050Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:32.2150528Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:32.2151172Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:32.2153133Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:53:32.2153554Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:32.2154004Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:53:32.2154473Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:32.2155019Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:53:32.2155640Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:53:32.2156568Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:53:32.2157481Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:32.2158061Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:53:32.2159111Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:53:32.2160191Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:53:32.2160835Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:53:32.2161258Z     
2026-01-14T08:53:32.2161555Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:32.2161955Z model fx: GraphModule(
2026-01-14T08:53:32.2162300Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:32.2163450Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:32.2164713Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:32.2165268Z   )
2026-01-14T08:53:32.2165458Z   (conv): ConvBn1d(
2026-01-14T08:53:32.2165711Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:53:32.2166192Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:32.2166715Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:32.2167829Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:32.2169311Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618]), max_val=tensor([0.1970, 0.2308, 0.2775]))
2026-01-14T08:53:32.2170014Z     )
2026-01-14T08:53:32.2170210Z   )
2026-01-14T08:53:32.2170500Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:32.2171570Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:32.2172812Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:53:32.2173358Z   )
2026-01-14T08:53:32.2173532Z )
2026-01-14T08:53:32.2173635Z 
2026-01-14T08:53:32.2173639Z 
2026-01-14T08:53:32.2173731Z 
2026-01-14T08:53:32.2173826Z def forward(self, x):
2026-01-14T08:53:32.2174199Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:32.2174775Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:53:32.2175364Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:53:32.2175912Z     return activation_post_process_1
2026-01-14T08:53:32.2176182Z     
2026-01-14T08:53:32.2176486Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:32.2176881Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:32.2177132Z          [0., 0., 0.],
2026-01-14T08:53:32.2177355Z          [0., 0., 0.]],
2026-01-14T08:53:32.2177509Z 
2026-01-14T08:53:32.2177588Z         [[0., 0., 0.],
2026-01-14T08:53:32.2177804Z          [0., 0., 0.],
2026-01-14T08:53:32.2178013Z          [0., 0., 0.]],
2026-01-14T08:53:32.2178162Z 
2026-01-14T08:53:32.2178238Z         [[0., 0., 0.],
2026-01-14T08:53:32.2178451Z          [0., 0., 0.],
2026-01-14T08:53:32.2178703Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:53:32.2179024Z converted model pt2e: GraphModule(
2026-01-14T08:53:32.2179300Z   (conv): Module()
2026-01-14T08:53:32.2179511Z   (bn): Module()
2026-01-14T08:53:32.2179706Z )
2026-01-14T08:53:32.2179805Z 
2026-01-14T08:53:32.2179815Z 
2026-01-14T08:53:32.2179819Z 
2026-01-14T08:53:32.2179911Z def forward(self, x):
2026-01-14T08:53:32.2180211Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:32.2180626Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:32.2181401Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:32.2182783Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:32.2183952Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:32.2184466Z     _scale_0 = self._scale_0
2026-01-14T08:53:32.2184750Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:53:32.2185071Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:53:32.2186062Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:53:32.2187053Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:53:32.2187975Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:53:32.2189372Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.014605328440666199, 8, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:53:50.7491148Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:50.7492670Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:53:50.7493136Z     
2026-01-14T08:53:50.7493449Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:50.7493872Z onverted model fx: GraphModule(
2026-01-14T08:53:50.7494284Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:50.7494690Z )
2026-01-14T08:53:50.7494799Z 
2026-01-14T08:53:50.7494805Z 
2026-01-14T08:53:50.7494809Z 
2026-01-14T08:53:50.7494910Z def forward(self, x):
2026-01-14T08:53:50.7495823Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:50.7497202Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:50.7498446Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:50.7499372Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014605328440666199, 8, -128, 127, torch.int8);  conv = None
2026-01-14T08:53:50.7500767Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:50.7501726Z     return dequantize_per_tensor_default_1
2026-01-14T08:53:50.7502016Z     
2026-01-14T08:53:50.7502327Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:50.7502721Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:50.7502971Z          [0., 0., 0.],
2026-01-14T08:53:50.7503187Z          [0., 0., 0.]],
2026-01-14T08:53:50.7503335Z 
2026-01-14T08:53:50.7503414Z         [[0., 0., 0.],
2026-01-14T08:53:50.7503620Z          [0., 0., 0.],
2026-01-14T08:53:50.7503838Z          [0., 0., 0.]],
2026-01-14T08:53:50.7503975Z 
2026-01-14T08:53:50.7504052Z         [[0., 0., 0.],
2026-01-14T08:53:50.7504269Z          [0., 0., 0.],
2026-01-14T08:53:50.7504484Z          [0., 0., 0.]]])
2026-01-14T08:53:50.7504715Z model pt2e: GraphModule(
2026-01-14T08:53:50.7504952Z   (conv): Module()
2026-01-14T08:53:50.7505155Z   (bn): Module()
2026-01-14T08:53:50.7505466Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:50.7506516Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:50.7507770Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:50.7508322Z   )
2026-01-14T08:53:50.7508604Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:50.7509671Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:50.7510918Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:53:50.7511478Z   )
2026-01-14T08:53:50.7511766Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:50.7512810Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:50.7514034Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:53:50.7514573Z   )
2026-01-14T08:53:50.7514750Z )
2026-01-14T08:53:50.7514850Z 
2026-01-14T08:53:50.7514855Z 
2026-01-14T08:53:50.7514859Z 
2026-01-14T08:53:50.7514956Z def forward(self, x):
2026-01-14T08:53:50.7515251Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:50.7515614Z     conv_weight = self.conv.weight
2026-01-14T08:53:50.7515892Z     bn_weight = self.bn.weight
2026-01-14T08:53:50.7516160Z     bn_bias = self.bn.bias
2026-01-14T08:53:50.7516429Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:53:50.7516755Z     bn_running_var = self.bn.running_var
2026-01-14T08:53:50.7517107Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:50.7517671Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:50.7518322Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:50.7518901Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:53:50.7519323Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:50.7519845Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:53:50.7520320Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:50.7520861Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:53:50.7521470Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:53:50.7522400Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:53:50.7523369Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:50.7523951Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:53:50.7524981Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:53:50.7526056Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:53:50.7526708Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:53:50.7527120Z     
2026-01-14T08:53:50.7527417Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:50.7527806Z model fx: GraphModule(
2026-01-14T08:53:50.7528145Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:50.7529211Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:50.7530455Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:50.7531013Z   )
2026-01-14T08:53:50.7531196Z   (conv): ConvBn1d(
2026-01-14T08:53:50.7531454Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:53:50.7531915Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:50.7532428Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:50.7533466Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:50.7534722Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:53:50.7535280Z     )
2026-01-14T08:53:50.7535452Z   )
2026-01-14T08:53:50.7535738Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:50.7536789Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:50.7538042Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:53:50.7545884Z   )
2026-01-14T08:53:50.7546081Z )
2026-01-14T08:53:50.7546183Z 
2026-01-14T08:53:50.7546188Z 
2026-01-14T08:53:50.7546192Z 
2026-01-14T08:53:50.7546282Z def forward(self, x):
2026-01-14T08:53:50.7546684Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:50.7547435Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:53:50.7548044Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:53:50.7548513Z     return activation_post_process_1
2026-01-14T08:53:50.7548789Z     
2026-01-14T08:53:50.7549099Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:50.7549609Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:50.7549868Z          [0., 0., 0.],
2026-01-14T08:53:50.7550093Z          [0., 0., 0.]],
2026-01-14T08:53:50.7550246Z 
2026-01-14T08:53:50.7550330Z         [[0., 0., 0.],
2026-01-14T08:53:50.7550557Z          [0., 0., 0.],
2026-01-14T08:53:50.7550788Z          [0., 0., 0.]],
2026-01-14T08:53:50.7550932Z 
2026-01-14T08:53:50.7551022Z         [[0., 0., 0.],
2026-01-14T08:53:50.7551239Z          [0., 0., 0.],
2026-01-14T08:53:50.7551501Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:53:50.7551828Z converted model pt2e: GraphModule(
2026-01-14T08:53:50.7552115Z   (conv): Module()
2026-01-14T08:53:50.7552336Z   (bn): Module()
2026-01-14T08:53:50.7552557Z )
2026-01-14T08:53:50.7552661Z 
2026-01-14T08:53:50.7552666Z 
2026-01-14T08:53:50.7552669Z 
2026-01-14T08:53:50.7552762Z def forward(self, x):
2026-01-14T08:53:50.7553080Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:50.7553502Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:50.7554283Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:50.7555650Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:50.7556797Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:50.7557353Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:53:50.7558212Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:53:50.7559076Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:53:50.7559990Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:53:50.7561369Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.014605328440666199, 8, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:53:53.5879281Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:53:53.5880469Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:53:53.5880924Z     
2026-01-14T08:53:53.5881233Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:53.5881638Z onverted model fx: GraphModule(
2026-01-14T08:53:53.5882036Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:53.5882442Z )
2026-01-14T08:53:53.5882618Z 
2026-01-14T08:53:53.5882622Z 
2026-01-14T08:53:53.5882626Z 
2026-01-14T08:53:53.5882718Z def forward(self, x):
2026-01-14T08:53:53.5883400Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:53.5884765Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:53.5886116Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:53.5887055Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014605328440666199, 8, -128, 127, torch.int8);  conv = None
2026-01-14T08:53:53.5888454Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:53.5889570Z     return dequantize_per_tensor_default_1
2026-01-14T08:53:53.5889855Z     
2026-01-14T08:53:53.5890151Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:53.5890548Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:53.5890788Z          [0., 0., 0.],
2026-01-14T08:53:53.5891013Z          [0., 0., 0.]],
2026-01-14T08:53:53.5891154Z 
2026-01-14T08:53:53.5891234Z         [[0., 0., 0.],
2026-01-14T08:53:53.5891447Z          [0., 0., 0.],
2026-01-14T08:53:53.5891659Z          [0., 0., 0.]],
2026-01-14T08:53:53.5891810Z 
2026-01-14T08:53:53.5891885Z         [[0., 0., 0.],
2026-01-14T08:53:53.5892096Z          [0., 0., 0.],
2026-01-14T08:53:53.5892315Z          [0., 0., 0.]]])
2026-01-14T08:53:53.5892550Z model pt2e: GraphModule(
2026-01-14T08:53:53.5892791Z   (conv1): Module()
2026-01-14T08:53:53.5893004Z   (bn1): Module()
2026-01-14T08:53:53.5893210Z   (conv2): Module()
2026-01-14T08:53:53.5893425Z   (bn2): Module()
2026-01-14T08:53:53.5893736Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:53.5894795Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:53.5896110Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:53.5896656Z   )
2026-01-14T08:53:53.5896956Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:53.5898070Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:53.5899538Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2878, -0.2584, -0.3162]), max_val=tensor([0.2745, 0.3315, 0.3105]))
2026-01-14T08:53:53.5900238Z   )
2026-01-14T08:53:53.5900521Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:53.5901637Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:53.5903095Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3233, -0.3086, -0.2979]), max_val=tensor([0.3026, 0.1712, 0.2405]))
2026-01-14T08:53:53.5903787Z   )
2026-01-14T08:53:53.5904081Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:53.5905127Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:53.5906370Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.805302619934082, max_val=2.310788631439209)
2026-01-14T08:53:53.5906909Z   )
2026-01-14T08:53:53.5907196Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:53.5908253Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:53.5909624Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1982380151748657, max_val=1.4133442640304565)
2026-01-14T08:53:53.5910179Z   )
2026-01-14T08:53:53.5910348Z )
2026-01-14T08:53:53.5910458Z 
2026-01-14T08:53:53.5910463Z 
2026-01-14T08:53:53.5910467Z 
2026-01-14T08:53:53.5910554Z def forward(self, x):
2026-01-14T08:53:53.5910938Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:53.5911301Z     conv1_weight = self.conv1.weight
2026-01-14T08:53:53.5911606Z     bn1_weight = self.bn1.weight
2026-01-14T08:53:53.5911876Z     bn1_bias = self.bn1.bias
2026-01-14T08:53:53.5912147Z     conv2_weight = self.conv2.weight
2026-01-14T08:53:53.5912431Z     conv2_bias = self.conv2.bias
2026-01-14T08:53:53.5912705Z     bn2_weight = self.bn2.weight
2026-01-14T08:53:53.5912968Z     bn2_bias = self.bn2.bias
2026-01-14T08:53:53.5913256Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:53:53.5913582Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:53:53.5913947Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:53:53.5914320Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:53:53.5914635Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:53:53.5914994Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:53:53.5915464Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:53.5916126Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:53:53.5916877Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:53:53.5917481Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:53:53.5917906Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:53.5918355Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:53:53.5918825Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:53.5919370Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:53:53.5919987Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:53:53.5920660Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:53:53.5921272Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:53:53.5921707Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:53:53.5922181Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:53:53.5922720Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T08:53:53.5923292Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:53:53.5923935Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:53:53.5924859Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:53:53.5925776Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T08:53:53.5926355Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T08:53:53.5927420Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:53:53.5928550Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:53:53.5929609Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:53:53.5930663Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:53.5931238Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T08:53:53.5931859Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T08:53:53.5932543Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:53:53.5933564Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:53:53.5934661Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:53:53.5935301Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:53:53.5935706Z     
2026-01-14T08:53:53.5936014Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:53.5936404Z model fx: GraphModule(
2026-01-14T08:53:53.5936743Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:53.5937789Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:53.5939263Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:53.5939817Z   )
2026-01-14T08:53:53.5939996Z   (conv1): ConvBn1d(
2026-01-14T08:53:53.5940260Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:53:53.5940713Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:53.5941221Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2350116Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:54:12.2352143Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3233, -0.3086, -0.2979]), max_val=tensor([0.3026, 0.1712, 0.2405]))
2026-01-14T08:54:12.2353069Z     )
2026-01-14T08:54:12.2353298Z   )
2026-01-14T08:54:12.2353666Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2355004Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.2356573Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.805302619934082, max_val=2.310788631439209)
2026-01-14T08:54:12.2357267Z   )
2026-01-14T08:54:12.2357506Z   (conv2): ConvBn1d(
2026-01-14T08:54:12.2357808Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:54:12.2358343Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:54:12.2358993Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2360362Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:54:12.2362225Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2878, -0.2584, -0.3162]), max_val=tensor([0.2745, 0.3315, 0.3105]))
2026-01-14T08:54:12.2363216Z     )
2026-01-14T08:54:12.2363440Z   )
2026-01-14T08:54:12.2363823Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2365458Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.2367064Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1982380151748657, max_val=1.4133442640304565)
2026-01-14T08:54:12.2367919Z   )
2026-01-14T08:54:12.2368136Z )
2026-01-14T08:54:12.2368266Z 
2026-01-14T08:54:12.2368271Z 
2026-01-14T08:54:12.2368276Z 
2026-01-14T08:54:12.2368384Z def forward(self, x):
2026-01-14T08:54:12.2368838Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:12.2369548Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:54:12.2370296Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:54:12.2371032Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:54:12.2371786Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:54:12.2372376Z     return activation_post_process_2
2026-01-14T08:54:12.2372700Z     
2026-01-14T08:54:12.2373062Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:12.2373531Z diff: tensor([[[0.],
2026-01-14T08:54:12.2373808Z          [0.],
2026-01-14T08:54:12.2374043Z          [0.]],
2026-01-14T08:54:12.2374198Z 
2026-01-14T08:54:12.2374291Z         [[0.],
2026-01-14T08:54:12.2374523Z          [0.],
2026-01-14T08:54:12.2374760Z          [0.]],
2026-01-14T08:54:12.2374906Z 
2026-01-14T08:54:12.2375023Z         [[0.],
2026-01-14T08:54:12.2375251Z          [0.],
2026-01-14T08:54:12.2375518Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:54:12.2375886Z converted model pt2e: GraphModule(
2026-01-14T08:54:12.2376225Z   (conv1): Module()
2026-01-14T08:54:12.2376479Z   (bn1): Module()
2026-01-14T08:54:12.2376732Z   (conv2): Module()
2026-01-14T08:54:12.2376980Z   (bn2): Module()
2026-01-14T08:54:12.2377233Z )
2026-01-14T08:54:12.2377356Z 
2026-01-14T08:54:12.2377361Z 
2026-01-14T08:54:12.2377365Z 
2026-01-14T08:54:12.2377477Z def forward(self, x):
2026-01-14T08:54:12.2377845Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:12.2378291Z     conv2_bias = self.conv2.bias
2026-01-14T08:54:12.2378691Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:54:12.2379200Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:54:12.2380164Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:54:12.2381945Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:12.2383314Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:54:12.2384052Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:54:12.2384573Z     _scale_0 = self._scale_0
2026-01-14T08:54:12.2384836Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:54:12.2385119Z     _scale_1 = self._scale_1
2026-01-14T08:54:12.2385376Z     _zero_point_1 = self._zero_point_1
2026-01-14T08:54:12.2385692Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T08:54:12.2386685Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T08:54:12.2387675Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:54:12.2388710Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T08:54:12.2390113Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.016141533851623535, -16, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T08:54:12.2391542Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016141533851623535, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:12.2392608Z     quantize_per_channel = self._frozen_param1
2026-01-14T08:54:12.2393568Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:54:12.2395137Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T08:54:12.2396490Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.010241499170660973, -11, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T08:54:12.2397926Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010241499170660973, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:54:12.2399050Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:54:12.2399492Z     
2026-01-14T08:54:12.2399782Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:12.2400187Z onverted model fx: GraphModule(
2026-01-14T08:54:12.2400573Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:12.2401099Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:12.2401484Z )
2026-01-14T08:54:12.2401594Z 
2026-01-14T08:54:12.2401599Z 
2026-01-14T08:54:12.2401603Z 
2026-01-14T08:54:12.2401692Z def forward(self, x):
2026-01-14T08:54:12.2402358Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:54:12.2403828Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:12.2404956Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:54:12.2405905Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.016141533851623535, -16, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:54:12.2407336Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016141533851623535, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:12.2408487Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:54:12.2409440Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.010241499170660973, -11, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:54:12.2410869Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010241499170660973, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:54:12.2411852Z     return dequantize_per_tensor_default_2
2026-01-14T08:54:12.2412132Z     
2026-01-14T08:54:12.2412427Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:12.2412817Z diff: tensor([[[0.],
2026-01-14T08:54:12.2413042Z          [0.],
2026-01-14T08:54:12.2413230Z          [0.]],
2026-01-14T08:54:12.2413448Z 
2026-01-14T08:54:12.2413525Z         [[0.],
2026-01-14T08:54:12.2413718Z          [0.],
2026-01-14T08:54:12.2413903Z          [0.]],
2026-01-14T08:54:12.2414023Z 
2026-01-14T08:54:12.2414107Z         [[0.],
2026-01-14T08:54:12.2414292Z          [0.],
2026-01-14T08:54:12.2414487Z          [0.]]])
2026-01-14T08:54:12.2414699Z model pt2e: GraphModule(
2026-01-14T08:54:12.2415023Z   (conv1): Module()
2026-01-14T08:54:12.2415227Z   (bn1): Module()
2026-01-14T08:54:12.2415441Z   (conv2): Module()
2026-01-14T08:54:12.2415643Z   (bn2): Module()
2026-01-14T08:54:12.2415959Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2417020Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.2418272Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:54:12.2418834Z   )
2026-01-14T08:54:12.2419122Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2420206Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:54:12.2421470Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3161814510822296, max_val=0.33154603838920593)
2026-01-14T08:54:12.2422032Z   )
2026-01-14T08:54:12.2422315Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2423373Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:54:12.2424615Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232710361480713, max_val=0.30256387591362)
2026-01-14T08:54:12.2425161Z   )
2026-01-14T08:54:12.2425448Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2426504Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.2427753Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.807204008102417, max_val=2.3096539974212646)
2026-01-14T08:54:12.2428295Z   )
2026-01-14T08:54:12.2428581Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2429633Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.2430881Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2001533508300781, max_val=1.4126498699188232)
2026-01-14T08:54:12.2431431Z   )
2026-01-14T08:54:12.2431603Z )
2026-01-14T08:54:12.2431707Z 
2026-01-14T08:54:12.2431712Z 
2026-01-14T08:54:12.2431716Z 
2026-01-14T08:54:12.2431801Z def forward(self, x):
2026-01-14T08:54:12.2432100Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:12.2432468Z     conv1_weight = self.conv1.weight
2026-01-14T08:54:12.2432765Z     bn1_weight = self.bn1.weight
2026-01-14T08:54:12.2433031Z     bn1_bias = self.bn1.bias
2026-01-14T08:54:12.2433294Z     conv2_weight = self.conv2.weight
2026-01-14T08:54:12.2433579Z     conv2_bias = self.conv2.bias
2026-01-14T08:54:12.2433848Z     bn2_weight = self.bn2.weight
2026-01-14T08:54:12.2434111Z     bn2_bias = self.bn2.bias
2026-01-14T08:54:12.2434392Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:54:12.2434707Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:54:12.2435153Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:54:12.2435521Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:54:12.2435842Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:54:12.2436206Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:54:12.2436677Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:12.2437442Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:54:12.2438185Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:54:12.2438789Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:54:12.2439565Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:54:12.2440020Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:54:12.2440517Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:54:12.2441075Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:54:12.2441709Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:54:12.2442386Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:54:12.2443073Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:54:12.2443524Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:54:12.2443998Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:54:12.2444501Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T08:54:12.2445079Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:54:12.2445735Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:54:12.2446674Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:54:12.2447597Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T08:54:12.2448187Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T08:54:12.2449258Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:54:12.2450370Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:54:12.2451438Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:54:12.2452414Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:54:12.2452998Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T08:54:12.2453632Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T08:54:12.2454246Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:54:12.2455289Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:54:12.2456387Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:54:12.2457034Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:54:12.2457445Z     
2026-01-14T08:54:12.2457895Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:12.2458294Z model fx: GraphModule(
2026-01-14T08:54:12.2458639Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2459708Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.2461082Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:54:12.2461648Z   )
2026-01-14T08:54:12.2461827Z   (conv1): ConvBn1d(
2026-01-14T08:54:12.2462093Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:54:12.2462564Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:54:12.2463078Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2464128Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:54:12.2465374Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232710361480713, max_val=0.30256387591362)
2026-01-14T08:54:12.2465934Z     )
2026-01-14T08:54:12.2466112Z   )
2026-01-14T08:54:12.2466401Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2467469Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.2468717Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.807204008102417, max_val=2.3096539974212646)
2026-01-14T08:54:12.2469272Z   )
2026-01-14T08:54:12.2469452Z   (conv2): ConvBn1d(
2026-01-14T08:54:12.2469710Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:54:12.2470153Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:54:12.2470674Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2471718Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:54:12.2472989Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3161814510822296, max_val=0.33154603838920593)
2026-01-14T08:54:12.2473561Z     )
2026-01-14T08:54:12.2473736Z   )
2026-01-14T08:54:12.2474028Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.2475102Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.2476349Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2001533508300781, max_val=1.4126498699188232)
2026-01-14T08:54:12.2476914Z   )
2026-01-14T08:54:12.2477089Z )
2026-01-14T08:54:12.2477201Z 
2026-01-14T08:54:12.2477206Z 
2026-01-14T08:54:12.2477210Z 
2026-01-14T08:54:12.2477303Z def forward(self, x):
2026-01-14T08:54:12.2477675Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:12.2478254Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:54:12.2478861Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:54:12.2479460Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:54:12.2480075Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:54:12.2480635Z     return activation_post_process_2
2026-01-14T08:54:12.2480909Z     
2026-01-14T08:54:12.2481215Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:12.2481603Z diff: tensor([[[0.],
2026-01-14T08:54:12.2481834Z          [0.],
2026-01-14T08:54:12.2482029Z          [0.]],
2026-01-14T08:54:12.2482164Z 
2026-01-14T08:54:51.7980538Z         [[0.],
2026-01-14T08:54:51.7981130Z          [0.],
2026-01-14T08:54:51.7981409Z          [0.]],
2026-01-14T08:54:51.7989712Z 
2026-01-14T08:54:51.7989836Z         [[0.],
2026-01-14T08:54:51.7990101Z          [0.],
2026-01-14T08:54:51.7990374Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:54:51.7990765Z converted model pt2e: GraphModule(
2026-01-14T08:54:51.7991101Z   (conv1): Module()
2026-01-14T08:54:51.7991367Z   (bn1): Module()
2026-01-14T08:54:51.7991622Z   (conv2): Module()
2026-01-14T08:54:51.7991886Z   (bn2): Module()
2026-01-14T08:54:51.7992143Z )
2026-01-14T08:54:51.7992267Z 
2026-01-14T08:54:51.7992272Z 
2026-01-14T08:54:51.7992277Z 
2026-01-14T08:54:51.7992399Z def forward(self, x):
2026-01-14T08:54:51.7992779Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:51.7993225Z     conv2_bias = self.conv2.bias
2026-01-14T08:54:51.7993647Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:54:51.7994152Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:54:51.7995143Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:54:51.7996886Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:51.7998346Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:54:51.7999305Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:54:51.8000004Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T08:54:51.8001138Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.0025454412680119276, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T08:54:51.8002279Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:54:51.8003548Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T08:54:51.8005336Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.016144542023539543, -16, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T08:54:51.8007183Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.016144542023539543, -16, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:54:51.8008419Z     quantize_per_tensor = self._frozen_param1
2026-01-14T08:54:51.8009511Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0026105986908078194, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:54:51.8011305Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T08:54:51.8012999Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.01024628710001707, -11, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T08:54:51.8015033Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.01024628710001707, -11, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T08:54:51.8016435Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T08:54:51.8017038Z     
2026-01-14T08:54:51.8017426Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:51.8017950Z onverted model fx: GraphModule(
2026-01-14T08:54:51.8018355Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:51.8018981Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:51.8019388Z )
2026-01-14T08:54:51.8019490Z 
2026-01-14T08:54:51.8019495Z 
2026-01-14T08:54:51.8019499Z 
2026-01-14T08:54:51.8019596Z def forward(self, x):
2026-01-14T08:54:51.8020257Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:54:51.8021636Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:51.8022754Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:54:51.8023712Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.016144542023539543, -16, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:54:51.8025143Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016144542023539543, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:51.8026287Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:54:51.8027244Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.01024628710001707, -11, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:54:51.8028667Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01024628710001707, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:54:51.8029637Z     return dequantize_per_tensor_default_2
2026-01-14T08:54:51.8029928Z     
2026-01-14T08:54:51.8030226Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:51.8030625Z diff: tensor([[[0.],
2026-01-14T08:54:51.8030840Z          [0.],
2026-01-14T08:54:51.8031045Z          [0.]],
2026-01-14T08:54:51.8031169Z 
2026-01-14T08:54:51.8031250Z         [[0.],
2026-01-14T08:54:51.8031452Z          [0.],
2026-01-14T08:54:51.8031650Z          [0.]],
2026-01-14T08:54:51.8031772Z 
2026-01-14T08:54:51.8031849Z         [[0.],
2026-01-14T08:54:51.8032049Z          [0.],
2026-01-14T08:54:51.8032240Z          [0.]]])
2026-01-14T08:54:51.8032665Z [32mPASSED[0m
2026-01-14T08:54:51.8033407Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T08:54:51.8034468Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T08:54:51.8035136Z   (conv): Module()
2026-01-14T08:54:51.8035347Z   (bn): Module()
2026-01-14T08:54:51.8035670Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:51.8036737Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:51.8037988Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:54:51.8038541Z   )
2026-01-14T08:54:51.8038844Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:51.8040387Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:54:51.8041870Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2845, -0.3289, -0.3229]), max_val=tensor([0.2989, 0.2870, 0.2939]))
2026-01-14T08:54:51.8042734Z   )
2026-01-14T08:54:51.8043024Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:51.8044095Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:51.8045289Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:54:51.8045792Z   )
2026-01-14T08:54:51.8045974Z )
2026-01-14T08:54:51.8046075Z 
2026-01-14T08:54:51.8046085Z 
2026-01-14T08:54:51.8046089Z 
2026-01-14T08:54:51.8046180Z def forward(self, x):
2026-01-14T08:54:51.8046492Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:51.8046868Z     conv_weight = self.conv.weight
2026-01-14T08:54:51.8047157Z     conv_bias = self.conv.bias
2026-01-14T08:54:51.8047432Z     bn_weight = self.bn.weight
2026-01-14T08:54:51.8047703Z     bn_bias = self.bn.bias
2026-01-14T08:54:51.8047978Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:54:51.8048295Z     bn_running_var = self.bn.running_var
2026-01-14T08:54:51.8048661Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:51.8049132Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:51.8049778Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:51.8050365Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:54:51.8050790Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:54:51.8051240Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:54:51.8051714Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:54:51.8052258Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:54:51.8052869Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:54:51.8053549Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:54:51.8054639Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:54:51.8055612Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:54:51.8056208Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:54:51.8056835Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:54:51.8057445Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:54:51.8058448Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:55:10.5486022Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:55:10.5486898Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:55:10.5487550Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:10.5487988Z     
2026-01-14T08:55:10.5488299Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:10.5488689Z model fx: GraphModule(
2026-01-14T08:55:10.5489370Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:10.5490488Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:10.5491741Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:10.5492460Z   )
2026-01-14T08:55:10.5492656Z   (conv): ConvBnReLU1d(
2026-01-14T08:55:10.5492926Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:55:10.5493365Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:55:10.5493887Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:10.5495195Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:55:10.5496920Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2845, -0.3289, -0.3229]), max_val=tensor([0.2989, 0.2870, 0.2939]))
2026-01-14T08:55:10.5497630Z     )
2026-01-14T08:55:10.5497811Z   )
2026-01-14T08:55:10.5498114Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:10.5499180Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:10.5500370Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:55:10.5500874Z   )
2026-01-14T08:55:10.5501057Z )
2026-01-14T08:55:10.5501161Z 
2026-01-14T08:55:10.5501173Z 
2026-01-14T08:55:10.5501177Z 
2026-01-14T08:55:10.5501276Z def forward(self, x):
2026-01-14T08:55:10.5501647Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:10.5502223Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:55:10.5502819Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:55:10.5503275Z     return activation_post_process_1
2026-01-14T08:55:10.5503555Z     
2026-01-14T08:55:10.5503854Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:10.5504257Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:10.5504503Z          [0., 0., 0.],
2026-01-14T08:55:10.5504768Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:55:10.5505088Z converted model pt2e: GraphModule(
2026-01-14T08:55:10.5505365Z   (conv): Module()
2026-01-14T08:55:10.5505579Z   (bn): Module()
2026-01-14T08:55:10.5505782Z )
2026-01-14T08:55:10.5505884Z 
2026-01-14T08:55:10.5505888Z 
2026-01-14T08:55:10.5505893Z 
2026-01-14T08:55:10.5505998Z def forward(self, x):
2026-01-14T08:55:10.5506304Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:10.5506666Z     conv_bias = self.conv.bias
2026-01-14T08:55:10.5506982Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:10.5507757Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:10.5509121Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:10.5510263Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:10.5510776Z     _scale_0 = self._scale_0
2026-01-14T08:55:10.5511039Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:55:10.5511363Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:55:10.5512441Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:55:10.5513940Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:55:10.5514954Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:55:10.5515793Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005544713232666254, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:55:10.5517217Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:10.5518334Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:55:10.5518770Z     
2026-01-14T08:55:10.5519074Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:10.5519475Z onverted model fx: GraphModule(
2026-01-14T08:55:10.5519751Z   (conv): ConvReLU1d(
2026-01-14T08:55:10.5520095Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:55:10.5520481Z     (1): ReLU()
2026-01-14T08:55:10.5520683Z   )
2026-01-14T08:55:10.5520860Z )
2026-01-14T08:55:10.5520960Z 
2026-01-14T08:55:10.5520964Z 
2026-01-14T08:55:10.5520968Z 
2026-01-14T08:55:10.5521064Z def forward(self, x):
2026-01-14T08:55:10.5521718Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:10.5523178Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:10.5524288Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:10.5525228Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005544713232666254, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:10.5526659Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:10.5527640Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:10.5527922Z     
2026-01-14T08:55:10.5528223Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:10.5528616Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:10.5528863Z          [0., 0., 0.],
2026-01-14T08:55:10.5529079Z          [0., 0., 0.]]])
2026-01-14T08:55:10.5529328Z model pt2e: GraphModule(
2026-01-14T08:55:10.5529564Z   (conv): Module()
2026-01-14T08:55:10.5529777Z   (bn): Module()
2026-01-14T08:55:10.5530087Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:10.5531187Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:10.5532424Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:10.5532968Z   )
2026-01-14T08:55:10.5533263Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:10.5534406Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:10.5535665Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3289433717727661, max_val=0.29890719056129456)
2026-01-14T08:55:10.5536224Z   )
2026-01-14T08:55:10.5536512Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:10.5537570Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:10.5538832Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:55:10.5539560Z   )
2026-01-14T08:55:10.5539751Z )
2026-01-14T08:55:10.5539852Z 
2026-01-14T08:55:10.5539857Z 
2026-01-14T08:55:10.5539861Z 
2026-01-14T08:55:10.5539958Z def forward(self, x):
2026-01-14T08:55:10.5540261Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:10.5540636Z     conv_weight = self.conv.weight
2026-01-14T08:55:10.5540927Z     conv_bias = self.conv.bias
2026-01-14T08:55:10.5541200Z     bn_weight = self.bn.weight
2026-01-14T08:55:10.5541458Z     bn_bias = self.bn.bias
2026-01-14T08:55:10.5541730Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:55:10.5542041Z     bn_running_var = self.bn.running_var
2026-01-14T08:55:10.5542401Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:10.5542868Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:10.5543518Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:10.5544111Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:55:10.5544528Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:55:10.5544973Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:55:10.5545444Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:55:10.5545987Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:55:10.5546600Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:55:10.5547266Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:55:10.5548355Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:55:10.5549327Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:55:10.5549910Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:55:10.5550547Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:55:34.8208488Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:55:34.8209738Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:55:34.8211146Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:55:34.8211944Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:55:34.8212538Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:34.8212956Z     
2026-01-14T08:55:34.8213259Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:34.8213816Z model fx: GraphModule(
2026-01-14T08:55:34.8214278Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:34.8215745Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:34.8217014Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:34.8217563Z   )
2026-01-14T08:55:34.8217768Z   (conv): ConvBnReLU1d(
2026-01-14T08:55:34.8218024Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:55:34.8218603Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:55:34.8219123Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:34.8220167Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:34.8221478Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3289433717727661, max_val=0.29890719056129456)
2026-01-14T08:55:34.8222065Z     )
2026-01-14T08:55:34.8222249Z   )
2026-01-14T08:55:34.8222552Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:34.8223627Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:34.8224840Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:55:34.8225356Z   )
2026-01-14T08:55:34.8225541Z )
2026-01-14T08:55:34.8225647Z 
2026-01-14T08:55:34.8225652Z 
2026-01-14T08:55:34.8225661Z 
2026-01-14T08:55:34.8225755Z def forward(self, x):
2026-01-14T08:55:34.8226132Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:34.8226716Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:55:34.8227314Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:55:34.8227785Z     return activation_post_process_1
2026-01-14T08:55:34.8228073Z     
2026-01-14T08:55:34.8228371Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:34.8228775Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:34.8229027Z          [0., 0., 0.],
2026-01-14T08:55:34.8229290Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:55:34.8229620Z converted model pt2e: GraphModule(
2026-01-14T08:55:34.8229904Z   (conv): Module()
2026-01-14T08:55:34.8230123Z   (bn): Module()
2026-01-14T08:55:34.8230347Z )
2026-01-14T08:55:34.8230453Z 
2026-01-14T08:55:34.8230457Z 
2026-01-14T08:55:34.8230461Z 
2026-01-14T08:55:34.8230561Z def forward(self, x):
2026-01-14T08:55:34.8230867Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:34.8231237Z     conv_bias = self.conv.bias
2026-01-14T08:55:34.8231556Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:34.8232350Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:34.8233733Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:34.8234897Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:34.8235449Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:55:34.8236322Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002590105403214693, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:55:34.8237810Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:55:34.8238817Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:55:34.8239967Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005544713232666254, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:55:34.8241411Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:55:34.8242760Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:55:34.8243210Z     
2026-01-14T08:55:34.8243593Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:34.8244061Z onverted model fx: GraphModule(
2026-01-14T08:55:34.8244338Z   (conv): ConvReLU1d(
2026-01-14T08:55:34.8244693Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:55:34.8245100Z     (1): ReLU()
2026-01-14T08:55:34.8245302Z   )
2026-01-14T08:55:34.8245489Z )
2026-01-14T08:55:34.8245593Z 
2026-01-14T08:55:34.8245598Z 
2026-01-14T08:55:34.8245602Z 
2026-01-14T08:55:34.8245702Z def forward(self, x):
2026-01-14T08:55:34.8246368Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:34.8247742Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:34.8248856Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:34.8249813Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005544713232666254, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:34.8251253Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:34.8252236Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:34.8252538Z     
2026-01-14T08:55:34.8252838Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:34.8253246Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:34.8253506Z          [0., 0., 0.],
2026-01-14T08:55:34.8253728Z          [0., 0., 0.]]])
2026-01-14T08:55:34.8254192Z [32mPASSED[0m
2026-01-14T08:55:34.8254831Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_cuda model pt2e: GraphModule(
2026-01-14T08:55:34.8255524Z   (conv): Module()
2026-01-14T08:55:34.8255737Z   (bn): Module()
2026-01-14T08:55:34.8256058Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:34.8257352Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:34.8258821Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:34.8259386Z   )
2026-01-14T08:55:34.8259684Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:34.8261043Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:55:34.8262978Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:55:34.8263800Z   )
2026-01-14T08:55:34.8264095Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:34.8265387Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:34.8266892Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T08:55:34.8267405Z   )
2026-01-14T08:55:34.8267586Z )
2026-01-14T08:55:34.8267706Z 
2026-01-14T08:55:34.8267712Z 
2026-01-14T08:55:34.8267717Z 
2026-01-14T08:55:34.8267822Z def forward(self, x):
2026-01-14T08:55:34.8268150Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:34.8268532Z     conv_weight = self.conv.weight
2026-01-14T08:55:34.8268833Z     conv_bias = self.conv.bias
2026-01-14T08:55:34.8269096Z     bn_weight = self.bn.weight
2026-01-14T08:55:34.8269362Z     bn_bias = self.bn.bias
2026-01-14T08:55:34.8269629Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:55:34.8269954Z     bn_running_var = self.bn.running_var
2026-01-14T08:55:34.8270316Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:34.8270793Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:34.8271438Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:34.8272030Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:55:34.8272457Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:55:34.8272896Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:55:34.8273374Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:55:34.8273923Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:55:34.8274549Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:55:53.6784645Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:55:53.6786028Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:55:53.6787018Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:55:53.6787612Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:55:53.6788240Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:55:53.6788878Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:55:53.6789891Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:55:53.6790876Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:55:53.6791452Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:55:53.6792049Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:53.6792472Z     
2026-01-14T08:55:53.6792791Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:53.6793200Z model fx: GraphModule(
2026-01-14T08:55:53.6793549Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:53.6795099Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:53.6796611Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:53.6797179Z   )
2026-01-14T08:55:53.6797509Z   (conv): ConvBnReLU1d(
2026-01-14T08:55:53.6797766Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:55:53.6798216Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:55:53.6798745Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:53.6800075Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:55:53.6801894Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:55:53.6802807Z     )
2026-01-14T08:55:53.6802996Z   )
2026-01-14T08:55:53.6803286Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:53.6804586Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:53.6806005Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T08:55:53.6806508Z   )
2026-01-14T08:55:53.6806694Z )
2026-01-14T08:55:53.6806797Z 
2026-01-14T08:55:53.6806802Z 
2026-01-14T08:55:53.6806805Z 
2026-01-14T08:55:53.6806902Z def forward(self, x):
2026-01-14T08:55:53.6807282Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:53.6807862Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:55:53.6808454Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:55:53.6808927Z     return activation_post_process_1
2026-01-14T08:55:53.6809198Z     
2026-01-14T08:55:53.6809498Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:53.6809892Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:53.6810143Z          [0., 0., 0.],
2026-01-14T08:55:53.6810434Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:55:53.6810807Z converted model pt2e: GraphModule(
2026-01-14T08:55:53.6811088Z   (conv): Module()
2026-01-14T08:55:53.6818224Z   (bn): Module()
2026-01-14T08:55:53.6818469Z )
2026-01-14T08:55:53.6818568Z 
2026-01-14T08:55:53.6818573Z 
2026-01-14T08:55:53.6818577Z 
2026-01-14T08:55:53.6818673Z def forward(self, x):
2026-01-14T08:55:53.6818990Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:53.6819343Z     conv_bias = self.conv.bias
2026-01-14T08:55:53.6819666Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:53.6820442Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:53.6821803Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:53.6822957Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:53.6823467Z     _scale_0 = self._scale_0
2026-01-14T08:55:53.6823745Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:55:53.6824176Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:55:53.6825149Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:55:53.6826664Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:55:53.6827678Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:55:53.6828530Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005538490135222673, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:55:53.6829967Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:53.6831080Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:55:53.6831523Z     
2026-01-14T08:55:53.6831818Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:53.6832229Z onverted model fx: GraphModule(
2026-01-14T08:55:53.6832500Z   (conv): ConvReLU1d(
2026-01-14T08:55:53.6832843Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:55:53.6833232Z     (1): ReLU()
2026-01-14T08:55:53.6833427Z   )
2026-01-14T08:55:53.6833600Z )
2026-01-14T08:55:53.6833698Z 
2026-01-14T08:55:53.6833702Z 
2026-01-14T08:55:53.6833706Z 
2026-01-14T08:55:53.6833793Z def forward(self, x):
2026-01-14T08:55:53.6834466Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:53.6835836Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:53.6836935Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:53.6837874Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005538490135222673, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:53.6839557Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:53.6840541Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:53.6840827Z     
2026-01-14T08:55:53.6841121Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:53.6841524Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:53.6841761Z          [0., 0., 0.],
2026-01-14T08:55:53.6842005Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:55:53.6842287Z model pt2e: GraphModule(
2026-01-14T08:55:53.6842532Z   (conv): Module()
2026-01-14T08:55:53.6842784Z   (bn): Module()
2026-01-14T08:55:53.6843096Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:53.6844426Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:53.6845882Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:53.6846433Z   )
2026-01-14T08:55:53.6846717Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:53.6848135Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:53.6849609Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:55:53.6850262Z   )
2026-01-14T08:55:53.6850551Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:53.6851830Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:53.6853226Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T08:55:53.6853728Z   )
2026-01-14T08:55:53.6853894Z )
2026-01-14T08:55:53.6854002Z 
2026-01-14T08:55:53.6854012Z 
2026-01-14T08:55:53.6854016Z 
2026-01-14T08:55:53.6854103Z def forward(self, x):
2026-01-14T08:55:53.6854406Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:53.6854761Z     conv_weight = self.conv.weight
2026-01-14T08:55:53.6855048Z     conv_bias = self.conv.bias
2026-01-14T08:55:53.6855305Z     bn_weight = self.bn.weight
2026-01-14T08:55:53.6855572Z     bn_bias = self.bn.bias
2026-01-14T08:56:17.9872466Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:56:17.9875141Z     bn_running_var = self.bn.running_var
2026-01-14T08:56:17.9875875Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:17.9876570Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:17.9877358Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:17.9877952Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:56:17.9878396Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:56:17.9878854Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:56:17.9879331Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:56:17.9879884Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:56:17.9880549Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:56:17.9881487Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:56:17.9882934Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:56:17.9883928Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:56:17.9884608Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:56:17.9885354Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:56:17.9885960Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:56:17.9886972Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:56:17.9887964Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:56:17.9888550Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:17.9889153Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:17.9889577Z     
2026-01-14T08:56:17.9889893Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:17.9890292Z model fx: GraphModule(
2026-01-14T08:56:17.9890887Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:17.9892209Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:17.9893886Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:17.9894459Z   )
2026-01-14T08:56:17.9894659Z   (conv): ConvBnReLU1d(
2026-01-14T08:56:17.9894930Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:56:17.9895386Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:56:17.9895912Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:17.9897244Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:17.9898768Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:56:17.9899350Z     )
2026-01-14T08:56:17.9899544Z   )
2026-01-14T08:56:17.9899840Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:17.9901165Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:17.9902613Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T08:56:17.9903129Z   )
2026-01-14T08:56:17.9903308Z )
2026-01-14T08:56:17.9903414Z 
2026-01-14T08:56:17.9903418Z 
2026-01-14T08:56:17.9903422Z 
2026-01-14T08:56:17.9903513Z def forward(self, x):
2026-01-14T08:56:17.9903968Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:17.9904593Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:17.9905191Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:17.9905648Z     return activation_post_process_1
2026-01-14T08:56:17.9905920Z     
2026-01-14T08:56:17.9906212Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:17.9906625Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:17.9906871Z          [0., 0., 0.],
2026-01-14T08:56:17.9907166Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:56:17.9907537Z converted model pt2e: GraphModule(
2026-01-14T08:56:17.9907808Z   (conv): Module()
2026-01-14T08:56:17.9908026Z   (bn): Module()
2026-01-14T08:56:17.9908222Z )
2026-01-14T08:56:17.9908321Z 
2026-01-14T08:56:17.9908326Z 
2026-01-14T08:56:17.9908337Z 
2026-01-14T08:56:17.9908424Z def forward(self, x):
2026-01-14T08:56:17.9908722Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:17.9909097Z     conv_bias = self.conv.bias
2026-01-14T08:56:17.9909415Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:17.9910186Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:17.9911550Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:17.9912698Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:17.9913396Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:56:17.9914268Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:56:17.9915654Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:56:17.9916675Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:56:17.9917525Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005538490135222673, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:17.9918956Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:56:17.9920086Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:56:17.9920524Z     
2026-01-14T08:56:17.9920824Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:17.9921229Z onverted model fx: GraphModule(
2026-01-14T08:56:17.9921502Z   (conv): ConvReLU1d(
2026-01-14T08:56:17.9921849Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:56:17.9922237Z     (1): ReLU()
2026-01-14T08:56:17.9922436Z   )
2026-01-14T08:56:17.9922608Z )
2026-01-14T08:56:17.9922790Z 
2026-01-14T08:56:17.9922794Z 
2026-01-14T08:56:17.9922799Z 
2026-01-14T08:56:17.9922898Z def forward(self, x):
2026-01-14T08:56:17.9923563Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:17.9924936Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:17.9926054Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:17.9926999Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005538490135222673, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:17.9928434Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:17.9929427Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:17.9929717Z     
2026-01-14T08:56:17.9930058Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:17.9930468Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:17.9930720Z          [0., 0., 0.],
2026-01-14T08:56:17.9930961Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:56:17.9931464Z [32mPASSED[0m
2026-01-14T08:56:17.9932133Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:56:17.9932858Z   (conv): Module()
2026-01-14T08:56:17.9933076Z   (bn): Module()
2026-01-14T08:56:17.9933403Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:17.9934472Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:17.9935714Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:17.9936282Z   )
2026-01-14T08:56:17.9936577Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:17.9937802Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:17.9939463Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3276, -0.3045, -0.2418]), max_val=tensor([0.2760, 0.3298, 0.3101]))
2026-01-14T08:56:17.9940307Z   )
2026-01-14T08:56:17.9940610Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:36.9389544Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:36.9391154Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3778926134109497)
2026-01-14T08:56:36.9391792Z   )
2026-01-14T08:56:36.9392005Z )
2026-01-14T08:56:36.9392141Z 
2026-01-14T08:56:36.9392169Z 
2026-01-14T08:56:36.9392174Z 
2026-01-14T08:56:36.9392287Z def forward(self, x):
2026-01-14T08:56:36.9392671Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:36.9393120Z     conv_weight = self.conv.weight
2026-01-14T08:56:36.9393478Z     bn_weight = self.bn.weight
2026-01-14T08:56:36.9393823Z     bn_bias = self.bn.bias
2026-01-14T08:56:36.9394160Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:56:36.9394566Z     bn_running_var = self.bn.running_var
2026-01-14T08:56:36.9395000Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:36.9395574Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:36.9396375Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:36.9397087Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:56:36.9397604Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:56:36.9398151Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:56:36.9398719Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:56:36.9399377Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:56:36.9400126Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:56:36.9401290Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:36.9402421Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:56:36.9403243Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:56:36.9404533Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:56:36.9405756Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:56:36.9406459Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:36.9407182Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:36.9407700Z     
2026-01-14T08:56:36.9408064Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:36.9408538Z model fx: GraphModule(
2026-01-14T08:56:36.9408952Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:36.9410270Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:36.9412129Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:36.9412831Z   )
2026-01-14T08:56:36.9413058Z   (conv): ConvBnReLU1d(
2026-01-14T08:56:36.9413392Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:36.9413959Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:56:36.9414587Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:36.9416161Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:36.9418022Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3276, -0.3045, -0.2418]), max_val=tensor([0.2760, 0.3298, 0.3101]))
2026-01-14T08:56:36.9418910Z     )
2026-01-14T08:56:36.9419125Z   )
2026-01-14T08:56:36.9419492Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:36.9420827Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:36.9422331Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3778926134109497)
2026-01-14T08:56:36.9422965Z   )
2026-01-14T08:56:36.9423177Z )
2026-01-14T08:56:36.9423300Z 
2026-01-14T08:56:36.9423305Z 
2026-01-14T08:56:36.9423318Z 
2026-01-14T08:56:36.9423424Z def forward(self, x):
2026-01-14T08:56:36.9423867Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:36.9424572Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:36.9425300Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:36.9425860Z     return activation_post_process_1
2026-01-14T08:56:36.9426200Z     
2026-01-14T08:56:36.9426556Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:36.9427039Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:36.9427336Z          [0., 0., 0.],
2026-01-14T08:56:36.9427636Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:36.9428021Z converted model pt2e: GraphModule(
2026-01-14T08:56:36.9428392Z   (conv): Module()
2026-01-14T08:56:36.9428609Z   (bn): Module()
2026-01-14T08:56:36.9428813Z )
2026-01-14T08:56:36.9428914Z 
2026-01-14T08:56:36.9428919Z 
2026-01-14T08:56:36.9428923Z 
2026-01-14T08:56:36.9429016Z def forward(self, x):
2026-01-14T08:56:36.9429313Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:36.9429726Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:36.9430495Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:36.9431854Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:36.9433002Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:36.9433518Z     _scale_0 = self._scale_0
2026-01-14T08:56:36.9433801Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:56:36.9434119Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:56:36.9435105Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:56:36.9436086Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:56:36.9437098Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:56:36.9438103Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:56:36.9439119Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0054035005159676075, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:36.9440680Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0054035005159676075, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:36.9441802Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:56:36.9442239Z     
2026-01-14T08:56:36.9442541Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:36.9442990Z onverted model fx: GraphModule(
2026-01-14T08:56:36.9443260Z   (conv): ConvReLU1d(
2026-01-14T08:56:36.9443609Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:56:36.9444004Z     (1): ReLU()
2026-01-14T08:56:36.9444205Z   )
2026-01-14T08:56:36.9444378Z )
2026-01-14T08:56:36.9444477Z 
2026-01-14T08:56:36.9444481Z 
2026-01-14T08:56:36.9444485Z 
2026-01-14T08:56:36.9444576Z def forward(self, x):
2026-01-14T08:56:36.9445238Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:36.9446651Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:36.9447761Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:36.9448708Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0054035005159676075, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:36.9450141Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0054035005159676075, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:36.9451125Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:36.9451411Z     
2026-01-14T08:56:36.9451712Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:36.9452104Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:36.9452352Z          [0., 0., 0.],
2026-01-14T08:56:36.9452569Z          [0., 0., 0.]]])
2026-01-14T08:56:36.9452813Z model pt2e: GraphModule(
2026-01-14T08:56:36.9453050Z   (conv): Module()
2026-01-14T08:56:36.9453263Z   (bn): Module()
2026-01-14T08:56:36.9453585Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:36.9454653Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:36.9455892Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:36.9456438Z   )
2026-01-14T08:56:36.9456737Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:36.9457803Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:36.9459061Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:56:36.9459620Z   )
2026-01-14T08:56:36.9459906Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.4590464Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:52.4592073Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3749419450759888)
2026-01-14T08:56:52.4592730Z   )
2026-01-14T08:56:52.4593156Z )
2026-01-14T08:56:52.4593292Z 
2026-01-14T08:56:52.4593297Z 
2026-01-14T08:56:52.4593302Z 
2026-01-14T08:56:52.4593419Z def forward(self, x):
2026-01-14T08:56:52.4593801Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:52.4594251Z     conv_weight = self.conv.weight
2026-01-14T08:56:52.4594619Z     bn_weight = self.bn.weight
2026-01-14T08:56:52.4594939Z     bn_bias = self.bn.bias
2026-01-14T08:56:52.4595270Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:56:52.4595654Z     bn_running_var = self.bn.running_var
2026-01-14T08:56:52.4596088Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:52.4596678Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:52.4597503Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:52.4598236Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:56:52.4598752Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:56:52.4599304Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:56:52.4599883Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:56:52.4600551Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:56:52.4601308Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:56:52.4602468Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:52.4603717Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:56:52.4604430Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:56:52.4605712Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:56:52.4606946Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:56:52.4607638Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:52.4608366Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:52.4608878Z     
2026-01-14T08:56:52.4609240Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:52.4609753Z model fx: GraphModule(
2026-01-14T08:56:52.4610185Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.4611509Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:52.4613084Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:52.4613789Z   )
2026-01-14T08:56:52.4614018Z   (conv): ConvBnReLU1d(
2026-01-14T08:56:52.4614353Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:52.4614920Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:56:52.4615557Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.4616974Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:52.4618584Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:56:52.4619301Z     )
2026-01-14T08:56:52.4619513Z   )
2026-01-14T08:56:52.4619873Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.4621305Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:52.4622822Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3749419450759888)
2026-01-14T08:56:52.4623460Z   )
2026-01-14T08:56:52.4623669Z )
2026-01-14T08:56:52.4623798Z 
2026-01-14T08:56:52.4623804Z 
2026-01-14T08:56:52.4623809Z 
2026-01-14T08:56:52.4623915Z def forward(self, x):
2026-01-14T08:56:52.4624373Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:52.4625097Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:52.4625838Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:52.4626407Z     return activation_post_process_1
2026-01-14T08:56:52.4626747Z     
2026-01-14T08:56:52.4627107Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:52.4627595Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:52.4627890Z          [0., 0., 0.],
2026-01-14T08:56:52.4628196Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:52.4628611Z converted model pt2e: GraphModule(
2026-01-14T08:56:52.4628975Z   (conv): Module()
2026-01-14T08:56:52.4629243Z   (bn): Module()
2026-01-14T08:56:52.4629489Z )
2026-01-14T08:56:52.4629615Z 
2026-01-14T08:56:52.4629620Z 
2026-01-14T08:56:52.4629625Z 
2026-01-14T08:56:52.4629741Z def forward(self, x):
2026-01-14T08:56:52.4630067Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:52.4630490Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:52.4631262Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:52.4632638Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:52.4633808Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:52.4634348Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:56:52.4635217Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002597068203613162, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:56:52.4636102Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:56:52.4637013Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:56:52.4638011Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:56:52.4638865Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0053919292986392975, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:52.4640490Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0053919292986392975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:56:52.4641613Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:56:52.4642046Z     
2026-01-14T08:56:52.4642515Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:52.4642961Z onverted model fx: GraphModule(
2026-01-14T08:56:52.4643236Z   (conv): ConvReLU1d(
2026-01-14T08:56:52.4643576Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:56:52.4643968Z     (1): ReLU()
2026-01-14T08:56:52.4644234Z   )
2026-01-14T08:56:52.4644469Z )
2026-01-14T08:56:52.4644704Z 
2026-01-14T08:56:52.4644708Z 
2026-01-14T08:56:52.4644712Z 
2026-01-14T08:56:52.4644806Z def forward(self, x):
2026-01-14T08:56:52.4645475Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:52.4646851Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:52.4647972Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:52.4648931Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0053919292986392975, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:52.4650399Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0053919292986392975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:52.4658929Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:52.4659248Z     
2026-01-14T08:56:52.4659561Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:52.4659976Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:52.4660231Z          [0., 0., 0.],
2026-01-14T08:56:52.4660463Z          [0., 0., 0.]]])
2026-01-14T08:56:52.4660919Z [32mPASSED[0m
2026-01-14T08:56:52.4661523Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T08:56:52.4662180Z   (conv): Module()
2026-01-14T08:56:52.4662508Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.4663653Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:52.4665124Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:56:52.4665831Z   )
2026-01-14T08:56:52.4666138Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.4667186Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:52.4668431Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:52.4668992Z   )
2026-01-14T08:56:52.4669290Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:53.9128468Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0038]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:53.9130068Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9578298330307007)
2026-01-14T08:56:53.9130715Z   )
2026-01-14T08:56:53.9130938Z )
2026-01-14T08:56:53.9131068Z 
2026-01-14T08:56:53.9131087Z 
2026-01-14T08:56:53.9131093Z 
2026-01-14T08:56:53.9131206Z def forward(self, x):
2026-01-14T08:56:53.9131581Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:53.9132048Z     conv_weight = self.conv.weight
2026-01-14T08:56:53.9132872Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:53.9133669Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:53.9134782Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:53.9135951Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:56:53.9136605Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:53.9137339Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:53.9137864Z     
2026-01-14T08:56:53.9138240Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:53.9138724Z model fx: GraphModule(
2026-01-14T08:56:53.9139356Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:53.9140696Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:53.9142273Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:53.9142986Z   )
2026-01-14T08:56:53.9143219Z   (conv): ConvReLU1d(
2026-01-14T08:56:53.9143552Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:53.9144020Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:53.9145404Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:53.9147290Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:56:53.9148201Z     )
2026-01-14T08:56:53.9148432Z   )
2026-01-14T08:56:53.9148790Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:53.9150208Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0038]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:53.9151740Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9578298330307007)
2026-01-14T08:56:53.9152387Z   )
2026-01-14T08:56:53.9152612Z )
2026-01-14T08:56:53.9152738Z 
2026-01-14T08:56:53.9152744Z 
2026-01-14T08:56:53.9152749Z 
2026-01-14T08:56:53.9152860Z def forward(self, x):
2026-01-14T08:56:53.9153326Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:53.9154053Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:53.9154810Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:53.9155388Z     return activation_post_process_1
2026-01-14T08:56:53.9155737Z     
2026-01-14T08:56:53.9156112Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:53.9156609Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:53.9156918Z          [0., 0., 0.],
2026-01-14T08:56:53.9157226Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:53.9157635Z converted model pt2e: GraphModule(
2026-01-14T08:56:53.9157975Z   (conv): Module()
2026-01-14T08:56:53.9158249Z )
2026-01-14T08:56:53.9158390Z 
2026-01-14T08:56:53.9158395Z 
2026-01-14T08:56:53.9158400Z 
2026-01-14T08:56:53.9158515Z def forward(self, x):
2026-01-14T08:56:53.9158916Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:53.9159387Z     _scale_0 = self._scale_0
2026-01-14T08:56:53.9159693Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:56:53.9160181Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:56:53.9161305Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:56:53.9162966Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:53.9164340Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:53.9165807Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:56:53.9166743Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:56:53.9167596Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0037561955396085978, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:53.9169034Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0037561955396085978, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:53.9170175Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:56:53.9170623Z     
2026-01-14T08:56:53.9170938Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:53.9171351Z onverted model fx: GraphModule(
2026-01-14T08:56:53.9171626Z   (conv): ConvReLU1d(
2026-01-14T08:56:53.9172020Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:56:53.9172457Z     (1): ReLU()
2026-01-14T08:56:53.9172674Z   )
2026-01-14T08:56:53.9172855Z )
2026-01-14T08:56:53.9172966Z 
2026-01-14T08:56:53.9172970Z 
2026-01-14T08:56:53.9172974Z 
2026-01-14T08:56:53.9173069Z def forward(self, x):
2026-01-14T08:56:53.9173743Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:53.9175115Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:53.9176233Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:53.9177187Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0037561955396085978, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:53.9178646Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0037561955396085978, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:53.9179652Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:53.9179945Z     
2026-01-14T08:56:53.9180256Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:53.9180670Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:53.9180975Z          [0., 0., 0.],
2026-01-14T08:56:53.9181201Z          [0., 0., 0.]]])
2026-01-14T08:56:53.9181459Z model pt2e: GraphModule(
2026-01-14T08:56:53.9181705Z   (conv): Module()
2026-01-14T08:56:53.9182044Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:53.9183127Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:53.9184490Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3119288384914398, max_val=0.23078612983226776)
2026-01-14T08:56:53.9185069Z   )
2026-01-14T08:56:53.9185366Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:53.9186438Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:53.9189195Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:53.9189760Z   )
2026-01-14T08:56:53.9190060Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:53.9191146Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0037]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:53.9192342Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9556508660316467)
2026-01-14T08:56:53.9192870Z   )
2026-01-14T08:56:53.9193046Z )
2026-01-14T08:56:53.9193165Z 
2026-01-14T08:56:53.9193170Z 
2026-01-14T08:56:53.9193174Z 
2026-01-14T08:56:53.9193270Z def forward(self, x):
2026-01-14T08:56:53.9193592Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:53.9193960Z     conv_weight = self.conv.weight
2026-01-14T08:56:53.9194462Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:53.9195098Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:53.9196003Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:53.9196845Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:56:53.9197375Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:53.9197974Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:53.9198403Z     
2026-01-14T08:56:53.9198712Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:53.9199118Z model fx: GraphModule(
2026-01-14T08:56:53.9199477Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:57.4937744Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:57.4939999Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:57.4940676Z   )
2026-01-14T08:56:57.4940876Z   (conv): ConvReLU1d(
2026-01-14T08:56:57.4941184Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:57.4941587Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:57.4942633Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:57.4943913Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3119288384914398, max_val=0.23078612983226776)
2026-01-14T08:56:57.4944487Z     )
2026-01-14T08:56:57.4944679Z   )
2026-01-14T08:56:57.4944990Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:57.4946058Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0037]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:57.4947662Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9556508660316467)
2026-01-14T08:56:57.4948188Z   )
2026-01-14T08:56:57.4948375Z )
2026-01-14T08:56:57.4948488Z 
2026-01-14T08:56:57.4948492Z 
2026-01-14T08:56:57.4948496Z 
2026-01-14T08:56:57.4948590Z def forward(self, x):
2026-01-14T08:56:57.4948966Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:57.4949755Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:57.4950356Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:57.4950820Z     return activation_post_process_1
2026-01-14T08:56:57.4951099Z     
2026-01-14T08:56:57.4951402Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:57.4951803Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:57.4952049Z          [0., 0., 0.],
2026-01-14T08:56:57.4952319Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:57.4952646Z converted model pt2e: GraphModule(
2026-01-14T08:56:57.4952934Z   (conv): Module()
2026-01-14T08:56:57.4953142Z )
2026-01-14T08:56:57.4953247Z 
2026-01-14T08:56:57.4953251Z 
2026-01-14T08:56:57.4953255Z 
2026-01-14T08:56:57.4953346Z def forward(self, x):
2026-01-14T08:56:57.4953656Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:57.4954065Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:56:57.4955066Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0024561325553804636, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:57.4956439Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:57.4957822Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:57.4959316Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:56:57.4960235Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:56:57.4961126Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003747650422155857, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:57.4962557Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003747650422155857, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:56:57.4963805Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:56:57.4964253Z     
2026-01-14T08:56:57.4964560Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:57.4964966Z onverted model fx: GraphModule(
2026-01-14T08:56:57.4965237Z   (conv): ConvReLU1d(
2026-01-14T08:56:57.4965620Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:56:57.4966053Z     (1): ReLU()
2026-01-14T08:56:57.4966249Z   )
2026-01-14T08:56:57.4966432Z )
2026-01-14T08:56:57.4966533Z 
2026-01-14T08:56:57.4966537Z 
2026-01-14T08:56:57.4966541Z 
2026-01-14T08:56:57.4966632Z def forward(self, x):
2026-01-14T08:56:57.4967299Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:57.4968662Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:57.4969875Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:57.4970833Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003747650422155857, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:57.4972266Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003747650422155857, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:57.4973332Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:57.4973623Z     
2026-01-14T08:56:57.4973920Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:57.4974324Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:57.4974571Z          [0., 0., 0.],
2026-01-14T08:56:57.4974809Z          [0., 0., 0.]]])
2026-01-14T08:56:57.4975052Z model pt2e: GraphModule(
2026-01-14T08:56:57.4975324Z   (conv): Module()
2026-01-14T08:56:57.4975653Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:57.4976789Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0025, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:57.4978281Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2203, -0.3233, -0.3086]), max_val=tensor([0.2796, 0.3026, 0.2405]))
2026-01-14T08:56:57.4978999Z   )
2026-01-14T08:56:57.4979291Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:57.4980357Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:57.4981598Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:57.4982168Z   )
2026-01-14T08:56:57.4982463Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:57.4983542Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-25], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:57.4984802Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8935509324073792, max_val=1.3209781646728516)
2026-01-14T08:56:57.4985358Z   )
2026-01-14T08:56:57.4985540Z )
2026-01-14T08:56:57.4985641Z 
2026-01-14T08:56:57.4985645Z 
2026-01-14T08:56:57.4985649Z 
2026-01-14T08:56:57.4985737Z def forward(self, x):
2026-01-14T08:56:57.4986051Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:57.4986420Z     conv_weight = self.conv.weight
2026-01-14T08:56:57.4986915Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:57.4987560Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:57.4988446Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:57.4989368Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:56:57.4989978Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:57.4990393Z     
2026-01-14T08:56:57.4990697Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:57.4991091Z model fx: GraphModule(
2026-01-14T08:56:57.4991469Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:57.4992652Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:57.4993905Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:57.4994467Z   )
2026-01-14T08:56:57.4994650Z   (conv): Conv1d(
2026-01-14T08:56:57.4994907Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:57.4995377Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:57.4996487Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0025, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:57.4997977Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2203, -0.3233, -0.3086]), max_val=tensor([0.2796, 0.3026, 0.2405]))
2026-01-14T08:56:57.4998679Z     )
2026-01-14T08:56:57.4998869Z   )
2026-01-14T08:56:57.4999164Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:57.5000241Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-25], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:57.5001493Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8935509324073792, max_val=1.3209781646728516)
2026-01-14T08:56:57.5002062Z   )
2026-01-14T08:56:57.5002243Z )
2026-01-14T08:56:57.5002344Z 
2026-01-14T08:56:57.5002348Z 
2026-01-14T08:56:57.5002352Z 
2026-01-14T08:56:57.5002443Z def forward(self, x):
2026-01-14T08:56:57.5002888Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:59.0796240Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:59.0797179Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:59.0798056Z     return activation_post_process_1
2026-01-14T08:56:59.0798438Z     
2026-01-14T08:56:59.0798749Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:59.0799230Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:59.0799490Z          [0., 0., 0.],
2026-01-14T08:56:59.0799744Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:59.0800164Z converted model pt2e: GraphModule(
2026-01-14T08:56:59.0800444Z   (conv): Module()
2026-01-14T08:56:59.0800665Z )
2026-01-14T08:56:59.0800796Z 
2026-01-14T08:56:59.0800802Z 
2026-01-14T08:56:59.0800807Z 
2026-01-14T08:56:59.0800942Z def forward(self, x):
2026-01-14T08:56:59.0801256Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:59.0801646Z     _scale_0 = self._scale_0
2026-01-14T08:56:59.0802007Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:56:59.0802365Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:56:59.0803775Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:56:59.0805304Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:59.0806687Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:59.0808159Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:56:59.0809771Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.008684427477419376, -25, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:56:59.0812089Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008684427477419376, -25, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:59.0813232Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:56:59.0813830Z     
2026-01-14T08:56:59.0814139Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:59.0814566Z onverted model fx: GraphModule(
2026-01-14T08:56:59.0815024Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:56:59.0815478Z )
2026-01-14T08:56:59.0815587Z 
2026-01-14T08:56:59.0815590Z 
2026-01-14T08:56:59.0815594Z 
2026-01-14T08:56:59.0815694Z def forward(self, x):
2026-01-14T08:56:59.0816365Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:59.0817740Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:59.0818868Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:59.0819819Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008684427477419376, -25, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:59.0821254Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008684427477419376, -25, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:59.0822240Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:59.0822546Z     
2026-01-14T08:56:59.0822856Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:59.0823269Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:59.0823524Z          [0., 0., 0.],
2026-01-14T08:56:59.0823750Z          [0., 0., 0.]]])
2026-01-14T08:56:59.0824006Z model pt2e: GraphModule(
2026-01-14T08:56:59.0824253Z   (conv): Module()
2026-01-14T08:56:59.0824581Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:59.0825667Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:59.0826948Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232726454734802, max_val=0.30256539583206177)
2026-01-14T08:56:59.0827524Z   )
2026-01-14T08:56:59.0827820Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:59.0828890Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:59.0830140Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:59.0830699Z   )
2026-01-14T08:56:59.0831006Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:59.0832076Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-26], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:59.0833332Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.887858510017395, max_val=1.3209781646728516)
2026-01-14T08:56:59.0833884Z   )
2026-01-14T08:56:59.0834072Z )
2026-01-14T08:56:59.0834175Z 
2026-01-14T08:56:59.0834180Z 
2026-01-14T08:56:59.0834184Z 
2026-01-14T08:56:59.0834282Z def forward(self, x):
2026-01-14T08:56:59.0834692Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:59.0835072Z     conv_weight = self.conv.weight
2026-01-14T08:56:59.0835571Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:59.0836226Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:59.0837262Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:59.0838185Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:56:59.0838806Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:59.0839659Z     
2026-01-14T08:56:59.0839965Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:59.0840367Z model fx: GraphModule(
2026-01-14T08:56:59.0840718Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:59.0841848Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:59.0843159Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:59.0843729Z   )
2026-01-14T08:56:59.0843916Z   (conv): Conv1d(
2026-01-14T08:56:59.0844176Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:59.0844563Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:59.0845616Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:59.0846910Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232726454734802, max_val=0.30256539583206177)
2026-01-14T08:56:59.0847480Z     )
2026-01-14T08:56:59.0847674Z   )
2026-01-14T08:56:59.0847969Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:59.0849042Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-26], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:59.0850305Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.887858510017395, max_val=1.3209781646728516)
2026-01-14T08:56:59.0850854Z   )
2026-01-14T08:56:59.0851070Z )
2026-01-14T08:56:59.0851172Z 
2026-01-14T08:56:59.0851177Z 
2026-01-14T08:56:59.0851181Z 
2026-01-14T08:56:59.0851269Z def forward(self, x):
2026-01-14T08:56:59.0851651Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:59.0852245Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:59.0852838Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:59.0853308Z     return activation_post_process_1
2026-01-14T08:56:59.0853579Z     
2026-01-14T08:56:59.0853880Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:59.0854280Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:59.0854530Z          [0., 0., 0.],
2026-01-14T08:56:59.0854788Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:59.0855115Z converted model pt2e: GraphModule(
2026-01-14T08:56:59.0855399Z   (conv): Module()
2026-01-14T08:56:59.0855610Z )
2026-01-14T08:56:59.0855711Z 
2026-01-14T08:56:59.0855715Z 
2026-01-14T08:56:59.0855729Z 
2026-01-14T08:56:59.0855818Z def forward(self, x):
2026-01-14T08:56:59.0856124Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:59.0856536Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:56:59.0857688Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.002545453840866685, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:59.0859061Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:59.0860563Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:59.0862044Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:56:59.0863358Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.008662103675305843, -26, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:58:11.9405134Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.008662103675305843, -26, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:11.9406577Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:58:11.9407237Z     
2026-01-14T08:58:11.9407647Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:11.9408249Z onverted model fx: GraphModule(
2026-01-14T08:58:11.9408686Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:58:11.9409134Z )
2026-01-14T08:58:11.9409237Z 
2026-01-14T08:58:11.9409241Z 
2026-01-14T08:58:11.9409244Z 
2026-01-14T08:58:11.9409339Z def forward(self, x):
2026-01-14T08:58:11.9410217Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:58:11.9411937Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:11.9413433Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:58:11.9414373Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008662103675305843, -26, -128, 127, torch.int8);  conv = None
2026-01-14T08:58:11.9415781Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008662103675305843, -26, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:11.9416749Z     return dequantize_per_tensor_default_1
2026-01-14T08:58:11.9417034Z     
2026-01-14T08:58:11.9417331Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:11.9417727Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:58:11.9425461Z          [0., 0., 0.],
2026-01-14T08:58:11.9425728Z          [0., 0., 0.]]])
2026-01-14T08:58:11.9426184Z [32mPASSED[0m
2026-01-14T08:58:11.9426864Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T08:58:11.9427947Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:58:11.9428936Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T08:58:11.9429586Z   (conv): Module()
2026-01-14T08:58:11.9429914Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:11.9431412Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:58:11.9432803Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2457]), max_val=tensor([-0.2457]))
2026-01-14T08:58:11.9433423Z   )
2026-01-14T08:58:11.9433750Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:11.9434994Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:11.9436249Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:58:11.9436801Z   )
2026-01-14T08:58:11.9437099Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:11.9438155Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:11.9439750Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:58:11.9440307Z   )
2026-01-14T08:58:11.9440607Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:11.9441689Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:11.9443221Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:58:11.9443736Z   )
2026-01-14T08:58:11.9443912Z )
2026-01-14T08:58:11.9444020Z 
2026-01-14T08:58:11.9444025Z 
2026-01-14T08:58:11.9444029Z 
2026-01-14T08:58:11.9444119Z def forward(self, x):
2026-01-14T08:58:11.9444435Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:11.9444795Z     conv_weight = self.conv.weight
2026-01-14T08:58:11.9445286Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:58:11.9445785Z     conv_bias = self.conv.bias
2026-01-14T08:58:11.9446183Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:58:11.9447037Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:58:11.9447924Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:58:11.9448805Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:58:11.9449588Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:58:11.9450101Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:58:11.9450687Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:58:11.9451113Z     
2026-01-14T08:58:11.9451416Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:11.9451801Z model fx: GraphModule(
2026-01-14T08:58:11.9452143Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:11.9453199Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:11.9454446Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:58:11.9454992Z   )
2026-01-14T08:58:11.9455168Z   (conv): Conv1d(
2026-01-14T08:58:11.9455396Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T08:58:11.9455897Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:11.9456948Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:58:11.9459307Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2457]), max_val=tensor([-0.2457]))
2026-01-14T08:58:11.9459925Z     )
2026-01-14T08:58:11.9460104Z   )
2026-01-14T08:58:11.9460386Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:11.9461453Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:11.9462717Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:58:11.9463280Z   )
2026-01-14T08:58:11.9463474Z   (relu): ReLU(inplace=True)
2026-01-14T08:58:11.9463834Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:11.9464904Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:11.9466106Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:58:11.9466612Z   )
2026-01-14T08:58:11.9466780Z )
2026-01-14T08:58:11.9466890Z 
2026-01-14T08:58:11.9466894Z 
2026-01-14T08:58:11.9466898Z 
2026-01-14T08:58:11.9466988Z def forward(self, x):
2026-01-14T08:58:11.9467360Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:58:11.9467819Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:58:11.9468298Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:58:11.9469055Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:58:11.9469681Z     relu = self.relu(add);  add = None
2026-01-14T08:58:11.9470115Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:58:11.9470583Z     return activation_post_process_2
2026-01-14T08:58:11.9470855Z     
2026-01-14T08:58:11.9471147Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:11.9471600Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:58:11.9471949Z converted model pt2e: GraphModule(
2026-01-14T08:58:11.9472228Z   (conv): Module()
2026-01-14T08:58:11.9472426Z )
2026-01-14T08:58:11.9472533Z 
2026-01-14T08:58:11.9472537Z 
2026-01-14T08:58:11.9472541Z 
2026-01-14T08:58:11.9472631Z def forward(self, x):
2026-01-14T08:58:11.9472946Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:11.9473298Z     _scale_0 = self._scale_0
2026-01-14T08:58:11.9473567Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:58:11.9473898Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:58:11.9475016Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:58:11.9476090Z     conv_bias = self.conv.bias
2026-01-14T08:58:11.9476790Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:58:11.9478041Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T08:58:11.9479599Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:13.2477710Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T08:58:13.2479969Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:58:13.2481415Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:13.2482982Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T08:58:13.2483879Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:58:13.2484733Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:58:13.2486197Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:13.2487347Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:58:13.2487809Z     
2026-01-14T08:58:13.2488119Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:13.2488542Z onverted model fx: GraphModule(
2026-01-14T08:58:13.2488950Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T08:58:13.2489387Z   (relu): ReLU(inplace=True)
2026-01-14T08:58:13.2489646Z )
2026-01-14T08:58:13.2489762Z 
2026-01-14T08:58:13.2489767Z 
2026-01-14T08:58:13.2489771Z 
2026-01-14T08:58:13.2489865Z def forward(self, x):
2026-01-14T08:58:13.2490550Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:58:13.2491935Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:13.2492936Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:58:13.2493746Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv = None
2026-01-14T08:58:13.2495190Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:13.2496569Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:58:13.2497291Z     relu = self.relu(add);  add = None
2026-01-14T08:58:13.2498069Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:58:13.2499517Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:13.2500517Z     return dequantize_per_tensor_default_2
2026-01-14T08:58:13.2500805Z     
2026-01-14T08:58:13.2501270Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:13.2501675Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T08:58:13.2501948Z model pt2e: GraphModule(
2026-01-14T08:58:13.2502196Z   (conv): Module()
2026-01-14T08:58:13.2502521Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:13.2503611Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:58:13.2505049Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24565386772155762, max_val=-0.24565386772155762)
2026-01-14T08:58:13.2505626Z   )
2026-01-14T08:58:13.2505920Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:13.2507001Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:13.2508249Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:58:13.2508811Z   )
2026-01-14T08:58:13.2509114Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:13.2510180Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:13.2511455Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:58:13.2512017Z   )
2026-01-14T08:58:13.2512316Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:13.2513399Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:13.2514588Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:58:13.2515103Z   )
2026-01-14T08:58:13.2515283Z )
2026-01-14T08:58:13.2515392Z 
2026-01-14T08:58:13.2515397Z 
2026-01-14T08:58:13.2515405Z 
2026-01-14T08:58:13.2515495Z def forward(self, x):
2026-01-14T08:58:13.2515807Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:13.2516172Z     conv_weight = self.conv.weight
2026-01-14T08:58:13.2516677Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:58:13.2517191Z     conv_bias = self.conv.bias
2026-01-14T08:58:13.2517601Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:58:13.2518468Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:58:13.2519365Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:58:13.2520264Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:58:13.2521057Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:58:13.2521576Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:58:13.2522168Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:58:13.2522596Z     
2026-01-14T08:58:13.2522993Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:13.2523432Z model fx: GraphModule(
2026-01-14T08:58:13.2523775Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:13.2524941Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:13.2526216Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:58:13.2526769Z   )
2026-01-14T08:58:13.2527045Z   (conv): Conv1d(
2026-01-14T08:58:13.2527277Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T08:58:13.2527630Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:13.2528696Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:58:13.2529982Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24565386772155762, max_val=-0.24565386772155762)
2026-01-14T08:58:13.2530559Z     )
2026-01-14T08:58:13.2530743Z   )
2026-01-14T08:58:13.2531038Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:13.2532113Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:13.2533389Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:58:13.2533961Z   )
2026-01-14T08:58:13.2534161Z   (relu): ReLU(inplace=True)
2026-01-14T08:58:13.2534528Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:13.2535604Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:13.2536815Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:58:13.2537330Z   )
2026-01-14T08:58:13.2537510Z )
2026-01-14T08:58:13.2537616Z 
2026-01-14T08:58:13.2537620Z 
2026-01-14T08:58:13.2537624Z 
2026-01-14T08:58:13.2537713Z def forward(self, x):
2026-01-14T08:58:13.2538091Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:58:13.2538560Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:58:13.2539355Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:58:13.2540118Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:58:13.2540748Z     relu = self.relu(add);  add = None
2026-01-14T08:58:13.2541195Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:58:13.2541664Z     return activation_post_process_2
2026-01-14T08:58:13.2541943Z     
2026-01-14T08:58:13.2542245Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:53.5677131Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:58:53.5679521Z converted model pt2e: GraphModule(
2026-01-14T08:58:53.5679895Z   (conv): Module()
2026-01-14T08:58:53.5680190Z )
2026-01-14T08:58:53.5680321Z 
2026-01-14T08:58:53.5680355Z 
2026-01-14T08:58:53.5680360Z 
2026-01-14T08:58:53.5680474Z def forward(self, x):
2026-01-14T08:58:53.5680849Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:53.5681348Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:58:53.5682607Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0019342823652550578, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:53.5683942Z     conv_bias = self.conv.bias
2026-01-14T08:58:53.5685222Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:58:53.5686811Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T08:58:53.5688677Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:53.5690841Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T08:58:53.5692606Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:58:53.5694430Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:53.5696296Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T08:58:53.5697409Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:58:53.5698447Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:58:53.5700268Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:58:53.5701688Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T08:58:53.5702235Z     
2026-01-14T08:58:53.5702601Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:53.5703098Z onverted model fx: GraphModule(
2026-01-14T08:58:53.5703583Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T08:58:53.5704104Z   (relu): ReLU(inplace=True)
2026-01-14T08:58:53.5704411Z )
2026-01-14T08:58:53.5704537Z 
2026-01-14T08:58:53.5704542Z 
2026-01-14T08:58:53.5704547Z 
2026-01-14T08:58:53.5704665Z def forward(self, x):
2026-01-14T08:58:53.5705493Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:58:53.5707224Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:53.5708558Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:58:53.5709416Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv = None
2026-01-14T08:58:53.5710826Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:53.5712165Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:58:53.5712861Z     relu = self.relu(add);  add = None
2026-01-14T08:58:53.5713614Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:58:53.5715135Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:53.5716122Z     return dequantize_per_tensor_default_2
2026-01-14T08:58:53.5716405Z     
2026-01-14T08:58:53.5716706Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:53.5717211Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T08:58:53.5717687Z [32mPASSED[0m
2026-01-14T08:58:53.5718432Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T08:58:53.5719563Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T08:58:53.5720583Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T08:58:53.5721235Z   (conv): Module()
2026-01-14T08:58:53.5721455Z   (bn): Module()
2026-01-14T08:58:53.5721774Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:53.5722905Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:53.5724184Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:58:53.5724740Z   )
2026-01-14T08:58:53.5725029Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:53.5726162Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:58:53.5727639Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3156, -0.1982, -0.3261]), max_val=tensor([0.2827, 0.2978, 0.2359]))
2026-01-14T08:58:53.5728355Z   )
2026-01-14T08:58:53.5728651Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:53.5729706Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:53.5730956Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:58:53.5731503Z   )
2026-01-14T08:58:53.5731795Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:53.5732848Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:53.5734086Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:58:53.5734642Z   )
2026-01-14T08:58:53.5734813Z )
2026-01-14T08:58:53.5734918Z 
2026-01-14T08:58:53.5734923Z 
2026-01-14T08:58:53.5734927Z 
2026-01-14T08:58:53.5735016Z def forward(self, x):
2026-01-14T08:58:53.5735320Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:53.5735695Z     conv_weight = self.conv.weight
2026-01-14T08:58:53.5735984Z     conv_bias = self.conv.bias
2026-01-14T08:58:53.5736249Z     bn_weight = self.bn.weight
2026-01-14T08:58:53.5736510Z     bn_bias = self.bn.bias
2026-01-14T08:58:53.5736773Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:58:53.5737090Z     bn_running_var = self.bn.running_var
2026-01-14T08:58:53.5737435Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:58:53.5737907Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:58:53.5738649Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:58:53.5739544Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:58:53.5739968Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:58:53.5740408Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:58:53.5741045Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:58:53.5741581Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:58:53.5742197Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:58:53.5742869Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:58:53.5743955Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:58:53.5744934Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:58:53.5745511Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:58:53.5746155Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:58:53.5746763Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:58:53.5747766Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:58:53.5748842Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:59:10.8026056Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:59:10.8027156Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:59:10.8027950Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:59:10.8028476Z     
2026-01-14T08:59:10.8028856Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:10.8029397Z model fx: GraphModule(
2026-01-14T08:59:10.8029819Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:10.8031178Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:10.8032844Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:59:10.8033554Z   )
2026-01-14T08:59:10.8033786Z   (conv): ConvBn1d(
2026-01-14T08:59:10.8034085Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:59:10.8034647Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:59:10.8035298Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:10.8036710Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:59:10.8038607Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3156, -0.1982, -0.3261]), max_val=tensor([0.2827, 0.2978, 0.2359]))
2026-01-14T08:59:10.8039771Z     )
2026-01-14T08:59:10.8039995Z   )
2026-01-14T08:59:10.8040351Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:10.8042073Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:10.8043768Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:59:10.8044465Z   )
2026-01-14T08:59:10.8044736Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:59:10.8045424Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:10.8046761Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:10.8048328Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:59:10.8049026Z   )
2026-01-14T08:59:10.8049242Z )
2026-01-14T08:59:10.8049374Z 
2026-01-14T08:59:10.8049380Z 
2026-01-14T08:59:10.8049385Z 
2026-01-14T08:59:10.8049501Z def forward(self, x):
2026-01-14T08:59:10.8049952Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:10.8050669Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:59:10.8051412Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:59:10.8052206Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:59:10.8053040Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:59:10.8053649Z     return activation_post_process_2
2026-01-14T08:59:10.8053986Z     
2026-01-14T08:59:10.8054342Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:10.8054832Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:59:10.8055135Z          [0., 0., 0.],
2026-01-14T08:59:10.8055433Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:59:10.8055838Z converted model pt2e: GraphModule(
2026-01-14T08:59:10.8056171Z   (conv): Module()
2026-01-14T08:59:10.8056428Z   (bn): Module()
2026-01-14T08:59:10.8056664Z )
﻿2026-01-14T08:59:10.8065766Z 
2026-01-14T08:59:10.8065772Z 
2026-01-14T08:59:10.8065775Z 
2026-01-14T08:59:10.8065872Z def forward(self, x):
2026-01-14T08:59:10.8066186Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:10.8066562Z     conv_bias = self.conv.bias
2026-01-14T08:59:10.8066883Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:10.8067660Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:59:10.8069028Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:10.8070171Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:10.8070685Z     _scale_0 = self._scale_0
2026-01-14T08:59:10.8070947Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:59:10.8071286Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:59:10.8072261Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:59:10.8073770Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:59:10.8075090Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010604282841086388, -5, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:59:10.8076651Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:59:10.8077953Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T08:59:10.8079072Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010604282841086388, -5, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:59:10.8080558Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:59:10.8081664Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:59:10.8082097Z     
2026-01-14T08:59:10.8082398Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:10.8082881Z onverted model fx: GraphModule(
2026-01-14T08:59:10.8083280Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:59:10.8083728Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:59:10.8084044Z )
2026-01-14T08:59:10.8084147Z 
2026-01-14T08:59:10.8084152Z 
2026-01-14T08:59:10.8084156Z 
2026-01-14T08:59:10.8084256Z def forward(self, x):
2026-01-14T08:59:10.8084916Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:59:10.8086270Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:10.8087369Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:59:10.8088313Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010604282841086388, -5, -128, 127, torch.int8);  conv = None
2026-01-14T08:59:10.8089769Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:59:10.8091050Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:59:10.8092066Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010604282841086388, -5, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:59:10.8093505Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:59:10.8094474Z     return dequantize_per_tensor_default_2
2026-01-14T08:59:10.8094771Z     
2026-01-14T08:59:10.8095068Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:10.8095469Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:59:10.8095722Z          [0., 0., 0.],
2026-01-14T08:59:10.8095949Z          [0., 0., 0.]]])
2026-01-14T08:59:10.8096205Z model pt2e: GraphModule(
2026-01-14T08:59:10.8096446Z   (conv): Module()
2026-01-14T08:59:10.8096665Z   (bn): Module()
2026-01-14T08:59:10.8096975Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:10.8098028Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:10.8099264Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:59:10.8099820Z   )
2026-01-14T08:59:10.8100203Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:10.8101265Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:59:10.8102517Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3261372148990631, max_val=0.297783762216568)
2026-01-14T08:59:10.8103109Z   )
2026-01-14T08:59:10.8111684Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.7397998Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:27.7399475Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:59:27.7400045Z   )
2026-01-14T08:59:27.7400366Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.7401444Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:27.7402787Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:59:27.7403345Z   )
2026-01-14T08:59:27.7403535Z )
2026-01-14T08:59:27.7403640Z 
2026-01-14T08:59:27.7403646Z 
2026-01-14T08:59:27.7403649Z 
2026-01-14T08:59:27.7403744Z def forward(self, x):
2026-01-14T08:59:27.7404123Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:27.7404493Z     conv_weight = self.conv.weight
2026-01-14T08:59:27.7404794Z     conv_bias = self.conv.bias
2026-01-14T08:59:27.7405078Z     bn_weight = self.bn.weight
2026-01-14T08:59:27.7405339Z     bn_bias = self.bn.bias
2026-01-14T08:59:27.7405618Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:59:27.7405930Z     bn_running_var = self.bn.running_var
2026-01-14T08:59:27.7406286Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:27.7407017Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:27.7407706Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:27.7408302Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:59:27.7408724Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:59:27.7409178Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:59:27.7409651Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:59:27.7410197Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:59:27.7410823Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:59:27.7411504Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:59:27.7412595Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:59:27.7413591Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:59:27.7414177Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:59:27.7414806Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:59:27.7415413Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:59:27.7416591Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:59:27.7417676Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:59:27.7418503Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:59:27.7419284Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:59:27.7419994Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:59:27.7420415Z     
2026-01-14T08:59:27.7420724Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:27.7421122Z model fx: GraphModule(
2026-01-14T08:59:27.7421477Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.7422557Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:27.7423805Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:59:27.7424370Z   )
2026-01-14T08:59:27.7424567Z   (conv): ConvBn1d(
2026-01-14T08:59:27.7424812Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:59:27.7425257Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:59:27.7425785Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.7426836Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:59:27.7428099Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3261372148990631, max_val=0.297783762216568)
2026-01-14T08:59:27.7428670Z     )
2026-01-14T08:59:27.7428856Z   )
2026-01-14T08:59:27.7429161Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.7430230Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:27.7431526Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:59:27.7432079Z   )
2026-01-14T08:59:27.7432313Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:59:27.7432744Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.7433805Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:27.7435053Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:59:27.7435606Z   )
2026-01-14T08:59:27.7435782Z )
2026-01-14T08:59:27.7435892Z 
2026-01-14T08:59:27.7435896Z 
2026-01-14T08:59:27.7435900Z 
2026-01-14T08:59:27.7435991Z def forward(self, x):
2026-01-14T08:59:27.7436366Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:27.7436954Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:59:27.7437553Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:59:27.7438179Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:59:27.7438841Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:59:27.7439539Z     return activation_post_process_2
2026-01-14T08:59:27.7439821Z     
2026-01-14T08:59:27.7440285Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:27.7440692Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:59:27.7440939Z          [0., 0., 0.],
2026-01-14T08:59:27.7441192Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:59:27.7441519Z converted model pt2e: GraphModule(
2026-01-14T08:59:27.7441792Z   (conv): Module()
2026-01-14T08:59:27.7442063Z   (bn): Module()
2026-01-14T08:59:27.7442259Z )
2026-01-14T08:59:27.7442366Z 
2026-01-14T08:59:27.7442370Z 
2026-01-14T08:59:27.7442374Z 
2026-01-14T08:59:27.7442463Z def forward(self, x):
2026-01-14T08:59:27.7442817Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:27.7443179Z     conv_bias = self.conv.bias
2026-01-14T08:59:27.7443501Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:27.7444270Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:59:27.7445646Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:27.7446794Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:27.7447348Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:59:27.7448216Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002568009542301297, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:59:27.7449608Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:59:27.7450947Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010644976049661636, -4, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:59:27.7452391Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:59:27.7453803Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T08:59:27.7454946Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010644976049661636, -4, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:59:27.7456394Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:59:27.7457506Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T08:59:27.7457953Z     
2026-01-14T08:59:27.7458254Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:27.7458670Z onverted model fx: GraphModule(
2026-01-14T08:59:27.7459063Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:59:27.7459519Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:59:27.7459829Z )
2026-01-14T08:59:27.7459930Z 
2026-01-14T08:59:27.7459934Z 
2026-01-14T08:59:27.7459938Z 
2026-01-14T08:59:27.7460030Z def forward(self, x):
2026-01-14T08:59:27.7460696Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:00:28.5115169Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:28.5116966Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:28.5118157Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010644976049661636, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:28.5119963Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:28.5121555Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:00:28.5122909Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010644976049661636, -4, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:00:28.5124745Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:00:28.5125984Z     return dequantize_per_tensor_default_2
2026-01-14T09:00:28.5126338Z     
2026-01-14T09:00:28.5126711Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:28.5127205Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:00:28.5127512Z          [0., 0., 0.],
2026-01-14T09:00:28.5127784Z          [0., 0., 0.]]])
2026-01-14T09:00:28.5128315Z [32mPASSED[0m
2026-01-14T09:00:28.5129147Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T09:00:28.5130518Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T09:00:28.5131787Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T09:00:28.5132583Z   (conv): Module()
2026-01-14T09:00:28.5132840Z   (bn): Module()
2026-01-14T09:00:28.5133222Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.5134556Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:28.5136288Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:28.5136973Z   )
2026-01-14T09:00:28.5137330Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.5138731Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:28.5140806Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1894, -0.1850, -0.1857]), max_val=tensor([0.1520, 0.1622, 0.1895]))
2026-01-14T09:00:28.5141693Z   )
2026-01-14T09:00:28.5142040Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.5143368Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:28.5144924Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9920659065246582, max_val=2.112386465072632)
2026-01-14T09:00:28.5145619Z   )
2026-01-14T09:00:28.5145839Z )
2026-01-14T09:00:28.5145961Z 
2026-01-14T09:00:28.5145966Z 
2026-01-14T09:00:28.5145971Z 
2026-01-14T09:00:28.5146079Z def forward(self, x):
2026-01-14T09:00:28.5146447Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:28.5146886Z     conv_weight = self.conv.weight
2026-01-14T09:00:28.5147237Z     conv_bias = self.conv.bias
2026-01-14T09:00:28.5147693Z     bn_weight = self.bn.weight
2026-01-14T09:00:28.5148023Z     bn_bias = self.bn.bias
2026-01-14T09:00:28.5148354Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:00:28.5148742Z     bn_running_var = self.bn.running_var
2026-01-14T09:00:28.5149175Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:28.5151318Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:28.5152144Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:28.5152861Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:00:28.5153375Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:28.5153908Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:28.5154494Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:00:28.5155176Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:28.5155929Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:28.5156765Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:00:28.5158123Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:00:28.5159359Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:00:28.5160084Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:00:28.5160875Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:00:28.5161633Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:00:28.5162970Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:28.5164403Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:28.5165203Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:28.5165719Z     
2026-01-14T09:00:28.5166082Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:28.5166558Z model fx: GraphModule(
2026-01-14T09:00:28.5166969Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.5168370Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:28.5169825Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:28.5170379Z   )
2026-01-14T09:00:28.5170568Z   (conv): ConvBn2d(
2026-01-14T09:00:28.5170813Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:00:28.5171264Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:28.5171788Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.5172889Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:28.5174360Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1894, -0.1850, -0.1857]), max_val=tensor([0.1520, 0.1622, 0.1895]))
2026-01-14T09:00:28.5175066Z     )
2026-01-14T09:00:28.5175241Z   )
2026-01-14T09:00:28.5175633Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.5176699Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:28.5177942Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9920659065246582, max_val=2.112386465072632)
2026-01-14T09:00:28.5178540Z   )
2026-01-14T09:00:28.5178712Z )
2026-01-14T09:00:28.5178820Z 
2026-01-14T09:00:28.5178824Z 
2026-01-14T09:00:28.5178828Z 
2026-01-14T09:00:28.5178915Z def forward(self, x):
2026-01-14T09:00:28.5179285Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:28.5179868Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:00:28.5180463Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:00:28.5180925Z     return activation_post_process_1
2026-01-14T09:00:28.5181203Z     
2026-01-14T09:00:28.5181542Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:28.5181944Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:28.5182192Z           [0., 0., 0.],
2026-01-14T09:00:28.5182420Z           [0., 0., 0.]],
2026-01-14T09:00:28.5182572Z 
2026-01-14T09:00:28.5182665Z          [[0., 0., 0.],
2026-01-14T09:00:28.5182884Z           [0., 0., 0.],
2026-01-14T09:00:28.5183108Z           [0., 0., 0.]],
2026-01-14T09:00:28.5183254Z 
2026-01-14T09:00:28.5183334Z          [[0., 0., 0.],
2026-01-14T09:00:28.5183556Z           [0., 0., 0.],
2026-01-14T09:00:28.5183815Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:00:28.5184152Z converted model pt2e: GraphModule(
2026-01-14T09:00:28.5184426Z   (conv): Module()
2026-01-14T09:00:28.5184647Z   (bn): Module()
2026-01-14T09:00:28.5184843Z )
2026-01-14T09:00:28.5184950Z 
2026-01-14T09:00:28.5184955Z 
2026-01-14T09:00:28.5184959Z 
2026-01-14T09:00:28.5185057Z def forward(self, x):
2026-01-14T09:00:28.5185366Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:28.5185727Z     conv_bias = self.conv.bias
2026-01-14T09:00:28.5186488Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:28.5187859Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:28.5188803Z     _scale_0 = self._scale_0
2026-01-14T09:00:28.5189079Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:00:28.5189399Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:00:45.7645642Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:00:45.7647643Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:00:45.7649337Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01609589159488678, -4, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:00:45.7651177Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01609589159488678, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:45.7652582Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:00:45.7653125Z     
2026-01-14T09:00:45.7653494Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:45.7653986Z onverted model fx: GraphModule(
2026-01-14T09:00:45.7654713Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:00:45.7655226Z )
2026-01-14T09:00:45.7655358Z 
2026-01-14T09:00:45.7655363Z 
2026-01-14T09:00:45.7655372Z 
2026-01-14T09:00:45.7655482Z def forward(self, x):
2026-01-14T09:00:45.7656358Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:45.7658164Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:45.7659571Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:45.7660743Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01609589159488678, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:45.7662518Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01609589159488678, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:45.7663748Z     return dequantize_per_tensor_default_1
2026-01-14T09:00:45.7664095Z     
2026-01-14T09:00:45.7664461Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:45.7664959Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:45.7665258Z           [0., 0., 0.],
2026-01-14T09:00:45.7665531Z           [0., 0., 0.]],
2026-01-14T09:00:45.7665711Z 
2026-01-14T09:00:45.7665808Z          [[0., 0., 0.],
2026-01-14T09:00:45.7666075Z           [0., 0., 0.],
2026-01-14T09:00:45.7666336Z           [0., 0., 0.]],
2026-01-14T09:00:45.7666526Z 
2026-01-14T09:00:45.7666622Z          [[0., 0., 0.],
2026-01-14T09:00:45.7666888Z           [0., 0., 0.],
2026-01-14T09:00:45.7667156Z           [0., 0., 0.]]]])
2026-01-14T09:00:45.7667447Z model pt2e: GraphModule(
2026-01-14T09:00:45.7667749Z   (conv): Module()
2026-01-14T09:00:45.7668009Z   (bn): Module()
2026-01-14T09:00:45.7668382Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:45.7669817Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:45.7671385Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:45.7672078Z   )
2026-01-14T09:00:45.7672427Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:45.7673761Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:00:45.7675357Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18937721848487854, max_val=0.18946029245853424)
2026-01-14T09:00:45.7676057Z   )
2026-01-14T09:00:45.7676407Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:45.7677727Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:45.7679288Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9922423362731934, max_val=2.1162424087524414)
2026-01-14T09:00:45.7679984Z   )
2026-01-14T09:00:45.7680199Z )
2026-01-14T09:00:45.7680326Z 
2026-01-14T09:00:45.7680331Z 
2026-01-14T09:00:45.7680336Z 
2026-01-14T09:00:45.7680444Z def forward(self, x):
2026-01-14T09:00:45.7680806Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:45.7681250Z     conv_weight = self.conv.weight
2026-01-14T09:00:45.7681694Z     conv_bias = self.conv.bias
2026-01-14T09:00:45.7682017Z     bn_weight = self.bn.weight
2026-01-14T09:00:45.7682340Z     bn_bias = self.bn.bias
2026-01-14T09:00:45.7682761Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:00:45.7683153Z     bn_running_var = self.bn.running_var
2026-01-14T09:00:45.7683586Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:45.7684222Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:45.7685017Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:45.7685747Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:00:45.7686269Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:45.7686804Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:45.7687393Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:00:45.7688066Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:45.7688829Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:45.7689678Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:00:45.7691032Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:00:45.7692266Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:00:45.7692987Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:00:45.7693782Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:00:45.7694551Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:00:45.7705559Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:45.7706729Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:45.7707403Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:45.7707838Z     
2026-01-14T09:00:45.7708143Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:45.7708533Z model fx: GraphModule(
2026-01-14T09:00:45.7708876Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:45.7709945Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:45.7711200Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:45.7711760Z   )
2026-01-14T09:00:45.7711963Z   (conv): ConvBn2d(
2026-01-14T09:00:45.7712212Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:00:45.7712676Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:45.7713206Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:45.7714261Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:00:45.7715535Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18937721848487854, max_val=0.18946029245853424)
2026-01-14T09:00:45.7716115Z     )
2026-01-14T09:00:45.7716311Z   )
2026-01-14T09:00:45.7716703Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:45.7717773Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:45.7719025Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9922423362731934, max_val=2.1162424087524414)
2026-01-14T09:00:45.7719639Z   )
2026-01-14T09:00:45.7719830Z )
2026-01-14T09:00:45.7719936Z 
2026-01-14T09:00:45.7719940Z 
2026-01-14T09:00:45.7719944Z 
2026-01-14T09:00:45.7720037Z def forward(self, x):
2026-01-14T09:00:45.7720418Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:45.7720992Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:00:45.7721593Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:00:45.7722048Z     return activation_post_process_1
2026-01-14T09:00:45.7722334Z     
2026-01-14T09:00:45.7722690Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:45.7723092Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:45.7723356Z           [0., 0., 0.],
2026-01-14T09:00:45.7723580Z           [0., 0., 0.]],
2026-01-14T09:00:45.7723729Z 
2026-01-14T09:00:45.7723821Z          [[0., 0., 0.],
2026-01-14T09:00:45.7724042Z           [0., 0., 0.],
2026-01-14T09:00:45.7724270Z           [0., 0., 0.]],
2026-01-14T09:00:45.7724420Z 
2026-01-14T09:00:45.7724503Z          [[0., 0., 0.],
2026-01-14T09:00:45.7724727Z           [0., 0., 0.],
2026-01-14T09:00:45.7724989Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:00:45.7725310Z converted model pt2e: GraphModule(
2026-01-14T09:00:45.7725585Z   (conv): Module()
2026-01-14T09:00:45.7725796Z   (bn): Module()
2026-01-14T09:00:45.7726000Z )
2026-01-14T09:00:45.7726098Z 
2026-01-14T09:00:45.7726102Z 
2026-01-14T09:00:45.7726107Z 
2026-01-14T09:00:45.7726197Z def forward(self, x):
2026-01-14T09:00:45.7726501Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:45.7726859Z     conv_bias = self.conv.bias
2026-01-14T09:00:45.7727618Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:56.9459579Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:56.9460628Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:00:56.9461533Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014918133383616805, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:00:56.9462974Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:00:56.9464314Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01611170545220375, -4, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:00:56.9465765Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01611170545220375, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:00:56.9466906Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:00:56.9467365Z     
2026-01-14T09:00:56.9467700Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:56.9468123Z onverted model fx: GraphModule(
2026-01-14T09:00:56.9468558Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:00:56.9468986Z )
2026-01-14T09:00:56.9469108Z 
2026-01-14T09:00:56.9469112Z 
2026-01-14T09:00:56.9469403Z 
2026-01-14T09:00:56.9469508Z def forward(self, x):
2026-01-14T09:00:56.9470202Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:56.9471580Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:56.9472807Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:56.9473746Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01611170545220375, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:56.9475155Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01611170545220375, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:56.9476139Z     return dequantize_per_tensor_default_1
2026-01-14T09:00:56.9476444Z     
2026-01-14T09:00:56.9476756Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:56.9477166Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:56.9477425Z           [0., 0., 0.],
2026-01-14T09:00:56.9477665Z           [0., 0., 0.]],
2026-01-14T09:00:56.9477820Z 
2026-01-14T09:00:56.9477904Z          [[0., 0., 0.],
2026-01-14T09:00:56.9478135Z           [0., 0., 0.],
2026-01-14T09:00:56.9478355Z           [0., 0., 0.]],
2026-01-14T09:00:56.9478511Z 
2026-01-14T09:00:56.9478592Z          [[0., 0., 0.],
2026-01-14T09:00:56.9478815Z           [0., 0., 0.],
2026-01-14T09:00:56.9479051Z           [0., 0., 0.]]]])
2026-01-14T09:00:56.9479522Z [32mPASSED[0m
2026-01-14T09:00:56.9480185Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_cuda model pt2e: GraphModule(
2026-01-14T09:00:56.9480892Z   (conv): Module()
2026-01-14T09:00:56.9481106Z   (bn): Module()
2026-01-14T09:00:56.9481430Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:56.9482887Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:56.9484365Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:56.9484918Z   )
2026-01-14T09:00:56.9485208Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:56.9486567Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:56.9488360Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:00:56.9489170Z   )
2026-01-14T09:00:56.9489473Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:56.9490738Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0165], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:56.9492194Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1394810676574707, max_val=2.0564441680908203)
2026-01-14T09:00:56.9492754Z   )
2026-01-14T09:00:56.9492930Z )
2026-01-14T09:00:56.9493039Z 
2026-01-14T09:00:56.9493424Z 
2026-01-14T09:00:56.9493430Z 
2026-01-14T09:00:56.9493525Z def forward(self, x):
2026-01-14T09:00:56.9493834Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:56.9494211Z     conv_weight = self.conv.weight
2026-01-14T09:00:56.9494504Z     conv_bias = self.conv.bias
2026-01-14T09:00:56.9494770Z     bn_weight = self.bn.weight
2026-01-14T09:00:56.9495087Z     bn_bias = self.bn.bias
2026-01-14T09:00:56.9495355Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:00:56.9495677Z     bn_running_var = self.bn.running_var
2026-01-14T09:00:56.9496047Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:56.9496513Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:56.9497157Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:56.9497742Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:00:56.9498168Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:56.9498606Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:56.9499084Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:00:56.9499639Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:56.9500247Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:56.9500917Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:00:56.9501983Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:00:56.9502967Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:00:56.9503561Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:00:56.9504195Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:00:56.9504807Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:00:56.9505853Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:56.9506926Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:56.9507574Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:56.9507995Z     
2026-01-14T09:00:56.9508296Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:56.9508688Z model fx: GraphModule(
2026-01-14T09:00:56.9509034Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:56.9510369Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:56.9511832Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:56.9512384Z   )
2026-01-14T09:00:56.9512570Z   (conv): ConvBn2d(
2026-01-14T09:00:56.9512812Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:00:56.9513254Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:56.9513776Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:56.9515183Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:56.9516978Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:00:56.9517847Z     )
2026-01-14T09:00:56.9518023Z   )
2026-01-14T09:00:56.9518324Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:56.9519595Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0165], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:56.9521045Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1394810676574707, max_val=2.0564441680908203)
2026-01-14T09:00:56.9521612Z   )
2026-01-14T09:00:56.9521791Z )
2026-01-14T09:00:56.9521902Z 
2026-01-14T09:00:56.9521906Z 
2026-01-14T09:00:56.9521910Z 
2026-01-14T09:00:56.9521998Z def forward(self, x):
2026-01-14T09:00:56.9522376Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:14.0768098Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:14.0768805Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:01:14.0769293Z     return activation_post_process_1
2026-01-14T09:01:14.0769587Z     
2026-01-14T09:01:14.0769906Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:14.0770325Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:01:14.0770580Z           [0., 0., 0.],
2026-01-14T09:01:14.0770813Z           [0., 0., 0.]],
2026-01-14T09:01:14.0770964Z 
2026-01-14T09:01:14.0771047Z          [[0., 0., 0.],
2026-01-14T09:01:14.0771279Z           [0., 0., 0.],
2026-01-14T09:01:14.0771521Z           [0., 0., 0.]],
2026-01-14T09:01:14.0771672Z 
2026-01-14T09:01:14.0771758Z          [[0., 0., 0.],
2026-01-14T09:01:14.0771990Z           [0., 0., 0.],
2026-01-14T09:01:14.0772546Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:01:14.0772923Z converted model pt2e: GraphModule(
2026-01-14T09:01:14.0773208Z   (conv): Module()
2026-01-14T09:01:14.0773436Z   (bn): Module()
2026-01-14T09:01:14.0773644Z )
2026-01-14T09:01:14.0773758Z 
2026-01-14T09:01:14.0773763Z 
2026-01-14T09:01:14.0773767Z 
2026-01-14T09:01:14.0773857Z def forward(self, x):
2026-01-14T09:01:14.0774170Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:14.0774536Z     conv_bias = self.conv.bias
2026-01-14T09:01:14.0775253Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:01:14.0776624Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:14.0777585Z     _scale_0 = self._scale_0
2026-01-14T09:01:14.0777859Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:01:14.0778178Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:01:14.0779163Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:01:14.0780675Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:01:14.0782012Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.016454609110951424, 2, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:01:14.0783611Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016454609110951424, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:14.0784730Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:01:14.0785254Z     
2026-01-14T09:01:14.0785549Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:14.0785963Z onverted model fx: GraphModule(
2026-01-14T09:01:14.0786390Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:01:14.0786799Z )
2026-01-14T09:01:14.0786905Z 
2026-01-14T09:01:14.0786910Z 
2026-01-14T09:01:14.0786914Z 
2026-01-14T09:01:14.0787001Z def forward(self, x):
2026-01-14T09:01:14.0787677Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:01:14.0789049Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:14.0790169Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:14.0791104Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016454609110951424, 2, -128, 127, torch.int8);  conv = None
2026-01-14T09:01:14.0792497Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016454609110951424, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:14.0793471Z     return dequantize_per_tensor_default_1
2026-01-14T09:01:14.0793856Z     
2026-01-14T09:01:14.0794267Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:14.0794797Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:01:14.0795106Z           [0., 0., 0.],
2026-01-14T09:01:14.0795359Z           [0., 0., 0.]],
2026-01-14T09:01:14.0795509Z 
2026-01-14T09:01:14.0795657Z          [[0., 0., 0.],
2026-01-14T09:01:14.0795882Z           [0., 0., 0.],
2026-01-14T09:01:14.0796104Z           [0., 0., 0.]],
2026-01-14T09:01:14.0796266Z 
2026-01-14T09:01:14.0796346Z          [[0., 0., 0.],
2026-01-14T09:01:14.0796558Z           [0., 0., 0.],
2026-01-14T09:01:14.0796796Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:01:14.0797092Z model pt2e: GraphModule(
2026-01-14T09:01:14.0797330Z   (conv): Module()
2026-01-14T09:01:14.0797543Z   (bn): Module()
2026-01-14T09:01:14.0797852Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:14.0799163Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:14.0800645Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:01:14.0801207Z   )
2026-01-14T09:01:14.0801507Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:14.0802893Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:14.0804400Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:01:14.0805214Z   )
2026-01-14T09:01:14.0805560Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:14.0806947Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0164], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:14.0808407Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.137371778488159, max_val=2.0522286891937256)
2026-01-14T09:01:14.0809038Z   )
2026-01-14T09:01:14.0809207Z )
2026-01-14T09:01:14.0809312Z 
2026-01-14T09:01:14.0809316Z 
2026-01-14T09:01:14.0809320Z 
2026-01-14T09:01:14.0809406Z def forward(self, x):
2026-01-14T09:01:14.0809711Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:14.0810076Z     conv_weight = self.conv.weight
2026-01-14T09:01:14.0810364Z     conv_bias = self.conv.bias
2026-01-14T09:01:14.0810626Z     bn_weight = self.bn.weight
2026-01-14T09:01:14.0810889Z     bn_bias = self.bn.bias
2026-01-14T09:01:14.0811155Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:01:14.0811491Z     bn_running_var = self.bn.running_var
2026-01-14T09:01:14.0811849Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:01:14.0812318Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:14.0812968Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:01:14.0813552Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:01:14.0813974Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:14.0814414Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:01:14.0814953Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:01:14.0815501Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:01:14.0816256Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:01:14.0816974Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:01:14.0818066Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:01:14.0819132Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:01:14.0819741Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:01:14.0820385Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:01:14.0821011Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:01:14.0822014Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:01:14.0823100Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:01:14.0823758Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:01:14.0824183Z     
2026-01-14T09:01:14.0824494Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:14.0824897Z model fx: GraphModule(
2026-01-14T09:01:14.0825249Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:14.0826546Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:14.0828030Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:01:14.0828595Z   )
2026-01-14T09:01:14.0828870Z   (conv): ConvBn2d(
2026-01-14T09:01:14.0829128Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:01:14.0829575Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:14.0830112Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:14.0831390Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:39.6238833Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:01:39.6241062Z     )
2026-01-14T09:01:39.6241692Z   )
2026-01-14T09:01:39.6242096Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:39.6243845Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0164], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:39.6245752Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.137371778488159, max_val=2.0522286891937256)
2026-01-14T09:01:39.6246461Z   )
2026-01-14T09:01:39.6246680Z )
2026-01-14T09:01:39.6246845Z 
2026-01-14T09:01:39.6246851Z 
2026-01-14T09:01:39.6246855Z 
2026-01-14T09:01:39.6246964Z def forward(self, x):
2026-01-14T09:01:39.6247421Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:39.6248127Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:39.6248862Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:01:39.6249425Z     return activation_post_process_1
2026-01-14T09:01:39.6249761Z     
2026-01-14T09:01:39.6250123Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:39.6250615Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:01:39.6251200Z           [0., 0., 0.],
2026-01-14T09:01:39.6251467Z           [0., 0., 0.]],
2026-01-14T09:01:39.6251647Z 
2026-01-14T09:01:39.6251755Z          [[0., 0., 0.],
2026-01-14T09:01:39.6252046Z           [0., 0., 0.],
2026-01-14T09:01:39.6252340Z           [0., 0., 0.]],
2026-01-14T09:01:39.6252517Z 
2026-01-14T09:01:39.6252615Z          [[0., 0., 0.],
2026-01-14T09:01:39.6252885Z           [0., 0., 0.],
2026-01-14T09:01:39.6253233Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:01:39.6253686Z converted model pt2e: GraphModule(
2026-01-14T09:01:39.6254026Z   (conv): Module()
2026-01-14T09:01:39.6254276Z   (bn): Module()
2026-01-14T09:01:39.6254523Z )
2026-01-14T09:01:39.6254648Z 
2026-01-14T09:01:39.6254653Z 
2026-01-14T09:01:39.6254658Z 
2026-01-14T09:01:39.6254772Z def forward(self, x):
2026-01-14T09:01:39.6255147Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:39.6255586Z     conv_bias = self.conv.bias
2026-01-14T09:01:39.6256478Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:01:39.6258238Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:39.6259565Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:01:39.6260450Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:01:39.6262013Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:01:39.6263337Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.016429806128144264, 2, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:01:39.6264768Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.016429806128144264, 2, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:01:39.6265941Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:01:39.6266386Z     
2026-01-14T09:01:39.6266681Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:39.6267077Z onverted model fx: GraphModule(
2026-01-14T09:01:39.6267476Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:01:39.6267872Z )
2026-01-14T09:01:39.6267970Z 
2026-01-14T09:01:39.6267980Z 
2026-01-14T09:01:39.6267990Z 
2026-01-14T09:01:39.6268075Z def forward(self, x):
2026-01-14T09:01:39.6268737Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:01:39.6270102Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:39.6271215Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:39.6272134Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016429806128144264, 2, -128, 127, torch.int8);  conv = None
2026-01-14T09:01:39.6273538Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016429806128144264, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:39.6274502Z     return dequantize_per_tensor_default_1
2026-01-14T09:01:39.6274779Z     
2026-01-14T09:01:39.6275074Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:39.6275546Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:01:39.6275793Z           [0., 0., 0.],
2026-01-14T09:01:39.6276009Z           [0., 0., 0.]],
2026-01-14T09:01:39.6276166Z 
2026-01-14T09:01:39.6276246Z          [[0., 0., 0.],
2026-01-14T09:01:39.6276460Z           [0., 0., 0.],
2026-01-14T09:01:39.6276677Z           [0., 0., 0.]],
2026-01-14T09:01:39.6276821Z 
2026-01-14T09:01:39.6276904Z          [[0., 0., 0.],
2026-01-14T09:01:39.6277109Z           [0., 0., 0.],
2026-01-14T09:01:39.6277348Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:01:39.6277835Z [32mPASSED[0m
2026-01-14T09:01:39.6278590Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T09:01:39.6279418Z   (conv): Module()
2026-01-14T09:01:39.6279638Z   (bn): Module()
2026-01-14T09:01:39.6279978Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:39.6281270Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:39.6282845Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:39.6283387Z   )
2026-01-14T09:01:39.6283683Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:39.6284803Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:39.6286357Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1774, -0.1913]), max_val=tensor([0.1806, 0.1870, 0.1478]))
2026-01-14T09:01:39.6287061Z   )
2026-01-14T09:01:39.6287343Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:39.6288394Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0279]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:39.6289668Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.481316328048706, max_val=3.622279405593872)
2026-01-14T09:01:39.6290211Z   )
2026-01-14T09:01:39.6290382Z )
2026-01-14T09:01:39.6290479Z 
2026-01-14T09:01:39.6290483Z 
2026-01-14T09:01:39.6290487Z 
2026-01-14T09:01:39.6290572Z def forward(self, x):
2026-01-14T09:01:39.6290875Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:39.6291238Z     conv_weight = self.conv.weight
2026-01-14T09:01:39.6291526Z     conv_bias = self.conv.bias
2026-01-14T09:01:39.6291790Z     bn_weight = self.bn.weight
2026-01-14T09:01:39.6292043Z     bn_bias = self.bn.bias
2026-01-14T09:01:39.6292317Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:01:39.6292623Z     bn_running_var = self.bn.running_var
2026-01-14T09:01:39.6292978Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:01:39.6293439Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:39.6294091Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:01:39.6294663Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:01:39.6295082Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:39.6295518Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:01:39.6295990Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:01:39.6296541Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:01:39.6297145Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:01:39.6297869Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:01:39.6298982Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:01:39.6299983Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:01:39.6300572Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:01:39.6301202Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:01:39.6301819Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:01:39.6302824Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:01:39.6303888Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:01:39.6304533Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:01:39.6304942Z     
2026-01-14T09:01:39.6305245Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:39.6305629Z model fx: GraphModule(
2026-01-14T09:01:39.6305970Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:39.6307119Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:39.6308384Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:39.6316668Z   )
2026-01-14T09:01:39.6316868Z   (conv): ConvBn2d(
2026-01-14T09:01:59.5487888Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T09:01:59.5488919Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:59.5489597Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:59.5491015Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:59.5492942Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1774, -0.1913]), max_val=tensor([0.1806, 0.1870, 0.1478]))
2026-01-14T09:01:59.5493886Z     )
2026-01-14T09:01:59.5494123Z   )
2026-01-14T09:01:59.5494489Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:59.5495843Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0279]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:59.5497433Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.481316328048706, max_val=3.622279405593872)
2026-01-14T09:01:59.5498136Z   )
2026-01-14T09:01:59.5498369Z )
2026-01-14T09:01:59.5498497Z 
2026-01-14T09:01:59.5498502Z 
2026-01-14T09:01:59.5498507Z 
2026-01-14T09:01:59.5498625Z def forward(self, x):
2026-01-14T09:01:59.5499085Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:59.5499809Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:59.5500557Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:01:59.5501142Z     return activation_post_process_1
2026-01-14T09:01:59.5501483Z     
2026-01-14T09:01:59.5501967Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:59.5502481Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5502839Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5503175Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5503496Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5503818Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5504140Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:59.5504375Z 
2026-01-14T09:01:59.5504479Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5504795Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5505118Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5505440Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5505754Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5506082Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:59.5506303Z 
2026-01-14T09:01:59.5506405Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5506733Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5507044Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5507364Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5507679Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5508067Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:01:59.5508504Z converted model pt2e: GraphModule(
2026-01-14T09:01:59.5508841Z   (conv): Module()
2026-01-14T09:01:59.5509105Z   (bn): Module()
2026-01-14T09:01:59.5509349Z )
2026-01-14T09:01:59.5509472Z 
2026-01-14T09:01:59.5509488Z 
2026-01-14T09:01:59.5509493Z 
2026-01-14T09:01:59.5509600Z def forward(self, x):
2026-01-14T09:01:59.5509963Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:59.5510407Z     conv_bias = self.conv.bias
2026-01-14T09:01:59.5511474Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:01:59.5513240Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:59.5514490Z     _scale_0 = self._scale_0
2026-01-14T09:01:59.5514814Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:01:59.5515217Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:01:59.5516463Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:01:59.5518425Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:01:59.5520169Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.027857238426804543, -3, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:01:59.5522014Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.027857238426804543, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:59.5523537Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:01:59.5524105Z     
2026-01-14T09:01:59.5524463Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:59.5524969Z onverted model fx: GraphModule(
2026-01-14T09:01:59.5525533Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T09:01:59.5526117Z )
2026-01-14T09:01:59.5526240Z 
2026-01-14T09:01:59.5526252Z 
2026-01-14T09:01:59.5526257Z 
2026-01-14T09:01:59.5526382Z def forward(self, x):
2026-01-14T09:01:59.5527259Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:01:59.5528962Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:59.5530088Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:59.5531042Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.027857238426804543, -3, -128, 127, torch.int8);  conv = None
2026-01-14T09:01:59.5532465Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.027857238426804543, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:59.5533445Z     return dequantize_per_tensor_default_1
2026-01-14T09:01:59.5533744Z     
2026-01-14T09:01:59.5534046Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:59.5534469Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5534767Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5535032Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5535300Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5535561Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5535832Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:59.5536018Z 
2026-01-14T09:01:59.5536103Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5536378Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5536641Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5536910Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5537177Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5537532Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:59.5537736Z 
2026-01-14T09:01:59.5537833Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5538113Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5538399Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5538675Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5539149Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:59.5539415Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T09:01:59.5539705Z model pt2e: GraphModule(
2026-01-14T09:01:59.5539957Z   (conv): Module()
2026-01-14T09:01:59.5540173Z   (bn): Module()
2026-01-14T09:01:59.5540495Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:59.5541567Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:59.5542917Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:59.5543477Z   )
2026-01-14T09:01:59.5543781Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:59.5544870Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:59.5546136Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T09:01:59.5546701Z   )
2026-01-14T09:01:59.5546989Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:59.5548101Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0278]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:59.5549352Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4796082973480225, max_val=3.620413064956665)
2026-01-14T09:01:59.5549900Z   )
2026-01-14T09:01:59.5551294Z )
2026-01-14T09:01:59.5551396Z 
2026-01-14T09:01:59.5551401Z 
2026-01-14T09:01:59.5551405Z 
2026-01-14T09:01:59.5551493Z def forward(self, x):
2026-01-14T09:01:59.5551814Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:59.5552191Z     conv_weight = self.conv.weight
2026-01-14T09:01:59.5552478Z     conv_bias = self.conv.bias
2026-01-14T09:01:59.5552754Z     bn_weight = self.bn.weight
2026-01-14T09:01:59.5553018Z     bn_bias = self.bn.bias
2026-01-14T09:01:59.5553299Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:01:59.5553615Z     bn_running_var = self.bn.running_var
2026-01-14T09:01:59.5553977Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:01:59.5554445Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:59.5555094Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:01:59.5555690Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:01:59.5556117Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:59.5556574Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:01:59.5557053Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:01:59.5557603Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:01:59.5558218Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:01:59.5558895Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:01:59.5560203Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:02:22.3967208Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:02:22.3970168Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:02:22.3971021Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:02:22.3972106Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:02:22.3973360Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:02:22.3974713Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:02:22.3975925Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:02:22.3976453Z     
2026-01-14T09:02:22.3976838Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:22.3977405Z model fx: GraphModule(
2026-01-14T09:02:22.3977861Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:22.3979199Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:22.3980786Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:02:22.3981488Z   )
2026-01-14T09:02:22.3981721Z   (conv): ConvBn2d(
2026-01-14T09:02:22.3982058Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T09:02:22.3982659Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:22.3983298Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:22.3984612Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:02:22.3986318Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T09:02:22.3987025Z     )
2026-01-14T09:02:22.3987248Z   )
2026-01-14T09:02:22.3987596Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:22.3988921Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0278]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:22.3990488Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4796082973480225, max_val=3.620413064956665)
2026-01-14T09:02:22.3991174Z   )
2026-01-14T09:02:22.3991410Z )
2026-01-14T09:02:22.3991536Z 
2026-01-14T09:02:22.3991541Z 
2026-01-14T09:02:22.3991546Z 
2026-01-14T09:02:22.3991655Z def forward(self, x):
2026-01-14T09:02:22.3992114Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:22.3992821Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:02:22.3993554Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:02:22.3994127Z     return activation_post_process_1
2026-01-14T09:02:22.3994454Z     
2026-01-14T09:02:22.3994812Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:22.3995304Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.3995661Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.3995975Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.3996296Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.3996605Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.3998749Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:02:22.3998986Z 
2026-01-14T09:02:22.3999096Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.3999411Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.3999724Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4000032Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4000407Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4000734Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:02:22.4000952Z 
2026-01-14T09:02:22.4001054Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4001368Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4001679Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4001995Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4002309Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4002821Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:02:22.4003257Z converted model pt2e: GraphModule(
2026-01-14T09:02:22.4003628Z   (conv): Module()
2026-01-14T09:02:22.4003906Z   (bn): Module()
2026-01-14T09:02:22.4004158Z )
2026-01-14T09:02:22.4004315Z 
2026-01-14T09:02:22.4004320Z 
2026-01-14T09:02:22.4004328Z 
2026-01-14T09:02:22.4004465Z def forward(self, x):
2026-01-14T09:02:22.4004803Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:22.4005177Z     conv_bias = self.conv.bias
2026-01-14T09:02:22.4005887Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:02:22.4007269Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:22.4008265Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:02:22.4009138Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0015061007579788566, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:02:22.4010574Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:02:22.4011990Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.02784322015941143, -3, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:02:22.4013416Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.02784322015941143, -3, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:02:22.4014524Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:02:22.4014965Z     
2026-01-14T09:02:22.4015261Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:22.4015676Z onverted model fx: GraphModule(
2026-01-14T09:02:22.4016132Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T09:02:22.4016595Z )
2026-01-14T09:02:22.4016696Z 
2026-01-14T09:02:22.4016700Z 
2026-01-14T09:02:22.4016704Z 
2026-01-14T09:02:22.4016800Z def forward(self, x):
2026-01-14T09:02:22.4017476Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:02:22.4018857Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:22.4019976Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:02:22.4021001Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.02784322015941143, -3, -128, 127, torch.int8);  conv = None
2026-01-14T09:02:22.4022409Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.02784322015941143, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:22.4023382Z     return dequantize_per_tensor_default_1
2026-01-14T09:02:22.4023724Z     
2026-01-14T09:02:22.4024023Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:22.4024438Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4024730Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4024992Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4025256Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4025516Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4025780Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:02:22.4025960Z 
2026-01-14T09:02:22.4026045Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4026313Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4026574Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4026844Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4027104Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4027369Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:02:22.4027549Z 
2026-01-14T09:02:22.4027645Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4027901Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4028166Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4028425Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4028697Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:02:22.4028956Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T09:02:22.4029460Z [32mPASSED[0m
2026-01-14T09:02:22.4030114Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T09:02:22.4030820Z   (conv): Module()
2026-01-14T09:02:22.4031046Z   (bn): Module()
2026-01-14T09:02:22.4031366Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:22.4032450Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:22.4033769Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:22.4034356Z   )
2026-01-14T09:02:22.4034687Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:22.4035819Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:22.4037293Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:02:22.4037994Z   )
2026-01-14T09:02:22.4038292Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:22.4039767Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:22.4041024Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1459269523620605, max_val=2.376943349838257)
2026-01-14T09:02:22.4041578Z   )
2026-01-14T09:02:22.4041748Z )
2026-01-14T09:02:22.4041854Z 
2026-01-14T09:02:22.4041858Z 
2026-01-14T09:02:22.4041862Z 
2026-01-14T09:02:22.4041949Z def forward(self, x):
2026-01-14T09:02:42.2871665Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:42.2872171Z     conv_weight = self.conv.weight
2026-01-14T09:02:42.2872876Z     bn_weight = self.bn.weight
2026-01-14T09:02:42.2873219Z     bn_bias = self.bn.bias
2026-01-14T09:02:42.2873551Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:02:42.2873934Z     bn_running_var = self.bn.running_var
2026-01-14T09:02:42.2874379Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:02:42.2874959Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:42.2875868Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:02:42.2876589Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:02:42.2877104Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:02:42.2877650Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:02:42.2878235Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:02:42.2878920Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:02:42.2879692Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:02:42.2880857Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:02:42.2882022Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:02:42.2882863Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:02:42.2884150Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:02:42.2885484Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:02:42.2886294Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:02:42.2886822Z     
2026-01-14T09:02:42.2887186Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:42.2887672Z model fx: GraphModule(
2026-01-14T09:02:42.2888188Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:42.2889521Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:42.2891168Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:42.2891866Z   )
2026-01-14T09:02:42.2892092Z   (conv): ConvBn2d(
2026-01-14T09:02:42.2892421Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:02:42.2893003Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:42.2893639Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:42.2895015Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:42.2896883Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:02:42.2897771Z     )
2026-01-14T09:02:42.2897986Z   )
2026-01-14T09:02:42.2898341Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:42.2899662Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:42.2901325Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1459269523620605, max_val=2.376943349838257)
2026-01-14T09:02:42.2902022Z   )
2026-01-14T09:02:42.2902245Z )
2026-01-14T09:02:42.2902369Z 
2026-01-14T09:02:42.2902374Z 
2026-01-14T09:02:42.2902388Z 
2026-01-14T09:02:42.2902498Z def forward(self, x):
2026-01-14T09:02:42.2902948Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:42.2903711Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:02:42.2904446Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:02:42.2905008Z     return activation_post_process_1
2026-01-14T09:02:42.2905349Z     
2026-01-14T09:02:42.2905699Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:42.2906188Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:42.2906491Z           [0., 0., 0.],
2026-01-14T09:02:42.2906766Z           [0., 0., 0.]],
2026-01-14T09:02:42.2906945Z 
2026-01-14T09:02:42.2907042Z          [[0., 0., 0.],
2026-01-14T09:02:42.2907317Z           [0., 0., 0.],
2026-01-14T09:02:42.2907578Z           [0., 0., 0.]],
2026-01-14T09:02:42.2907763Z 
2026-01-14T09:02:42.2907858Z          [[0., 0., 0.],
2026-01-14T09:02:42.2908124Z           [0., 0., 0.],
2026-01-14T09:02:42.2908385Z           [0., 0., 0.]]],
2026-01-14T09:02:42.2908565Z 
2026-01-14T09:02:42.2908570Z 
2026-01-14T09:02:42.2908677Z         [[[0., 0., 0.],
2026-01-14T09:02:42.2908935Z           [0., 0., 0.],
2026-01-14T09:02:42.2909201Z           [0., 0., 0.]],
2026-01-14T09:02:42.2909389Z 
2026-01-14T09:02:42.2909497Z          [[0., 0., 0.],
2026-01-14T09:02:42.2909785Z           [0., 0., 0.],
2026-01-14T09:02:42.2910044Z           [0., 0., 0.]],
2026-01-14T09:02:42.2910227Z 
2026-01-14T09:02:42.2910323Z          [[0., 0., 0.],
2026-01-14T09:02:42.2910586Z           [0., 0., 0.],
2026-01-14T09:02:42.2910846Z           [0., 0., 0.]]],
2026-01-14T09:02:42.2911025Z 
2026-01-14T09:02:42.2911030Z 
2026-01-14T09:02:42.2911135Z         [[[0., 0., 0.],
2026-01-14T09:02:42.2911404Z           [0., 0., 0.],
2026-01-14T09:02:42.2911671Z           [0., 0., 0.]],
2026-01-14T09:02:42.2911847Z 
2026-01-14T09:02:42.2911943Z          [[0., 0., 0.],
2026-01-14T09:02:42.2912272Z           [0., 0., 0.],
2026-01-14T09:02:42.2912540Z           [0., 0., 0.]],
2026-01-14T09:02:42.2912721Z 
2026-01-14T09:02:42.2912817Z          [[0., 0., 0.],
2026-01-14T09:02:42.2913082Z           [0., 0., 0.],
2026-01-14T09:02:42.2913383Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:02:42.2913810Z converted model pt2e: GraphModule(
2026-01-14T09:02:42.2914159Z   (conv): Module()
2026-01-14T09:02:42.2914423Z   (bn): Module()
2026-01-14T09:02:42.2914668Z )
2026-01-14T09:02:42.2914798Z 
2026-01-14T09:02:42.2914803Z 
2026-01-14T09:02:42.2914808Z 
2026-01-14T09:02:42.2914918Z def forward(self, x):
2026-01-14T09:02:42.2915250Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:42.2916043Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:42.2917426Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:42.2918369Z     _scale_0 = self._scale_0
2026-01-14T09:02:42.2918641Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:02:42.2918963Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:02:42.2919993Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:02:42.2920986Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:02:42.2922010Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:02:42.2923488Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01773674599826336, -7, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:02:42.2924918Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01773674599826336, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:42.2926066Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:02:42.2926512Z     
2026-01-14T09:02:42.2926807Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:42.2927221Z onverted model fx: GraphModule(
2026-01-14T09:02:42.2927637Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:02:42.2928043Z )
2026-01-14T09:02:42.2928146Z 
2026-01-14T09:02:42.2928150Z 
2026-01-14T09:02:42.2928160Z 
2026-01-14T09:02:42.2928258Z def forward(self, x):
2026-01-14T09:02:42.2928931Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:42.2930295Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:42.2931416Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:02:42.2932349Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01773674599826336, -7, -128, 127, torch.int8);  conv = None
2026-01-14T09:02:42.2933764Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01773674599826336, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:42.2934740Z     return dequantize_per_tensor_default_1
2026-01-14T09:02:42.2935031Z     
2026-01-14T09:02:42.2935332Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:42.2935786Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:42.2936044Z           [0., 0., 0.],
2026-01-14T09:02:42.2936277Z           [0., 0., 0.]],
2026-01-14T09:02:42.2936432Z 
2026-01-14T09:02:42.2936512Z          [[0., 0., 0.],
2026-01-14T09:02:42.2936731Z           [0., 0., 0.],
2026-01-14T09:02:42.2936955Z           [0., 0., 0.]],
2026-01-14T09:02:42.2937102Z 
2026-01-14T09:02:42.2937185Z          [[0., 0., 0.],
2026-01-14T09:02:42.2937409Z           [0., 0., 0.],
2026-01-14T09:02:42.2937632Z           [0., 0., 0.]]],
2026-01-14T09:02:42.2937799Z 
2026-01-14T09:02:42.2937803Z 
2026-01-14T09:02:42.2937891Z         [[[0., 0., 0.],
2026-01-14T09:02:42.2938108Z           [0., 0., 0.],
2026-01-14T09:02:42.2948490Z           [0., 0., 0.]],
2026-01-14T09:02:42.2948696Z 
2026-01-14T09:02:42.2948822Z          [[0., 0., 0.],
2026-01-14T09:02:42.2949072Z           [0., 0., 0.],
2026-01-14T09:02:42.2949314Z           [0., 0., 0.]],
2026-01-14T09:02:42.2949470Z 
2026-01-14T09:02:42.2949550Z          [[0., 0., 0.],
2026-01-14T09:02:42.2949838Z           [0., 0., 0.],
2026-01-14T09:02:42.2950110Z           [0., 0., 0.]]],
2026-01-14T09:02:42.2950316Z 
2026-01-14T09:02:42.2950321Z 
2026-01-14T09:02:42.2950406Z         [[[0., 0., 0.],
2026-01-14T09:02:42.2950676Z           [0., 0., 0.],
2026-01-14T09:02:42.2950901Z           [0., 0., 0.]],
2026-01-14T09:02:42.2951051Z 
2026-01-14T09:02:42.2951141Z          [[0., 0., 0.],
2026-01-14T09:02:42.2951364Z           [0., 0., 0.],
2026-01-14T09:02:42.2951596Z           [0., 0., 0.]],
2026-01-14T09:02:42.2951747Z 
2026-01-14T09:02:42.2951830Z          [[0., 0., 0.],
2026-01-14T09:02:42.2952062Z           [0., 0., 0.],
2026-01-14T09:02:42.2952295Z           [0., 0., 0.]]]])
2026-01-14T09:02:42.2952560Z model pt2e: GraphModule(
2026-01-14T09:02:42.2952984Z   (conv): Module()
2026-01-14T09:02:42.2953216Z   (bn): Module()
2026-01-14T09:02:42.2953548Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:42.2954626Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:42.2955942Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:56.5616941Z   )
2026-01-14T09:02:56.5617962Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:56.5619109Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:02:56.5620508Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:02:56.5621082Z   )
2026-01-14T09:02:56.5621379Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:56.5622450Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:56.5623719Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1475415229797363, max_val=2.368046283721924)
2026-01-14T09:02:56.5624303Z   )
2026-01-14T09:02:56.5624491Z )
2026-01-14T09:02:56.5624604Z 
2026-01-14T09:02:56.5624608Z 
2026-01-14T09:02:56.5624612Z 
2026-01-14T09:02:56.5624705Z def forward(self, x):
2026-01-14T09:02:56.5625013Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:56.5625379Z     conv_weight = self.conv.weight
2026-01-14T09:02:56.5625682Z     bn_weight = self.bn.weight
2026-01-14T09:02:56.5625947Z     bn_bias = self.bn.bias
2026-01-14T09:02:56.5626229Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:02:56.5626542Z     bn_running_var = self.bn.running_var
2026-01-14T09:02:56.5627218Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:02:56.5627694Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:56.5628339Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:02:56.5628934Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:02:56.5629351Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:02:56.5629797Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:02:56.5630271Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:02:56.5630824Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:02:56.5631443Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:02:56.5632359Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:02:56.5633282Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:02:56.5633875Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:02:56.5634906Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:02:56.5635977Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:02:56.5636620Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:02:56.5637218Z     
2026-01-14T09:02:56.5637520Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:56.5637922Z model fx: GraphModule(
2026-01-14T09:02:56.5638261Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:56.5639647Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:56.5641013Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:56.5641564Z   )
2026-01-14T09:02:56.5641755Z   (conv): ConvBn2d(
2026-01-14T09:02:56.5642022Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:02:56.5642507Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:56.5643132Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:56.5644188Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:02:56.5645470Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:02:56.5646040Z     )
2026-01-14T09:02:56.5646243Z   )
2026-01-14T09:02:56.5646536Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:56.5647605Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:56.5648857Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1475415229797363, max_val=2.368046283721924)
2026-01-14T09:02:56.5649415Z   )
2026-01-14T09:02:56.5649603Z )
2026-01-14T09:02:56.5649710Z 
2026-01-14T09:02:56.5649715Z 
2026-01-14T09:02:56.5649719Z 
2026-01-14T09:02:56.5649812Z def forward(self, x):
2026-01-14T09:02:56.5650308Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:56.5650901Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:02:56.5651494Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:02:56.5651974Z     return activation_post_process_1
2026-01-14T09:02:56.5652257Z     
2026-01-14T09:02:56.5652555Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:56.5652969Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:56.5653224Z           [0., 0., 0.],
2026-01-14T09:02:56.5653455Z           [0., 0., 0.]],
2026-01-14T09:02:56.5653606Z 
2026-01-14T09:02:56.5653693Z          [[0., 0., 0.],
2026-01-14T09:02:56.5653923Z           [0., 0., 0.],
2026-01-14T09:02:56.5654149Z           [0., 0., 0.]],
2026-01-14T09:02:56.5654308Z 
2026-01-14T09:02:56.5654388Z          [[0., 0., 0.],
2026-01-14T09:02:56.5654614Z           [0., 0., 0.],
2026-01-14T09:02:56.5654835Z           [0., 0., 0.]]],
2026-01-14T09:02:56.5654986Z 
2026-01-14T09:02:56.5654990Z 
2026-01-14T09:02:56.5655083Z         [[[0., 0., 0.],
2026-01-14T09:02:56.5655303Z           [0., 0., 0.],
2026-01-14T09:02:56.5655528Z           [0., 0., 0.]],
2026-01-14T09:02:56.5655675Z 
2026-01-14T09:02:56.5655754Z          [[0., 0., 0.],
2026-01-14T09:02:56.5655975Z           [0., 0., 0.],
2026-01-14T09:02:56.5656192Z           [0., 0., 0.]],
2026-01-14T09:02:56.5656347Z 
2026-01-14T09:02:56.5656429Z          [[0., 0., 0.],
2026-01-14T09:02:56.5656651Z           [0., 0., 0.],
2026-01-14T09:02:56.5656869Z           [0., 0., 0.]]],
2026-01-14T09:02:56.5657018Z 
2026-01-14T09:02:56.5657023Z 
2026-01-14T09:02:56.5657110Z         [[[0., 0., 0.],
2026-01-14T09:02:56.5657344Z           [0., 0., 0.],
2026-01-14T09:02:56.5657698Z           [0., 0., 0.]],
2026-01-14T09:02:56.5657858Z 
2026-01-14T09:02:56.5657937Z          [[0., 0., 0.],
2026-01-14T09:02:56.5658150Z           [0., 0., 0.],
2026-01-14T09:02:56.5658379Z           [0., 0., 0.]],
2026-01-14T09:02:56.5658525Z 
2026-01-14T09:02:56.5658616Z          [[0., 0., 0.],
2026-01-14T09:02:56.5658831Z           [0., 0., 0.],
2026-01-14T09:02:56.5659144Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:02:56.5659473Z converted model pt2e: GraphModule(
2026-01-14T09:02:56.5659755Z   (conv): Module()
2026-01-14T09:02:56.5659968Z   (bn): Module()
2026-01-14T09:02:56.5660177Z )
2026-01-14T09:02:56.5660280Z 
2026-01-14T09:02:56.5660284Z 
2026-01-14T09:02:56.5660288Z 
2026-01-14T09:02:56.5660386Z def forward(self, x):
2026-01-14T09:02:56.5660691Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:56.5661496Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:56.5662867Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:56.5663851Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:02:56.5664729Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:02:56.5665605Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:02:56.5666527Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:02:56.5667918Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01770818792283535, -7, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:02:56.5669354Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01770818792283535, -7, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:02:56.5670524Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:02:56.5670971Z     
2026-01-14T09:02:56.5671277Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:56.5671686Z onverted model fx: GraphModule(
2026-01-14T09:02:56.5672102Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:02:56.5672511Z )
2026-01-14T09:02:56.5672624Z 
2026-01-14T09:02:56.5672628Z 
2026-01-14T09:02:56.5672632Z 
2026-01-14T09:02:56.5672726Z def forward(self, x):
2026-01-14T09:02:56.5673408Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:56.5674776Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:56.5675896Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:02:56.5676834Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01770818792283535, -7, -128, 127, torch.int8);  conv = None
2026-01-14T09:02:56.5678233Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01770818792283535, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:56.5679212Z     return dequantize_per_tensor_default_1
2026-01-14T09:02:56.5679500Z     
2026-01-14T09:02:56.5679810Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:56.5680295Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:56.5680552Z           [0., 0., 0.],
2026-01-14T09:02:56.5680780Z           [0., 0., 0.]],
2026-01-14T09:02:56.5680932Z 
2026-01-14T09:02:56.5681015Z          [[0., 0., 0.],
2026-01-14T09:02:56.5681238Z           [0., 0., 0.],
2026-01-14T09:02:56.5681457Z           [0., 0., 0.]],
2026-01-14T09:02:56.5681662Z 
2026-01-14T09:02:56.5681748Z          [[0., 0., 0.],
2026-01-14T09:02:56.5681967Z           [0., 0., 0.],
2026-01-14T09:02:56.5682201Z           [0., 0., 0.]]],
2026-01-14T09:02:56.5682352Z 
2026-01-14T09:02:56.5682356Z 
2026-01-14T09:02:56.5682441Z         [[[0., 0., 0.],
2026-01-14T09:02:56.5682710Z           [0., 0., 0.],
2026-01-14T09:02:56.5682942Z           [0., 0., 0.]],
2026-01-14T09:02:56.5683093Z 
2026-01-14T09:02:56.5683176Z          [[0., 0., 0.],
2026-01-14T09:02:56.5683400Z           [0., 0., 0.],
2026-01-14T09:02:56.5683617Z           [0., 0., 0.]],
2026-01-14T09:02:56.5683778Z 
2026-01-14T09:02:56.5683865Z          [[0., 0., 0.],
2026-01-14T09:02:56.5684081Z           [0., 0., 0.],
2026-01-14T09:02:56.5684308Z           [0., 0., 0.]]],
2026-01-14T09:02:56.5684458Z 
2026-01-14T09:02:59.4368997Z 
2026-01-14T09:02:59.4369418Z         [[[0., 0., 0.],
2026-01-14T09:02:59.4369689Z           [0., 0., 0.],
2026-01-14T09:02:59.4370010Z           [0., 0., 0.]],
2026-01-14T09:02:59.4370284Z 
2026-01-14T09:02:59.4370421Z          [[0., 0., 0.],
2026-01-14T09:02:59.4370727Z           [0., 0., 0.],
2026-01-14T09:02:59.4371036Z           [0., 0., 0.]],
2026-01-14T09:02:59.4371232Z 
2026-01-14T09:02:59.4371318Z          [[0., 0., 0.],
2026-01-14T09:02:59.4371548Z           [0., 0., 0.],
2026-01-14T09:02:59.4371778Z           [0., 0., 0.]]]])
2026-01-14T09:02:59.4372045Z model pt2e: GraphModule(
2026-01-14T09:02:59.4372304Z   (conv1): Module()
2026-01-14T09:02:59.4372524Z   (bn1): Module()
2026-01-14T09:02:59.4372754Z   (conv2): Module()
2026-01-14T09:02:59.4372976Z   (bn2): Module()
2026-01-14T09:02:59.4373316Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:59.4374407Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:59.4375925Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:59.4376504Z   )
2026-01-14T09:02:59.4376803Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:59.4377957Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:59.4379465Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1921, -0.1899, -0.1895]), max_val=tensor([0.1769, 0.1726, 0.1697]))
2026-01-14T09:02:59.4380167Z   )
2026-01-14T09:02:59.4380458Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:59.4381603Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:59.4383091Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:02:59.4383815Z   )
2026-01-14T09:02:59.4384107Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:59.4385203Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:59.4386611Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7323514223098755, max_val=2.7138354778289795)
2026-01-14T09:02:59.4387171Z   )
2026-01-14T09:02:59.4387467Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:59.4388535Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:59.4389868Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4053945541381836, max_val=1.4082176685333252)
2026-01-14T09:02:59.4390433Z   )
2026-01-14T09:02:59.4390604Z )
2026-01-14T09:02:59.4390702Z 
2026-01-14T09:02:59.4390707Z 
2026-01-14T09:02:59.4390720Z 
2026-01-14T09:02:59.4390806Z def forward(self, x):
2026-01-14T09:02:59.4391107Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:59.4391481Z     conv1_weight = self.conv1.weight
2026-01-14T09:02:59.4391783Z     bn1_weight = self.bn1.weight
2026-01-14T09:02:59.4392061Z     bn1_bias = self.bn1.bias
2026-01-14T09:02:59.4392330Z     conv2_weight = self.conv2.weight
2026-01-14T09:02:59.4392622Z     conv2_bias = self.conv2.bias
2026-01-14T09:02:59.4392900Z     bn2_weight = self.bn2.weight
2026-01-14T09:02:59.4393165Z     bn2_bias = self.bn2.bias
2026-01-14T09:02:59.4393454Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:02:59.4393777Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:02:59.4394143Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:02:59.4394513Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:02:59.4394838Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:02:59.4395201Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:02:59.4395677Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:59.4396350Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:02:59.4397111Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:02:59.4397778Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:02:59.4398213Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:02:59.4398670Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:02:59.4399171Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:02:59.4399731Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:02:59.4400360Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:02:59.4401033Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:02:59.4401660Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:02:59.4402104Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:02:59.4402693Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:02:59.4403205Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T09:02:59.4403784Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:02:59.4404433Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:02:59.4405363Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:02:59.4406288Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T09:02:59.4406894Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T09:02:59.4408080Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:02:59.4409200Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:02:59.4410260Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:02:59.4411289Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:02:59.4411877Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T09:02:59.4412517Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T09:02:59.4413136Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:02:59.4414171Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:02:59.4415334Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:02:59.4415984Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:02:59.4416396Z     
2026-01-14T09:02:59.4416702Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:59.4417087Z model fx: GraphModule(
2026-01-14T09:02:59.4417434Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:59.4418510Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:59.4419767Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:59.4420334Z   )
2026-01-14T09:02:59.4420518Z   (conv1): ConvBn2d(
2026-01-14T09:02:59.4420867Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:02:59.4421341Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:59.4421857Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:59.4422963Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:59.4424437Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:02:59.4425141Z     )
2026-01-14T09:02:59.4425310Z   )
2026-01-14T09:02:59.4425603Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:59.4426671Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:59.4427921Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7323514223098755, max_val=2.7138354778289795)
2026-01-14T09:02:59.4428477Z   )
2026-01-14T09:02:59.4428654Z   (conv2): ConvBn2d(
2026-01-14T09:02:59.4428898Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:02:59.4429350Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:59.4429861Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:59.4431054Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:03:19.5061476Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1921, -0.1899, -0.1895]), max_val=tensor([0.1769, 0.1726, 0.1697]))
2026-01-14T09:03:19.5062444Z     )
2026-01-14T09:03:19.5062903Z   )
2026-01-14T09:03:19.5063268Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:19.5064612Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:19.5066207Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4053945541381836, max_val=1.4082176685333252)
2026-01-14T09:03:19.5066914Z   )
2026-01-14T09:03:19.5067138Z )
2026-01-14T09:03:19.5067262Z 
2026-01-14T09:03:19.5067267Z 
2026-01-14T09:03:19.5067284Z 
2026-01-14T09:03:19.5067399Z def forward(self, x):
2026-01-14T09:03:19.5067848Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:19.5068572Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:03:19.5069328Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:03:19.5070079Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:03:19.5070829Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:03:19.5071408Z     return activation_post_process_2
2026-01-14T09:03:19.5071745Z     
2026-01-14T09:03:19.5072101Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:19.5072588Z diff: tensor([[[[0.]],
2026-01-14T09:03:19.5072770Z 
2026-01-14T09:03:19.5072863Z          [[0.]],
2026-01-14T09:03:19.5073022Z 
2026-01-14T09:03:19.5073122Z          [[0.]]],
2026-01-14T09:03:19.5073279Z 
2026-01-14T09:03:19.5073284Z 
2026-01-14T09:03:19.5073376Z         [[[0.]],
2026-01-14T09:03:19.5073535Z 
2026-01-14T09:03:19.5073627Z          [[0.]],
2026-01-14T09:03:19.5073875Z 
2026-01-14T09:03:19.5073978Z          [[0.]]],
2026-01-14T09:03:19.5074126Z 
2026-01-14T09:03:19.5074131Z 
2026-01-14T09:03:19.5074222Z         [[[0.]],
2026-01-14T09:03:19.5074374Z 
2026-01-14T09:03:19.5074477Z          [[0.]],
2026-01-14T09:03:19.5074623Z 
2026-01-14T09:03:19.5074752Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:03:19.5075139Z converted model pt2e: GraphModule(
2026-01-14T09:03:19.5075473Z   (conv1): Module()
2026-01-14T09:03:19.5075738Z   (bn1): Module()
2026-01-14T09:03:19.5075998Z   (conv2): Module()
2026-01-14T09:03:19.5076250Z   (bn2): Module()
2026-01-14T09:03:19.5076492Z )
2026-01-14T09:03:19.5076615Z 
2026-01-14T09:03:19.5076619Z 
2026-01-14T09:03:19.5076624Z 
2026-01-14T09:03:19.5076729Z def forward(self, x):
2026-01-14T09:03:19.5077103Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:19.5077539Z     conv2_bias = self.conv2.bias
2026-01-14T09:03:19.5078421Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:03:19.5080151Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:19.5081333Z     _scale_0 = self._scale_0
2026-01-14T09:03:19.5081664Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:03:19.5082008Z     _scale_1 = self._scale_1
2026-01-14T09:03:19.5082329Z     _zero_point_1 = self._zero_point_1
2026-01-14T09:03:19.5082798Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T09:03:19.5084235Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T09:03:19.5085516Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:03:19.5086699Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T09:03:19.5088531Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.01743602752685547, -29, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T09:03:19.5090359Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01743602752685547, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:19.5091592Z     quantize_per_channel = self._frozen_param1
2026-01-14T09:03:19.5092820Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:03:19.5094737Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T09:03:19.5096086Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.011033773422241211, -1, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T09:03:19.5097511Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011033773422241211, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:03:19.5098605Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:03:19.5099047Z     
2026-01-14T09:03:19.5099349Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:19.5099748Z onverted model fx: GraphModule(
2026-01-14T09:03:19.5100154Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:03:19.5100755Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:03:19.5101161Z )
2026-01-14T09:03:19.5101264Z 
2026-01-14T09:03:19.5101268Z 
2026-01-14T09:03:19.5101272Z 
2026-01-14T09:03:19.5101358Z def forward(self, x):
2026-01-14T09:03:19.5102034Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:03:19.5103391Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:19.5104507Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:03:19.5105472Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.01743602752685547, -29, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:03:19.5106880Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01743602752685547, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:19.5108013Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:03:19.5108971Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.011033773422241211, -1, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:03:19.5110374Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011033773422241211, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:03:19.5111420Z     return dequantize_per_tensor_default_2
2026-01-14T09:03:19.5111717Z     
2026-01-14T09:03:19.5112006Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:19.5112395Z diff: tensor([[[[0.]],
2026-01-14T09:03:19.5112542Z 
2026-01-14T09:03:19.5112622Z          [[0.]],
2026-01-14T09:03:19.5112825Z 
2026-01-14T09:03:19.5112900Z          [[0.]]],
2026-01-14T09:03:19.5113023Z 
2026-01-14T09:03:19.5113027Z 
2026-01-14T09:03:19.5113110Z         [[[0.]],
2026-01-14T09:03:19.5113230Z 
2026-01-14T09:03:19.5113305Z          [[0.]],
2026-01-14T09:03:19.5113431Z 
2026-01-14T09:03:19.5113505Z          [[0.]]],
2026-01-14T09:03:19.5113626Z 
2026-01-14T09:03:19.5113630Z 
2026-01-14T09:03:19.5113709Z         [[[0.]],
2026-01-14T09:03:19.5113827Z 
2026-01-14T09:03:19.5113900Z          [[0.]],
2026-01-14T09:03:19.5114020Z 
2026-01-14T09:03:19.5114103Z          [[0.]]]])
2026-01-14T09:03:19.5114318Z model pt2e: GraphModule(
2026-01-14T09:03:19.5114564Z   (conv1): Module()
2026-01-14T09:03:19.5114768Z   (bn1): Module()
2026-01-14T09:03:19.5114974Z   (conv2): Module()
2026-01-14T09:03:19.5115179Z   (bn2): Module()
2026-01-14T09:03:19.5115504Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:19.5116563Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:19.5117807Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:03:19.5118359Z   )
2026-01-14T09:03:19.5118642Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:19.5119708Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:19.5121010Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1921343356370926, max_val=0.1768510341644287)
2026-01-14T09:03:19.5121605Z   )
2026-01-14T09:03:19.5121898Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:19.5123042Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:19.5124324Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T09:03:19.5124889Z   )
2026-01-14T09:03:19.5125172Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:19.5126245Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:19.5127490Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7288155555725098, max_val=2.7138354778289795)
2026-01-14T09:03:19.5128054Z   )
2026-01-14T09:03:19.5128337Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:19.5129407Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:19.5130654Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4025696516036987, max_val=1.4086220264434814)
2026-01-14T09:03:19.5131201Z   )
2026-01-14T09:03:19.5131372Z )
2026-01-14T09:03:19.5131487Z 
2026-01-14T09:03:19.5131491Z 
2026-01-14T09:03:19.5131494Z 
2026-01-14T09:03:19.5131586Z def forward(self, x):
2026-01-14T09:03:19.5131985Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:19.5132354Z     conv1_weight = self.conv1.weight
2026-01-14T09:03:33.8732206Z     bn1_weight = self.bn1.weight
2026-01-14T09:03:33.8732600Z     bn1_bias = self.bn1.bias
2026-01-14T09:03:33.8732889Z     conv2_weight = self.conv2.weight
2026-01-14T09:03:33.8733205Z     conv2_bias = self.conv2.bias
2026-01-14T09:03:33.8733648Z     bn2_weight = self.bn2.weight
2026-01-14T09:03:33.8733936Z     bn2_bias = self.bn2.bias
2026-01-14T09:03:33.8734228Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:03:33.8734570Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:03:33.8734948Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:03:33.8735324Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:03:33.8735655Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:03:33.8736016Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:03:33.8736509Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:33.8737174Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:03:33.8737937Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:03:33.8738559Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:03:33.8739205Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:03:33.8739824Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:03:33.8740451Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:03:33.8741040Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:03:33.8741673Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:03:33.8742370Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:03:33.8743009Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:03:33.8743462Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:03:33.8744065Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:03:33.8744588Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T09:03:33.8745200Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:03:33.8745858Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:03:33.8746810Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:03:33.8747755Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T09:03:33.8748374Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T09:03:33.8749457Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:03:33.8750580Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:03:33.8751646Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:03:33.8752644Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:03:33.8753244Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T09:03:33.8753907Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T09:03:33.8754695Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:03:33.8755736Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:03:33.8756857Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:03:33.8757571Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:03:33.8758010Z     
2026-01-14T09:03:33.8758326Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:33.8758731Z model fx: GraphModule(
2026-01-14T09:03:33.8759092Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:33.8760181Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:33.8761476Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:03:33.8762049Z   )
2026-01-14T09:03:33.8762254Z   (conv1): ConvBn2d(
2026-01-14T09:03:33.8762609Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:03:33.8763104Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:33.8763641Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:33.8764693Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:33.8765979Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T09:03:33.8766560Z     )
2026-01-14T09:03:33.8766753Z   )
2026-01-14T09:03:33.8767058Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:33.8768128Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:33.8769443Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7288155555725098, max_val=2.7138354778289795)
2026-01-14T09:03:33.8769999Z   )
2026-01-14T09:03:33.8770195Z   (conv2): ConvBn2d(
2026-01-14T09:03:33.8770450Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:03:33.8770897Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:33.8771442Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:33.8772491Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:33.8773764Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1921343356370926, max_val=0.1768510341644287)
2026-01-14T09:03:33.8774339Z     )
2026-01-14T09:03:33.8774520Z   )
2026-01-14T09:03:33.8774824Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:33.8775889Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:33.8777144Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4025696516036987, max_val=1.4086220264434814)
2026-01-14T09:03:33.8777704Z   )
2026-01-14T09:03:33.8777886Z )
2026-01-14T09:03:33.8777991Z 
2026-01-14T09:03:33.8777996Z 
2026-01-14T09:03:33.8778007Z 
2026-01-14T09:03:33.8778222Z def forward(self, x):
2026-01-14T09:03:33.8778595Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:33.8779186Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:03:33.8779796Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:03:33.8782033Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:03:33.8782637Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:03:33.8783096Z     return activation_post_process_2
2026-01-14T09:03:33.8783368Z     
2026-01-14T09:03:33.8783658Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:33.8784069Z diff: tensor([[[[0.]],
2026-01-14T09:03:33.8784240Z 
2026-01-14T09:03:33.8784328Z          [[0.]],
2026-01-14T09:03:33.8784462Z 
2026-01-14T09:03:33.8784539Z          [[0.]]],
2026-01-14T09:03:33.8784663Z 
2026-01-14T09:03:33.8784672Z 
2026-01-14T09:03:33.8784757Z         [[[0.]],
2026-01-14T09:03:33.8784879Z 
2026-01-14T09:03:33.8784957Z          [[0.]],
2026-01-14T09:03:33.8785083Z 
2026-01-14T09:03:33.8785162Z          [[0.]]],
2026-01-14T09:03:33.8785288Z 
2026-01-14T09:03:33.8785292Z 
2026-01-14T09:03:33.8785366Z         [[[0.]],
2026-01-14T09:03:33.8785492Z 
2026-01-14T09:03:33.8785573Z          [[0.]],
2026-01-14T09:03:33.8785693Z 
2026-01-14T09:03:33.8785808Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:03:33.8786122Z converted model pt2e: GraphModule(
2026-01-14T09:03:33.8786403Z   (conv1): Module()
2026-01-14T09:03:33.8786611Z   (bn1): Module()
2026-01-14T09:03:33.8786822Z   (conv2): Module()
2026-01-14T09:03:33.8787028Z   (bn2): Module()
2026-01-14T09:03:33.8787231Z )
2026-01-14T09:03:33.8787336Z 
2026-01-14T09:03:33.8787340Z 
2026-01-14T09:03:33.8787344Z 
2026-01-14T09:03:33.8787432Z def forward(self, x):
2026-01-14T09:03:33.8787742Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:33.8788120Z     conv2_bias = self.conv2.bias
2026-01-14T09:03:33.8788839Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:03:33.8790283Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:33.8791269Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T09:03:33.8792154Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.001512790797278285, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T09:03:33.8793055Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:03:33.8794010Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T09:03:33.8795425Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.017422160133719444, -29, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T09:03:33.8796890Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.017422160133719444, -29, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:03:33.8797886Z     quantize_per_tensor = self._frozen_param1
2026-01-14T09:04:00.8978372Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001512868795543909, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:04:00.8981370Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T09:04:00.8983152Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.011024280451238155, -1, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T09:04:00.8984991Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.011024280451238155, -1, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T09:04:00.8986486Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T09:04:00.8987040Z     
2026-01-14T09:04:00.8987406Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:00.8987910Z onverted model fx: GraphModule(
2026-01-14T09:04:00.8988414Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:04:00.8989099Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:04:00.8989616Z )
2026-01-14T09:04:00.8989752Z 
2026-01-14T09:04:00.8989757Z 
2026-01-14T09:04:00.8989762Z 
2026-01-14T09:04:00.8989871Z def forward(self, x):
2026-01-14T09:04:00.8990709Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:04:00.8992440Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:00.8993900Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:00.8995097Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.017422160133719444, -29, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:04:00.8996541Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.017422160133719444, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:00.8997683Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:04:00.8998743Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.011024280451238155, -1, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:04:00.9000148Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011024280451238155, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:04:00.9001121Z     return dequantize_per_tensor_default_2
2026-01-14T09:04:00.9001412Z     
2026-01-14T09:04:00.9001706Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:00.9002108Z diff: tensor([[[[0.]],
2026-01-14T09:04:00.9002260Z 
2026-01-14T09:04:00.9002339Z          [[0.]],
2026-01-14T09:04:00.9002472Z 
2026-01-14T09:04:00.9002629Z          [[0.]]],
2026-01-14T09:04:00.9002758Z 
2026-01-14T09:04:00.9002762Z 
2026-01-14T09:04:00.9002845Z         [[[0.]],
2026-01-14T09:04:00.9002973Z 
2026-01-14T09:04:00.9003048Z          [[0.]],
2026-01-14T09:04:00.9003171Z 
2026-01-14T09:04:00.9003258Z          [[0.]]],
2026-01-14T09:04:00.9003381Z 
2026-01-14T09:04:00.9003387Z 
2026-01-14T09:04:00.9003462Z         [[[0.]],
2026-01-14T09:04:00.9003587Z 
2026-01-14T09:04:00.9003666Z          [[0.]],
2026-01-14T09:04:00.9003786Z 
2026-01-14T09:04:00.9003863Z          [[0.]]]])
2026-01-14T09:04:00.9004292Z [32mPASSED[0m
2026-01-14T09:04:00.9005036Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T09:04:00.9006088Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T09:04:00.9006743Z   (conv): Module()
2026-01-14T09:04:00.9007050Z   (bn): Module()
2026-01-14T09:04:00.9007372Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:00.9008433Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:00.9009739Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:00.9010292Z   )
2026-01-14T09:04:00.9010581Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:00.9011715Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:00.9013201Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1835, -0.1822, -0.1883]), max_val=tensor([0.1799, 0.1856, 0.1719]))
2026-01-14T09:04:00.9013903Z   )
2026-01-14T09:04:00.9014203Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:00.9015276Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:00.9016475Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2505061626434326)
2026-01-14T09:04:00.9016986Z   )
2026-01-14T09:04:00.9017154Z )
2026-01-14T09:04:00.9017258Z 
2026-01-14T09:04:00.9017268Z 
2026-01-14T09:04:00.9017273Z 
2026-01-14T09:04:00.9017364Z def forward(self, x):
2026-01-14T09:04:00.9017663Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:00.9018030Z     conv_weight = self.conv.weight
2026-01-14T09:04:00.9018316Z     conv_bias = self.conv.bias
2026-01-14T09:04:00.9018591Z     bn_weight = self.bn.weight
2026-01-14T09:04:00.9018856Z     bn_bias = self.bn.bias
2026-01-14T09:04:00.9019125Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:00.9019497Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:00.9019848Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:00.9020332Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:00.9020977Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:00.9021619Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:00.9022148Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:00.9022716Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:00.9023321Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:04:00.9024009Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:00.9024660Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:00.9025335Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:00.9026438Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:00.9027445Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:04:00.9028040Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:04:00.9028695Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:04:00.9029311Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:00.9030409Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:00.9031412Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:00.9032125Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:00.9032930Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:00.9033453Z     
2026-01-14T09:04:00.9033765Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:00.9034165Z model fx: GraphModule(
2026-01-14T09:04:00.9034505Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:00.9035591Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:00.9036850Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:00.9037414Z   )
2026-01-14T09:04:00.9037607Z   (conv): ConvBnReLU2d(
2026-01-14T09:04:00.9037865Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:04:00.9038318Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:00.9038838Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:00.9040320Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:00.9041796Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1835, -0.1822, -0.1883]), max_val=tensor([0.1799, 0.1856, 0.1719]))
2026-01-14T09:04:00.9042621Z     )
2026-01-14T09:04:00.9042804Z   )
2026-01-14T09:04:00.9043091Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:00.9044173Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:00.9045461Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2505061626434326)
2026-01-14T09:04:00.9045970Z   )
2026-01-14T09:04:00.9046147Z )
2026-01-14T09:04:00.9046247Z 
2026-01-14T09:04:00.9046251Z 
2026-01-14T09:04:00.9046256Z 
2026-01-14T09:04:00.9046343Z def forward(self, x):
2026-01-14T09:04:00.9046718Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:00.9047290Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:04:21.0151234Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:04:21.0153579Z     return activation_post_process_1
2026-01-14T09:04:21.0153959Z     
2026-01-14T09:04:21.0154357Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:21.0154870Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:21.0156262Z           [0., 0., 0.],
2026-01-14T09:04:21.0156571Z           [0., 0., 0.]],
2026-01-14T09:04:21.0156757Z 
2026-01-14T09:04:21.0156860Z          [[0., 0., 0.],
2026-01-14T09:04:21.0157131Z           [0., 0., 0.],
2026-01-14T09:04:21.0157396Z           [0., 0., 0.]],
2026-01-14T09:04:21.0157583Z 
2026-01-14T09:04:21.0157685Z          [[0., 0., 0.],
2026-01-14T09:04:21.0157947Z           [0., 0., 0.],
2026-01-14T09:04:21.0158276Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:04:21.0158695Z converted model pt2e: GraphModule(
2026-01-14T09:04:21.0159029Z   (conv): Module()
2026-01-14T09:04:21.0159292Z   (bn): Module()
2026-01-14T09:04:21.0159531Z )
2026-01-14T09:04:21.0159923Z 
2026-01-14T09:04:21.0159930Z 
2026-01-14T09:04:21.0159960Z 
2026-01-14T09:04:21.0160083Z def forward(self, x):
2026-01-14T09:04:21.0160457Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:21.0160900Z     conv_bias = self.conv.bias
2026-01-14T09:04:21.0161802Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:21.0163791Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:21.0164979Z     _scale_0 = self._scale_0
2026-01-14T09:04:21.0165309Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:04:21.0165696Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:04:21.0166938Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:04:21.0168852Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:04:21.0170038Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:04:21.0171106Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.004903945606201887, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:04:21.0172903Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004903945606201887, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:21.0174321Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:04:21.0174877Z     
2026-01-14T09:04:21.0175242Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:21.0175746Z onverted model fx: GraphModule(
2026-01-14T09:04:21.0176187Z   (conv): ConvReLU2d(
2026-01-14T09:04:21.0176546Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:04:21.0176938Z     (1): ReLU()
2026-01-14T09:04:21.0177139Z   )
2026-01-14T09:04:21.0177308Z )
2026-01-14T09:04:21.0177413Z 
2026-01-14T09:04:21.0177418Z 
2026-01-14T09:04:21.0177422Z 
2026-01-14T09:04:21.0177509Z def forward(self, x):
2026-01-14T09:04:21.0178177Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:21.0179533Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:21.0180648Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:21.0181596Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.004903945606201887, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:21.0183012Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004903945606201887, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:21.0184000Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:21.0184285Z     
2026-01-14T09:04:21.0184583Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:21.0184982Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:21.0185230Z           [0., 0., 0.],
2026-01-14T09:04:21.0185455Z           [0., 0., 0.]],
2026-01-14T09:04:21.0185601Z 
2026-01-14T09:04:21.0185680Z          [[0., 0., 0.],
2026-01-14T09:04:21.0185995Z           [0., 0., 0.],
2026-01-14T09:04:21.0186212Z           [0., 0., 0.]],
2026-01-14T09:04:21.0186364Z 
2026-01-14T09:04:21.0186441Z          [[0., 0., 0.],
2026-01-14T09:04:21.0186656Z           [0., 0., 0.],
2026-01-14T09:04:21.0186876Z           [0., 0., 0.]]]])
2026-01-14T09:04:21.0187116Z model pt2e: GraphModule(
2026-01-14T09:04:21.0187357Z   (conv): Module()
2026-01-14T09:04:21.0187614Z   (bn): Module()
2026-01-14T09:04:21.0187922Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:21.0188985Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:21.0190222Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:21.0190775Z   )
2026-01-14T09:04:21.0191064Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:21.0192125Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:21.0193384Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.1855725795030594)
2026-01-14T09:04:21.0193937Z   )
2026-01-14T09:04:21.0194225Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:21.0195279Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:21.0196470Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2396948337554932)
2026-01-14T09:04:21.0196975Z   )
2026-01-14T09:04:21.0197141Z )
2026-01-14T09:04:21.0197251Z 
2026-01-14T09:04:21.0197255Z 
2026-01-14T09:04:21.0197259Z 
2026-01-14T09:04:21.0197348Z def forward(self, x):
2026-01-14T09:04:21.0197645Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:21.0198059Z     conv_weight = self.conv.weight
2026-01-14T09:04:21.0198349Z     conv_bias = self.conv.bias
2026-01-14T09:04:21.0198618Z     bn_weight = self.bn.weight
2026-01-14T09:04:21.0198879Z     bn_bias = self.bn.bias
2026-01-14T09:04:21.0199145Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:21.0199468Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:21.0199815Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:21.0200286Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:21.0200926Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:21.0201515Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:21.0201944Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:21.0202382Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:21.0202930Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:04:21.0203487Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:21.0204131Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:21.0204812Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:21.0205898Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:21.0206893Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:04:21.0207572Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:04:21.0208223Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:04:21.0208852Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:21.0209861Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:21.0210896Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:21.0211463Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:21.0212057Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:21.0212483Z     
2026-01-14T09:04:21.0212777Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:21.0213178Z model fx: GraphModule(
2026-01-14T09:04:21.0213521Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:21.0214600Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:21.0215855Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:21.0216405Z   )
2026-01-14T09:04:21.0216601Z   (conv): ConvBnReLU2d(
2026-01-14T09:04:21.0216858Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:04:21.0217312Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:21.0217826Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:21.0218876Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:21.0220144Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.1855725795030594)
2026-01-14T09:04:21.0220748Z     )
2026-01-14T09:04:21.0220927Z   )
2026-01-14T09:04:21.0221214Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:43.8721750Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:43.8724118Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2396948337554932)
2026-01-14T09:04:43.8724668Z   )
2026-01-14T09:04:43.8724853Z )
2026-01-14T09:04:43.8724961Z 
2026-01-14T09:04:43.8724965Z 
2026-01-14T09:04:43.8724969Z 
2026-01-14T09:04:43.8725070Z def forward(self, x):
2026-01-14T09:04:43.8725461Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:43.8726060Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:04:43.8726660Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:04:43.8727125Z     return activation_post_process_1
2026-01-14T09:04:43.8727415Z     
2026-01-14T09:04:43.8727723Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:43.8728132Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:43.8728391Z           [0., 0., 0.],
2026-01-14T09:04:43.8728636Z           [0., 0., 0.]],
2026-01-14T09:04:43.8728787Z 
2026-01-14T09:04:43.8728871Z          [[0., 0., 0.],
2026-01-14T09:04:43.8729105Z           [0., 0., 0.],
2026-01-14T09:04:43.8729327Z           [0., 0., 0.]],
2026-01-14T09:04:43.8729485Z 
2026-01-14T09:04:43.8729568Z          [[0., 0., 0.],
2026-01-14T09:04:43.8729804Z           [0., 0., 0.],
2026-01-14T09:04:43.8738122Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:04:43.8738492Z converted model pt2e: GraphModule(
2026-01-14T09:04:43.8738783Z   (conv): Module()
2026-01-14T09:04:43.8739313Z   (bn): Module()
2026-01-14T09:04:43.8739533Z )
2026-01-14T09:04:43.8739636Z 
2026-01-14T09:04:43.8739640Z 
2026-01-14T09:04:43.8739644Z 
2026-01-14T09:04:43.8739841Z def forward(self, x):
2026-01-14T09:04:43.8740147Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:43.8740515Z     conv_bias = self.conv.bias
2026-01-14T09:04:43.8741215Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:43.8742595Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:43.8743569Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:04:43.8744441Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014826410915702581, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:04:43.8745841Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:04:43.8746783Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:04:43.8747646Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.004861548542976379, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:04:43.8749083Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.004861548542976379, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:04:43.8750209Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:04:43.8750656Z     
2026-01-14T09:04:43.8750953Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:43.8751466Z onverted model fx: GraphModule(
2026-01-14T09:04:43.8751729Z   (conv): ConvReLU2d(
2026-01-14T09:04:43.8752098Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:04:43.8752511Z     (1): ReLU()
2026-01-14T09:04:43.8752705Z   )
2026-01-14T09:04:43.8752882Z )
2026-01-14T09:04:43.8752981Z 
2026-01-14T09:04:43.8752985Z 
2026-01-14T09:04:43.8752990Z 
2026-01-14T09:04:43.8753079Z def forward(self, x):
2026-01-14T09:04:43.8753754Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:43.8755187Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:43.8756302Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:43.8757253Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.004861548542976379, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:43.8758678Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004861548542976379, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:43.8759661Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:43.8759951Z     
2026-01-14T09:04:43.8760244Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:43.8760644Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:43.8760885Z           [0., 0., 0.],
2026-01-14T09:04:43.8761108Z           [0., 0., 0.]],
2026-01-14T09:04:43.8761378Z 
2026-01-14T09:04:43.8761460Z          [[0., 0., 0.],
2026-01-14T09:04:43.8761680Z           [0., 0., 0.],
2026-01-14T09:04:43.8761893Z           [0., 0., 0.]],
2026-01-14T09:04:43.8762045Z 
2026-01-14T09:04:43.8762120Z          [[0., 0., 0.],
2026-01-14T09:04:43.8762335Z           [0., 0., 0.],
2026-01-14T09:04:43.8762598Z           [0., 0., 0.]]]])
2026-01-14T09:04:43.8763104Z [32mPASSED[0m
2026-01-14T09:04:43.8763736Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_cuda model pt2e: GraphModule(
2026-01-14T09:04:43.8764426Z   (conv): Module()
2026-01-14T09:04:43.8764630Z   (bn): Module()
2026-01-14T09:04:43.8764971Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:43.8766293Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:43.8767760Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:43.8768312Z   )
2026-01-14T09:04:43.8768597Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:43.8769958Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:43.8771767Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:04:43.8772576Z   )
2026-01-14T09:04:43.8772871Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:43.8774151Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:43.8775632Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0564441680908203)
2026-01-14T09:04:43.8776140Z   )
2026-01-14T09:04:43.8776308Z )
2026-01-14T09:04:43.8776415Z 
2026-01-14T09:04:43.8776419Z 
2026-01-14T09:04:43.8776423Z 
2026-01-14T09:04:43.8776510Z def forward(self, x):
2026-01-14T09:04:43.8776810Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:43.8777183Z     conv_weight = self.conv.weight
2026-01-14T09:04:43.8777478Z     conv_bias = self.conv.bias
2026-01-14T09:04:43.8777739Z     bn_weight = self.bn.weight
2026-01-14T09:04:43.8778008Z     bn_bias = self.bn.bias
2026-01-14T09:04:43.8778283Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:43.8778601Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:43.8778969Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:43.8779446Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:43.8780099Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:43.8780682Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:43.8781107Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:43.8781546Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:43.8782028Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:04:43.8782569Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:43.8783268Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:43.8783945Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:43.8785079Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:43.8786113Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:04:43.8786699Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:04:43.8787342Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:04:43.8787962Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:43.8788979Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:43.8789966Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:43.8790534Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:43.8791119Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:43.8791535Z     
2026-01-14T09:04:43.8791825Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:43.8792221Z model fx: GraphModule(
2026-01-14T09:04:43.8792561Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:43.8796735Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:04.1490202Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:04.1490883Z   )
2026-01-14T09:05:04.1491082Z   (conv): ConvBnReLU2d(
2026-01-14T09:05:04.1491608Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:05:04.1492063Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:05:04.1492595Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:04.1493932Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:04.1495784Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:05:04.1496600Z     )
2026-01-14T09:05:04.1496794Z   )
2026-01-14T09:05:04.1497098Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:04.1498384Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:04.1499813Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0564441680908203)
2026-01-14T09:05:04.1500322Z   )
2026-01-14T09:05:04.1500520Z )
2026-01-14T09:05:04.1500634Z 
2026-01-14T09:05:04.1500639Z 
2026-01-14T09:05:04.1500643Z 
2026-01-14T09:05:04.1500746Z def forward(self, x):
2026-01-14T09:05:04.1501118Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:04.1501797Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:04.1502396Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:04.1502854Z     return activation_post_process_1
2026-01-14T09:05:04.1503132Z     
2026-01-14T09:05:04.1503426Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:04.1503905Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:04.1504159Z           [0., 0., 0.],
2026-01-14T09:05:04.1504385Z           [0., 0., 0.]],
2026-01-14T09:05:04.1504536Z 
2026-01-14T09:05:04.1504621Z          [[0., 0., 0.],
2026-01-14T09:05:04.1504845Z           [0., 0., 0.],
2026-01-14T09:05:04.1505061Z           [0., 0., 0.]],
2026-01-14T09:05:04.1505214Z 
2026-01-14T09:05:04.1505301Z          [[0., 0., 0.],
2026-01-14T09:05:04.1505523Z           [0., 0., 0.],
2026-01-14T09:05:04.1505808Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:05:04.1506183Z converted model pt2e: GraphModule(
2026-01-14T09:05:04.1506464Z   (conv): Module()
2026-01-14T09:05:04.1506684Z   (bn): Module()
2026-01-14T09:05:04.1506884Z )
2026-01-14T09:05:04.1506997Z 
2026-01-14T09:05:04.1507001Z 
2026-01-14T09:05:04.1507007Z 
2026-01-14T09:05:04.1507095Z def forward(self, x):
2026-01-14T09:05:04.1507403Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:04.1507762Z     conv_bias = self.conv.bias
2026-01-14T09:05:04.1508465Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:04.1509821Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:04.1510757Z     _scale_0 = self._scale_0
2026-01-14T09:05:04.1511056Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:05:04.1511539Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:05:04.1512516Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:05:04.1514061Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:05:04.1515016Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:05:04.1515864Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.008064487017691135, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:04.1517278Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008064487017691135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:04.1518396Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:05:04.1518830Z     
2026-01-14T09:05:04.1519130Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:04.1519540Z onverted model fx: GraphModule(
2026-01-14T09:05:04.1519804Z   (conv): ConvReLU2d(
2026-01-14T09:05:04.1520162Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:05:04.1520556Z     (1): ReLU()
2026-01-14T09:05:04.1520754Z   )
2026-01-14T09:05:04.1520947Z )
2026-01-14T09:05:04.1521063Z 
2026-01-14T09:05:04.1521068Z 
2026-01-14T09:05:04.1521073Z 
2026-01-14T09:05:04.1521172Z def forward(self, x):
2026-01-14T09:05:04.1521829Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:04.1523321Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:04.1524434Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:04.1525369Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008064487017691135, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:04.1526829Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008064487017691135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:04.1527806Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:04.1528089Z     
2026-01-14T09:05:04.1528392Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:04.1528782Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:04.1529033Z           [0., 0., 0.],
2026-01-14T09:05:04.1529262Z           [0., 0., 0.]],
2026-01-14T09:05:04.1529414Z 
2026-01-14T09:05:04.1529492Z          [[0., 0., 0.],
2026-01-14T09:05:04.1529711Z           [0., 0., 0.],
2026-01-14T09:05:04.1529926Z           [0., 0., 0.]],
2026-01-14T09:05:04.1530069Z 
2026-01-14T09:05:04.1530154Z          [[0., 0., 0.],
2026-01-14T09:05:04.1530365Z           [0., 0., 0.],
2026-01-14T09:05:04.1530611Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:05:04.1530902Z model pt2e: GraphModule(
2026-01-14T09:05:04.1531145Z   (conv): Module()
2026-01-14T09:05:04.1531351Z   (bn): Module()
2026-01-14T09:05:04.1531676Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:04.1532958Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:04.1534481Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:04.1535031Z   )
2026-01-14T09:05:04.1535316Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:04.1536643Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:04.1538130Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:05:04.1538690Z   )
2026-01-14T09:05:04.1539160Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:04.1540445Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0080], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:04.1541866Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0522286891937256)
2026-01-14T09:05:04.1542369Z   )
2026-01-14T09:05:04.1542538Z )
2026-01-14T09:05:04.1542641Z 
2026-01-14T09:05:04.1542651Z 
2026-01-14T09:05:04.1542655Z 
2026-01-14T09:05:04.1542742Z def forward(self, x):
2026-01-14T09:05:04.1543038Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:04.1543403Z     conv_weight = self.conv.weight
2026-01-14T09:05:04.1543689Z     conv_bias = self.conv.bias
2026-01-14T09:05:04.1543952Z     bn_weight = self.bn.weight
2026-01-14T09:05:04.1544214Z     bn_bias = self.bn.bias
2026-01-14T09:05:04.1544478Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:05:04.1544793Z     bn_running_var = self.bn.running_var
2026-01-14T09:05:04.1545222Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:04.1545699Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:04.1546340Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:04.1546933Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:05:04.1547418Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:05:04.1547856Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:05:04.1548336Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:05:04.1548879Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:05:04.1549498Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:05:04.1550163Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:05:04.1551307Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:05:04.1552298Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:05:04.1552881Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:05:04.1553526Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:05:04.1554142Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:05:26.9310033Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:05:26.9312811Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:05:26.9313895Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:26.9314649Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:26.9315355Z     
2026-01-14T09:05:26.9315734Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:26.9316229Z model fx: GraphModule(
2026-01-14T09:05:26.9316661Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:26.9318304Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:26.9320164Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:26.9320867Z   )
2026-01-14T09:05:26.9321118Z   (conv): ConvBnReLU2d(
2026-01-14T09:05:26.9321433Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:05:26.9321986Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:05:26.9322766Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:26.9324344Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:26.9326226Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:05:26.9326929Z     )
2026-01-14T09:05:26.9327153Z   )
2026-01-14T09:05:26.9327504Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:26.9329211Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0080], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:26.9331004Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0522286891937256)
2026-01-14T09:05:26.9331765Z   )
2026-01-14T09:05:26.9331985Z )
2026-01-14T09:05:26.9332109Z 
2026-01-14T09:05:26.9332114Z 
2026-01-14T09:05:26.9332119Z 
2026-01-14T09:05:26.9332244Z def forward(self, x):
2026-01-14T09:05:26.9332691Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:26.9333407Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:26.9334133Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:26.9334706Z     return activation_post_process_1
2026-01-14T09:05:26.9335035Z     
2026-01-14T09:05:26.9335400Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:26.9335891Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:26.9336196Z           [0., 0., 0.],
2026-01-14T09:05:26.9336477Z           [0., 0., 0.]],
2026-01-14T09:05:26.9336655Z 
2026-01-14T09:05:26.9336752Z          [[0., 0., 0.],
2026-01-14T09:05:26.9337020Z           [0., 0., 0.],
2026-01-14T09:05:26.9337286Z           [0., 0., 0.]],
2026-01-14T09:05:26.9337471Z 
2026-01-14T09:05:26.9337566Z          [[0., 0., 0.],
2026-01-14T09:05:26.9337827Z           [0., 0., 0.],
2026-01-14T09:05:26.9338182Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:05:26.9338634Z converted model pt2e: GraphModule(
2026-01-14T09:05:26.9339168Z   (conv): Module()
2026-01-14T09:05:26.9339435Z   (bn): Module()
2026-01-14T09:05:26.9339677Z )
2026-01-14T09:05:26.9339800Z 
2026-01-14T09:05:26.9339805Z 
2026-01-14T09:05:26.9339817Z 
2026-01-14T09:05:26.9339925Z def forward(self, x):
2026-01-14T09:05:26.9340381Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:26.9340832Z     conv_bias = self.conv.bias
2026-01-14T09:05:26.9341703Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:26.9343496Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:26.9344790Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:05:26.9345778Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:05:26.9347181Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:05:26.9348111Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:05:26.9348955Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.00804795604199171, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:26.9350373Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.00804795604199171, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:05:26.9351491Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:05:26.9351928Z     
2026-01-14T09:05:26.9352230Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:26.9352630Z onverted model fx: GraphModule(
2026-01-14T09:05:26.9352899Z   (conv): ConvReLU2d(
2026-01-14T09:05:26.9353253Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:05:26.9353734Z     (1): ReLU()
2026-01-14T09:05:26.9353933Z   )
2026-01-14T09:05:26.9354112Z )
2026-01-14T09:05:26.9354212Z 
2026-01-14T09:05:26.9354216Z 
2026-01-14T09:05:26.9354223Z 
2026-01-14T09:05:26.9354316Z def forward(self, x):
2026-01-14T09:05:26.9354976Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:26.9356404Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:26.9357515Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:26.9358456Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.00804795604199171, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:26.9359879Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.00804795604199171, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:26.9360863Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:26.9361163Z     
2026-01-14T09:05:26.9361467Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:26.9361873Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:26.9362125Z           [0., 0., 0.],
2026-01-14T09:05:26.9362346Z           [0., 0., 0.]],
2026-01-14T09:05:26.9362495Z 
2026-01-14T09:05:26.9362639Z          [[0., 0., 0.],
2026-01-14T09:05:26.9362857Z           [0., 0., 0.],
2026-01-14T09:05:26.9363081Z           [0., 0., 0.]],
2026-01-14T09:05:26.9363233Z 
2026-01-14T09:05:26.9363316Z          [[0., 0., 0.],
2026-01-14T09:05:26.9363540Z           [0., 0., 0.],
2026-01-14T09:05:26.9363781Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:05:26.9364334Z [32mPASSED[0m
2026-01-14T09:05:26.9365018Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T09:05:26.9365768Z   (conv): Module()
2026-01-14T09:05:26.9365985Z   (bn): Module()
2026-01-14T09:05:26.9366304Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:26.9367390Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:26.9368625Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:26.9369195Z   )
2026-01-14T09:05:26.9378394Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:26.9379554Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:26.9381055Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1866, -0.1825, -0.1912]), max_val=tensor([0.1747, 0.1914, 0.1702]))
2026-01-14T09:05:26.9381773Z   )
2026-01-14T09:05:26.9382072Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:26.9383159Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:26.9384358Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.984864354133606)
2026-01-14T09:05:26.9384873Z   )
2026-01-14T09:05:26.9385053Z )
2026-01-14T09:05:26.9385165Z 
2026-01-14T09:05:26.9385169Z 
2026-01-14T09:05:26.9385175Z 
2026-01-14T09:05:26.9385350Z def forward(self, x):
2026-01-14T09:05:26.9385668Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:26.9386038Z     conv_weight = self.conv.weight
2026-01-14T09:05:26.9386346Z     bn_weight = self.bn.weight
2026-01-14T09:05:26.9386614Z     bn_bias = self.bn.bias
2026-01-14T09:05:26.9386897Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:05:26.9387271Z     bn_running_var = self.bn.running_var
2026-01-14T09:05:26.9387632Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:26.9388115Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:26.9388765Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:26.9389363Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:05:26.9389794Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:05:26.9390252Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:05:26.9390731Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:05:26.9391292Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:05:47.2978298Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:05:47.2981609Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:47.2982864Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:05:47.2983598Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:05:47.2985224Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:05:47.2986470Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:05:47.2987179Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:47.2988026Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:47.2988543Z     
2026-01-14T09:05:47.2988924Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:47.2989406Z model fx: GraphModule(
2026-01-14T09:05:47.2989827Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.2991159Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:47.2992789Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:47.2993491Z   )
2026-01-14T09:05:47.2993731Z   (conv): ConvBnReLU2d(
2026-01-14T09:05:47.2994079Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:47.2994660Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:05:47.2995301Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.2996694Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:47.2998558Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1866, -0.1825, -0.1912]), max_val=tensor([0.1747, 0.1914, 0.1702]))
2026-01-14T09:05:47.2999457Z     )
2026-01-14T09:05:47.2999683Z   )
2026-01-14T09:05:47.3000042Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.3001489Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:47.3003086Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.984864354133606)
2026-01-14T09:05:47.3003821Z   )
2026-01-14T09:05:47.3004043Z )
2026-01-14T09:05:47.3004177Z 
2026-01-14T09:05:47.3004182Z 
2026-01-14T09:05:47.3004187Z 
2026-01-14T09:05:47.3004297Z def forward(self, x):
2026-01-14T09:05:47.3004759Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:47.3005462Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:47.3006199Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:47.3006764Z     return activation_post_process_1
2026-01-14T09:05:47.3007106Z     
2026-01-14T09:05:47.3007472Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:47.3007969Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:47.3008279Z           [0., 0., 0.],
2026-01-14T09:05:47.3008555Z           [0., 0., 0.]],
2026-01-14T09:05:47.3008737Z 
2026-01-14T09:05:47.3008847Z          [[0., 0., 0.],
2026-01-14T09:05:47.3009119Z           [0., 0., 0.],
2026-01-14T09:05:47.3009397Z           [0., 0., 0.]],
2026-01-14T09:05:47.3009574Z 
2026-01-14T09:05:47.3009672Z          [[0., 0., 0.],
2026-01-14T09:05:47.3009948Z           [0., 0., 0.],
2026-01-14T09:05:47.3010257Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:47.3010671Z converted model pt2e: GraphModule(
2026-01-14T09:05:47.3011004Z   (conv): Module()
2026-01-14T09:05:47.3011266Z   (bn): Module()
2026-01-14T09:05:47.3011519Z )
2026-01-14T09:05:47.3011641Z 
2026-01-14T09:05:47.3011646Z 
2026-01-14T09:05:47.3011651Z 
2026-01-14T09:05:47.3011759Z def forward(self, x):
2026-01-14T09:05:47.3012196Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:47.3013177Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:47.3014955Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:47.3016150Z     _scale_0 = self._scale_0
2026-01-14T09:05:47.3016471Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:05:47.3016864Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:05:47.3018100Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:05:47.3019441Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:05:47.3020387Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:05:47.3021377Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:05:47.3022265Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007783781737089157, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:47.3023693Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007783781737089157, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:47.3024813Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:05:47.3025260Z     
2026-01-14T09:05:47.3025562Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:47.3025979Z onverted model fx: GraphModule(
2026-01-14T09:05:47.3027877Z   (conv): ConvReLU2d(
2026-01-14T09:05:47.3028258Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:05:47.3028659Z     (1): ReLU()
2026-01-14T09:05:47.3028864Z   )
2026-01-14T09:05:47.3029038Z )
2026-01-14T09:05:47.3029155Z 
2026-01-14T09:05:47.3029159Z 
2026-01-14T09:05:47.3029211Z 
2026-01-14T09:05:47.3029300Z def forward(self, x):
2026-01-14T09:05:47.3029979Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:47.3031341Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:47.3032450Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:47.3033398Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007783781737089157, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:47.3034825Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007783781737089157, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:47.3035811Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:47.3036107Z     
2026-01-14T09:05:47.3036399Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:47.3036802Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:47.3037050Z           [0., 0., 0.],
2026-01-14T09:05:47.3037287Z           [0., 0., 0.]],
2026-01-14T09:05:47.3037437Z 
2026-01-14T09:05:47.3037519Z          [[0., 0., 0.],
2026-01-14T09:05:47.3037742Z           [0., 0., 0.],
2026-01-14T09:05:47.3037964Z           [0., 0., 0.]],
2026-01-14T09:05:47.3038113Z 
2026-01-14T09:05:47.3038252Z          [[0., 0., 0.],
2026-01-14T09:05:47.3038491Z           [0., 0., 0.],
2026-01-14T09:05:47.3038713Z           [0., 0., 0.]]]])
2026-01-14T09:05:47.3039161Z model pt2e: GraphModule(
2026-01-14T09:05:47.3039487Z   (conv): Module()
2026-01-14T09:05:47.3039704Z   (bn): Module()
2026-01-14T09:05:47.3040020Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.3041097Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:47.3042355Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:47.3042962Z   )
2026-01-14T09:05:47.3043259Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.3044323Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:47.3045586Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T09:05:47.3046153Z   )
2026-01-14T09:05:47.3046438Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.3047503Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:47.3048680Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9838534593582153)
2026-01-14T09:05:47.3049183Z   )
2026-01-14T09:05:47.3049370Z )
2026-01-14T09:05:47.3049469Z 
2026-01-14T09:05:47.3049473Z 
2026-01-14T09:05:47.3049477Z 
2026-01-14T09:05:47.3049568Z def forward(self, x):
2026-01-14T09:05:47.3049953Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:47.3050317Z     conv_weight = self.conv.weight
2026-01-14T09:05:47.3050606Z     bn_weight = self.bn.weight
2026-01-14T09:05:47.3050872Z     bn_bias = self.bn.bias
2026-01-14T09:05:47.3051163Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:05:47.3051486Z     bn_running_var = self.bn.running_var
2026-01-14T09:05:47.3051960Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:47.3052546Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:47.3053334Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:47.3054042Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:05:47.3054455Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:05:47.3054897Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:06:02.8800835Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:06:02.8801663Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:06:02.8802596Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:06:02.8803924Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:06:02.8805124Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:06:02.8805872Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:06:02.8807269Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:06:02.8808788Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:06:02.8809509Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:06:02.8810255Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:06:02.8810885Z     
2026-01-14T09:06:02.8811259Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:02.8811769Z model fx: GraphModule(
2026-01-14T09:06:02.8812184Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:02.8813548Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:02.8815182Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:06:02.8815876Z   )
2026-01-14T09:06:02.8816128Z   (conv): ConvBnReLU2d(
2026-01-14T09:06:02.8816478Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:06:02.8817074Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:06:02.8817718Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:02.8819044Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:02.8820670Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T09:06:02.8821385Z     )
2026-01-14T09:06:02.8821615Z   )
2026-01-14T09:06:02.8821964Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:02.8823440Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:02.8824976Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9838534593582153)
2026-01-14T09:06:02.8825614Z   )
2026-01-14T09:06:02.8825842Z )
2026-01-14T09:06:02.8825968Z 
2026-01-14T09:06:02.8825973Z 
2026-01-14T09:06:02.8826062Z 
2026-01-14T09:06:02.8826173Z def forward(self, x):
2026-01-14T09:06:02.8826634Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:02.8827345Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:02.8828104Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:02.8828676Z     return activation_post_process_1
2026-01-14T09:06:02.8829017Z     
2026-01-14T09:06:02.8829374Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:02.8829876Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:02.8830190Z           [0., 0., 0.],
2026-01-14T09:06:02.8830461Z           [0., 0., 0.]],
2026-01-14T09:06:02.8830642Z 
2026-01-14T09:06:02.8830746Z          [[0., 0., 0.],
2026-01-14T09:06:02.8831015Z           [0., 0., 0.],
2026-01-14T09:06:02.8831286Z           [0., 0., 0.]],
2026-01-14T09:06:02.8831463Z 
2026-01-14T09:06:02.8831562Z          [[0., 0., 0.],
2026-01-14T09:06:02.8831834Z           [0., 0., 0.],
2026-01-14T09:06:02.8832145Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:02.8832557Z converted model pt2e: GraphModule(
2026-01-14T09:06:02.8832905Z   (conv): Module()
2026-01-14T09:06:02.8833156Z   (bn): Module()
2026-01-14T09:06:02.8833402Z )
2026-01-14T09:06:02.8833524Z 
2026-01-14T09:06:02.8833529Z 
2026-01-14T09:06:02.8833534Z 
2026-01-14T09:06:02.8833642Z def forward(self, x):
2026-01-14T09:06:02.8834011Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:02.8835060Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:02.8836890Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:02.8838052Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:06:02.8838919Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001507229870185256, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:06:02.8839968Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:06:02.8840885Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:06:02.8841892Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:06:02.8842797Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007779817562550306, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:06:02.8844231Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007779817562550306, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:06:02.8845366Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:06:02.8845815Z     
2026-01-14T09:06:02.8846113Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:02.8846534Z onverted model fx: GraphModule(
2026-01-14T09:06:02.8846805Z   (conv): ConvReLU2d(
2026-01-14T09:06:02.8847174Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:06:02.8847574Z     (1): ReLU()
2026-01-14T09:06:02.8847787Z   )
2026-01-14T09:06:02.8847970Z )
2026-01-14T09:06:02.8848160Z 
2026-01-14T09:06:02.8848165Z 
2026-01-14T09:06:02.8848169Z 
2026-01-14T09:06:02.8848261Z def forward(self, x):
2026-01-14T09:06:02.8848940Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:02.8850313Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:02.8851502Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:02.8852451Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007779817562550306, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:02.8853884Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007779817562550306, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:02.8854878Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:02.8855168Z     
2026-01-14T09:06:02.8855478Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:02.8855881Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:02.8856142Z           [0., 0., 0.],
2026-01-14T09:06:02.8856379Z           [0., 0., 0.]],
2026-01-14T09:06:02.8856529Z 
2026-01-14T09:06:02.8856611Z          [[0., 0., 0.],
2026-01-14T09:06:02.8856839Z           [0., 0., 0.],
2026-01-14T09:06:02.8857067Z           [0., 0., 0.]],
2026-01-14T09:06:02.8857222Z 
2026-01-14T09:06:02.8857304Z          [[0., 0., 0.],
2026-01-14T09:06:02.8857530Z           [0., 0., 0.],
2026-01-14T09:06:02.8857767Z           [0., 0., 0.]]]])
2026-01-14T09:06:02.8858221Z [32mPASSED[0m
2026-01-14T09:06:02.8858914Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T09:06:02.8859571Z   (conv): Module()
2026-01-14T09:06:02.8859897Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:02.8861110Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:02.8862592Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:06:02.8863304Z   )
2026-01-14T09:06:02.8863607Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:02.8864680Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:02.8865937Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:06:02.8866497Z   )
2026-01-14T09:06:02.8866798Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:02.8867870Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:02.8869074Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5882599353790283)
2026-01-14T09:06:02.8869586Z   )
2026-01-14T09:06:02.8869768Z )
2026-01-14T09:06:02.8869880Z 
2026-01-14T09:06:02.8869884Z 
2026-01-14T09:06:02.8869888Z 
2026-01-14T09:06:02.8869977Z def forward(self, x):
2026-01-14T09:06:02.8870291Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:02.8870662Z     conv_weight = self.conv.weight
2026-01-14T09:06:02.8871220Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:02.8871856Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:02.8872753Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:06:02.8873633Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:06:04.3828591Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:06:04.3829362Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:06:04.3829882Z     
2026-01-14T09:06:04.3830249Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:04.3830730Z model fx: GraphModule(
2026-01-14T09:06:04.3831165Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:04.3832518Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:04.3834184Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:06:04.3834887Z   )
2026-01-14T09:06:04.3835120Z   (conv): ConvReLU2d(
2026-01-14T09:06:04.3835459Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:06:04.3835945Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:04.3837317Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:04.3839753Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:06:04.3840661Z     )
2026-01-14T09:06:04.3840883Z   )
2026-01-14T09:06:04.3841354Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:04.3842803Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:04.3844322Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5882599353790283)
2026-01-14T09:06:04.3844950Z   )
2026-01-14T09:06:04.3845181Z )
2026-01-14T09:06:04.3845309Z 
2026-01-14T09:06:04.3845314Z 
2026-01-14T09:06:04.3845319Z 
2026-01-14T09:06:04.3845432Z def forward(self, x):
2026-01-14T09:06:04.3845885Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:04.3846606Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:04.3847329Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:04.3847901Z     return activation_post_process_1
2026-01-14T09:06:04.3848227Z     
2026-01-14T09:06:04.3848590Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:04.3849090Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:04.3849386Z           [0., 0., 0.],
2026-01-14T09:06:04.3849655Z           [0., 0., 0.]],
2026-01-14T09:06:04.3849835Z 
2026-01-14T09:06:04.3849932Z          [[0., 0., 0.],
2026-01-14T09:06:04.3850201Z           [0., 0., 0.],
2026-01-14T09:06:04.3850462Z           [0., 0., 0.]],
2026-01-14T09:06:04.3850643Z 
2026-01-14T09:06:04.3850740Z          [[0., 0., 0.],
2026-01-14T09:06:04.3850998Z           [0., 0., 0.],
2026-01-14T09:06:04.3851311Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:04.3851747Z converted model pt2e: GraphModule(
2026-01-14T09:06:04.3852191Z   (conv): Module()
2026-01-14T09:06:04.3852455Z )
2026-01-14T09:06:04.3852577Z 
2026-01-14T09:06:04.3852582Z 
2026-01-14T09:06:04.3852586Z 
2026-01-14T09:06:04.3852698Z def forward(self, x):
2026-01-14T09:06:04.3853066Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:04.3853501Z     _scale_0 = self._scale_0
2026-01-14T09:06:04.3853918Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:06:04.3854340Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:06:04.3855726Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:06:04.3857706Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:04.3859082Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:04.3860544Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:06:04.3861456Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:06:04.3862297Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006228470243513584, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:06:04.3863715Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006228470243513584, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:04.3864892Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:06:04.3865353Z     
2026-01-14T09:06:04.3865661Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:04.3866069Z onverted model fx: GraphModule(
2026-01-14T09:06:04.3866382Z   (conv): ConvReLU2d(
2026-01-14T09:06:04.3866783Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:06:04.3867230Z     (1): ReLU()
2026-01-14T09:06:04.3867438Z   )
2026-01-14T09:06:04.3867618Z )
2026-01-14T09:06:04.3867727Z 
2026-01-14T09:06:04.3867731Z 
2026-01-14T09:06:04.3867735Z 
2026-01-14T09:06:04.3867824Z def forward(self, x):
2026-01-14T09:06:04.3868494Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:04.3869863Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:04.3870981Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:04.3871922Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006228470243513584, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:04.3873346Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006228470243513584, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:04.3874335Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:04.3874629Z     
2026-01-14T09:06:04.3874933Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:04.3875330Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:04.3875588Z           [0., 0., 0.],
2026-01-14T09:06:04.3875816Z           [0., 0., 0.]],
2026-01-14T09:06:04.3875973Z 
2026-01-14T09:06:04.3876058Z          [[0., 0., 0.],
2026-01-14T09:06:04.3876338Z           [0., 0., 0.],
2026-01-14T09:06:04.3876559Z           [0., 0., 0.]],
2026-01-14T09:06:04.3876707Z 
2026-01-14T09:06:04.3876794Z          [[0., 0., 0.],
2026-01-14T09:06:04.3877014Z           [0., 0., 0.],
2026-01-14T09:06:04.3877248Z           [0., 0., 0.]]]])
2026-01-14T09:06:04.3877495Z model pt2e: GraphModule(
2026-01-14T09:06:04.3877819Z   (conv): Module()
2026-01-14T09:06:04.3878143Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:04.3879217Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:04.3880483Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965116143226624, max_val=0.18703685700893402)
2026-01-14T09:06:04.3881041Z   )
2026-01-14T09:06:04.3881342Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:04.3882389Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:04.3883702Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:06:04.3884259Z   )
2026-01-14T09:06:04.3884540Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:04.3885596Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:04.3886778Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5892566442489624)
2026-01-14T09:06:04.3887332Z   )
2026-01-14T09:06:04.3887563Z )
2026-01-14T09:06:04.3887663Z 
2026-01-14T09:06:04.3887672Z 
2026-01-14T09:06:04.3887676Z 
2026-01-14T09:06:04.3887763Z def forward(self, x):
2026-01-14T09:06:04.3888077Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:04.3888478Z     conv_weight = self.conv.weight
2026-01-14T09:06:04.3888974Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:04.3889611Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:04.3890497Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:06:04.3891325Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:06:04.3891839Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:06:04.3892425Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:06:04.3892836Z     
2026-01-14T09:06:04.3893135Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:04.3893520Z model fx: GraphModule(
2026-01-14T09:06:04.3893868Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:04.3894929Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:04.3896175Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:06:04.3896725Z   )
2026-01-14T09:06:04.3896909Z   (conv): ConvReLU2d(
2026-01-14T09:06:04.3897187Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:06:04.3897589Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:04.3898682Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:05.8622002Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965116143226624, max_val=0.18703685700893402)
2026-01-14T09:06:05.8622785Z     )
2026-01-14T09:06:05.8623345Z   )
2026-01-14T09:06:05.8623715Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:05.8625079Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:05.8626628Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5892566442489624)
2026-01-14T09:06:05.8627268Z   )
2026-01-14T09:06:05.8627497Z )
2026-01-14T09:06:05.8627623Z 
2026-01-14T09:06:05.8627629Z 
2026-01-14T09:06:05.8627649Z 
2026-01-14T09:06:05.8627770Z def forward(self, x):
2026-01-14T09:06:05.8628230Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:05.8628957Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:05.8629695Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:05.8630274Z     return activation_post_process_1
2026-01-14T09:06:05.8630614Z     
2026-01-14T09:06:05.8630972Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:05.8631473Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:05.8631774Z           [0., 0., 0.],
2026-01-14T09:06:05.8632048Z           [0., 0., 0.]],
2026-01-14T09:06:05.8632229Z 
2026-01-14T09:06:05.8632328Z          [[0., 0., 0.],
2026-01-14T09:06:05.8632599Z           [0., 0., 0.],
2026-01-14T09:06:05.8632861Z           [0., 0., 0.]],
2026-01-14T09:06:05.8633047Z 
2026-01-14T09:06:05.8633277Z          [[0., 0., 0.],
2026-01-14T09:06:05.8633561Z           [0., 0., 0.],
2026-01-14T09:06:05.8633874Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:05.8634289Z converted model pt2e: GraphModule(
2026-01-14T09:06:05.8634729Z   (conv): Module()
2026-01-14T09:06:05.8634990Z )
2026-01-14T09:06:05.8635114Z 
2026-01-14T09:06:05.8635119Z 
2026-01-14T09:06:05.8635128Z 
2026-01-14T09:06:05.8635236Z def forward(self, x):
2026-01-14T09:06:05.8635619Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:05.8636136Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:06:05.8637395Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0014933162601664662, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:05.8639410Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:05.8641039Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:05.8642590Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:06:05.8643509Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:06:05.8644347Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006232379004359245, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:06:05.8645777Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.006232379004359245, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:06:05.8647002Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:06:05.8647480Z     
2026-01-14T09:06:05.8647807Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:05.8648217Z onverted model fx: GraphModule(
2026-01-14T09:06:05.8648492Z   (conv): ConvReLU2d(
2026-01-14T09:06:05.8648890Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:06:05.8649414Z     (1): ReLU()
2026-01-14T09:06:05.8649619Z   )
2026-01-14T09:06:05.8649793Z )
2026-01-14T09:06:05.8649893Z 
2026-01-14T09:06:05.8649898Z 
2026-01-14T09:06:05.8649902Z 
2026-01-14T09:06:05.8649996Z def forward(self, x):
2026-01-14T09:06:05.8650664Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:05.8652035Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:05.8653148Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:05.8654088Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006232379004359245, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:05.8655516Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006232379004359245, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:05.8656491Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:05.8656784Z     
2026-01-14T09:06:05.8657088Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:05.8657484Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:05.8657739Z           [0., 0., 0.],
2026-01-14T09:06:05.8658040Z           [0., 0., 0.]],
2026-01-14T09:06:05.8658204Z 
2026-01-14T09:06:05.8658287Z          [[0., 0., 0.],
2026-01-14T09:06:05.8658503Z           [0., 0., 0.],
2026-01-14T09:06:05.8658728Z           [0., 0., 0.]],
2026-01-14T09:06:05.8658940Z 
2026-01-14T09:06:05.8659020Z          [[0., 0., 0.],
2026-01-14T09:06:05.8659241Z           [0., 0., 0.],
2026-01-14T09:06:05.8659463Z           [0., 0., 0.]]]])
2026-01-14T09:06:05.8659715Z model pt2e: GraphModule(
2026-01-14T09:06:05.8659958Z   (conv): Module()
2026-01-14T09:06:05.8660275Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:05.8661405Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:05.8662881Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:06:05.8663593Z   )
2026-01-14T09:06:05.8663892Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:05.8664944Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:05.8666194Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:06:05.8666747Z   )
2026-01-14T09:06:05.8667051Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:05.8668164Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0080]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:05.8669463Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9872972965240479, max_val=1.0470484495162964)
2026-01-14T09:06:05.8670034Z   )
2026-01-14T09:06:05.8670210Z )
2026-01-14T09:06:05.8670322Z 
2026-01-14T09:06:05.8670328Z 
2026-01-14T09:06:05.8670332Z 
2026-01-14T09:06:05.8670424Z def forward(self, x):
2026-01-14T09:06:05.8670739Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:05.8671153Z     conv_weight = self.conv.weight
2026-01-14T09:06:05.8671657Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:05.8672297Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:05.8673201Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:06:05.8674125Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:06:05.8674748Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:06:05.8675176Z     
2026-01-14T09:06:05.8675477Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:05.8675882Z model fx: GraphModule(
2026-01-14T09:06:05.8676225Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:05.8677299Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:05.8678567Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:06:05.8679121Z   )
2026-01-14T09:06:05.8679312Z   (conv): Conv2d(
2026-01-14T09:06:05.8679579Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:06:05.8679982Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:05.8681173Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:05.8682817Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:06:05.8683543Z     )
2026-01-14T09:06:05.8683726Z   )
2026-01-14T09:06:05.8684028Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:05.8685099Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0080]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:05.8686364Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9872972965240479, max_val=1.0470484495162964)
2026-01-14T09:06:05.8686938Z   )
2026-01-14T09:06:05.8687120Z )
2026-01-14T09:06:05.8687220Z 
2026-01-14T09:06:05.8687225Z 
2026-01-14T09:06:05.8687228Z 
2026-01-14T09:06:05.8687316Z def forward(self, x):
2026-01-14T09:06:05.8687700Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:05.8688282Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:05.8688888Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:05.8689360Z     return activation_post_process_1
2026-01-14T09:06:05.8689632Z     
2026-01-14T09:06:05.8689963Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:05.8690365Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:05.8690630Z           [0., 0., 0.],
2026-01-14T09:06:05.8690851Z           [0., 0., 0.]],
2026-01-14T09:06:05.8691008Z 
2026-01-14T09:06:05.8691088Z          [[0., 0., 0.],
2026-01-14T09:06:05.8691312Z           [0., 0., 0.],
2026-01-14T09:06:05.8691597Z           [0., 0., 0.]],
2026-01-14T09:06:05.8691747Z 
2026-01-14T09:06:05.8691836Z          [[0., 0., 0.],
2026-01-14T09:06:05.8692049Z           [0., 0., 0.],
2026-01-14T09:06:10.7808117Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:10.7808579Z converted model pt2e: GraphModule(
2026-01-14T09:06:10.7809032Z   (conv): Module()
2026-01-14T09:06:10.7809651Z )
2026-01-14T09:06:10.7809777Z 
2026-01-14T09:06:10.7809782Z 
2026-01-14T09:06:10.7809786Z 
2026-01-14T09:06:10.7809894Z def forward(self, x):
2026-01-14T09:06:10.7810268Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:10.7810714Z     _scale_0 = self._scale_0
2026-01-14T09:06:10.7811038Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:06:10.7811458Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:06:10.7812881Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:06:10.7814787Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:10.7816525Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:10.7818376Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:06:10.7820010Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.007977825589478016, -4, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:06:10.7821928Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007977825589478016, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:10.7823334Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:06:10.7823991Z     
2026-01-14T09:06:10.7824357Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:10.7824864Z onverted model fx: GraphModule(
2026-01-14T09:06:10.7825408Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:06:10.7825975Z )
2026-01-14T09:06:10.7826105Z 
2026-01-14T09:06:10.7826110Z 
2026-01-14T09:06:10.7826115Z 
2026-01-14T09:06:10.7826232Z def forward(self, x):
2026-01-14T09:06:10.7827056Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:10.7828788Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:10.7830215Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:10.7831382Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007977825589478016, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:10.7833166Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007977825589478016, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:10.7834398Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:10.7834780Z     
2026-01-14T09:06:10.7835153Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:10.7835642Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:10.7835952Z           [0., 0., 0.],
2026-01-14T09:06:10.7836323Z           [0., 0., 0.]],
2026-01-14T09:06:10.7836516Z 
2026-01-14T09:06:10.7836617Z          [[0., 0., 0.],
2026-01-14T09:06:10.7836886Z           [0., 0., 0.],
2026-01-14T09:06:10.7837164Z           [0., 0., 0.]],
2026-01-14T09:06:10.7837344Z 
2026-01-14T09:06:10.7837444Z          [[0., 0., 0.],
2026-01-14T09:06:10.7837723Z           [0., 0., 0.],
2026-01-14T09:06:10.7838060Z           [0., 0., 0.]]]])
2026-01-14T09:06:10.7838360Z model pt2e: GraphModule(
2026-01-14T09:06:10.7838664Z   (conv): Module()
2026-01-14T09:06:10.7839344Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:10.7840703Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:10.7842304Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212539494037628, max_val=0.18097467720508575)
2026-01-14T09:06:10.7843120Z   )
2026-01-14T09:06:10.7843479Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:10.7844798Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:10.7846369Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:06:10.7847056Z   )
2026-01-14T09:06:10.7847417Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:10.7848741Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:10.7850402Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9800506234169006, max_val=1.0470484495162964)
2026-01-14T09:06:10.7851112Z   )
2026-01-14T09:06:10.7851326Z )
2026-01-14T09:06:10.7851459Z 
2026-01-14T09:06:10.7851537Z 
2026-01-14T09:06:10.7851542Z 
2026-01-14T09:06:10.7851652Z def forward(self, x):
2026-01-14T09:06:10.7852025Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:10.7852473Z     conv_weight = self.conv.weight
2026-01-14T09:06:10.7853088Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:10.7853871Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:10.7854985Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:06:10.7856126Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:06:10.7856880Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:06:10.7857408Z     
2026-01-14T09:06:10.7857778Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:10.7858267Z model fx: GraphModule(
2026-01-14T09:06:10.7858669Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:10.7859997Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:10.7861559Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:06:10.7862244Z   )
2026-01-14T09:06:10.7862465Z   (conv): Conv2d(
2026-01-14T09:06:10.7862813Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:06:10.7863320Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:10.7864691Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:10.7865973Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212539494037628, max_val=0.18097467720508575)
2026-01-14T09:06:10.7866603Z     )
2026-01-14T09:06:10.7866784Z   )
2026-01-14T09:06:10.7867069Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:10.7868124Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:10.7869372Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9800506234169006, max_val=1.0470484495162964)
2026-01-14T09:06:10.7869920Z   )
2026-01-14T09:06:10.7870099Z )
2026-01-14T09:06:10.7870198Z 
2026-01-14T09:06:10.7870205Z 
2026-01-14T09:06:10.7870209Z 
2026-01-14T09:06:10.7870304Z def forward(self, x):
2026-01-14T09:06:10.7870669Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:10.7871245Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:10.7871836Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:10.7872296Z     return activation_post_process_1
2026-01-14T09:06:10.7872560Z     
2026-01-14T09:06:10.7872856Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:10.7873245Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:10.7873495Z           [0., 0., 0.],
2026-01-14T09:06:10.7873715Z           [0., 0., 0.]],
2026-01-14T09:06:10.7873861Z 
2026-01-14T09:06:10.7873972Z          [[0., 0., 0.],
2026-01-14T09:06:10.7874190Z           [0., 0., 0.],
2026-01-14T09:06:10.7874462Z           [0., 0., 0.]],
2026-01-14T09:06:10.7874615Z 
2026-01-14T09:06:10.7874698Z          [[0., 0., 0.],
2026-01-14T09:06:10.7874908Z           [0., 0., 0.],
2026-01-14T09:06:10.7875166Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:10.7875535Z converted model pt2e: GraphModule(
2026-01-14T09:06:10.7875805Z   (conv): Module()
2026-01-14T09:06:10.7876007Z )
2026-01-14T09:06:10.7876108Z 
2026-01-14T09:06:10.7876112Z 
2026-01-14T09:06:10.7876116Z 
2026-01-14T09:06:10.7876203Z def forward(self, x):
2026-01-14T09:06:10.7876499Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:10.7876902Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:06:10.7877896Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0015127983642742038, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:10.7879273Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:10.7880652Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:10.7882137Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:06:10.7883501Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.007949408143758774, -5, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:07:23.4026115Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007949408143758774, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:07:23.4027521Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:07:23.4027984Z     
2026-01-14T09:07:23.4028287Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:23.4028708Z onverted model fx: GraphModule(
2026-01-14T09:07:23.4029167Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:07:23.4029727Z )
2026-01-14T09:07:23.4029841Z 
2026-01-14T09:07:23.4029845Z 
2026-01-14T09:07:23.4029856Z 
2026-01-14T09:07:23.4029950Z def forward(self, x):
2026-01-14T09:07:23.4030621Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:07:23.4031990Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:23.4033108Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:07:23.4034045Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007949408143758774, -5, -128, 127, torch.int8);  conv = None
2026-01-14T09:07:23.4035455Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007949408143758774, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:07:23.4036436Z     return dequantize_per_tensor_default_1
2026-01-14T09:07:23.4036727Z     
2026-01-14T09:07:23.4037035Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:23.4037436Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:23.4037696Z           [0., 0., 0.],
2026-01-14T09:07:23.4037924Z           [0., 0., 0.]],
2026-01-14T09:07:23.4038088Z 
2026-01-14T09:07:23.4038172Z          [[0., 0., 0.],
2026-01-14T09:07:23.4038501Z           [0., 0., 0.],
2026-01-14T09:07:23.4038736Z           [0., 0., 0.]],
2026-01-14T09:07:23.4038887Z 
2026-01-14T09:07:23.4039149Z          [[0., 0., 0.],
2026-01-14T09:07:23.4039370Z           [0., 0., 0.],
2026-01-14T09:07:23.4039707Z           [0., 0., 0.]]]])
2026-01-14T09:07:23.4040199Z [32mPASSED[0m
2026-01-14T09:07:23.4040886Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T09:07:23.4041997Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T09:07:23.4043068Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T09:07:23.4043713Z   (conv): Module()
2026-01-14T09:07:23.4044033Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:23.4045119Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:07:23.4046448Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2877]), max_val=tensor([-0.2877]))
2026-01-14T09:07:23.4047061Z   )
2026-01-14T09:07:23.4047363Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:23.4048412Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:23.4049647Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:07:23.4050203Z   )
2026-01-14T09:07:23.4050490Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:23.4051639Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:23.4052900Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:07:23.4053454Z   )
2026-01-14T09:07:23.4053810Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:23.4054865Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:23.4056057Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:07:23.4056561Z   )
2026-01-14T09:07:23.4056734Z )
2026-01-14T09:07:23.4056835Z 
2026-01-14T09:07:23.4056839Z 
2026-01-14T09:07:23.4056843Z 
2026-01-14T09:07:23.4056942Z def forward(self, x):
2026-01-14T09:07:23.4057245Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:23.4057615Z     conv_weight = self.conv.weight
2026-01-14T09:07:23.4058113Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:07:23.4058626Z     conv_bias = self.conv.bias
2026-01-14T09:07:23.4059032Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:07:23.4059947Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:07:23.4060844Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:07:23.4061727Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:07:23.4062590Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:07:23.4063113Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:07:23.4063702Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:07:23.4064168Z     
2026-01-14T09:07:23.4064469Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:23.4064880Z model fx: GraphModule(
2026-01-14T09:07:23.4065220Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:23.4066289Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:23.4067547Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:07:23.4068103Z   )
2026-01-14T09:07:23.4068293Z   (conv): Conv2d(
2026-01-14T09:07:23.4068533Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T09:07:23.4068902Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:23.4069968Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:07:23.4071344Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2877]), max_val=tensor([-0.2877]))
2026-01-14T09:07:23.4071964Z     )
2026-01-14T09:07:23.4072144Z   )
2026-01-14T09:07:23.4072440Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:23.4073491Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:23.4074798Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:07:23.4075365Z   )
2026-01-14T09:07:23.4075562Z   (relu): ReLU(inplace=True)
2026-01-14T09:07:23.4075922Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:23.4076982Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:23.4078232Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:07:23.4078737Z   )
2026-01-14T09:07:23.4078912Z )
2026-01-14T09:07:23.4079014Z 
2026-01-14T09:07:23.4079018Z 
2026-01-14T09:07:23.4079022Z 
2026-01-14T09:07:23.4079121Z def forward(self, x):
2026-01-14T09:07:23.4079488Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:07:23.4079958Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:07:23.4080423Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:07:23.4081189Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:07:23.4081811Z     relu = self.relu(add);  add = None
2026-01-14T09:07:23.4082250Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:07:23.4082765Z     return activation_post_process_2
2026-01-14T09:07:23.4083033Z     
2026-01-14T09:07:23.4083335Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:23.4083731Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:23.4083988Z           [0., 0., 0.],
2026-01-14T09:07:23.4084248Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:07:23.4084585Z converted model pt2e: GraphModule(
2026-01-14T09:07:23.4084866Z   (conv): Module()
2026-01-14T09:07:23.4085122Z )
2026-01-14T09:07:23.4085229Z 
2026-01-14T09:07:23.4085233Z 
2026-01-14T09:07:23.4085237Z 
2026-01-14T09:07:23.4085334Z def forward(self, x):
2026-01-14T09:07:23.4085636Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:23.4086043Z     _scale_0 = self._scale_0
2026-01-14T09:07:23.4086309Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:07:23.4086670Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:07:23.4087784Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:07:23.4088845Z     conv_bias = self.conv.bias
2026-01-14T09:07:23.4089545Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:07:23.4090821Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:07:24.7361533Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:24.7363408Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T09:07:24.7364804Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.003615050343796611, 43, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:07:24.7366396Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:07:24.7368199Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T09:07:24.7369256Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:07:24.7370311Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.003489378374069929, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:07:24.7372068Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:07:24.7373427Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:07:24.7373881Z     
2026-01-14T09:07:24.7374208Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:24.7374621Z onverted model fx: GraphModule(
2026-01-14T09:07:24.7375046Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T09:07:24.7382784Z   (relu): ReLU(inplace=True)
2026-01-14T09:07:24.7383087Z )
2026-01-14T09:07:24.7383195Z 
2026-01-14T09:07:24.7383199Z 
2026-01-14T09:07:24.7383211Z 
2026-01-14T09:07:24.7383314Z def forward(self, x):
2026-01-14T09:07:24.7383982Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:07:24.7385337Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:24.7386310Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:07:24.7387201Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003615050343796611, 43, -128, 127, torch.int8);  conv = None
2026-01-14T09:07:24.7388619Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:07:24.7390028Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:07:24.7390721Z     relu = self.relu(add);  add = None
2026-01-14T09:07:24.7391477Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003489378374069929, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:07:24.7392896Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:07:24.7393885Z     return dequantize_per_tensor_default_2
2026-01-14T09:07:24.7394179Z     
2026-01-14T09:07:24.7394474Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:24.7394886Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:24.7395135Z           [0., 0., 0.],
2026-01-14T09:07:24.7395360Z           [0., 0., 0.]]]])
2026-01-14T09:07:24.7395606Z model pt2e: GraphModule(
2026-01-14T09:07:24.7395854Z   (conv): Module()
2026-01-14T09:07:24.7396171Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:24.7397249Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:07:24.7398602Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28767645359039307, max_val=-0.28767645359039307)
2026-01-14T09:07:24.7399176Z   )
2026-01-14T09:07:24.7399516Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:24.7400576Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:24.7401819Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:07:24.7402411Z   )
2026-01-14T09:07:24.7402776Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:24.7403822Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:24.7405077Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:07:24.7405636Z   )
2026-01-14T09:07:24.7405919Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:24.7406977Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:24.7408165Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:07:24.7408675Z   )
2026-01-14T09:07:24.7408840Z )
2026-01-14T09:07:24.7408947Z 
2026-01-14T09:07:24.7408952Z 
2026-01-14T09:07:24.7408956Z 
2026-01-14T09:07:24.7409042Z def forward(self, x):
2026-01-14T09:07:24.7409349Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:24.7409705Z     conv_weight = self.conv.weight
2026-01-14T09:07:24.7410203Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:07:24.7410754Z     conv_bias = self.conv.bias
2026-01-14T09:07:24.7411152Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:07:24.7412014Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:07:24.7412940Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:07:24.7413832Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:07:24.7414610Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:07:24.7415120Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:07:24.7415712Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:07:24.7416120Z     
2026-01-14T09:07:24.7416422Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:24.7416811Z model fx: GraphModule(
2026-01-14T09:07:24.7417159Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:24.7418213Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:24.7419480Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:07:24.7420040Z   )
2026-01-14T09:07:24.7420221Z   (conv): Conv2d(
2026-01-14T09:07:24.7420461Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T09:07:24.7420823Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:24.7421932Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:07:24.7423224Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28767645359039307, max_val=-0.28767645359039307)
2026-01-14T09:07:24.7423811Z     )
2026-01-14T09:07:24.7423990Z   )
2026-01-14T09:07:24.7424273Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:24.7425391Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:24.7426651Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:07:24.7427214Z   )
2026-01-14T09:07:24.7427412Z   (relu): ReLU(inplace=True)
2026-01-14T09:07:24.7427768Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:24.7428850Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:24.7430056Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:07:24.7430571Z   )
2026-01-14T09:07:24.7430740Z )
2026-01-14T09:07:24.7430846Z 
2026-01-14T09:07:24.7430851Z 
2026-01-14T09:07:24.7430855Z 
2026-01-14T09:07:24.7430941Z def forward(self, x):
2026-01-14T09:07:24.7431316Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:07:24.7431777Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:07:24.7432250Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:08:05.8297971Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:08:05.8298844Z     relu = self.relu(add);  add = None
2026-01-14T09:08:05.8299408Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:08:05.8300093Z     return activation_post_process_2
2026-01-14T09:08:05.8300446Z     
2026-01-14T09:08:05.8300820Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:05.8301319Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:05.8301632Z           [0., 0., 0.],
2026-01-14T09:08:05.8301944Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:08:05.8302348Z converted model pt2e: GraphModule(
2026-01-14T09:08:05.8302683Z   (conv): Module()
2026-01-14T09:08:05.8302941Z )
2026-01-14T09:08:05.8303067Z 
2026-01-14T09:08:05.8303072Z 
2026-01-14T09:08:05.8303077Z 
2026-01-14T09:08:05.8303185Z def forward(self, x):
2026-01-14T09:08:05.8303562Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:05.8304075Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:08:05.8305321Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.002265168819576502, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:05.8306512Z     conv_bias = self.conv.bias
2026-01-14T09:08:05.8307383Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:08:05.8308922Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:08:05.8310759Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:05.8312821Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T09:08:05.8314555Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.003615050343796611, 43, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:08:05.8316351Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:05.8318289Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T09:08:05.8319375Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:08:05.8320414Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.003489378374069929, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:08:05.8322221Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:08:05.8323729Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:08:05.8324287Z     
2026-01-14T09:08:05.8324651Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:05.8325156Z onverted model fx: GraphModule(
2026-01-14T09:08:05.8325648Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T09:08:05.8326170Z   (relu): ReLU(inplace=True)
2026-01-14T09:08:05.8326473Z )
2026-01-14T09:08:05.8326594Z 
2026-01-14T09:08:05.8326599Z 
2026-01-14T09:08:05.8326604Z 
2026-01-14T09:08:05.8326720Z def forward(self, x):
2026-01-14T09:08:05.8327691Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:08:05.8329159Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:05.8330179Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:08:05.8330968Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003615050343796611, 43, -128, 127, torch.int8);  conv = None
2026-01-14T09:08:05.8332364Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:05.8333703Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:08:05.8334402Z     relu = self.relu(add);  add = None
2026-01-14T09:08:05.8335153Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003489378374069929, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:08:05.8336574Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:05.8337553Z     return dequantize_per_tensor_default_2
2026-01-14T09:08:05.8337833Z     
2026-01-14T09:08:05.8338131Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:05.8338521Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:05.8338771Z           [0., 0., 0.],
2026-01-14T09:08:05.8339286Z           [0., 0., 0.]]]])
2026-01-14T09:08:05.8339744Z [32mPASSED[0m
2026-01-14T09:08:05.8340583Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T09:08:05.8341722Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T09:08:05.8342778Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec [32mPASSED[0m
2026-01-14T09:08:05.8343807Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T09:08:05.8344465Z   (conv): Module()
2026-01-14T09:08:05.8344673Z   (bn): Module()
2026-01-14T09:08:05.8344994Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:05.8346052Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:05.8347316Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:05.8347860Z   )
2026-01-14T09:08:05.8348145Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:05.8349269Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:08:05.8350737Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1872, -0.1882, -0.1827]), max_val=tensor([0.1805, 0.1400, 0.1829]))
2026-01-14T09:08:05.8351449Z   )
2026-01-14T09:08:05.8351744Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:05.8352875Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:05.8354118Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:08:05.8354728Z   )
2026-01-14T09:08:05.8355012Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:05.8356071Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:05.8357303Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:08:05.8357849Z   )
2026-01-14T09:08:05.8358028Z )
2026-01-14T09:08:05.8358129Z 
2026-01-14T09:08:05.8358133Z 
2026-01-14T09:08:05.8358137Z 
2026-01-14T09:08:05.8358225Z def forward(self, x):
2026-01-14T09:08:05.8358551Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:05.8358909Z     conv_weight = self.conv.weight
2026-01-14T09:08:05.8359198Z     conv_bias = self.conv.bias
2026-01-14T09:08:05.8359470Z     bn_weight = self.bn.weight
2026-01-14T09:08:05.8359731Z     bn_bias = self.bn.bias
2026-01-14T09:08:05.8360005Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:08:05.8360318Z     bn_running_var = self.bn.running_var
2026-01-14T09:08:05.8360678Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:08:05.8361143Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:05.8361793Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:08:05.8362369Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:08:05.8362864Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:08:05.8363307Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:08:05.8363835Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:08:05.8364385Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:08:05.8364990Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:08:05.8365665Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:08:05.8366795Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:08:05.8367767Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:08:26.5617925Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:08:26.5621142Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:08:26.5621955Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:08:26.5623221Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:08:26.5624567Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:08:26.5625594Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:08:26.5626574Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:08:26.5627337Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:08:26.5627860Z     
2026-01-14T09:08:26.5628223Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:26.5629008Z model fx: GraphModule(
2026-01-14T09:08:26.5629430Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:26.5630773Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:26.5632448Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:26.5633132Z   )
2026-01-14T09:08:26.5633369Z   (conv): ConvBn2d(
2026-01-14T09:08:26.5633656Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:08:26.5634204Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:08:26.5634839Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:26.5636217Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:08:26.5638078Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1872, -0.1882, -0.1827]), max_val=tensor([0.1805, 0.1400, 0.1829]))
2026-01-14T09:08:26.5639189Z     )
2026-01-14T09:08:26.5639425Z   )
2026-01-14T09:08:26.5639779Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:26.5641103Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:26.5642762Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:08:26.5643449Z   )
2026-01-14T09:08:26.5643730Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:08:26.5644355Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:26.5645688Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:26.5647260Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:08:26.5648089Z   )
2026-01-14T09:08:26.5648310Z )
2026-01-14T09:08:26.5648432Z 
2026-01-14T09:08:26.5648437Z 
2026-01-14T09:08:26.5648442Z 
2026-01-14T09:08:26.5648548Z def forward(self, x):
2026-01-14T09:08:26.5649006Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:26.5649713Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:08:26.5650439Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:08:26.5651226Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:08:26.5652037Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:08:26.5652670Z     return activation_post_process_2
2026-01-14T09:08:26.5653004Z     
2026-01-14T09:08:26.5653357Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:26.5653893Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:26.5654206Z           [0., 0., 0.],
2026-01-14T09:08:26.5654489Z           [0., 0., 0.]],
2026-01-14T09:08:26.5654677Z 
2026-01-14T09:08:26.5654784Z          [[0., 0., 0.],
2026-01-14T09:08:26.5655047Z           [0., 0., 0.],
2026-01-14T09:08:26.5655271Z           [0., 0., 0.]],
2026-01-14T09:08:26.5655413Z 
2026-01-14T09:08:26.5655493Z          [[0., 0., 0.],
2026-01-14T09:08:26.5655706Z           [0., 0., 0.],
2026-01-14T09:08:26.5655949Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:08:26.5656374Z converted model pt2e: GraphModule(
2026-01-14T09:08:26.5656643Z   (conv): Module()
2026-01-14T09:08:26.5656856Z   (bn): Module()
2026-01-14T09:08:26.5657045Z )
2026-01-14T09:08:26.5657148Z 
2026-01-14T09:08:26.5657217Z 
2026-01-14T09:08:26.5657221Z 
2026-01-14T09:08:26.5657311Z def forward(self, x):
2026-01-14T09:08:26.5657612Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:26.5657970Z     conv_bias = self.conv.bias
2026-01-14T09:08:26.5658668Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:08:26.5660023Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:26.5660956Z     _scale_0 = self._scale_0
2026-01-14T09:08:26.5661225Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:08:26.5661541Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:08:26.5662513Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:08:26.5664008Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:08:26.5665343Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.014923675917088985, -46, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:08:26.5666777Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:26.5668115Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T09:08:26.5669246Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014923675917088985, -46, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:08:26.5670692Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:26.5671840Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:08:26.5672286Z     
2026-01-14T09:08:26.5672574Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:26.5672975Z onverted model fx: GraphModule(
2026-01-14T09:08:26.5673373Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:08:26.5673828Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:08:26.5674128Z )
2026-01-14T09:08:26.5674226Z 
2026-01-14T09:08:26.5674230Z 
2026-01-14T09:08:26.5674234Z 
2026-01-14T09:08:26.5674318Z def forward(self, x):
2026-01-14T09:08:26.5674983Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:08:26.5676343Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:26.5677442Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:08:26.5678430Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014923675917088985, -46, -128, 127, torch.int8);  conv = None
2026-01-14T09:08:26.5679908Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:26.5681121Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:08:26.5682136Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014923675917088985, -46, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:08:26.5683655Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:26.5684658Z     return dequantize_per_tensor_default_2
2026-01-14T09:08:26.5684948Z     
2026-01-14T09:08:26.5685245Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:26.5685646Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:26.5685890Z           [0., 0., 0.],
2026-01-14T09:08:26.5686113Z           [0., 0., 0.]],
2026-01-14T09:08:26.5686261Z 
2026-01-14T09:08:26.5686349Z          [[0., 0., 0.],
2026-01-14T09:08:26.5686567Z           [0., 0., 0.],
2026-01-14T09:08:26.5686784Z           [0., 0., 0.]],
2026-01-14T09:08:26.5686929Z 
2026-01-14T09:08:26.5687007Z          [[0., 0., 0.],
2026-01-14T09:08:26.5687228Z           [0., 0., 0.],
2026-01-14T09:08:26.5687439Z           [0., 0., 0.]]]])
2026-01-14T09:08:26.5687685Z model pt2e: GraphModule(
2026-01-14T09:08:26.5687918Z   (conv): Module()
2026-01-14T09:08:26.5688135Z   (bn): Module()
2026-01-14T09:08:26.5688443Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:26.5689498Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:40.9799324Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:40.9800094Z   )
2026-01-14T09:08:40.9800452Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:40.9801821Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:08:40.9803646Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18815943598747253, max_val=0.1829397827386856)
2026-01-14T09:08:40.9804360Z   )
2026-01-14T09:08:40.9804708Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:40.9806046Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:40.9807610Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:40.9808295Z   )
2026-01-14T09:08:40.9808658Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:40.9809974Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:40.9811533Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:40.9812271Z   )
2026-01-14T09:08:40.9812492Z )
2026-01-14T09:08:40.9812626Z 
2026-01-14T09:08:40.9812631Z 
2026-01-14T09:08:40.9812636Z 
2026-01-14T09:08:40.9812744Z def forward(self, x):
2026-01-14T09:08:40.9813109Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:40.9813668Z     conv_weight = self.conv.weight
2026-01-14T09:08:40.9814031Z     conv_bias = self.conv.bias
2026-01-14T09:08:40.9814353Z     bn_weight = self.bn.weight
2026-01-14T09:08:40.9814674Z     bn_bias = self.bn.bias
2026-01-14T09:08:40.9815100Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:08:40.9815490Z     bn_running_var = self.bn.running_var
2026-01-14T09:08:40.9815914Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:08:40.9816501Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:40.9817291Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:08:40.9818015Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:08:40.9818526Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:08:40.9819058Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:08:40.9819646Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:08:40.9820316Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:08:40.9821087Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:08:40.9821919Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:08:40.9823288Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:08:40.9824529Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:08:40.9825245Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:08:40.9826037Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:08:40.9826801Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:08:40.9828109Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:08:40.9829458Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:08:40.9830510Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:08:40.9831485Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:08:40.9832251Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:08:40.9832768Z     
2026-01-14T09:08:40.9833129Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:40.9833608Z model fx: GraphModule(
2026-01-14T09:08:40.9834022Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:40.9835349Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:40.9836922Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:40.9837615Z   )
2026-01-14T09:08:40.9837841Z   (conv): ConvBn2d(
2026-01-14T09:08:40.9838136Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:08:40.9838673Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:08:40.9839733Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:40.9841157Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:08:40.9842859Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18815943598747253, max_val=0.1829397827386856)
2026-01-14T09:08:40.9843566Z     )
2026-01-14T09:08:40.9843863Z   )
2026-01-14T09:08:40.9844214Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:40.9845538Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:40.9847119Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:40.9847816Z   )
2026-01-14T09:08:40.9848089Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:08:40.9848602Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:40.9849938Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:40.9851522Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:40.9852241Z   )
2026-01-14T09:08:40.9852468Z )
2026-01-14T09:08:40.9852593Z 
2026-01-14T09:08:40.9852598Z 
2026-01-14T09:08:40.9852603Z 
2026-01-14T09:08:40.9852717Z def forward(self, x):
2026-01-14T09:08:40.9853194Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:40.9853863Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:08:40.9854454Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:08:40.9855080Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:08:40.9855821Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:08:40.9856308Z     return activation_post_process_2
2026-01-14T09:08:40.9856581Z     
2026-01-14T09:08:40.9856880Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:40.9857281Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:40.9865625Z           [0., 0., 0.],
2026-01-14T09:08:40.9866016Z           [0., 0., 0.]],
2026-01-14T09:08:40.9866165Z 
2026-01-14T09:08:40.9866246Z          [[0., 0., 0.],
2026-01-14T09:08:40.9866473Z           [0., 0., 0.],
2026-01-14T09:08:40.9866694Z           [0., 0., 0.]],
2026-01-14T09:08:40.9866850Z 
2026-01-14T09:08:40.9866932Z          [[0., 0., 0.],
2026-01-14T09:08:40.9867151Z           [0., 0., 0.],
2026-01-14T09:08:40.9867412Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:08:40.9867745Z converted model pt2e: GraphModule(
2026-01-14T09:08:40.9868028Z   (conv): Module()
2026-01-14T09:08:40.9868243Z   (bn): Module()
2026-01-14T09:08:40.9868440Z )
2026-01-14T09:08:40.9868547Z 
2026-01-14T09:08:40.9868551Z 
2026-01-14T09:08:40.9868555Z 
2026-01-14T09:08:40.9868650Z def forward(self, x):
2026-01-14T09:08:40.9868954Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:40.9869323Z     conv_bias = self.conv.bias
2026-01-14T09:08:40.9870016Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:08:40.9871389Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:40.9872410Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:08:40.9873328Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014815704198554158, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:08:40.9874730Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:08:40.9876116Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.014958353713154793, -45, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:08:40.9877561Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:40.9878870Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T09:08:40.9880016Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014958353713154793, -45, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:09:10.9785723Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:09:10.9786876Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:09:10.9787335Z     
2026-01-14T09:09:10.9787647Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:09:10.9788063Z onverted model fx: GraphModule(
2026-01-14T09:09:10.9788490Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:09:10.9788980Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:09:10.9789293Z )
2026-01-14T09:09:10.9789403Z 
2026-01-14T09:09:10.9789407Z 
2026-01-14T09:09:10.9789411Z 
2026-01-14T09:09:10.9789501Z def forward(self, x):
2026-01-14T09:09:10.9790375Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:09:10.9791760Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:09:10.9792884Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:09:10.9793914Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014958353713154793, -45, -128, 127, torch.int8);  conv = None
2026-01-14T09:09:10.9795339Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:09:10.9796529Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:09:10.9797553Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014958353713154793, -45, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:09:10.9799019Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:09:10.9800016Z     return dequantize_per_tensor_default_2
2026-01-14T09:09:10.9800298Z     
2026-01-14T09:09:10.9800603Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:09:10.9800996Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:09:10.9801249Z           [0., 0., 0.],
2026-01-14T09:09:10.9801466Z           [0., 0., 0.]],
2026-01-14T09:09:10.9801642Z 
2026-01-14T09:09:10.9801723Z          [[0., 0., 0.],
2026-01-14T09:09:10.9801942Z           [0., 0., 0.],
2026-01-14T09:09:10.9802155Z           [0., 0., 0.]],
2026-01-14T09:09:10.9804059Z 
2026-01-14T09:09:10.9804162Z          [[0., 0., 0.],
2026-01-14T09:09:10.9804390Z           [0., 0., 0.],
2026-01-14T09:09:10.9804617Z           [0., 0., 0.]]]])
2026-01-14T09:09:10.9805091Z [32mPASSED[0m
2026-01-14T09:09:10.9805860Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_mobilenet_v2 [33mSKIPPED[0m
2026-01-14T09:09:10.9806865Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_resnet18 [33mSKIPPED[0m
2026-01-14T09:09:10.9807842Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizeMixQATAndPTQ::test_mixing_qat_ptq [33mSKIPPED[0m
2026-01-14T09:09:10.9808760Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add [32mPASSED[0m
2026-01-14T09:09:10.9809633Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add_relu [32mPASSED[0m
2026-01-14T09:09:10.9810526Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_conv2d [32mPASSED[0m
2026-01-14T09:09:10.9811428Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_dynamic_linear [32mPASSED[0m
2026-01-14T09:09:10.9812347Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_maxpool2d [32mPASSED[0m
2026-01-14T09:09:10.9813221Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq [32mPASSED[0m
2026-01-14T09:09:10.9814130Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq_per_channel [32mPASSED[0m
2026-01-14T09:09:10.9815071Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_static_linear [32mPASSED[0m
2026-01-14T09:09:10.9816518Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9818460Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9820314Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9822254Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9824097Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9825958Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9827809Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9829651Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9831496Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9833380Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9835211Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9837086Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9838937Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9840969Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9842862Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9844709Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9846548Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9848467Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9850324Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:10.9852221Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:10.9854113Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:16.9145996Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:16.9148416Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:16.9150757Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:16.9153076Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:16.9155638Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:16.9157950Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:16.9160345Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:16.9162818Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:16.9165138Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:16.9167438Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:16.9169733Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:16.9171929Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:16.9173324Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:16.9173850Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:16.9175475Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:16.9176869Z graph_break []
2026-01-14T09:09:16.9177178Z [32mPASSED[0m
2026-01-14T09:09:16.9178400Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:16.9179866Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:16.9180389Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:16.9181604Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:16.9182707Z graph_break []
2026-01-14T09:09:16.9182998Z [32mPASSED[0m
2026-01-14T09:09:16.9184222Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:16.9185591Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:16.9186103Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:16.9187939Z inductor [('pattern_matcher_nodes', 7), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_binary_matcher_nodes', 2), ('qlinear_weight_prepack_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:16.9189652Z graph_break []
2026-01-14T09:09:16.9189946Z [32mPASSED[0m
2026-01-14T09:09:16.9191216Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:16.9192610Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:16.9193124Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:16.9194344Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:16.9195443Z graph_break []
2026-01-14T09:09:16.9195736Z [32mPASSED[0m
2026-01-14T09:09:16.9196955Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:16.9198342Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:16.9198849Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:16.9200068Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:16.9201174Z graph_break []
2026-01-14T09:09:16.9201458Z [32mPASSED[0m
2026-01-14T09:09:16.9202757Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:16.9204127Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:16.9204646Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:16.9205927Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:16.9207023Z graph_break []
2026-01-14T09:09:16.9207326Z [32mPASSED[0m
2026-01-14T09:09:16.9208540Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:16.9209963Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:16.9210483Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:16.9211693Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:16.9212791Z graph_break []
2026-01-14T09:09:16.9213077Z [32mPASSED[0m
2026-01-14T09:09:16.9214300Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:16.9215660Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:16.9216165Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:16.9217383Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:16.9218475Z graph_break []
2026-01-14T09:09:16.9218768Z [32mPASSED[0m
2026-01-14T09:09:16.9219987Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:16.9221406Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:16.9221925Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:16.9223429Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:16.9224868Z graph_break []
2026-01-14T09:09:16.9225159Z [32mPASSED[0m
2026-01-14T09:09:25.5848240Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5849747Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:25.5850285Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5851540Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5852660Z graph_break []
2026-01-14T09:09:25.5853151Z [32mPASSED[0m
2026-01-14T09:09:25.5854379Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5855756Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:25.5856270Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5858351Z inductor [('pattern_matcher_nodes', 8), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_nodes', 4), ('qlinear_binary_matcher_nodes', 2), ('qlinear_weight_prepack_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5860089Z graph_break []
2026-01-14T09:09:25.5860388Z [32mPASSED[0m
2026-01-14T09:09:25.5861617Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5863067Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:25.5863591Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5864833Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5865936Z graph_break []
2026-01-14T09:09:25.5866240Z [32mPASSED[0m
2026-01-14T09:09:25.5867470Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5868857Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:25.5869382Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5870604Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5871715Z graph_break []
2026-01-14T09:09:25.5872006Z [32mPASSED[0m
2026-01-14T09:09:25.5873231Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5874742Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:25.5875275Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5876498Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5877681Z graph_break []
2026-01-14T09:09:25.5877983Z [32mPASSED[0m
2026-01-14T09:09:25.5879193Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5880580Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:25.5881102Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5882328Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5883587Z graph_break []
2026-01-14T09:09:25.5883885Z [32mPASSED[0m
2026-01-14T09:09:25.5885104Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5886473Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:25.5886988Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5888209Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5889318Z graph_break []
2026-01-14T09:09:25.5889608Z [32mPASSED[0m
2026-01-14T09:09:25.5890936Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5892305Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:25.5892827Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5894373Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5895765Z graph_break []
2026-01-14T09:09:25.5896062Z [32mPASSED[0m
2026-01-14T09:09:25.5897278Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5898639Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:25.5899150Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5900376Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5901494Z graph_break []
2026-01-14T09:09:25.5901779Z [32mPASSED[0m
2026-01-14T09:09:25.5903015Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5904383Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:25.5904899Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5906461Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5907888Z graph_break []
2026-01-14T09:09:25.5908183Z [32mPASSED[0m
2026-01-14T09:09:25.5909393Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5910753Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:25.5911269Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5912492Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5913593Z graph_break []
2026-01-14T09:09:25.5913877Z [32mPASSED[0m
2026-01-14T09:09:25.5915100Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5916472Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:25.5916980Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5918196Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5919292Z graph_break []
2026-01-14T09:09:25.5919586Z [32mPASSED[0m
2026-01-14T09:09:25.5920856Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:25.5922219Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:25.5922824Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:25.5924040Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:25.5925195Z graph_break []
2026-01-14T09:09:25.5925499Z [32mPASSED[0m
2026-01-14T09:09:32.0213383Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0214566Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:32.0215032Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0216013Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0216888Z graph_break []
2026-01-14T09:09:32.0217329Z [32mPASSED[0m
2026-01-14T09:09:32.0218300Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0219369Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:32.0219791Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0220950Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0221817Z graph_break []
2026-01-14T09:09:32.0222062Z [32mPASSED[0m
2026-01-14T09:09:32.0223018Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0224197Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:32.0224616Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0225817Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0226915Z graph_break []
2026-01-14T09:09:32.0227158Z [32mPASSED[0m
2026-01-14T09:09:32.0228127Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0229204Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:32.0229628Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0230602Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0231466Z graph_break []
2026-01-14T09:09:32.0231704Z [32mPASSED[0m
2026-01-14T09:09:32.0232657Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0233832Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:32.0234264Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0235456Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0236637Z graph_break []
2026-01-14T09:09:32.0236876Z [32mPASSED[0m
2026-01-14T09:09:32.0237831Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0238902Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:32.0239692Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0240678Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0241548Z graph_break []
2026-01-14T09:09:32.0241807Z [32mPASSED[0m
2026-01-14T09:09:32.0242842Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0243925Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:32.0244362Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0245330Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0246293Z graph_break []
2026-01-14T09:09:32.0246558Z [32mPASSED[0m
2026-01-14T09:09:32.0247524Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0248680Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:32.0249104Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0250076Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0250955Z graph_break []
2026-01-14T09:09:32.0251200Z [32mPASSED[0m
2026-01-14T09:09:32.0252170Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0253241Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:32.0253663Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0254634Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0255500Z graph_break []
2026-01-14T09:09:32.0255745Z [32mPASSED[0m
2026-01-14T09:09:32.0256741Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:32.0257809Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:32.0258233Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:32.0259270Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:32.0260149Z graph_break []
2026-01-14T09:09:32.0260396Z [32mPASSED[0m
2026-01-14T09:09:32.0261496Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:32.0263449Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:32.0265283Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:32.0267116Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:32.0268961Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:32.0270793Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:32.0272687Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:32.0274528Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:32.0276394Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0931091Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0933477Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0935790Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0938089Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0940748Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0943095Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0945616Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0948009Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0950422Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0952746Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0955060Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0957387Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0959727Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0962042Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0964569Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0966961Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0969270Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0971579Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0973885Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0976192Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0978573Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0980891Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:36.0983246Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:36.0985461Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:36.0986957Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:36.0987487Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:36.0989013Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:36.0990422Z graph_break []
2026-01-14T09:09:36.0990719Z [32mPASSED[0m
2026-01-14T09:09:36.0991972Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:36.0993362Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:36.0993877Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:36.0995117Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:36.0996228Z graph_break []
2026-01-14T09:09:36.0996525Z [32mPASSED[0m
2026-01-14T09:09:36.0997755Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:36.0999182Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:36.0999710Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:36.1001230Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:36.1002775Z graph_break []
2026-01-14T09:09:36.1003078Z [32mPASSED[0m
2026-01-14T09:09:36.1004299Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:36.1005683Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:36.1006240Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:36.1007415Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:36.1008354Z graph_break []
2026-01-14T09:09:36.1008601Z [32mPASSED[0m
2026-01-14T09:09:36.1009581Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:36.1010680Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:36.1011112Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:36.1012091Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:36.1020383Z graph_break []
2026-01-14T09:09:47.5906704Z [32mPASSED[0m
2026-01-14T09:09:47.5908259Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5909685Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:47.5910306Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5911554Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5912673Z graph_break []
2026-01-14T09:09:47.5912974Z [32mPASSED[0m
2026-01-14T09:09:47.5914218Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5915585Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:47.5916112Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5917347Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5918453Z graph_break []
2026-01-14T09:09:47.5918761Z [32mPASSED[0m
2026-01-14T09:09:47.5919971Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5921382Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:47.5921902Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5923342Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5924545Z graph_break []
2026-01-14T09:09:47.5924837Z [32mPASSED[0m
2026-01-14T09:09:47.5926056Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5927427Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:47.5927941Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5929454Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5930839Z graph_break []
2026-01-14T09:09:47.5931131Z [32mPASSED[0m
2026-01-14T09:09:47.5932353Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5933712Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:47.5934231Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5935446Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5936554Z graph_break []
2026-01-14T09:09:47.5936842Z [32mPASSED[0m
2026-01-14T09:09:47.5938109Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5939704Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:47.5940222Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5941733Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5943213Z graph_break []
2026-01-14T09:09:47.5943521Z [32mPASSED[0m
2026-01-14T09:09:47.5944730Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5946076Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:47.5946601Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5947824Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5948938Z graph_break []
2026-01-14T09:09:47.5949239Z [32mPASSED[0m
2026-01-14T09:09:47.5950463Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5951839Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:47.5952362Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5953657Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5954769Z graph_break []
2026-01-14T09:09:47.5955065Z [32mPASSED[0m
2026-01-14T09:09:47.5956343Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5957707Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:47.5958220Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5959443Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5960544Z graph_break []
2026-01-14T09:09:47.5960848Z [32mPASSED[0m
2026-01-14T09:09:47.5962061Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5963507Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:47.5964029Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5965248Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5966357Z graph_break []
2026-01-14T09:09:47.5966653Z [32mPASSED[0m
2026-01-14T09:09:47.5967865Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5969293Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:47.5969809Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5971037Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5972183Z graph_break []
2026-01-14T09:09:47.5972482Z [32mPASSED[0m
2026-01-14T09:09:47.5973704Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5975063Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:47.5975582Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5977092Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5978494Z graph_break []
2026-01-14T09:09:47.5978793Z [32mPASSED[0m
2026-01-14T09:09:47.5979994Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:47.5981364Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:47.5981875Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:47.5983100Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:47.5984275Z graph_break []
2026-01-14T09:09:47.5984574Z [32mPASSED[0m
2026-01-14T09:09:59.1287113Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1288898Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:59.1289446Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1290965Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1292370Z graph_break []
2026-01-14T09:09:59.1292867Z [32mPASSED[0m
2026-01-14T09:09:59.1294097Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1295457Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:59.1295976Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1297209Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1298322Z graph_break []
2026-01-14T09:09:59.1298614Z [32mPASSED[0m
2026-01-14T09:09:59.1299840Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1301202Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:59.1301849Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1303071Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1304179Z graph_break []
2026-01-14T09:09:59.1304478Z [32mPASSED[0m
2026-01-14T09:09:59.1305778Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1307142Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:59.1307652Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1308878Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1309986Z graph_break []
2026-01-14T09:09:59.1310275Z [32mPASSED[0m
2026-01-14T09:09:59.1311495Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1312858Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:59.1313377Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1314599Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1315697Z graph_break []
2026-01-14T09:09:59.1315992Z [32mPASSED[0m
2026-01-14T09:09:59.1317293Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1318657Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:59.1319227Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1320445Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1321560Z graph_break []
2026-01-14T09:09:59.1321858Z [32mPASSED[0m
2026-01-14T09:09:59.1323178Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1324560Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:59.1325081Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1326612Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1328023Z graph_break []
2026-01-14T09:09:59.1328319Z [32mPASSED[0m
2026-01-14T09:09:59.1329541Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1330903Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:09:59.1331427Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1332720Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1333841Z graph_break []
2026-01-14T09:09:59.1334134Z [32mPASSED[0m
2026-01-14T09:09:59.1335348Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1336769Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:59.1337280Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1338883Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1340386Z graph_break []
2026-01-14T09:09:59.1340648Z [32mPASSED[0m
2026-01-14T09:09:59.1341601Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1342665Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:09:59.1343090Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1344066Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1344936Z graph_break []
2026-01-14T09:09:59.1345184Z [32mPASSED[0m
2026-01-14T09:09:59.1346240Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1347321Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:59.1347746Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1348783Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1349658Z graph_break []
2026-01-14T09:09:59.1349904Z [32mPASSED[0m
2026-01-14T09:09:59.1350910Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1351986Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:09:59.1352404Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1353382Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1354248Z graph_break []
2026-01-14T09:09:59.1354497Z [32mPASSED[0m
2026-01-14T09:09:59.1355459Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:59.1356538Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:59.1356966Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:59.1357931Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:59.1358806Z graph_break []
2026-01-14T09:09:59.1359118Z [32mPASSED[0m
2026-01-14T09:11:21.2854610Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:11:21.2856070Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:11:21.2856900Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:11:21.2858143Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:11:21.2859262Z graph_break []
2026-01-14T09:11:21.2859767Z [32mPASSED[0m
2026-01-14T09:11:21.2860585Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_cpu stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:11:21.2861498Z inline_call []
2026-01-14T09:11:21.2861770Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:11:21.2862216Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:11:21.2863742Z inductor [('pattern_matcher_nodes', 10), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:11:21.2865155Z graph_break []
2026-01-14T09:11:21.2865456Z [32mPASSED[0m
2026-01-14T09:11:21.2866346Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_input_dim_exceeds_2 stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:11:21.2867327Z inline_call []
2026-01-14T09:11:21.2867588Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:11:21.2868030Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:11:21.2869682Z inductor [('pattern_matcher_nodes', 18), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:11:21.2871177Z graph_break []
2026-01-14T09:11:21.2871476Z [32mPASSED[0m
2026-01-14T09:11:21.2872296Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_qat_cpu stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:11:21.2873220Z inline_call []
2026-01-14T09:11:21.2873487Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:11:21.2873917Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:11:21.2875462Z inductor [('pattern_matcher_nodes', 10), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:11:21.2876868Z graph_break []
2026-01-14T09:11:21.2877154Z [32mPASSED[0m
2026-01-14T09:11:21.2878090Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T09:11:21.2879622Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T09:11:21.2881153Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T09:11:21.2882756Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T09:11:21.2884096Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_cpu [33mSKIPPED[0m
2026-01-14T09:11:21.2885488Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu [33mSKIPPED[0m
2026-01-14T09:11:21.2886968Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:11:21.2888524Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:11:21.2890133Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:11:21.2891555Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_cpu [33mSKIPPED[0m
2026-01-14T09:11:21.2892825Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:11:21.2894137Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:11:21.2895586Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:11:21.2896972Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:11:21.2898320Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:11:21.2899883Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:11:21.2901297Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mul_cpu [33mSKIPPED[0m
2026-01-14T09:11:21.2902510Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_cpu [33mSKIPPED[0m
2026-01-14T09:11:21.2903879Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:11:21.2905215Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:11:21.2906731Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:11:21.2908060Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_dynamic_fp16 stats [('calls_captured', 20), ('unique_graphs', 16)]
2026-01-14T09:11:21.2908758Z inline_call []
2026-01-14T09:11:21.2908979Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:11:21.2909336Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:11:21.2910322Z inductor [('pattern_matcher_nodes', 15), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 5), ('extern_calls', 4), ('qlinear_weight_prepack_matcher_count', 2), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:11:21.2911200Z graph_break []
2026-01-14T09:11:21.2911439Z [32mPASSED[0m
2026-01-14T09:11:21.2912102Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_relu_dynamic_fp16 stats [('calls_captured', 24), ('unique_graphs', 16)]
2026-01-14T09:11:21.2912829Z inline_call []
2026-01-14T09:11:21.2913053Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:11:21.2913413Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:11:21.2914392Z inductor [('pattern_matcher_nodes', 17), ('qlinear_weight_prepack_matcher_nodes', 14), ('pattern_matcher_count', 5), ('extern_calls', 4), ('qlinear_weight_prepack_matcher_count', 2), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:11:21.2915268Z graph_break []
2026-01-14T09:11:21.2915503Z [32mPASSED[0m
2026-01-14T09:11:21.2916146Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d stats [('calls_captured', 1958), ('unique_graphs', 224)]
2026-01-14T09:11:21.2916839Z inline_call []
2026-01-14T09:11:21.2917168Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:11:21.2917531Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:11:21.2918974Z inductor [('pattern_matcher_nodes', 7), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qconv_unary_matcher_nodes', 2), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:11:21.2920316Z graph_break []
2026-01-14T09:11:21.2920555Z [32mPASSED[0m
2026-01-14T09:11:21.2921221Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add stats [('calls_captured', 1967), ('unique_graphs', 224)]
2026-01-14T09:11:21.2921924Z inline_call []
2026-01-14T09:11:21.2922142Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:11:21.2922498Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:11:21.2924737Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 7), ('qconv2d_binary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_nodes', 2), ('extern_calls', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv2d_binary_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1)]
2026-01-14T09:11:21.2926792Z graph_break []
2026-01-14T09:11:21.2927039Z [32mPASSED[0m
2026-01-14T09:11:21.2927702Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add_relu stats [('calls_captured', 1969), ('unique_graphs', 224)]
2026-01-14T09:11:21.2928422Z inline_call []
2026-01-14T09:11:21.2928630Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:11:21.2929044Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1904754Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 7), ('qconv2d_binary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_nodes', 2), ('extern_calls', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv2d_binary_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1)]
2026-01-14T09:13:38.1908639Z graph_break []
2026-01-14T09:13:38.1909079Z [32mPASSED[0m
2026-01-14T09:13:38.1909818Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardswish stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:38.1910558Z inline_call []
2026-01-14T09:13:38.1910785Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1911154Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1912553Z inductor [('pattern_matcher_nodes', 24), ('qconv_unary_matcher_nodes', 14), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:38.1913852Z graph_break []
2026-01-14T09:13:38.1914103Z [32mPASSED[0m
2026-01-14T09:13:38.1914810Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardtanh stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:38.1915542Z inline_call []
2026-01-14T09:13:38.1915771Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1916128Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1917631Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:38.1918924Z graph_break []
2026-01-14T09:13:38.1919170Z [32mPASSED[0m
2026-01-14T09:13:38.1919829Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:38.1920649Z inline_call []
2026-01-14T09:13:38.1920880Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1921251Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1922711Z inductor [('pattern_matcher_nodes', 16), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:38.1924011Z graph_break []
2026-01-14T09:13:38.1924266Z [32mPASSED[0m
2026-01-14T09:13:38.1924917Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu6 stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:38.1925637Z inline_call []
2026-01-14T09:13:38.1925858Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1926226Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1927616Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:38.1928900Z graph_break []
2026-01-14T09:13:38.1929152Z [32mPASSED[0m
2026-01-14T09:13:38.1929895Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_silu stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:38.1930611Z inline_call []
2026-01-14T09:13:38.1930877Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1931244Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1932628Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:38.1933924Z graph_break []
2026-01-14T09:13:38.1934178Z [32mPASSED[0m
2026-01-14T09:13:38.1934768Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qcat stats [('calls_captured', 26), ('unique_graphs', 8)]
2026-01-14T09:13:38.1935433Z inline_call []
2026-01-14T09:13:38.1935659Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1936028Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1937641Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 7), ('qconv_unary_matcher_nodes', 4), ('qcat_matcher_nodes', 4), ('extern_calls', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('fxgraph_cache_bypass', 1), ('qcat_matcher_count', 1)]
2026-01-14T09:13:38.1939346Z graph_break []
2026-01-14T09:13:38.1939664Z [32mPASSED[0m
2026-01-14T09:13:38.1940297Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv1d_relu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:13:38.1940999Z inline_call []
2026-01-14T09:13:38.1941225Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1942087Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1943544Z inductor [('pattern_matcher_nodes', 13), ('qconv_weight_prepack_matcher_nodes', 6), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:38.1944890Z graph_break []
2026-01-14T09:13:38.1945142Z [32mPASSED[0m
2026-01-14T09:13:38.1945769Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_2 stats [('calls_captured', 13), ('unique_graphs', 8)]
2026-01-14T09:13:38.1946449Z inline_call []
2026-01-14T09:13:38.1946673Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1947028Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1948203Z inductor [('pattern_matcher_nodes', 5), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qconv_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:13:38.1949262Z graph_break []
2026-01-14T09:13:38.1949509Z [32mPASSED[0m
2026-01-14T09:13:38.1950127Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_3 stats [('calls_captured', 29), ('unique_graphs', 8)]
2026-01-14T09:13:38.1950805Z inline_call []
2026-01-14T09:13:38.1951024Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1951375Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1953774Z inductor [('pattern_matcher_nodes', 18), ('pattern_matcher_count', 8), ('qconv_weight_prepack_matcher_nodes', 7), ('qcat_matcher_nodes', 4), ('extern_calls', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_nodes', 2), ('qconv2d_binary_matcher_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv_unary_matcher_count', 1), ('qconv2d_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qcat_matcher_count', 1)]
2026-01-14T09:13:38.1956055Z graph_break []
2026-01-14T09:13:38.1963815Z [32mPASSED[0m
2026-01-14T09:13:38.1964582Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_broadcast_shapes_cpu stats [('calls_captured', 15), ('unique_graphs', 8)]
2026-01-14T09:13:38.1965363Z inline_call []
2026-01-14T09:13:38.1965594Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1965952Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1967183Z inductor [('pattern_matcher_nodes', 5), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qconv_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:13:38.1968250Z graph_break []
2026-01-14T09:13:38.1968546Z [32mPASSED[0m
2026-01-14T09:13:38.1969046Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_cpu inline_call []
2026-01-14T09:13:38.1969672Z stats [('calls_captured', 24), ('unique_graphs', 8)]
2026-01-14T09:13:38.1970026Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:38.1970390Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:38.1971833Z inductor [('pattern_matcher_nodes', 16), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv2d_binary_matcher_nodes', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv2d_binary_matcher_count', 2), ('qconv2d_binary_lower_count', 2), ('qconv2d_binary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:38.1973171Z graph_break []
2026-01-14T09:13:38.1973413Z [32mPASSED[0m
2026-01-14T09:13:38.1974105Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:13:38.1975122Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:13:38.1976168Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:13:49.2019197Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_cpu inline_call []
2026-01-14T09:13:49.2020471Z stats [('calls_captured', 28), ('unique_graphs', 8)]
2026-01-14T09:13:49.2020825Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:49.2021187Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:49.2022642Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv2d_binary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv2d_binary_matcher_count', 2), ('qconv2d_binary_lower_count', 2), ('qconv2d_binary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:49.2024011Z graph_break []
2026-01-14T09:13:49.2024465Z [32mPASSED[0m
2026-01-14T09:13:49.2025118Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2026170Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:13:49.2027250Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:13:49.2028308Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_cpu stats [('calls_captured', 21), ('unique_graphs', 8)]
2026-01-14T09:13:49.2028992Z inline_call []
2026-01-14T09:13:49.2029221Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:49.2029578Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:49.2031140Z inductor [('pattern_matcher_nodes', 19), ('qconv_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qconv_unary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 3), ('qconv_unary_lower_count', 3), ('qconv_unary_lower_nodes', 3), ('extern_calls', 3), ('qconv_unary_matcher_count', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:49.2032525Z graph_break []
2026-01-14T09:13:49.2032771Z [32mPASSED[0m
2026-01-14T09:13:49.2033460Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_dequant_promotion_cpu stats [('calls_captured', 24), ('unique_graphs', 8)]
2026-01-14T09:13:49.2034202Z inline_call []
2026-01-14T09:13:49.2034422Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:49.2034774Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:49.2036935Z inductor [('pattern_matcher_nodes', 22), ('qconv_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 10), ('qconv_unary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qconv_unary_matcher_count', 2), ('qconv2d_binary_matcher_nodes', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv2d_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1)]
2026-01-14T09:13:49.2039230Z graph_break []
2026-01-14T09:13:49.2039474Z [32mPASSED[0m
2026-01-14T09:13:49.2040086Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2041073Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:13:49.2042105Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:13:49.2042901Z inline_call []
2026-01-14T09:13:49.2043125Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:49.2043595Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:49.2044997Z inductor [('pattern_matcher_nodes', 23), ('qconv_unary_matcher_nodes', 13), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:49.2046359Z graph_break []
2026-01-14T09:13:49.2046614Z [32mPASSED[0m
2026-01-14T09:13:49.2047250Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2048336Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2049455Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2050540Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:13:49.2051256Z inline_call []
2026-01-14T09:13:49.2051472Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:49.2051831Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:49.2053223Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:49.2054499Z graph_break []
2026-01-14T09:13:49.2054742Z [32mPASSED[0m
2026-01-14T09:13:49.2055371Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2056516Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2057626Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2058741Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:13:49.2059771Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:13:49.2060477Z inline_call []
2026-01-14T09:13:49.2060703Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:49.2061065Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:49.2062476Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:49.2063775Z graph_break []
2026-01-14T09:13:49.2064016Z [32mPASSED[0m
2026-01-14T09:13:49.2064646Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2065660Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:13:49.2066356Z inline_call []
2026-01-14T09:13:49.2066582Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:49.2066943Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:49.2068390Z inductor [('pattern_matcher_nodes', 15), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:49.2069685Z graph_break []
2026-01-14T09:13:49.2069931Z [32mPASSED[0m
2026-01-14T09:13:49.2070548Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2071628Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_int8_mixed_bf16_xpu [33mSKIPPED[0m
2026-01-14T09:13:49.2072676Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:13:49.2073366Z inline_call []
2026-01-14T09:13:49.2073587Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:49.2073948Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:49.2075329Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:49.2076616Z graph_break []
2026-01-14T09:13:49.2076855Z [32mPASSED[0m
2026-01-14T09:13:49.2077469Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2078506Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2079572Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:13:49.2080646Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_with_concat_cpu stats [('calls_captured', 32), ('unique_graphs', 8)]
2026-01-14T09:13:49.2081368Z inline_call []
2026-01-14T09:13:49.2081650Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:49.2082015Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:17:20.2788548Z inductor [('pattern_matcher_nodes', 30), ('pattern_matcher_count', 14), ('qconv_weight_prepack_matcher_nodes', 13), ('qconv_unary_matcher_nodes', 6), ('extern_calls', 6), ('qcat_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 4), ('qconv_unary_lower_count', 4), ('qconv_unary_lower_nodes', 4), ('qconv_unary_matcher_count', 3), ('dequant_promotion_matcher_count', 2), ('dequant_promotion_matcher_nodes', 2), ('fxgraph_cache_bypass', 1), ('qcat_matcher_count', 1)]
2026-01-14T09:17:20.2791300Z graph_break []
2026-01-14T09:17:20.2791809Z [32mPASSED[0m
2026-01-14T09:17:20.2792601Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qflatten stats [('calls_captured', 27), ('unique_graphs', 8)]
2026-01-14T09:17:20.2793446Z inline_call []
2026-01-14T09:17:20.2793719Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:20.2794169Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:17:20.2796202Z inductor [('pattern_matcher_nodes', 12), ('pattern_matcher_count', 5), ('qconv_weight_prepack_matcher_nodes', 4), ('qconv_unary_matcher_nodes', 3), ('qreshape_matcher_nodes', 3), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qreshape_matcher_count', 1), ('extern_calls', 1)]
2026-01-14T09:17:20.2798133Z graph_break []
2026-01-14T09:17:20.2798425Z [32mPASSED[0m
2026-01-14T09:17:20.2799273Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_False inline_call []
2026-01-14T09:17:20.2800269Z stats [('calls_captured', 56), ('unique_graphs', 16)]
2026-01-14T09:17:20.2800688Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:20.2801132Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:17:20.2804144Z inductor [('pattern_matcher_nodes', 102), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 10), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:17:20.2806871Z graph_break []
2026-01-14T09:17:20.2807177Z [32mPASSED[0m
2026-01-14T09:17:20.2808004Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_True inline_call []
2026-01-14T09:17:20.2808998Z stats [('calls_captured', 60), ('unique_graphs', 16)]
2026-01-14T09:17:20.2809432Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:20.2809875Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:17:20.2812590Z inductor [('pattern_matcher_nodes', 101), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 9), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:17:20.2815191Z graph_break []
2026-01-14T09:17:20.2815478Z [32mPASSED[0m
2026-01-14T09:17:20.2816304Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_False inline_call []
2026-01-14T09:17:20.2817289Z stats [('calls_captured', 56), ('unique_graphs', 16)]
2026-01-14T09:17:20.2817838Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:20.2818283Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:17:20.2820991Z inductor [('pattern_matcher_nodes', 102), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 10), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:17:20.2823654Z graph_break []
2026-01-14T09:17:20.2823964Z [32mPASSED[0m
2026-01-14T09:17:20.2824784Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_True inline_call []
2026-01-14T09:17:20.2825774Z stats [('calls_captured', 60), ('unique_graphs', 16)]
2026-01-14T09:17:20.2826205Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:20.2826643Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:17:20.2829360Z inductor [('pattern_matcher_nodes', 101), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 9), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:17:20.2831957Z graph_break []
2026-01-14T09:17:20.2832247Z [32mPASSED[0m
2026-01-14T09:17:20.2833080Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_False inline_call []
2026-01-14T09:17:20.2834121Z stats [('calls_captured', 64), ('unique_graphs', 16)]
2026-01-14T09:17:20.2834546Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:20.2834978Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:17:20.2837572Z inductor [('pattern_matcher_nodes', 106), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 14), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:17:20.2839960Z graph_break []
2026-01-14T09:17:20.2840218Z [32mPASSED[0m
2026-01-14T09:17:20.2840879Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_True inline_call []
2026-01-14T09:17:20.2841657Z stats [('calls_captured', 68), ('unique_graphs', 16)]
2026-01-14T09:17:20.2841993Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:20.2842353Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:17:20.2844508Z inductor [('pattern_matcher_nodes', 105), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 13), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:17:20.2846488Z graph_break []
2026-01-14T09:17:20.2846730Z [32mPASSED[0m
2026-01-14T09:17:20.2847472Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_False inline_call []
2026-01-14T09:17:20.2848404Z stats [('calls_captured', 64), ('unique_graphs', 16)]
2026-01-14T09:17:20.2848838Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:20.2849234Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:17:20.2851315Z inductor [('pattern_matcher_nodes', 106), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 14), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:17:20.2853282Z graph_break []
2026-01-14T09:17:20.2853535Z [32mPASSED[0m
2026-01-14T09:17:20.2854177Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_True inline_call []
2026-01-14T09:17:20.2854944Z stats [('calls_captured', 68), ('unique_graphs', 16)]
2026-01-14T09:17:20.2855281Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:20.2855634Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:17:44.9493286Z inductor [('pattern_matcher_nodes', 105), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 13), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:17:44.9495976Z graph_break []
2026-01-14T09:17:44.9496934Z [32mPASSED[0m
2026-01-14T09:17:44.9498021Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:17:44.9499783Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:17:44.9501638Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:17:44.9503355Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:17:44.9505085Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:17:44.9506809Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:17:44.9508530Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:17:44.9510247Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:17:44.9511703Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_cpu stats [('calls_captured', 16), ('unique_graphs', 8)]
2026-01-14T09:17:44.9512558Z inline_call []
2026-01-14T09:17:44.9512831Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:44.9513265Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:17:44.9515209Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:17:44.9517001Z graph_break []
2026-01-14T09:17:44.9517302Z [32mPASSED[0m
2026-01-14T09:17:44.9518169Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:17:44.9519117Z inline_call []
2026-01-14T09:17:44.9519390Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:44.9519861Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:17:44.9522766Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:17:44.9525460Z graph_break []
2026-01-14T09:17:44.9525757Z [32mPASSED[0m
2026-01-14T09:17:44.9526720Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:17:44.9527771Z inline_call []
2026-01-14T09:17:44.9528031Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:44.9528469Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:17:44.9531347Z inductor [('pattern_matcher_nodes', 33), ('qlinear_weight_prepack_matcher_nodes', 18), ('pattern_matcher_count', 15), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('dequant_promotion_matcher_nodes', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:17:44.9534088Z graph_break []
2026-01-14T09:17:44.9534381Z [32mPASSED[0m
2026-01-14T09:17:44.9535277Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_dynamic_cpu stats [('calls_captured', 27), ('unique_graphs', 8)]
2026-01-14T09:17:44.9536261Z inline_call []
2026-01-14T09:17:44.9536522Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:44.9536962Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:17:44.9539668Z inductor [('pattern_matcher_nodes', 18), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:17:44.9542046Z graph_break []
2026-01-14T09:17:44.9542350Z [32mPASSED[0m
2026-01-14T09:17:44.9543214Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:17:44.9544723Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:17:44.9546088Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:17:44.9546790Z inline_call []
2026-01-14T09:17:44.9547020Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:44.9547377Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:17:44.9548884Z inductor [('pattern_matcher_nodes', 31), ('qlinear_unary_matcher_nodes', 21), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:17:44.9550231Z graph_break []
2026-01-14T09:17:44.9550474Z [32mPASSED[0m
2026-01-14T09:17:44.9551104Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:17:44.9552154Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2 stats [('calls_captured', 16), ('unique_graphs', 8)]
2026-01-14T09:17:44.9552895Z inline_call []
2026-01-14T09:17:44.9553114Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:44.9553463Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:17:44.9554901Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:17:44.9556232Z graph_break []
2026-01-14T09:17:44.9556469Z [32mPASSED[0m
2026-01-14T09:17:44.9557219Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2_and_not_contiguous stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:17:44.9558034Z inline_call []
2026-01-14T09:17:44.9558255Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:44.9558685Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:17:44.9560122Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:17:44.9561510Z graph_break []
2026-01-14T09:17:44.9561743Z [32mPASSED[0m
2026-01-14T09:17:44.9562349Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:17:44.9563466Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:17:44.9564683Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:17:44.9565815Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mul_cpu stats [('calls_captured', 17), ('unique_graphs', 8)]
2026-01-14T09:17:44.9566503Z inline_call []
2026-01-14T09:17:44.9566723Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:17:44.9567074Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3452236Z inductor [('pattern_matcher_nodes', 7), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_unary_matcher_nodes', 2), ('qlinear_weight_prepack_matcher_count', 1), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:18:02.3454020Z graph_break []
2026-01-14T09:18:02.3454529Z [32mPASSED[0m
2026-01-14T09:18:02.3457283Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:18:02.3458200Z inline_call []
2026-01-14T09:18:02.3458476Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3458925Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3460869Z inductor [('pattern_matcher_nodes', 15), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:18:02.3462603Z graph_break []
2026-01-14T09:18:02.3462931Z [32mPASSED[0m
2026-01-14T09:18:02.3463808Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_input_dim_exceeds_2 stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:18:02.3464770Z inline_call []
2026-01-14T09:18:02.3465047Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3465494Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3467337Z inductor [('pattern_matcher_nodes', 23), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 10), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:18:02.3469051Z graph_break []
2026-01-14T09:18:02.3469349Z [32mPASSED[0m
2026-01-14T09:18:02.3470124Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:18:02.3471499Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:18:02.3472853Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qmaxpool2d stats [('calls_captured', 19), ('unique_graphs', 8)]
2026-01-14T09:18:02.3473706Z inline_call []
2026-01-14T09:18:02.3474079Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3474521Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3476569Z inductor [('pattern_matcher_nodes', 12), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 4), ('qmaxpool2d_matcher_nodes', 4), ('qconv_unary_matcher_nodes', 3), ('extern_calls', 3), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qmaxpool2d_matcher_count', 1)]
2026-01-14T09:18:02.3478577Z graph_break []
2026-01-14T09:18:02.3478873Z [32mPASSED[0m
2026-01-14T09:18:02.3479999Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_False [32mPASSED[0m
2026-01-14T09:18:02.3481890Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_True [32mPASSED[0m
2026-01-14T09:18:02.3483918Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_False [32mPASSED[0m
2026-01-14T09:18:02.3485789Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_True [32mPASSED[0m
2026-01-14T09:18:02.3487584Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3488757Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:18:02.3489276Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3490599Z inductor [('pattern_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_nodes', 6), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:18:02.3491710Z graph_break []
2026-01-14T09:18:02.3491999Z [32mPASSED[0m
2026-01-14T09:18:02.3493076Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3494278Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:18:02.3494820Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3496335Z inductor [('pattern_matcher_nodes', 10), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:18:02.3497732Z graph_break []
2026-01-14T09:18:02.3498021Z [32mPASSED[0m
2026-01-14T09:18:02.3499043Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3500205Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:18:02.3500719Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3501935Z inductor [('pattern_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_nodes', 6), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:18:02.3503035Z graph_break []
2026-01-14T09:18:02.3503332Z [32mPASSED[0m
2026-01-14T09:18:02.3504338Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3505502Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:18:02.3506066Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3507289Z inductor [('pattern_matcher_nodes', 9), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:18:02.3508388Z graph_break []
2026-01-14T09:18:02.3508725Z [32mPASSED[0m
2026-01-14T09:18:02.3509830Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_False [32mPASSED[0m
2026-01-14T09:18:02.3511701Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_True [32mPASSED[0m
2026-01-14T09:18:02.3513584Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_False [32mPASSED[0m
2026-01-14T09:18:02.3515471Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_True [32mPASSED[0m
2026-01-14T09:18:02.3517267Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3518458Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:18:02.3518985Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3520378Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 5), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:18:02.3521670Z graph_break []
2026-01-14T09:18:02.3521965Z [32mPASSED[0m
2026-01-14T09:18:02.3523117Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3524350Z stats [('calls_captured', 14), ('unique_graphs', 1)]
2026-01-14T09:18:02.3524867Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3526592Z inductor [('pattern_matcher_nodes', 13), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 6), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:18:02.3535891Z graph_break []
2026-01-14T09:18:02.3536336Z [32mPASSED[0m
2026-01-14T09:18:02.3537204Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:02.3538133Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:18:02.3538567Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:02.3539933Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 5), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:18:02.3540935Z graph_break []
2026-01-14T09:20:09.3628733Z [32mPASSED[0m
2026-01-14T09:20:09.3629656Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:20:09.3630773Z stats [('calls_captured', 14), ('unique_graphs', 1)]
2026-01-14T09:20:09.3631307Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:20:09.3632818Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 5), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:20:09.3634026Z graph_break []
2026-01-14T09:20:09.3634376Z [32mPASSED[0m
2026-01-14T09:20:09.3635351Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_q_attention_block [33mSKIPPED[0m
2026-01-14T09:20:09.3636768Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T09:20:09.3637873Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T09:20:09.3639408Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag_with_output_quant [33mSKIPPED[0m
2026-01-14T09:20:09.3640454Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block inline_call []
2026-01-14T09:20:09.3641121Z stats [('calls_captured', 52), ('unique_graphs', 8)]
2026-01-14T09:20:09.3641473Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:20:09.3641841Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:20:09.3643498Z inductor [('pattern_matcher_nodes', 74), ('pattern_matcher_count', 26), ('qlinear_weight_prepack_matcher_nodes', 24), ('extern_calls', 6), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('dequant_promotion_matcher_nodes', 2), ('fuse_attention', 1), ('dequant_promotion_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:20:09.3644958Z graph_break []
2026-01-14T09:20:09.3645226Z [32mPASSED[0m
2026-01-14T09:20:09.3645904Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qat_bn_conv2d stats [('calls_captured', 1960), ('unique_graphs', 224)]
2026-01-14T09:20:09.3646640Z inline_call []
2026-01-14T09:20:09.3647010Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:20:09.3647373Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:20:09.3648795Z inductor [('pattern_matcher_nodes', 7), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qconv_unary_matcher_nodes', 2), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:20:09.3650176Z graph_break []
2026-01-14T09:20:09.3650422Z [32mPASSED[0m
2026-01-14T09:20:09.3651186Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qconv2d_maxpool2d_linear_dynamic_cpu stats [('calls_captured', 30), ('unique_graphs', 8)]
2026-01-14T09:20:09.3652011Z inline_call []
2026-01-14T09:20:09.3652328Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:20:09.3654704Z inductor [('pattern_matcher_nodes', 21), ('pattern_matcher_count', 8), ('qlinear_weight_prepack_matcher_nodes', 4), ('qconv_weight_prepack_matcher_nodes', 4), ('qmaxpool2d_matcher_nodes', 4), ('extern_calls', 4), ('qconv_unary_matcher_nodes', 3), ('qreshape_matcher_nodes', 3), ('qlinear_weight_prepack_matcher_count', 1), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qmaxpool2d_matcher_count', 1), ('qreshape_matcher_count', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1)]
2026-01-14T09:20:09.3656972Z graph_break []
2026-01-14T09:20:09.3657213Z [32mPASSED[0m
2026-01-14T09:20:09.3657934Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_adaptive_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T09:20:09.3659059Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_annotate_mul_tensor [32mPASSED[0m
2026-01-14T09:20:09.3660206Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_attention_block [32mPASSED[0m
2026-01-14T09:20:09.3661272Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T09:20:09.3662314Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe [32mPASSED[0m
2026-01-14T09:20:09.3663456Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_same_inputs [32mPASSED[0m
2026-01-14T09:20:09.3664573Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_single_input [32mPASSED[0m
2026-01-14T09:20:09.3665607Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d [32mPASSED[0m
2026-01-14T09:20:09.3666605Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary [32mPASSED[0m
2026-01-14T09:20:09.3667643Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary2 [32mPASSED[0m
2026-01-14T09:20:09.3668711Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary_unary [32mPASSED[0m
2026-01-14T09:20:09.3669829Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_serials_binary_unary [32mPASSED[0m
2026-01-14T09:20:09.3670907Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_unary [32mPASSED[0m
2026-01-14T09:20:09.3671962Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_dynamic_quant_linear [32mPASSED[0m
2026-01-14T09:20:09.3673045Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe [32mPASSED[0m
2026-01-14T09:20:09.3674183Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_linear_recipe [32mPASSED[0m
2026-01-14T09:20:09.3675293Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_maxpool2d_recipe [32mPASSED[0m
2026-01-14T09:20:09.3676401Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe [32mPASSED[0m
2026-01-14T09:20:09.3677444Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe2 [32mPASSED[0m
2026-01-14T09:20:09.3678457Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear [32mPASSED[0m
2026-01-14T09:20:09.3679453Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary [32mPASSED[0m
2026-01-14T09:20:09.3680495Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary2 [32mPASSED[0m
2026-01-14T09:20:09.3681562Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic [32mPASSED[0m
2026-01-14T09:20:09.3682737Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic_qat [32mPASSED[0m
2026-01-14T09:20:09.3683843Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_qat [32mPASSED[0m
2026-01-14T09:20:09.3684914Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary [32mPASSED[0m
2026-01-14T09:20:09.3686040Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic [32mPASSED[0m
2026-01-14T09:20:09.3687205Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic_qat [32mPASSED[0m
2026-01-14T09:20:09.3688361Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_qat [32mPASSED[0m
2026-01-14T09:20:09.3689558Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_serials [32mPASSED[0m
2026-01-14T09:20:09.3690679Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_dynamic_fp16 [32mPASSED[0m
2026-01-14T09:20:09.3691740Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary [32mPASSED[0m
2026-01-14T09:20:09.3692923Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic [32mPASSED[0m
2026-01-14T09:20:09.3694050Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic_qat [32mPASSED[0m
2026-01-14T09:20:09.3695136Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_qat [32mPASSED[0m
2026-01-14T09:20:09.3696193Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_lowering_to_x86 [33mSKIPPED[0m
2026-01-14T09:20:09.3697256Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_maxpool2d_recipe [32mPASSED[0m
2026-01-14T09:20:09.3698284Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d [32mPASSED[0m
2026-01-14T09:20:09.3699377Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary [32mPASSED[0m
2026-01-14T09:23:35.4023067Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary2 [32mPASSED[0m
2026-01-14T09:23:35.4024196Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary_unary [32mPASSED[0m
2026-01-14T09:23:35.4025667Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_unary [32mPASSED[0m
2026-01-14T09:23:35.4027543Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_dynamic_quant_linear [32mPASSED[0m
2026-01-14T09:23:35.4028978Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case1 [32mPASSED[0m
2026-01-14T09:23:35.4030386Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case2 [32mPASSED[0m
2026-01-14T09:23:35.4031674Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs [32mPASSED[0m
2026-01-14T09:23:35.4033117Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig [32mPASSED[0m
2026-01-14T09:23:35.4034403Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_for_dynamic_quant [32mPASSED[0m
2026-01-14T09:23:35.4035896Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_with_underscores [32mPASSED[0m
2026-01-14T09:23:35.4037132Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_with_mixed_configs [32mPASSED[0m
2026-01-14T09:23:35.4038211Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T09:23:35.4039762Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm_weight_in_bkn_layout [33mSKIPPED[0m
2026-01-14T09:23:35.4040905Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.4042022Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.4043331Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T09:23:35.4044718Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.4045848Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.4046963Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T09:23:35.4048333Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-1 [33mSKIPPED[0m
2026-01-14T09:23:35.4049420Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-2 [33mSKIPPED[0m
2026-01-14T09:23:35.4050647Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_create_tensor_out_of_inference_mode [33mSKIPPED[0m
2026-01-14T09:23:35.4051895Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_expected_gpu_kernel_fbgemm [33mSKIPPED[0m
2026-01-14T09:23:35.4053220Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.4054756Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.4056298Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.4057893Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.4059471Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.4061000Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.4062701Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.4064296Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.4065626Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.4066839Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.4068133Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes2 [33mSKIPPED[0m
2026-01-14T09:23:35.4069440Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes3 [33mSKIPPED[0m
2026-01-14T09:23:35.4070717Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.4071998Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.4073214Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes2 [33mSKIPPED[0m
2026-01-14T09:23:35.4074479Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes3 [33mSKIPPED[0m
2026-01-14T09:23:35.4076273Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4078432Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4080480Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4082767Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4084905Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4086875Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4088991Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4091148Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4093157Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4095254Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4097369Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4266924Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4269175Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4271464Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4273526Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4275845Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4278146Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4280364Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4282676Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4284894Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4286961Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4289159Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4291216Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4293298Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4295327Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4297457Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4299580Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4301663Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4303883Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4306081Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4308059Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4310424Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4312699Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4314749Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4317023Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4319287Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4321281Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4323641Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4325977Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4327971Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4330304Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4332532Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4334536Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4336728Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4339177Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4341244Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4514281Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4516872Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4519042Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4521106Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4523666Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4525955Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4527923Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4530233Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4532681Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4534644Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4536989Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4539500Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4541479Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4543760Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4545732Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4547991Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4550054Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:23:35.4552360Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:23:35.4554800Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4556828Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4559234Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4561597Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4563716Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4566095Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4568583Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4570689Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4573061Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4575433Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4577471Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4579778Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4582143Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4584168Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4586579Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4588950Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4591062Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4749055Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4751575Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4753906Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4755967Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4758360Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4760699Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4762924Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4765314Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4767638Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4769673Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4771992Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4774321Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4776482Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4778822Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4781255Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4783297Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4785606Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4787902Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4789958Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4792249Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4794400Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4796672Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4798743Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4800975Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4803363Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4805416Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4807762Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4810101Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4812244Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4814578Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4817031Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4819093Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4821339Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4823644Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4984857Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4987308Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4989635Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4991771Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4994103Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.4996426Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.4998450Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5000741Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5003095Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5005226Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5007683Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5010088Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5012116Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5014429Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5016764Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5018810Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5021120Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5023519Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5025603Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5027923Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5030279Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5032346Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5034683Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5037029Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5039411Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5041887Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5044203Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5046544Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5048742Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5051137Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5053405Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5055596Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5058043Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5060301Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5218810Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5221183Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5223541Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5225629Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5227995Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5230375Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5232570Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5234946Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5237399Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5239780Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5242135Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5253393Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5255914Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5258302Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5260729Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5263251Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5265514Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5267900Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5270167Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5272313Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5274669Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5277088Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5279190Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5281614Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5284003Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5286080Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5288417Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5290486Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5292649Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5294931Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5297173Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5299519Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5301742Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5303906Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5452580Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5455099Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5457323Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5459821Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5461906Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5464806Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5467204Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5469568Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5472088Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5474208Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5476716Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5479086Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5481309Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5483920Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5486459Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5488563Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5491112Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5493567Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5495880Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5498516Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5500826Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5503342Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5505888Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5507984Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5510484Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5513041Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5515127Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5517690Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5520107Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5522311Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5524936Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5527194Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5529556Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5532227Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5684635Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5687196Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5689496Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5691544Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5693809Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5696031Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5698059Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5700457Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5702583Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5705092Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5707150Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5709614Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5712084Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5714174Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5716593Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5719068Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5721225Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5723841Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5726223Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5728482Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5731015Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5733225Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5735756Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5738229Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5740615Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5743060Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5745490Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5747520Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5749925Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5752333Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5754552Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5757032Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5759508Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5761757Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5918388Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5920732Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5923191Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5925235Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5927837Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5930210Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5932448Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5934711Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5936893Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5939223Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5941437Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5943752Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5946361Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5948601Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5950909Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5953054Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5955284Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5957601Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5959745Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5961957Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5964437Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5966697Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5968914Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5971236Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5973391Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5975603Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5977906Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5980171Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5982396Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5984746Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5987006Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5989298Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.5991672Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.5993850Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6151385Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6153874Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6156240Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6158425Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6160772Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6163198Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6165288Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6167598Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6169917Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6172131Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6174454Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6176799Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6178970Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6181358Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6183621Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6185814Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6188252Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6190513Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6192829Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6195001Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6197268Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6199426Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6201703Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6204174Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6206433Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6208783Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6211228Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6213321Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6215703Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6218069Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6220148Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6222508Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6224933Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6227088Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6385111Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6387433Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6389812Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6391980Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6394456Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6397163Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6399381Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6401743Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6404182Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6406369Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6408720Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6410940Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6413109Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6415604Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6417860Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6420222Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6422589Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6424788Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6427046Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6429405Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6431579Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6433923Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6436303Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6438556Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6441066Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6443228Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6445597Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6447654Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6450125Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6452512Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6454726Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6457088Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:23:35.6459376Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:23:35.6461447Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6624635Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6626884Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6629329Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6631427Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6633659Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6636002Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6638056Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6640536Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6642934Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6644940Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6647284Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6649685Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6651763Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6654048Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6656343Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6658350Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6660636Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6662872Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6664966Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6667264Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6669661Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6671649Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6673939Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6676253Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6678289Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6680630Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6683158Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6685237Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6687619Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6689781Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6691992Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6694150Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6696505Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6698728Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6700964Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6863340Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6865841Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6868260Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6870372Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6872779Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6875221Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6877367Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6879732Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6882205Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6884376Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6886772Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6889084Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6891177Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6893458Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6895824Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6897955Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6900362Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6902742Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6904952Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6907409Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6909620Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6911746Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6914297Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6916376Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6918815Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6921126Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6923199Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6925334Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6927764Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6929816Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6932182Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6934223Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6936617Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.6938720Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.6941342Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7134149Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7136573Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7138935Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7141268Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7143680Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7146086Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7148203Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7150657Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7152851Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7155008Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7157410Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7159755Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7162078Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7164470Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7166545Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7168694Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7170901Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7173061Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7175209Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7177360Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7179717Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7181739Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7184062Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7186452Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7188503Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7190323Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_has_compatible_shallow_copy_type [33mSKIPPED[0m
2026-01-14T09:23:35.7191651Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_index_select [33mSKIPPED[0m
2026-01-14T09:23:35.7193145Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7194717Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7196311Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7198036Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7199651Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T09:23:35.7200802Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_per_row_config_before_dim [33mSKIPPED[0m
2026-01-14T09:23:35.7201961Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config0 [33mSKIPPED[0m
2026-01-14T09:23:35.7203384Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config1 [33mSKIPPED[0m
2026-01-14T09:23:35.7204542Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config2 [33mSKIPPED[0m
2026-01-14T09:23:35.7206034Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:23:35.7207474Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:23:35.7209030Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:23:35.7210650Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:23:35.7522934Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:23:35.7524721Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:23:35.7526504Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:23:35.7528327Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:23:35.7529820Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:23:35.7531463Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:23:35.7533276Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:23:35.7535050Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:23:35.7536414Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity0 [33mSKIPPED[0m
2026-01-14T09:23:35.7537916Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity1 [33mSKIPPED[0m
2026-01-14T09:23:35.7539694Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity0 [33mSKIPPED[0m
2026-01-14T09:23:35.7541209Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity1 [33mSKIPPED[0m
2026-01-14T09:23:35.7542446Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity0 [33mSKIPPED[0m
2026-01-14T09:23:35.7543816Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity1 [33mSKIPPED[0m
2026-01-14T09:23:35.7545477Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7546819Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7548365Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T09:23:35.7549564Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7550886Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7552369Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T09:23:35.7553728Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_dtype_layout [33mSKIPPED[0m
2026-01-14T09:23:35.7554980Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_transpose [33mSKIPPED[0m
2026-01-14T09:23:35.7556178Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_conv2d_weight [33mSKIPPED[0m
2026-01-14T09:23:35.7557541Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7559207Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7560910Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7562199Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7563650Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T09:23:35.7565603Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T09:23:35.7567488Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T09:23:35.7569060Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T09:23:35.7570441Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config0 [33mSKIPPED[0m
2026-01-14T09:23:35.7572065Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config1 [33mSKIPPED[0m
2026-01-14T09:23:35.7573508Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_from_int4_tensor [33mSKIPPED[0m
2026-01-14T09:23:35.7575118Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config0 [33mSKIPPED[0m
2026-01-14T09:23:35.7576348Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config1 [33mSKIPPED[0m
2026-01-14T09:23:35.7577801Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T09:23:35.7579415Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T09:23:35.7581064Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config0 [33mSKIPPED[0m
2026-01-14T09:23:35.7582334Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config1 [33mSKIPPED[0m
2026-01-14T09:23:35.7583504Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_activation_prescaling [33mSKIPPED[0m
2026-01-14T09:23:35.7584840Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T09:23:35.7585919Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7586891Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7587945Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes2 [33mSKIPPED[0m
2026-01-14T09:23:35.7589244Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_linear [33mSKIPPED[0m
2026-01-14T09:23:35.7590284Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T09:23:35.7591374Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice [33mSKIPPED[0m
2026-01-14T09:23:35.7592572Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_and_copy_similar_to_vllm [33mSKIPPED[0m
2026-01-14T09:23:35.7602965Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_preserves_aliasing [33mSKIPPED[0m
2026-01-14T09:23:35.7604045Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes0 [33mSKIPPED[0m
2026-01-14T09:23:35.7605055Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes1 [33mSKIPPED[0m
2026-01-14T09:23:35.7606225Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes2 [33mSKIPPED[0m
2026-01-14T09:23:35.7607588Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config0 [33mSKIPPED[0m
2026-01-14T09:23:35.7609254Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config1 [33mSKIPPED[0m
2026-01-14T09:23:35.7610669Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_cant_initialize_in_cpu [33mSKIPPED[0m
2026-01-14T09:23:35.7612226Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_128 [33mSKIPPED[0m
2026-01-14T09:24:24.3682403Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_32 [33mSKIPPED[0m
2026-01-14T09:24:24.3684005Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_64 [33mSKIPPED[0m
2026-01-14T09:24:24.3685596Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_error_conditions [33mSKIPPED[0m
2026-01-14T09:24:24.3686943Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config0 [33mSKIPPED[0m
2026-01-14T09:24:24.3688390Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config1 [33mSKIPPED[0m
2026-01-14T09:24:24.3689724Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config0 [33mSKIPPED[0m
2026-01-14T09:24:24.3691065Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config1 [33mSKIPPED[0m
2026-01-14T09:24:24.3692407Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config0 [33mSKIPPED[0m
2026-01-14T09:24:24.3693754Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config1 [33mSKIPPED[0m
2026-01-14T09:24:24.3695154Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_mm_int4wo_device_cuda_bfloat16 [33mSKIPPED[0m
2026-01-14T09:24:24.3696532Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T09:24:24.3697867Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T09:24:24.3699388Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config0 [33mSKIPPED[0m
2026-01-14T09:24:24.3700882Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config1 [33mSKIPPED[0m
2026-01-14T09:24:24.3702349Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config0 [33mSKIPPED[0m
2026-01-14T09:24:24.3703682Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config1 [33mSKIPPED[0m
2026-01-14T09:24:24.3705039Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config0 [33mSKIPPED[0m
2026-01-14T09:24:24.3706475Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config1 [33mSKIPPED[0m
2026-01-14T09:24:24.3707817Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_to_device [33mSKIPPED[0m
2026-01-14T09:24:24.3708961Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_available_gpu_kernels [32mPASSED[0m
2026-01-14T09:24:24.3710073Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config0 [32mPASSED[0m
2026-01-14T09:24:24.3711200Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config1 [32mPASSED[0m
2026-01-14T09:24:24.3712369Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config2 [32mPASSED[0m
2026-01-14T09:24:24.3713777Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config3 [32mPASSED[0m
2026-01-14T09:24:24.3715034Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config0 [32mPASSED[0m
2026-01-14T09:24:24.3716167Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config1 [32mPASSED[0m
2026-01-14T09:24:24.3717297Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config2 [32mPASSED[0m
2026-01-14T09:24:24.3718488Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config3 [32mPASSED[0m
2026-01-14T09:24:24.3719575Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config0 [32mPASSED[0m
2026-01-14T09:24:24.3720607Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config1 [32mPASSED[0m
2026-01-14T09:24:24.3721644Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config2 [32mPASSED[0m
2026-01-14T09:24:24.3722742Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config3 [32mPASSED[0m
2026-01-14T09:24:24.3723939Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3725298Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3726646Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3727984Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3729384Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3730724Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3732112Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3733459Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3734793Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3736130Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3737478Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3738805Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3740418Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3741777Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3743173Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3744602Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3745946Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3747304Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3748716Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes0 [32mPASSED[0m
2026-01-14T09:24:24.3750054Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes1 [32mPASSED[0m
2026-01-14T09:24:24.3751458Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes0 [32mPASSED[0m
2026-01-14T09:25:18.3534026Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes1 [32mPASSED[0m
2026-01-14T09:25:18.3535923Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes0 [32mPASSED[0m
2026-01-14T09:25:18.3537487Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes1 [32mPASSED[0m
2026-01-14T09:25:18.3539461Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes0 [32mPASSED[0m
2026-01-14T09:25:18.3540817Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes1 [32mPASSED[0m
2026-01-14T09:25:18.3542408Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes0 [32mPASSED[0m
2026-01-14T09:25:18.3543911Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes1 [32mPASSED[0m
2026-01-14T09:25:18.3545463Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes0 [32mPASSED[0m
2026-01-14T09:25:18.3546939Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes1 [32mPASSED[0m
2026-01-14T09:25:18.3548299Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes0 [32mPASSED[0m
2026-01-14T09:25:18.3549652Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes1 [32mPASSED[0m
2026-01-14T09:25:18.3550909Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config0 [32mPASSED[0m
2026-01-14T09:25:18.3552055Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config1 [32mPASSED[0m
2026-01-14T09:25:18.3553155Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config2 [32mPASSED[0m
2026-01-14T09:25:18.3554293Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config3 [32mPASSED[0m
2026-01-14T09:25:18.3555424Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3556735Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_cuda_float16 [32mPASSED[0m
2026-01-14T09:25:18.3558098Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3559463Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:25:18.3560651Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3561871Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_cuda_float16 [32mPASSED[0m
2026-01-14T09:25:18.3563199Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3564344Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:25:18.3565532Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3566730Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_cuda_float16 [32mPASSED[0m
2026-01-14T09:25:18.3567921Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3569183Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:25:18.3570303Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3571460Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_cuda_float16 [32mPASSED[0m
2026-01-14T09:25:18.3572640Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3573950Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:25:18.3575330Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity0_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3576958Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity1_bfloat16 [32mPASSED[0m
2026-01-14T09:25:18.3579269Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3582550Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3585786Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3589029Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3592343Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3595548Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3598909Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3602035Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3605485Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3704672Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3708166Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3711303Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3714539Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3717705Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3722874Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3726276Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3729631Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3732889Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3736015Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3739724Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3742954Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3746830Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3750093Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3753410Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3756589Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3759875Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3763303Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3766882Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3770151Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3773623Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3776960Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3864959Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3868518Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3871916Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3875504Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3878930Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3882483Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3885903Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3889471Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3892788Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3896310Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3899747Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3903004Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3906471Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3909766Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3913463Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3917059Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3920639Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3924110Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3927749Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3931188Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.3934721Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.3938069Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4024665Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4028284Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4031808Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4035181Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4038640Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4042309Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4045849Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4049329Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4053004Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4056357Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4059998Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4063337Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4066800Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4070290Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4073735Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4076862Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4080284Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4083608Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4087239Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4090615Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4094019Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4097231Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4184194Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4187704Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4191178Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4194638Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4197941Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4201283Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4204833Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4208265Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4211740Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4215085Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4218431Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4221803Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4225160Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4228665Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4232164Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4235529Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4238941Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4242368Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4246158Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4249497Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4252883Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4256411Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4342878Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4346613Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4349855Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4353676Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4356897Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4360532Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4363951Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4367548Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4370941Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4374510Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4377828Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4381319Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4384610Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4388125Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4391505Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4395107Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4398385Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4401886Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4405231Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4408624Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4412117Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4415579Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4501959Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4505091Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4508452Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4511567Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4515130Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4518382Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4521698Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4524974Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4528191Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4531592Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4534938Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4538397Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4541839Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4545064Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4548366Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4551688Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4555146Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4558504Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4561616Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4565023Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4568221Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4571729Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4659983Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4663633Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4666849Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4670529Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4673834Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4677099Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4680614Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4683899Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4687584Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4690981Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4694727Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4697878Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4701182Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4704442Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4707771Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4711160Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4714605Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4717857Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4721123Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4724545Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4727836Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4731223Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4817602Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4820998Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4824318Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4827626Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4830908Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4834203Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4837601Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4841210Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4844631Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4847768Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4851125Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4854390Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4857860Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4861288Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4864524Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4867833Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4871051Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4874454Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4877810Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4881237Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4884566Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4887825Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4975564Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4979000Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4982408Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4985721Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4988954Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4992227Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.4996053Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.4999419Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5002781Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5005975Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5009181Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5012428Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5015703Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5018844Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5022005Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5025282Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5028735Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5032007Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5035752Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5039160Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5042388Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5045834Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5132538Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5136102Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5139888Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5143394Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5146773Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5150132Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5153570Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5156894Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5160224Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5163687Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5176121Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5179824Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5183308Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5186758Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5189934Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5193347Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5196727Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5200180Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5203727Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5207200Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5211046Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5214806Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5289171Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5292740Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5296189Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5300048Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5303196Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5306891Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5310019Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5313641Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5317072Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5320831Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5323918Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5327374Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5330587Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5334351Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5337502Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5341053Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5344292Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5347594Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5351156Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5354455Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5357860Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5360853Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5443792Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5446858Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5450373Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5453995Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5457422Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5460699Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5463850Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5467343Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5470671Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5474152Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5477605Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5481076Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5484278Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5487890Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5491213Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5494825Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5497842Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5501231Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5504623Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5507879Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:18.5511090Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:18.5514298Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:26.2424247Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:26.2428379Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:26.2432139Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:26.2436056Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:26.2440159Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:26.2444041Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:26.2449598Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:26.2453339Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:26.2457151Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:26.2460953Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:25:26.2464822Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:25:26.2467428Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T09:25:26.2469425Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_ATEN_KLEIDIAI: 'opaque_aten_kleidiai'>} [33mSKIPPED[0m
2026-01-14T09:25:26.2471750Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>} [33mSKIPPED[0m
2026-01-14T09:25:26.2473647Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_conv2d [32mPASSED[0m
2026-01-14T09:25:26.2475345Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_embedding [32mPASSED[0m
2026-01-14T09:25:26.2477072Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T09:25:26.2479004Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config_with_unwrap [32mPASSED[0m
2026-01-14T09:25:26.2481127Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_intx_weight_only_config [32mPASSED[0m
2026-01-14T09:25:26.2483020Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T09:25:26.2484846Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_intx_weight_only_config [32mPASSED[0m
2026-01-14T09:25:26.2486464Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_linear [32mPASSED[0m
2026-01-14T09:25:26.2489037Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.2492377Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.2495751Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.2499084Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.2502420Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.2505732Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.2509278Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.5451812Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.5455332Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.5458693Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.5462045Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.5465411Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.5468845Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.5472271Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.5475608Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.5478973Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.5482372Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.5485813Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.5489236Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.5492603Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.5496010Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.5499377Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.5502729Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.5506067Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.5509499Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.5512919Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.5516268Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.5519698Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.5523184Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.5526558Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.5529986Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.5533399Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.8241981Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.8245502Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.8248874Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.8252354Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.8255711Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.8259169Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.8262532Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.8265880Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.8269241Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.8272701Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.8276061Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.8279486Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.8282908Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.8286262Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.8289635Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.8293061Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.8296427Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.8299827Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.8303241Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.8306597Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.8309960Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.8313377Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:26.8316761Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:26.8320218Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:26.8323672Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.0923317Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.0926735Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.0930215Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.0933662Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.0937017Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.0940575Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.0943961Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.0947351Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.0950771Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.0954150Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.0957587Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.0960934Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.0964430Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.0967800Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.0971325Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.0974792Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.0978195Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.0981597Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.0985016Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.0988405Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.0991851Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.0995304Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.0998694Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.1002072Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.1005528Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.3618316Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.3621782Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.3625273Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.3628671Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.3632231Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.3635627Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.3639287Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.3642980Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.3646514Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.3649899Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.3653297Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.3656688Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.3660167Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.3663533Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.3666972Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.3670410Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.3673838Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.3677224Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.3680688Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.3684190Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.3687633Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.3691016Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.3694393Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.3697774Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.3701263Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.6305615Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.6309073Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.6312501Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.6315902Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.6319284Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.6322928Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.6326339Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.6329821Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.6333273Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.6336697Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.6340393Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.6343817Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.6347298Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.6350695Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.6354111Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.6357525Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.6361030Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.6364491Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.6367948Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.6371373Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.6374775Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.6378212Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.6381682Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.6385092Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.6388537Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.8948445Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.8951860Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.8955232Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.8958749Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.8962119Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.8965649Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.8969022Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.8972377Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.8975750Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.8979205Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.8982700Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.8986055Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.8989425Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.8992793Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.8996165Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.8999556Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.9002979Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.9006375Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.9009724Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.9013060Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.9016465Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.9019956Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:27.9023365Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:27.9026706Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:27.9030054Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.1618008Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.1621484Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.1625021Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.1628430Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.1631889Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.1635319Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.1638728Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.1642638Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.1646075Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.1649577Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.1652991Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.1656402Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.1659818Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.1663330Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.1666727Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.1670202Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.1673635Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.1677050Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.1680441Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.1684000Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.1687431Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.1690885Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.1694258Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.1697673Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.1701107Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.4319304Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.4322909Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.4326403Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.4329966Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.4333403Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.4336821Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.4340485Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.4343956Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.4347373Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.4350803Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.4354200Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.4357624Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.4363211Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.4366692Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.4370333Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.4373706Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.4377084Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.4380463Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.4383895Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.4387351Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.4390777Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.4394681Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.4398127Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.4401626Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.4405227Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.5737485Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.5740553Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.5743321Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.5745955Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.5748675Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.5751332Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.5754033Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:25:28.5756659Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:25:28.5759281Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:25:28.5761327Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T09:25:28.5762888Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_intx_weight_only_config [32mPASSED[0m
2026-01-14T09:25:28.5764210Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice [32mPASSED[0m
2026-01-14T09:25:28.5765514Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice_and_copy_ [32mPASSED[0m
2026-01-14T09:25:28.5766779Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_to_dtype [32mPASSED[0m
2026-01-14T09:25:28.5767890Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_False [33mSKIPPED[0m
2026-01-14T09:25:28.5768920Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_True [33mSKIPPED[0m
2026-01-14T09:25:28.5769880Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_False [33mSKIPPED[0m
2026-01-14T09:25:28.5770829Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_True [33mSKIPPED[0m
2026-01-14T09:25:28.5771873Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5772987Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5774080Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5775167Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5776265Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5777362Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5786375Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5787639Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5788753Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5789916Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5791031Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5792132Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5793229Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5794338Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5795436Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5796525Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5797628Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5798722Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5799814Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5801015Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5802108Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5803303Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5804443Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5805521Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5806620Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5807717Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5808818Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5809915Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:28.5811041Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:28.5812163Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0179899Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:43.0181334Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0183061Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:43.0184451Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0185917Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:43.0187286Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0188644Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:43.0190007Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0191374Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:43.0192720Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0194094Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:43.0195466Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0196841Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:43.0198205Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0199563Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:43.0201031Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0202395Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:25:43.0203836Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:25:43.0205129Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_add_tensors [32mPASSED[0m
2026-01-14T09:25:43.0206221Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_inplace_operation [32mPASSED[0m
2026-01-14T09:25:43.0207301Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_pad_unpad [32mPASSED[0m
2026-01-14T09:25:43.0208424Z test/quantization/test_gptq.py::TestMultiTensorInputRecorder::test_multitensor_input_recorder [32mPASSED[0m
2026-01-14T09:25:43.0209537Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_calc_success [32mPASSED[0m
2026-01-14T09:25:43.0210552Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_row_errors [32mPASSED[0m
2026-01-14T09:25:43.0211549Z test/quantization/test_observer.py::TestQuantFlow::test_fixed_qparams_observer [32mPASSED[0m
2026-01-14T09:25:43.0212589Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_channel_affine [32mPASSED[0m
2026-01-14T09:25:43.0213649Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_tensor_affine [32mPASSED[0m
2026-01-14T09:25:43.0214619Z test/quantization/test_observer.py::TestQuantFlow::test_mse_observer [32mPASSED[0m
2026-01-14T09:25:43.0215736Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_False [32mPASSED[0m
2026-01-14T09:25:43.0217021Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_True [32mPASSED[0m
2026-01-14T09:25:43.0218156Z test/quantization/test_qat.py::TestQAT::test_composable_qat_quantizer [32mPASSED[0m
2026-01-14T09:25:43.0219061Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dtype [32mPASSED[0m
2026-01-14T09:25:43.0220308Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dynamic_and_range_learning [32mPASSED[0m
2026-01-14T09:25:43.0221319Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_eps [32mPASSED[0m
2026-01-14T09:25:43.0222269Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity [32mPASSED[0m
2026-01-14T09:25:43.0223312Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity_error_cases [32mPASSED[0m
2026-01-14T09:25:43.0224339Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_mapping_type [32mPASSED[0m
2026-01-14T09:25:43.0225307Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_torch_intx [32mPASSED[0m
2026-01-14T09:25:43.0226270Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_channel_group [32mPASSED[0m
2026-01-14T09:25:43.0227182Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token [32mPASSED[0m
2026-01-14T09:25:43.0228231Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.0229309Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float16 [32mPASSED[0m
2026-01-14T09:25:43.0230483Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float32 [32mPASSED[0m
2026-01-14T09:25:43.0231473Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_embedding_4w [32mPASSED[0m
2026-01-14T09:25:43.0232365Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_4w [32mPASSED[0m
2026-01-14T09:25:43.0233264Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_8da4w [32mPASSED[0m
2026-01-14T09:25:43.0234357Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T09:25:43.0235509Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T09:25:43.0236490Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_repr [32mPASSED[0m
2026-01-14T09:25:43.0237433Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_int4_preshuffled_primitives [33mSKIPPED[0m
2026-01-14T09:25:43.0238445Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_primitives [33mSKIPPED[0m
2026-01-14T09:25:43.0239596Z test/quantization/test_qat.py::TestQAT::test_fbgemm_int4_weight_only_primitives [33mSKIPPED[0m
2026-01-14T09:25:43.0240560Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_config [32mPASSED[0m
2026-01-14T09:25:43.0241517Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity0 [32mPASSED[0m
2026-01-14T09:25:43.0242487Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity1 [32mPASSED[0m
2026-01-14T09:25:43.0243478Z test/quantization/test_qat.py::TestQAT::test_infer_fp8_int4_config [32mPASSED[0m
2026-01-14T09:25:43.0244364Z test/quantization/test_qat.py::TestQAT::test_infer_int4_weight_only_config [32mPASSED[0m
2026-01-14T09:25:43.0245272Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e [32mPASSED[0m
2026-01-14T09:25:43.0246268Z test/quantization/test_qat.py::TestQAT::test_nvfp4_fake_quanitzed_linear_mixed_precision [33mSKIPPED[0m
2026-01-14T09:25:43.0247225Z test/quantization/test_qat.py::TestQAT::test_qat_4w_embedding [32mPASSED[0m
2026-01-14T09:25:43.0248131Z test/quantization/test_qat.py::TestQAT::test_qat_4w_linear tensor(5.9366e-05, device='cuda:0', dtype=torch.bfloat16,
2026-01-14T09:25:43.0248856Z        grad_fn=<AbsBackward0>)
2026-01-14T09:25:43.0249220Z [32mPASSED[0m
2026-01-14T09:25:43.0249846Z test/quantization/test_qat.py::TestQAT::test_qat_4w_primitives tensor(0.0005, device='cuda:0', dtype=torch.bfloat16)
2026-01-14T09:25:43.0250810Z [32mPASSED[0m
2026-01-14T09:25:43.0251550Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer tensor(0.0038, device='cuda:0', dtype=torch.bfloat16, grad_fn=<AbsBackward0>)
2026-01-14T09:25:43.0252488Z [32mPASSED[0m
2026-01-14T09:25:43.0253072Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer_gradients [32mPASSED[0m
2026-01-14T09:25:43.0253929Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_eps [32mPASSED[0m
2026-01-14T09:25:43.0254718Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_linear [32mPASSED[0m
2026-01-14T09:25:43.0255626Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.0256634Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float16 [32mPASSED[0m
2026-01-14T09:25:43.0257623Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float32 [32mPASSED[0m
2026-01-14T09:25:43.0258540Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer [32mPASSED[0m
2026-01-14T09:25:43.0259466Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant [32mPASSED[0m
2026-01-14T09:25:43.0260539Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant_backward [32mPASSED[0m
2026-01-14T09:25:43.0261565Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_gradients [32mPASSED[0m
2026-01-14T09:25:43.0262515Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_meta_weights [32mPASSED[0m
2026-01-14T09:25:43.0263476Z test/quantization/test_qat.py::TestQAT::test_qat_api_convert_no_quantization [32mPASSED[0m
2026-01-14T09:25:43.0264372Z test/quantization/test_qat.py::TestQAT::test_qat_api_deprecation [32mPASSED[0m
2026-01-14T09:25:43.0265234Z test/quantization/test_qat.py::TestQAT::test_qat_config_init [32mPASSED[0m
2026-01-14T09:25:43.8423407Z test/quantization/test_qat.py::TestQAT::test_qat_fp8a4w_quantizer [32mPASSED[0m
2026-01-14T09:25:43.8424402Z test/quantization/test_qat.py::TestQAT::test_qat_linear_bias [32mPASSED[0m
2026-01-14T09:25:43.8425760Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T09:25:43.8427565Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T09:25:43.8429269Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T09:25:43.8431058Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T09:25:43.8432512Z test/quantization/test_qat.py::TestQAT::test_qat_prototype_bc [32mPASSED[0m
2026-01-14T09:25:43.8434018Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T09:25:43.8435420Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T09:25:43.8436198Z test/quantization/test_qat.py::TestQAT::test_quantize_api_e2e [32mPASSED[0m
2026-01-14T09:25:43.8436886Z test/quantization/test_qat.py::TestQAT::test_quantize_api_errors [32mPASSED[0m
2026-01-14T09:25:43.8437638Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity0 [33mSKIPPED[0m
2026-01-14T09:25:43.8438456Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity1 [33mSKIPPED[0m
2026-01-14T09:25:43.8439397Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_int4 [33mSKIPPED[0m
2026-01-14T09:25:43.8440332Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T09:25:43.8441464Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T09:25:43.8442675Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T09:25:43.8443909Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T09:25:43.8444831Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_int4 [32mPASSED[0m
2026-01-14T09:25:43.8447964Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity0_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8449197Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity1_float32 [32mPASSED[0m
2026-01-14T09:25:43.8450432Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity2_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8451861Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity3_float32 [32mPASSED[0m
2026-01-14T09:25:43.8453090Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity4_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8454334Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity5_float32 [32mPASSED[0m
2026-01-14T09:25:43.8455565Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity6_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8456789Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity7_float32 [32mPASSED[0m
2026-01-14T09:25:43.8458027Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity10_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8459263Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity11_float32 [32mPASSED[0m
2026-01-14T09:25:43.8460498Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity8_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8461725Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity9_float32 [32mPASSED[0m
2026-01-14T09:25:43.8463041Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity12_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8464285Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity13_float32 [32mPASSED[0m
2026-01-14T09:25:43.8465525Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity14_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8466828Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity15_float32 [32mPASSED[0m
2026-01-14T09:25:43.8468061Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity16_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8469287Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity17_float32 [32mPASSED[0m
2026-01-14T09:25:43.8470521Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity18_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8471758Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity19_float32 [32mPASSED[0m
2026-01-14T09:25:43.8473000Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity20_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8474242Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity21_float32 [32mPASSED[0m
2026-01-14T09:25:43.8475472Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity22_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8476707Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity23_float32 [32mPASSED[0m
2026-01-14T09:25:43.8477938Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity24_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8479163Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity25_float32 [32mPASSED[0m
2026-01-14T09:25:43.8480445Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity26_bfloat16 [32mPASSED[0m
2026-01-14T09:25:43.8481676Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity27_float32 [32mPASSED[0m
2026-01-14T09:25:43.8483083Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity0_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8484426Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity1_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8485794Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity2_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8487104Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity3_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8488422Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity4_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8489761Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity5_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8491087Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity6_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8492402Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity7_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8493732Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity10_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8495063Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity11_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8496394Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity12_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8497802Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity13_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8499140Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity14_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8500479Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity15_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8501865Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity8_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8503195Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity9_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8504541Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity16_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8505884Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity17_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8507236Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity18_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8508571Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity19_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8509898Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity20_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:43.8511030Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity21_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:43.8512096Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity22_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8199385Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity23_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8202020Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity24_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8204274Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity25_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8206106Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity26_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8207170Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity27_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8208248Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity28_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8209322Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity29_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8210369Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity30_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8211429Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity31_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8212483Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity32_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8213536Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity33_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8214589Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity34_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8215635Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity35_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8216683Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity36_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8217822Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity37_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8218869Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity38_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8219917Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity39_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8221026Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity40_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8222087Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity41_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8223138Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity42_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8224176Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity43_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8225234Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity44_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8226295Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity45_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8227344Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity46_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8228396Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity47_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8229439Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity48_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8230498Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity49_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8231603Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity50_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8232656Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity51_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8233753Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity52_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8234803Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity53_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8235858Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity54_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:25:45.8236906Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity55_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:25:45.8237874Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T09:25:45.8238777Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T09:25:45.8239734Z test/quantization/test_qat.py::TestQAT::test_quantize_api_prepare [32mPASSED[0m
2026-01-14T09:25:45.8240562Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls0 [32mPASSED[0m
2026-01-14T09:25:45.8241495Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls1 [32mPASSED[0m
2026-01-14T09:25:45.8242435Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls2 [32mPASSED[0m
2026-01-14T09:25:45.8243288Z test/quantization/test_qat.py::TestQAT::test_replace_linear_8da4w [32mPASSED[0m
2026-01-14T09:25:45.8243961Z test/quantization/test_qat.py::TestQAT::test_replace_linear_int4 [32mPASSED[0m
2026-01-14T09:25:45.8244674Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer [32mPASSED[0m
2026-01-14T09:25:45.8245560Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer_linear_bias [32mPASSED[0m
2026-01-14T09:25:45.8246377Z test/quantization/test_quant_api.py::TestQuantFlow::test_config_deprecation [32mPASSED[0m
2026-01-14T09:25:45.8247203Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_singleline [32mPASSED[0m
2026-01-14T09:25:45.8248139Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_eager_mode_impl [33mSKIPPED[0m
2026-01-14T09:25:45.8249191Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_unified_impl [33mSKIPPED[0m
2026-01-14T09:25:45.8250086Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4_wo_quant_save_load [33mSKIPPED[0m
2026-01-14T09:25:45.8250979Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T09:25:45.8251927Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T09:25:45.8252876Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T09:25:45.8253822Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T09:25:45.8254770Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T09:25:45.8255705Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T09:25:45.8256648Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T09:25:45.8257581Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T09:25:45.8258522Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T09:25:45.8259533Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T09:25:45.8260475Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T09:25:45.8261484Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T09:25:45.8262361Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cuda_serialization [32mPASSED[0m
2026-01-14T09:25:45.8263186Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8_wo_quant_save_load [32mPASSED[0m
2026-01-14T09:25:45.8264035Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8wo_quantized_model_to_device [32mPASSED[0m
2026-01-14T09:25:45.8264897Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_default [32mPASSED[0m
2026-01-14T09:25:45.8265798Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_embedding_linear [32mPASSED[0m
2026-01-14T09:25:45.8266699Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_module_name [32mPASSED[0m
2026-01-14T09:25:45.8267585Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_basic [32mPASSED[0m
2026-01-14T09:25:45.8268490Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_fullmatch [32mPASSED[0m
2026-01-14T09:25:45.8269403Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence [32mPASSED[0m
2026-01-14T09:25:45.8270334Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence2 [32mPASSED[0m
2026-01-14T09:25:54.6781672Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_skip [32mPASSED[0m
2026-01-14T09:25:54.6782583Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_model_streaming [32mPASSED[0m
2026-01-14T09:25:54.6783866Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type0 [32mPASSED[0m
2026-01-14T09:25:54.6784871Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type1 [32mPASSED[0m
2026-01-14T09:25:54.6785833Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load [32mPASSED[0m
2026-01-14T09:25:54.6786901Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load_map_location [32mPASSED[0m
2026-01-14T09:25:54.6787840Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config0 [32mPASSED[0m
2026-01-14T09:25:54.6788703Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config1 [32mPASSED[0m
2026-01-14T09:25:54.6789559Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config2 [32mPASSED[0m
2026-01-14T09:25:54.6790435Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config3 [32mPASSED[0m
2026-01-14T09:25:54.6791300Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config4 [32mPASSED[0m
2026-01-14T09:25:54.6792153Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config5 [32mPASSED[0m
2026-01-14T09:25:54.6793022Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config6 [32mPASSED[0m
2026-01-14T09:25:54.6793881Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config7 [32mPASSED[0m
2026-01-14T09:25:54.6794743Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config8 [32mPASSED[0m
2026-01-14T09:25:54.6795608Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config9 [32mPASSED[0m
2026-01-14T09:25:54.6796491Z test/quantization/test_quant_api.py::TestFqnToConfig::test_filter_fn_and_fqn_to_config_error [33mSKIPPED[0m
2026-01-14T09:25:54.6797617Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_module_config_and_fqn_config_both_specified [33mSKIPPED[0m
2026-01-14T09:25:54.6798631Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module [33mSKIPPED[0m
2026-01-14T09:25:54.6799706Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_module_swap [33mSKIPPED[0m
2026-01-14T09:25:54.6800717Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_param [33mSKIPPED[0m
2026-01-14T09:25:54.6801625Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_custom [33mSKIPPED[0m
2026-01-14T09:25:54.6802487Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_linear [33mSKIPPED[0m
2026-01-14T09:25:54.6803452Z test/quantization/test_quant_api.py::TestFqnToConfig::test_non_fqn_config_filter_fn_none [33mSKIPPED[0m
2026-01-14T09:25:54.6804440Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_module_over_param_regex [33mSKIPPED[0m
2026-01-14T09:25:54.6805466Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_default [33mSKIPPED[0m
2026-01-14T09:25:54.6806466Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module [33mSKIPPED[0m
2026-01-14T09:25:54.6807500Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module_regex [33mSKIPPED[0m
2026-01-14T09:25:54.6808552Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_default [33mSKIPPED[0m
2026-01-14T09:25:54.6809639Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_module_regex [33mSKIPPED[0m
2026-01-14T09:25:54.6810691Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param [33mSKIPPED[0m
2026-01-14T09:25:54.6811783Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param_regex [33mSKIPPED[0m
2026-01-14T09:25:54.6812742Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_exact [33mSKIPPED[0m
2026-01-14T09:25:54.6813607Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_regex [33mSKIPPED[0m
2026-01-14T09:25:54.6814569Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantized_model_streaming_fqn_config [33mSKIPPED[0m
2026-01-14T09:25:54.6815438Z test/quantization/test_quant_api.py::TestFqnToConfig::test_top_level_param [33mSKIPPED[0m
2026-01-14T09:25:54.6816390Z test/quantization/test_quant_api.py::TestFqnToConfig::test_unsupported_param_config_raises_not_implemented_error [33mSKIPPED[0m
2026-01-14T09:25:54.6817508Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_and_quantize_scale_only_sinq [32mPASSED[0m
2026-01-14T09:25:54.6818555Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym [32mPASSED[0m
2026-01-14T09:25:54.6819592Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym_no_clipping_err [32mPASSED[0m
2026-01-14T09:25:54.6820639Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym [32mPASSED[0m
2026-01-14T09:25:54.6821642Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym_eps [32mPASSED[0m
2026-01-14T09:25:54.6822638Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_sym [32mPASSED[0m
2026-01-14T09:25:54.6823621Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_token_asym [32mPASSED[0m
2026-01-14T09:25:54.6824569Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine [32mPASSED[0m
2026-01-14T09:25:54.6825600Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine_cachemask [32mPASSED[0m
2026-01-14T09:25:54.6826592Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_blockwise_scaling [32mPASSED[0m
2026-01-14T09:25:54.6827670Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_rowwise_scaling_3d_weight_axis_1 [32mPASSED[0m
2026-01-14T09:25:54.6828762Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric [32mPASSED[0m
2026-01-14T09:25:54.6829780Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric_memory [32mPASSED[0m
2026-01-14T09:25:54.6830801Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_groupwise_affine_qparams [32mPASSED[0m
2026-01-14T09:25:54.6831885Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_dequantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T09:25:54.6833049Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_quantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T09:25:54.6834140Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_maybe_expand_scale_to_tensor_shape [32mPASSED[0m
2026-01-14T09:25:54.6835192Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max [32mPASSED[0m
2026-01-14T09:25:54.6836298Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_dtype [32mPASSED[0m
2026-01-14T09:25:54.6837434Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_zero_input [32mPASSED[0m
2026-01-14T09:25:54.6838528Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym [32mPASSED[0m
2026-01-14T09:25:54.6839878Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d [32mPASSED[0m
2026-01-14T09:25:54.6841095Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d_multi_dim_reduction [32mPASSED[0m
2026-01-14T09:25:54.6842216Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_group_sym [32mPASSED[0m
2026-01-14T09:25:54.6843297Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_tensor_asym [32mPASSED[0m
2026-01-14T09:25:54.6844269Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_raises [32mPASSED[0m
2026-01-14T09:25:54.6845068Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity [33mSKIPPED[0m
2026-01-14T09:25:54.6845871Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity_scaled [33mSKIPPED[0m
2026-01-14T09:25:54.6846654Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_srelu [33mSKIPPED[0m
2026-01-14T09:25:54.6847450Z test/sparsity/test_activation24.py::test_srelu_fp8_semi_sparse_activation_linear [33mSKIPPED[0m
2026-01-14T09:25:54.6848266Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_eye [33mSKIPPED[0m
2026-01-14T09:25:54.6849100Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_random_tensor [33mSKIPPED[0m
2026-01-14T09:25:54.6850133Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification [33mSKIPPED[0m
2026-01-14T09:25:54.6851351Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification_compile [33mSKIPPED[0m
2026-01-14T09:25:54.6852349Z test/sparsity/test_sparse_api.py::TestSemiStructuredSparse::test_sparse [33mSKIPPED[0m
2026-01-14T09:29:17.4008214Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T09:29:17.4010825Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T09:29:17.4012413Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T09:29:17.4013615Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T09:29:17.4014915Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_quant_semi_sparse_compile_False [33mSKIPPED[0m
2026-01-14T09:29:17.4016098Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1 [32mPASSED[0m
2026-01-14T09:29:17.4017320Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024 [32mPASSED[0m
2026-01-14T09:29:17.4018530Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1 [32mPASSED[0m
2026-01-14T09:29:17.4019730Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1024 [32mPASSED[0m
2026-01-14T09:29:17.4020914Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False [32mPASSED[0m
2026-01-14T09:29:17.4021955Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_True [32mPASSED[0m
2026-01-14T09:29:17.4022758Z test/sparsity/test_supermask.py::TestSupermask::test_from_linear [32mPASSED[0m
2026-01-14T09:29:17.4023589Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_2 [32mPASSED[0m
2026-01-14T09:29:17.4024530Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_4 [32mPASSED[0m
2026-01-14T09:29:17.4025472Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_8 [32mPASSED[0m
2026-01-14T09:29:17.4026399Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_2 [32mPASSED[0m
2026-01-14T09:29:17.4027337Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_4 [32mPASSED[0m
2026-01-14T09:29:17.4028414Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_8 [32mPASSED[0m
2026-01-14T09:29:17.4029252Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4 [32mPASSED[0m
2026-01-14T09:29:17.4030063Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T09:29:17.4030924Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_prepare [32mPASSED[0m
2026-01-14T09:29:17.4031619Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_squash_mask [32mPASSED[0m
2026-01-14T09:29:17.4032392Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T09:29:17.4033278Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured_custom_config [32mPASSED[0m
2026-01-14T09:29:17.4034207Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_False [32mPASSED[0m
2026-01-14T09:29:17.4035112Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_True [32mPASSED[0m
2026-01-14T09:29:17.4036023Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cuda_compile_False [32mPASSED[0m
2026-01-14T09:29:17.4036936Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cuda_compile_True [32mPASSED[0m
2026-01-14T09:29:17.4038065Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_False [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:29:17.4039374Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:29:17.4039898Z [32mPASSED[0m
2026-01-14T09:29:17.4040737Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_True [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:29:17.4041861Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:29:17.4042373Z [32mPASSED[0m
2026-01-14T09:29:17.4043400Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cuda_compile_False [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:29:17.4044724Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:29:17.4045307Z [32mPASSED[0m
2026-01-14T09:29:17.4046266Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cuda_compile_True [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:29:17.4047483Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:29:17.4047993Z [32mPASSED[0m
2026-01-14T09:29:17.4048567Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4049465Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_compile_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4050386Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4051302Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_correctness_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4052215Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4053096Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_compile_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4054005Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4054926Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_correctness_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4055890Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_Adam4bit [33mSKIPPED[0m
2026-01-14T09:29:17.4056816Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_AdamW4bit [33mSKIPPED[0m
2026-01-14T09:29:17.4057682Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_Adam8bit [33mSKIPPED[0m
2026-01-14T09:29:17.4058624Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_AdamW8bit [33mSKIPPED[0m
2026-01-14T09:29:17.4059525Z test/test_low_bit_optim.py::TestOptim::test_optim_bf16_stochastic_round_correctness_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4060448Z test/test_low_bit_optim.py::TestOptim::test_optim_bf16_stochastic_round_correctness_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4061432Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_1 [32mPASSED[0m
2026-01-14T09:29:17.4062452Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_2 [32mPASSED[0m
2026-01-14T09:29:17.4063467Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_True_grad_accum_1 [32mPASSED[0m
2026-01-14T09:29:17.4064332Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_save_load [32mPASSED[0m
2026-01-14T09:29:17.4065182Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4066157Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam4bit_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4067159Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4068119Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam8bit_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4069136Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4070091Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_AdamFp8_device_cuda [33mSKIPPED[0m
2026-01-14T09:29:17.4071079Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4071999Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4072928Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4073847Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4074763Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4075690Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4076609Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4077526Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:29:17.4078445Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4079361Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_bfloat16_device_cuda [33mSKIPPED[0m
2026-01-14T09:29:17.4080280Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T09:29:17.4081189Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_float32_device_cuda [33mSKIPPED[0m
2026-01-14T09:32:15.0336695Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0339930Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0341088Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0342186Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0343334Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0344649Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0345696Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0346600Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0347517Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0348428Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_bfloat16_device_cuda [33mSKIPPED[0m
2026-01-14T09:32:15.0349344Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0350254Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_float32_device_cuda [33mSKIPPED[0m
2026-01-14T09:32:15.0351136Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0351986Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam4bit_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0352832Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0353820Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam8bit_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0354672Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0355519Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_AdamFp8_device_cuda [33mSKIPPED[0m
2026-01-14T09:32:15.0356468Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape0_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0357367Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape0_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0358220Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape1_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0359073Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape1_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0359912Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape0_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0360769Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape0_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0361608Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape1_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0362551Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape1_device_cuda [32mPASSED[0m
2026-01-14T09:32:15.0363400Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape0_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0364252Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape0_device_cuda [33mSKIPPED[0m
2026-01-14T09:32:15.0365108Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape1_device_cpu [32mPASSED[0m
2026-01-14T09:32:15.0365960Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape1_device_cuda [33mSKIPPED[0m
2026-01-14T09:32:15.0367013Z test/test_low_bit_optim.py::TestFSDP2::test_fsdp2 I0114 09:30:38.651000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 68788
2026-01-14T09:32:15.0368184Z I0114 09:30:38.652000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 68789
2026-01-14T09:32:15.0368799Z dist init r=0, world=2
2026-01-14T09:32:15.0369045Z dist init r=1, world=2
2026-01-14T09:32:15.0369316Z [32mPASSED[0m
2026-01-14T09:32:15.0370076Z test/test_low_bit_optim.py::TestFSDP2::test_uneven_shard I0114 09:32:03.584000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 0 with pid 71394
2026-01-14T09:32:15.0371259Z I0114 09:32:03.586000 1006 site-packages/torch/testing/_internal/common_distributed.py:729] Started process 1 with pid 71395
2026-01-14T09:32:15.0371864Z dist init r=0, world=2
2026-01-14T09:32:15.0372105Z dist init r=1, world=2
2026-01-14T09:32:15.0372368Z [32mPASSED[0m
2026-01-14T09:32:15.0372899Z test/test_model_architecture.py::TestModels::test_ln_linear_activation_model_0_cpu [32mPASSED[0m
2026-01-14T09:32:15.0373737Z test/test_model_architecture.py::TestModels::test_ln_linear_activation_model_1_cuda [32mPASSED[0m
2026-01-14T09:32:15.0374528Z test/test_model_architecture.py::TestModels::test_toy_linear_model_0_cpu [32mPASSED[0m
2026-01-14T09:32:15.0375277Z test/test_model_architecture.py::TestModels::test_toy_linear_model_1_cuda [32mPASSED[0m
2026-01-14T09:32:15.0376044Z test/test_model_architecture.py::TestModels::test_transformer_block_0_cpu [32mPASSED[0m
2026-01-14T09:32:15.0376817Z test/test_model_architecture.py::TestModels::test_transformer_block_1_cuda [32mPASSED[0m
2026-01-14T09:32:15.0377913Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0379252Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0380670Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0382025Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0383391Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0384746Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0386089Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0387442Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0388791Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0390136Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0391476Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0392827Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0394224Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0395557Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0396939Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0398345Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0399680Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0401035Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0402373Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0403756Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0405102Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0563573Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0565205Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0566563Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0567963Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0569287Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0570627Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0571951Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0573277Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0574615Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0575947Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0577271Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0578602Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0580017Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0581345Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0582673Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0584108Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0585436Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0586800Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0588155Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0589482Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0590818Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0592157Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0593536Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0594864Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0596248Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0597580Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0598917Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0600267Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0601584Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0602982Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0604331Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0605646Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0606979Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0608380Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0609702Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0611083Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0612411Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0613721Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0615055Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0616394Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0617711Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0619058Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0620393Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0621763Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0623099Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0624468Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0625788Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0627122Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0790941Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0792468Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0793807Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0795129Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0796437Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0797863Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0799191Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0800504Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0801895Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0803301Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0804618Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0805944Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0807268Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0808590Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0809919Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0811240Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0812625Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0813963Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0815348Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0816665Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0817989Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0819327Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0820644Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0821969Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0823304Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0824620Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0825996Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0827316Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0828598Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0829915Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0831205Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0832483Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0833767Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0835053Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0836322Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0837604Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0838893Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0840480Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0841769Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0843157Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0844414Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0845694Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0846985Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0848247Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0849532Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0850808Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.0852073Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.0853351Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.0854723Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1024213Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1025738Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1027022Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1028283Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1029568Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1030840Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1032092Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1033376Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1034651Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1035981Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1037254Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1038590Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1040040Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1041303Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1042636Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1043896Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1045162Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1046432Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1047695Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1048963Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1050298Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1051561Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1052839Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1054161Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1055410Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1056669Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1057945Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1059194Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1060451Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1061717Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1062981Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1064303Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1065570Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1066892Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1068159Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1069427Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1070693Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1071951Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1073226Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1074486Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1075751Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1077030Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1078330Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1079610Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1080886Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1082177Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1083502Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:15.1084782Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:15.1086034Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:15.1087308Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:16.1502667Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:16.1504339Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:16.1505603Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:16.1506984Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:16.1508306Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:16.1509580Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:16.1510853Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:16.1519822Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:16.1521108Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:16.1522366Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:16.1523698Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:16.1524958Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:16.1526226Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:16.1527467Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:16.1528827Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:16.1530102Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:16.1531404Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:16.1532663Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:16.1533929Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:16.1535177Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:32:16.1536443Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:16.1537712Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:32:16.1539269Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:32:16.1540547Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:32:16.1541612Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1542576Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1543462Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1544400Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1545291Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1546166Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1547055Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1547935Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1548822Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1549709Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1550586Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1551468Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1552356Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1553236Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1554120Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1554958Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1557298Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1558112Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1558911Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1559781Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1560577Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1561378Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1562178Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1563048Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1563860Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1564650Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1565451Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1566254Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:32:16.1567044Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:32:16.1567841Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:32:16.1568743Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:32:16.1569787Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:32:16.1570779Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:32:16.1571812Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:32:16.1572802Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:32:16.1573782Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:32:16.1574773Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:32:16.1575763Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:32:16.1576744Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:32:16.1577731Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:32:20.3388233Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:32:20.3389328Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:32:20.3390334Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T09:32:20.3391327Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T09:32:20.3392308Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T09:32:20.3393524Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T09:32:20.3394530Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T09:32:20.3395521Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T09:32:20.3396583Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T09:32:20.3397566Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T09:32:20.3398549Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T09:32:20.3399527Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T09:32:20.3400524Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T09:32:20.3401528Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T09:32:20.3402575Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:32:20.3403570Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:32:20.3404545Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:32:20.3405539Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:32:20.3406593Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:32:20.3407577Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:32:20.3408577Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:32:20.3409627Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:32:20.3410620Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:32:20.3411607Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:32:20.3412598Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:32:20.3413608Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:32:20.3414598Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T09:32:20.3415575Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T09:32:20.3416569Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T09:32:20.3417562Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T09:32:20.3418554Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T09:32:20.3419550Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T09:32:20.3420597Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T09:32:20.3421608Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T09:32:20.3422598Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T09:32:20.3423635Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T09:32:20.3424636Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T09:32:20.3425625Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T09:32:20.3426619Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:32:20.3427602Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:32:20.3428596Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:32:20.3429603Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:32:20.3430585Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:32:20.3431575Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:32:20.3432575Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:32:20.3433566Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:32:20.3434647Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:32:20.3435633Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:32:20.3436665Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:32:20.3437652Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:32:20.3438667Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:32:20.3439851Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:32:20.3440895Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:32:20.3441930Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:32:20.3442996Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:32:20.3444030Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:32:20.3445063Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:32:20.3446087Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:32:20.3447132Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:32:20.3448232Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:32:20.3449265Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:32:20.3450309Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:32:20.3451491Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T09:32:20.3452528Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T09:32:20.3453573Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T09:32:20.3454619Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T09:32:25.5028751Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T09:32:25.5030388Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T09:32:25.5031435Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T09:32:25.5032466Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T09:32:25.5033495Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T09:32:25.5034515Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T09:32:25.5035693Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T09:32:25.5036730Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T09:32:25.5037834Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:32:25.5038847Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:32:25.5040071Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:32:25.5041112Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:32:25.5042139Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:32:25.5043252Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:32:25.5044275Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:32:25.5045306Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:32:25.5046333Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:32:25.5047351Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:32:25.5048386Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:32:25.5049416Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:32:25.5050650Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T09:32:25.5051699Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T09:32:25.5052723Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T09:32:25.5053831Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T09:32:25.5054857Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T09:32:25.5055888Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T09:32:25.5056933Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T09:32:25.5057961Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T09:32:25.5059004Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T09:32:25.5060034Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T09:32:25.5061076Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T09:32:25.5062121Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T09:32:25.5063205Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:32:25.5064239Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:32:25.5065271Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:32:25.5066348Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:32:25.5067381Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:32:25.5068396Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:32:25.5069425Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:32:25.5070457Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:32:25.5071480Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:32:25.5072502Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:32:25.5073529Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:32:25.5074569Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:32:25.5075472Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:32:25.5076252Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:32:25.5077091Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:32:25.5077874Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:32:25.5078651Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:32:25.5079434Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:32:25.5080256Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:32:25.5081041Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:32:25.5081821Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:32:25.5082642Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:32:25.5083426Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:32:25.5084205Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:32:25.5084998Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T09:32:25.5085778Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T09:32:25.5086575Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T09:32:25.5087373Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T09:32:25.5088159Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T09:32:25.5088947Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T09:32:25.5089789Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T09:32:25.5090587Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T09:32:25.5091373Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T09:32:25.5092200Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T09:32:25.5092994Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T09:32:25.5093783Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T09:32:25.5094579Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:32:25.5095359Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:32:27.8540285Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:32:27.8541424Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:32:27.8542209Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:32:27.8542989Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:32:27.8543767Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:32:27.8544564Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:32:27.8545344Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:32:27.8546113Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:32:27.8546896Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:32:27.8547802Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:32:27.8548585Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T09:32:27.8549359Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T09:32:27.8550217Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T09:32:27.8551011Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T09:32:27.8551791Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T09:32:27.8552571Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T09:32:27.8553346Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T09:32:27.8554138Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T09:32:27.8554918Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T09:32:27.8555697Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T09:32:27.8556487Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T09:32:27.8557274Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T09:32:27.8558058Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:32:27.8558832Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:32:27.8559721Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:32:27.8560523Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:32:27.8561302Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:32:27.8562148Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:32:27.8563022Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:32:27.8563810Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:32:27.8564605Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:32:27.8565385Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:32:27.8566185Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:32:27.8566982Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:32:27.8567670Z test/test_ops.py::test_swizzle_mm [33mSKIPPED[0m (ROCm not available)
2026-01-14T09:32:27.8568359Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8569095Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8569849Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8570599Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8571347Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8572090Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8572883Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8573627Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8574359Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8575106Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8575897Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8576631Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8577372Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8578104Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8578862Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8579632Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8580388Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8581146Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8581891Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8582649Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8583409Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8584173Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8584942Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8585757Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8586501Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8587223Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8587999Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8588739Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8589478Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8590218Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8590943Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8591672Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8592412Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8593146Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8593889Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8594617Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8595362Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8596107Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8596854Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8597614Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8598423Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8599179Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8599929Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8600691Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8601503Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8602271Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8603091Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8603849Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8604602Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8605337Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8606066Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8606826Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8935822Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8937657Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8939596Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8940816Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8941586Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8942456Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8943199Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8943962Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8944773Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8945532Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8946295Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8947050Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8947826Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8948591Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8949356Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8950119Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8950883Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8951662Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8952436Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8953210Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8953965Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8954729Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8955563Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8956317Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8957082Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8957835Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8958656Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8959414Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8960162Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8960932Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8961692Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8962527Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8963281Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8964032Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8964801Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8965585Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8966370Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8967150Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8967919Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8968743Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8969523Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8970347Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8971122Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8971922Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8972671Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8973401Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8974136Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8974868Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8975614Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8976361Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8977086Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8977816Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8978542Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8979284Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8980030Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8980760Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8981546Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8982272Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8983015Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8983761Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8984583Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8985334Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8986078Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8986822Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8987579Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8988342Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8989099Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8989853Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8990591Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8991301Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8992030Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8992760Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8993485Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8994273Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8994991Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8995707Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8996477Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8997213Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8997955Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.8998682Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.8999430Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9000159Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9000925Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9001680Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9002430Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9003255Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9004005Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9004759Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9005516Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9297067Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9307734Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9308693Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9309435Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9310156Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9310974Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9311702Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9312433Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9313171Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9313881Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9314615Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9315339Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9316075Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9316810Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9317538Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9318274Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9318999Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9319736Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9320555Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9321297Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9322045Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9322925Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9323681Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9324429Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9325190Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9325951Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9326697Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9327442Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9328169Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9328911Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9329656Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9330399Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9331142Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9331872Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9332609Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9333349Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9334170Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9334918Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9335654Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9336443Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9337179Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9337938Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9338706Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9339818Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9340596Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9341347Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9342107Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9342872Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9343638Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9344406Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:32:27.9345164Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:32:27.9346049Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9347104Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9348079Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9349123Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9350091Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9351066Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9352045Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9353018Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9353999Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9354958Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9355938Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9356922Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9357895Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9358877Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9359869Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9360938Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9361921Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9362950Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9363943Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9365009Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9366000Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9366996Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9367983Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9368983Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9369972Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9370945Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9371932Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9372912Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9373891Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9374928Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9609387Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9610731Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9611865Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9612834Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9613837Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9614826Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9615815Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9616816Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9617809Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9618833Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9619839Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9620820Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9621829Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9622831Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9623907Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9624901Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9625898Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9626969Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9627966Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9628971Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9629964Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9630966Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9631955Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9632929Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9633923Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9634904Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9635892Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9636867Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9637954Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9638947Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9640198Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9641263Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9642261Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9643328Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9644324Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9645315Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9646324Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9647329Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9648333Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9649334Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9650341Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9651355Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9652409Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9653386Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9654386Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9655428Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9656423Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9657403Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9658409Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9659407Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9660389Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9661368Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9662347Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9663335Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9664324Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9665309Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9666395Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9667397Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9668440Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9669435Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9670432Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9671442Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9672440Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9673429Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9674431Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9675432Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9676435Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9677409Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9678386Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9679390Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9921775Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9924167Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9926138Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9928086Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9930162Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9931387Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9932360Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9933362Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9934365Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9935336Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9936336Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9937320Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9938310Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9939461Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9940516Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9941528Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9942518Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9943562Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9944569Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9945556Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9946543Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9947509Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9948492Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9949482Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9950458Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9951429Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9952402Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9953395Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9954369Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9955405Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9956388Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9957370Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9958419Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9959401Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9960384Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9961382Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9962373Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9963404Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9964404Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9965400Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9966382Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9967362Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9968346Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9969409Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9970412Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9971513Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9972503Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9973486Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9974479Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9975453Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9976437Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9977421Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9978419Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9979392Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9980395Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9981433Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9982439Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9983479Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9984472Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9985491Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9986563Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9987561Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9988563Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9989565Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9990581Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9991566Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9992578Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9993597Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:27.9994587Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:27.9995570Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0217721Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0219236Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0220234Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0222684Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0223654Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0224641Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0225597Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0226549Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0227523Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0228497Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0229484Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0230459Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0231435Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0232424Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0233400Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0234383Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0235439Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0236436Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0237422Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0238451Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0239629Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0240627Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0241600Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0242630Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0243598Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0244581Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0245551Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0246500Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0247480Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0248527Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0249498Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0250467Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0251491Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0252476Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0253447Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0254425Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0255414Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0256411Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0257396Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0258361Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0259346Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0260337Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0261301Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0262281Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0263321Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:32:28.0264312Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:32:28.0265359Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0266486Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0267559Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0268632Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0269695Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0270763Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0271820Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0272896Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0273965Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0275029Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0276115Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0277245Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0278348Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0279493Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0280585Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0281687Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0282858Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0283955Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0285048Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0286129Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0287223Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0491413Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0493953Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0496330Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0498521Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0500606Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0501818Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0502910Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0503991Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0505091Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0506189Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0507291Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0508415Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0509509Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0510606Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0511703Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0512863Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0513974Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0515130Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0516239Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0517334Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0518429Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0519535Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0520622Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0521722Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0522902Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0523990Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0525084Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0526179Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0527346Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0528448Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0529539Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0530671Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0531767Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0532855Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0533961Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0535064Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0536154Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0537263Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0538357Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0539650Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0540841Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0541937Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0543094Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0544195Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0545302Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0546423Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0547530Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0548642Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0549762Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0550879Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0552007Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0553119Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0554226Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0555412Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0556497Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0557604Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0558756Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0559848Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0560946Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0562048Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0563224Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0756328Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0757489Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0758595Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0759695Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0760897Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0762018Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0763313Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0764687Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0766017Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0767330Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0768658Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0769987Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0771315Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0772642Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0773968Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0775296Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0776632Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0778017Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0779363Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0780716Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0782122Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0783470Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0784805Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0786152Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0787489Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0788819Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0790174Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0791526Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0792870Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0794213Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0795604Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0796957Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0798352Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0799695Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0801047Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0802399Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0803600Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0811901Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0813026Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0814127Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0815231Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0816344Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0817540Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0818663Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0819772Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0820930Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0822043Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0823148Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0824272Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0825389Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0826504Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0827628Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0828738Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0829853Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0830972Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0832132Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0833244Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0834408Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T09:32:28.0835531Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T09:32:28.0836639Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1029009Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1030953Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1032039Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1033118Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1034188Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1035250Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1036323Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1037485Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1038555Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1039869Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1041011Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1042076Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1043193Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1044273Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1045363Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1046442Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1047532Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1048612Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1049700Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1050782Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1051941Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1053027Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1054187Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1055271Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1056358Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1057434Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1058533Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1059620Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1060709Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1061806Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1062895Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1063986Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1065073Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1066226Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1067317Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1068395Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1069519Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1070604Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1071690Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1072811Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1073904Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1075010Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1076117Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1077225Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1078318Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1079481Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1080586Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1081728Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1082888Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1083972Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1085070Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1086162Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1087252Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1088348Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1089442Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1090544Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1091640Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1092737Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1093897Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1094991Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1096094Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1297851Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1298982Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1300074Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1301230Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1302326Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1303428Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1304529Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1305618Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1306719Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1307931Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1309035Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1310193Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1311281Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1312384Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1313463Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1314552Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1315652Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1316747Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1317847Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1318944Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1320029Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1321123Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1322281Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1323447Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1324539Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1325679Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1326767Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1327854Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1328952Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1330044Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1331128Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1332219Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1333311Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1334403Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1335491Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1336628Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1337722Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1338851Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1340087Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1341183Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1342272Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1343373Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1344473Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1345571Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1346676Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1347776Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1348880Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1349983Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1351156Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1352267Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1353373Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1354543Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1355652Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1356761Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1357876Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1358990Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1360099Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1361213Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1362335Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1363489Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1364663Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1539713Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1541299Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1542643Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1543983Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1545315Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1546658Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1548001Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1549338Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1550678Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1552003Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1553342Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1554760Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1555870Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1556982Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1558157Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1559268Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1560387Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1561505Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1562697Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1563811Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1564920Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1566031Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1567135Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1568246Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1569545Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype0-Xq_Wq_dtypes0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1570916Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype1-Xq_Wq_dtypes1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1572267Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype2-Xq_Wq_dtypes2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1573577Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype3-Xq_Wq_dtypes3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1574874Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype4-Xq_Wq_dtypes4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1576173Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype5-Xq_Wq_dtypes5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1577487Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype6-Xq_Wq_dtypes6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1578806Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype7-Xq_Wq_dtypes7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1580130Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype8-Xq_Wq_dtypes8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1581455Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype9-Xq_Wq_dtypes9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1582779Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype10-Xq_Wq_dtypes10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1584179Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype11-Xq_Wq_dtypes11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1585522Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype12-Xq_Wq_dtypes12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1586936Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype13-Xq_Wq_dtypes13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1588289Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype14-Xq_Wq_dtypes14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1589642Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype15-Xq_Wq_dtypes15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1591042Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype16-Xq_Wq_dtypes16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1592392Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype17-Xq_Wq_dtypes17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1593736Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype18-Xq_Wq_dtypes18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1595092Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype19-Xq_Wq_dtypes19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1596436Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype20-Xq_Wq_dtypes20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1597827Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype21-Xq_Wq_dtypes21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1599178Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype22-Xq_Wq_dtypes22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1600569Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype23-Xq_Wq_dtypes23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1601912Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype24-Xq_Wq_dtypes24-1-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1603329Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype25-Xq_Wq_dtypes25-1-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1604667Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype26-Xq_Wq_dtypes26-1-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1606004Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype27-Xq_Wq_dtypes27-1-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1607346Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype28-Xq_Wq_dtypes28-1-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1608702Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype29-Xq_Wq_dtypes29-1-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1766267Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype30-Xq_Wq_dtypes30-1-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1768999Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype31-Xq_Wq_dtypes31-1-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1771222Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype32-Xq_Wq_dtypes32-1-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1772556Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype33-Xq_Wq_dtypes33-1-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1773919Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype34-Xq_Wq_dtypes34-1-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1775330Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype35-Xq_Wq_dtypes35-1-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1776655Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype36-Xq_Wq_dtypes36-4-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1778020Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype37-Xq_Wq_dtypes37-4-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1779366Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype38-Xq_Wq_dtypes38-4-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1780712Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype39-Xq_Wq_dtypes39-4-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1782063Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype40-Xq_Wq_dtypes40-4-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1783394Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype41-Xq_Wq_dtypes41-4-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1784731Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype42-Xq_Wq_dtypes42-4-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1786244Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype43-Xq_Wq_dtypes43-4-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1787594Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype44-Xq_Wq_dtypes44-4-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1788986Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype45-Xq_Wq_dtypes45-4-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1790321Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype46-Xq_Wq_dtypes46-4-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1791663Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype47-Xq_Wq_dtypes47-4-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1793019Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype48-Xq_Wq_dtypes48-1-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1794360Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype49-Xq_Wq_dtypes49-1-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1795700Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype50-Xq_Wq_dtypes50-1-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1797060Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype51-Xq_Wq_dtypes51-1-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1798395Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype52-Xq_Wq_dtypes52-1-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1799743Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype53-Xq_Wq_dtypes53-1-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1801188Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype54-Xq_Wq_dtypes54-1-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1802592Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype55-Xq_Wq_dtypes55-1-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1803987Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype56-Xq_Wq_dtypes56-1-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1805324Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype57-Xq_Wq_dtypes57-1-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1806663Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype58-Xq_Wq_dtypes58-1-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1808031Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype59-Xq_Wq_dtypes59-1-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1809379Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype60-Xq_Wq_dtypes60-4-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1810741Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype61-Xq_Wq_dtypes61-4-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1812132Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype62-Xq_Wq_dtypes62-4-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1813470Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype63-Xq_Wq_dtypes63-4-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1814865Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype64-Xq_Wq_dtypes64-4-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1816217Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype65-Xq_Wq_dtypes65-4-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1817596Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype66-Xq_Wq_dtypes66-4-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1818938Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype67-Xq_Wq_dtypes67-4-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1820298Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype68-Xq_Wq_dtypes68-4-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1821688Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype69-Xq_Wq_dtypes69-4-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1823029Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype70-Xq_Wq_dtypes70-4-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1824396Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype71-Xq_Wq_dtypes71-4-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1825747Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype72-Xq_Wq_dtypes72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1827102Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype73-Xq_Wq_dtypes73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1828447Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype74-Xq_Wq_dtypes74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1829827Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype75-Xq_Wq_dtypes75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1831180Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype76-Xq_Wq_dtypes76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1832513Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype77-Xq_Wq_dtypes77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1833907Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype78-Xq_Wq_dtypes78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1835255Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype79-Xq_Wq_dtypes79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1989068Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype80-Xq_Wq_dtypes80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1990444Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype81-Xq_Wq_dtypes81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1991800Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype82-Xq_Wq_dtypes82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1993142Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype83-Xq_Wq_dtypes83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1994482Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype84-Xq_Wq_dtypes84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1995823Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype85-Xq_Wq_dtypes85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T09:32:28.1997247Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype86-Xq_Wq_dtypes86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T09:32:28.1998597Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype87-Xq_Wq_dtypes87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2000005Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype88-Xq_Wq_dtypes88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2001350Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype89-Xq_Wq_dtypes89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2002749Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype90-Xq_Wq_dtypes90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2004087Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype91-Xq_Wq_dtypes91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2005419Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype92-Xq_Wq_dtypes92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2006775Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype93-Xq_Wq_dtypes93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2008122Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype94-Xq_Wq_dtypes94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2009457Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype95-Xq_Wq_dtypes95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2010808Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype96-Xq_Wq_dtypes96-1-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2012241Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype97-Xq_Wq_dtypes97-1-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2013573Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype98-Xq_Wq_dtypes98-1-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2014975Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype99-Xq_Wq_dtypes99-1-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2016317Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype100-Xq_Wq_dtypes100-1-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2017700Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype101-Xq_Wq_dtypes101-1-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2019086Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype102-Xq_Wq_dtypes102-1-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2020447Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype103-Xq_Wq_dtypes103-1-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2021836Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype104-Xq_Wq_dtypes104-1-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2023219Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype105-Xq_Wq_dtypes105-1-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2024592Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype106-Xq_Wq_dtypes106-1-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2026027Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype107-Xq_Wq_dtypes107-1-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2027404Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype108-Xq_Wq_dtypes108-4-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2028817Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype109-Xq_Wq_dtypes109-4-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2030195Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype110-Xq_Wq_dtypes110-4-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2031562Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype111-Xq_Wq_dtypes111-4-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2032931Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype112-Xq_Wq_dtypes112-4-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2034310Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype113-Xq_Wq_dtypes113-4-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2035673Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype114-Xq_Wq_dtypes114-4-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2037042Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype115-Xq_Wq_dtypes115-4-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2038411Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype116-Xq_Wq_dtypes116-4-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2039994Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype117-Xq_Wq_dtypes117-4-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2041430Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype118-Xq_Wq_dtypes118-4-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2042848Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype119-Xq_Wq_dtypes119-4-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2044203Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype120-Xq_Wq_dtypes120-1-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2045632Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype121-Xq_Wq_dtypes121-1-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2046986Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype122-Xq_Wq_dtypes122-1-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2048339Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype123-Xq_Wq_dtypes123-1-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2049692Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype124-Xq_Wq_dtypes124-1-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2051041Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype125-Xq_Wq_dtypes125-1-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2052406Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype126-Xq_Wq_dtypes126-1-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2053765Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype127-Xq_Wq_dtypes127-1-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2055175Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype128-Xq_Wq_dtypes128-1-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2056539Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype129-Xq_Wq_dtypes129-1-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2209387Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype130-Xq_Wq_dtypes130-1-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2210944Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype131-Xq_Wq_dtypes131-1-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2212309Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype132-Xq_Wq_dtypes132-4-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2213679Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype133-Xq_Wq_dtypes133-4-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2215046Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype134-Xq_Wq_dtypes134-4-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2216412Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype135-Xq_Wq_dtypes135-4-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2217779Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype136-Xq_Wq_dtypes136-4-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2219152Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype137-Xq_Wq_dtypes137-4-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2220524Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype138-Xq_Wq_dtypes138-4-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2222003Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype139-Xq_Wq_dtypes139-4-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2223376Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype140-Xq_Wq_dtypes140-4-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2224749Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype141-Xq_Wq_dtypes141-4-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2226184Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype142-Xq_Wq_dtypes142-4-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2227546Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype143-Xq_Wq_dtypes143-4-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2228923Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype144-Xq_Wq_dtypes144-1-size_mnk144-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2230291Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype145-Xq_Wq_dtypes145-1-size_mnk145-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2231649Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype146-Xq_Wq_dtypes146-1-size_mnk146-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2233026Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype147-Xq_Wq_dtypes147-1-size_mnk147-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2234386Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype148-Xq_Wq_dtypes148-1-size_mnk148-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2235747Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype149-Xq_Wq_dtypes149-1-size_mnk149-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2237177Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype150-Xq_Wq_dtypes150-1-size_mnk150-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2238593Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype151-Xq_Wq_dtypes151-1-size_mnk151-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2240136Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype152-Xq_Wq_dtypes152-1-size_mnk152-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2241500Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype153-Xq_Wq_dtypes153-1-size_mnk153-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2242912Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype154-Xq_Wq_dtypes154-1-size_mnk154-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2244281Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype155-Xq_Wq_dtypes155-1-size_mnk155-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2245658Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype156-Xq_Wq_dtypes156-4-size_mnk156-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2247017Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype157-Xq_Wq_dtypes157-4-size_mnk157-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2248396Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype158-Xq_Wq_dtypes158-4-size_mnk158-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2249762Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype159-Xq_Wq_dtypes159-4-size_mnk159-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2251197Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype160-Xq_Wq_dtypes160-4-size_mnk160-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2252562Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype161-Xq_Wq_dtypes161-4-size_mnk161-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2253919Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype162-Xq_Wq_dtypes162-4-size_mnk162-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2255335Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype163-Xq_Wq_dtypes163-4-size_mnk163-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2256708Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype164-Xq_Wq_dtypes164-4-size_mnk164-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2258076Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype165-Xq_Wq_dtypes165-4-size_mnk165-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2259440Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype166-Xq_Wq_dtypes166-4-size_mnk166-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2260804Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype167-Xq_Wq_dtypes167-4-size_mnk167-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2262158Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype168-Xq_Wq_dtypes168-1-size_mnk168-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2263515Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype169-Xq_Wq_dtypes169-1-size_mnk169-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2264874Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype170-Xq_Wq_dtypes170-1-size_mnk170-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2266294Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype171-Xq_Wq_dtypes171-1-size_mnk171-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2267657Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype172-Xq_Wq_dtypes172-1-size_mnk172-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2269115Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype173-Xq_Wq_dtypes173-1-size_mnk173-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2270483Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype174-Xq_Wq_dtypes174-1-size_mnk174-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2271900Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype175-Xq_Wq_dtypes175-1-size_mnk175-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2273260Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype176-Xq_Wq_dtypes176-1-size_mnk176-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2274623Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype177-Xq_Wq_dtypes177-1-size_mnk177-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2275993Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype178-Xq_Wq_dtypes178-1-size_mnk178-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2536368Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype179-Xq_Wq_dtypes179-1-size_mnk179-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2537875Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype180-Xq_Wq_dtypes180-4-size_mnk180-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2539395Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype181-Xq_Wq_dtypes181-4-size_mnk181-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2540866Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype182-Xq_Wq_dtypes182-4-size_mnk182-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2542222Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype183-Xq_Wq_dtypes183-4-size_mnk183-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2543640Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype184-Xq_Wq_dtypes184-4-size_mnk184-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2545001Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype185-Xq_Wq_dtypes185-4-size_mnk185-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2546354Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype186-Xq_Wq_dtypes186-4-size_mnk186-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2548032Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype187-Xq_Wq_dtypes187-4-size_mnk187-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2549714Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype188-Xq_Wq_dtypes188-4-size_mnk188-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2559490Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype189-Xq_Wq_dtypes189-4-size_mnk189-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2560925Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype190-Xq_Wq_dtypes190-4-size_mnk190-False] [33mSKIPPED[0m
2026-01-14T09:32:28.2562275Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype191-Xq_Wq_dtypes191-4-size_mnk191-True] [33mSKIPPED[0m
2026-01-14T09:32:28.2563465Z test/test_utils.py::TestTorchVersion::test_torch_version_at_least [32mPASSED[0m
2026-01-14T09:32:28.2564157Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls [32mPASSED[0m
2026-01-14T09:32:28.2564900Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_attr [32mPASSED[0m
2026-01-14T09:32:28.2565782Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_data [32mPASSED[0m
2026-01-14T09:32:28.2566620Z test/test_utils.py::TestTorchAOBaseTensor::test_implements_and_torch_function_together [32mPASSED[0m
2026-01-14T09:32:28.2567384Z test/test_utils.py::TestTorchAOBaseTensor::test_print_arg_types [32mPASSED[0m
2026-01-14T09:32:28.2567741Z 
2026-01-14T09:32:28.2568005Z [33m=============================== warnings summary ===============================[0m
2026-01-14T09:32:28.2568578Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1
2026-01-14T09:32:28.2570579Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1: DeprecationWarning: Importing from torchao.dtypes.uintx.dyn_int8_act_int4_wei_cpu_layout is deprecated. Please use 'from torchao.prototype.dtypes import Int8DynamicActInt4WeightCPULayout' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:32:28.2572413Z     from .dyn_int8_act_int4_wei_cpu_layout import (
2026-01-14T09:32:28.2572654Z 
2026-01-14T09:32:28.2572934Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22
2026-01-14T09:32:28.2574763Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22: DeprecationWarning: Importing from torchao.dtypes.uintx.uintx_layout is deprecated. Please use 'from torchao.prototype.dtypes import UintxLayout, UintxTensor' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:32:28.2576404Z     from .uintx_layout import (
2026-01-14T09:32:28.2576582Z 
2026-01-14T09:32:28.2576890Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23
2026-01-14T09:32:28.2578707Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23: DeprecationWarning: Importing BlockSparseLayout from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import BlockSparseLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T09:32:28.2580471Z     from .uintx.block_sparse_layout import BlockSparseLayout
2026-01-14T09:32:28.2580742Z 
2026-01-14T09:32:28.2580994Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24
2026-01-14T09:32:28.2582762Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24: DeprecationWarning: Importing from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import CutlassInt4PackedLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T09:32:28.2584476Z     from .uintx.cutlass_int4_packed_layout import CutlassInt4PackedLayout
2026-01-14T09:32:28.2584802Z 
2026-01-14T09:32:28.2585181Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539: 2 warnings
2026-01-14T09:32:28.2585778Z test/core/test_config.py: 2 warnings
2026-01-14T09:32:28.2586072Z test/dtypes/test_uintx.py: 84 warnings
2026-01-14T09:32:28.2586383Z test/hqq/test_hqq_affine.py: 6 warnings
2026-01-14T09:32:28.2587521Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539: UserWarning: `UIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:32:28.2588644Z     warnings.warn(
2026-01-14T09:32:28.2588783Z 
2026-01-14T09:32:28.2589167Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T09:32:28.2589955Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T09:32:28.2590702Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7]
2026-01-14T09:32:28.2591352Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_print_quantized_module
2026-01-14T09:32:28.2591979Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_weights_only
2026-01-14T09:32:28.2592691Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cuda_bfloat16
2026-01-14T09:32:28.2594181Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209: UserWarning: `Int4DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:32:28.2595395Z     warnings.warn(
2026-01-14T09:32:28.2595526Z 
2026-01-14T09:32:28.2595915Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: 3 warnings
2026-01-14T09:32:28.2596502Z test/core/test_config.py: 2 warnings
2026-01-14T09:32:28.2596830Z test/dtypes/test_affine_quantized.py: 4 warnings
2026-01-14T09:32:28.2597189Z test/integration/test_integration.py: 6 warnings
2026-01-14T09:32:28.2597530Z test/quantization/test_qat.py: 6 warnings
2026-01-14T09:32:28.2597862Z test/quantization/test_quant_api.py: 2 warnings
2026-01-14T09:32:28.2599100Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: UserWarning: `Int8DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:32:28.2600307Z     warnings.warn(
2026-01-14T09:32:28.2600440Z 
2026-01-14T09:32:28.2600871Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T09:32:28.2601655Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T09:32:28.2602335Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14]
2026-01-14T09:32:28.2603705Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272: UserWarning: `GemliteUIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:32:28.2604922Z     warnings.warn(
2026-01-14T09:32:28.2605055Z 
2026-01-14T09:32:28.2605392Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: 1 warning
2026-01-14T09:32:28.2605946Z test/core/test_config.py: 1 warning
2026-01-14T09:32:28.2606253Z test/prototype/test_parq.py: 25 warnings
2026-01-14T09:32:28.2606592Z test/quantization/test_quant_api.py: 2 warnings
2026-01-14T09:32:28.2607808Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: UserWarning: Config Deprecation: _default is deprecated and will no longer be supported in a future release. Please see https://github.com/pytorch/ao/issues/3229 for more details.
2026-01-14T09:32:28.2608981Z     warnings.warn(
2026-01-14T09:32:28.2609128Z 
2026-01-14T09:32:28.2609262Z test/prototype/mx_formats/test_mx_tensor.py:531
2026-01-14T09:32:28.2610675Z   /pytorch/ao/test/prototype/mx_formats/test_mx_tensor.py:531: PytestUnknownMarkWarning: Unknown pytest.mark.skipIf - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
2026-01-14T09:32:28.2612135Z     @pytest.mark.skipIf(not is_sm_at_least_90(), "Need sm90+")
2026-01-14T09:32:28.2612456Z 
2026-01-14T09:32:28.2612847Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360
2026-01-14T09:32:28.2615006Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360: UserWarning: `Float8StaticActivationFloat8WeightConfig` version 1 will be deleted in a future release of torchao. Please migrate to version 2 by setting version=2. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:32:28.2616491Z     warnings.warn(
2026-01-14T09:32:28.2616628Z 
2026-01-14T09:32:28.2616761Z test/dtypes/test_affine_quantized.py: 7 warnings
2026-01-14T09:32:28.2617140Z test/integration/test_integration.py: 52 warnings
2026-01-14T09:32:28.2617512Z test/quantization/test_quant_api.py: 8 warnings
2026-01-14T09:32:28.2618873Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T09:32:28.2620268Z     warnings.warn(
2026-01-14T09:32:28.2620406Z 
2026-01-14T09:32:28.2620539Z test/dtypes/test_affine_quantized.py: 10 warnings
2026-01-14T09:32:28.2620886Z test/hqq/test_hqq_affine.py: 1 warning
2026-01-14T09:32:28.2621220Z test/integration/test_integration.py: 18 warnings
2026-01-14T09:32:28.2621588Z test/quantization/test_quant_api.py: 17 warnings
2026-01-14T09:32:28.2622944Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:827: UserWarning: Config Deprecation: version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T09:32:28.2624327Z     warnings.warn(
2026-01-14T09:32:28.2624467Z 
2026-01-14T09:32:28.2624597Z test/dtypes/test_affine_quantized.py: 9 warnings
2026-01-14T09:32:28.2624935Z test/hqq/test_hqq_affine.py: 1 warning
2026-01-14T09:32:28.2625278Z test/integration/test_integration.py: 96 warnings
2026-01-14T09:32:28.2625704Z test/quantization/test_quant_api.py: 5 warnings
2026-01-14T09:32:28.2627362Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/tensor_core_tiled_layout.py:241: UserWarning: Models quantized with version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please upgrade torchao and quantize again, or download a newer torchao checkpoint, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T09:32:28.2629114Z     warnings.warn(
2026-01-14T09:32:28.2629247Z 
2026-01-14T09:32:28.2629382Z test/dtypes/test_affine_quantized.py: 1 warning
2026-01-14T09:32:28.2629743Z test/integration/test_integration.py: 31 warnings
2026-01-14T09:32:28.2630115Z test/quantization/test_quant_api.py: 108 warnings
2026-01-14T09:32:28.2631746Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/int4_cpu_layout.py:82: UserWarning: Models quantized with version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please upgrade torchao and quantize again, or download a newer torchao checkpoint, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T09:32:28.2633324Z     warnings.warn(
2026-01-14T09:32:28.2633462Z 
2026-01-14T09:32:28.2633655Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16
2026-01-14T09:32:28.2634114Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16
2026-01-14T09:32:28.2634570Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32
2026-01-14T09:32:28.2635941Z   /pytorch/ao/test/dtypes/test_nf4.py:224: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:32:28.2637389Z     torch.testing.assert_allclose(input_tensor, nf4_to_dtype, atol=0.13, rtol=0.13)
2026-01-14T09:32:28.2637752Z 
2026-01-14T09:32:28.2637988Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16
2026-01-14T09:32:28.2638445Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16
2026-01-14T09:32:28.2638894Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32
2026-01-14T09:32:28.2640627Z   /pytorch/ao/test/dtypes/test_nf4.py:230: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:32:28.2641923Z     torch.testing.assert_allclose(
2026-01-14T09:32:28.2642115Z 
2026-01-14T09:32:28.2642223Z test/float8/test_base.py: 36 warnings
2026-01-14T09:32:28.2643507Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/float8/float8_linear.py:261: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:852.)
2026-01-14T09:32:28.2644763Z     autocast_dtype = torch.get_autocast_gpu_dtype()
2026-01-14T09:32:28.2645002Z 
2026-01-14T09:32:28.2645205Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_0_cuda
2026-01-14T09:32:28.2645702Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_1_cuda
2026-01-14T09:32:28.2647170Z   /pytorch/ao/test/kernel/test_autotuner.py:50: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:32:28.2648521Z     torch.testing.assert_allclose(out32_1, out32_2)
2026-01-14T09:32:28.2648770Z 
2026-01-14T09:32:28.2648990Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_0_cuda
2026-01-14T09:32:28.2649546Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu
2026-01-14T09:32:28.2650196Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_2_cuda
2026-01-14T09:32:28.2650736Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu
2026-01-14T09:32:28.2652164Z   /pytorch/ao/test/kernel/test_autotuner.py:96: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:32:28.2653574Z     torch.testing.assert_allclose(out32_1, out32_2)
2026-01-14T09:32:28.2653819Z 
2026-01-14T09:32:28.2654136Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook
2026-01-14T09:32:28.2655487Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py:903: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1517.)
2026-01-14T09:32:28.2656634Z     return callable(*args, **kwargs)
2026-01-14T09:32:28.2656835Z 
2026-01-14T09:32:28.2657071Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace
2026-01-14T09:32:28.2658754Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/sparsifier/utils.py:134: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
2026-01-14T09:32:28.2660299Z     assert self.mask.shape == x.shape
2026-01-14T09:32:28.2660496Z 
2026-01-14T09:32:28.2660716Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler
2026-01-14T09:32:28.2661244Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step
2026-01-14T09:32:28.2663582Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/scheduler/base_scheduler.py:133: UserWarning: Detected call of `scheduler.step()` before `sparsifier.step()`. You have to make sure you run the sparsifier.step() BEFORE any calls to the scheduler.step().
2026-01-14T09:32:28.2664814Z     warnings.warn(
2026-01-14T09:32:28.2665012Z 
2026-01-14T09:32:28.2665345Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_complex_conv2d
2026-01-14T09:32:28.2666551Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/pruner/prune_functions.py:347: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
2026-01-14T09:32:28.2667903Z   Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)
2026-01-14T09:32:28.2668607Z     flattened_pruned_biases = torch.tensor(
2026-01-14T09:32:28.2668823Z 
2026-01-14T09:32:28.2669088Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu
2026-01-14T09:32:28.2670509Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:42: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T09:32:28.2671848Z     m, guards = torchdynamo.export(  # noqa: F841©
2026-01-14T09:32:28.2672089Z 
2026-01-14T09:32:28.2672336Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu
2026-01-14T09:32:28.2673716Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:86: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T09:32:28.2674980Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T09:32:28.2675218Z 
2026-01-14T09:32:28.2675589Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict
2026-01-14T09:32:28.2677059Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:118: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T09:32:28.2678378Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T09:32:28.2678617Z 
2026-01-14T09:32:28.2678787Z test/quantization/pt2e/test_quantize_pt2e.py: 18 warnings
2026-01-14T09:32:28.2679236Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 88 warnings
2026-01-14T09:32:28.2679686Z test/quantization/pt2e/test_representation.py: 8 warnings
2026-01-14T09:32:28.2680468Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/testing/pt2e/_xnnpack_quantizer.py:289: UserWarning: XNNPACKQuantizer is deprecated!
2026-01-14T09:32:28.2681256Z     warnings.warn(f"{self.__class__.__name__} is deprecated!")
2026-01-14T09:32:28.2681543Z 
2026-01-14T09:32:28.2681891Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_conv_linear_quantization
2026-01-14T09:32:28.2682689Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_quantizer
2026-01-14T09:32:28.2683703Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/testing/pt2e/utils.py:108: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T09:32:28.2684532Z   For migrations of users: 
2026-01-14T09:32:28.2685289Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T09:32:28.2686775Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T09:32:28.2688125Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T09:32:28.2688822Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T09:32:28.2689241Z     m_fx = prepare_fx(
2026-01-14T09:32:28.2689388Z 
2026-01-14T09:32:28.2689666Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported
2026-01-14T09:32:28.2691064Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:923: UserWarning: Was not able to add assertion to guarantee correct input x to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.
2026-01-14T09:32:28.2692257Z     warnings.warn(
2026-01-14T09:32:28.2692393Z 
2026-01-14T09:32:28.2692642Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T09:32:28.2693367Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node
2026-01-14T09:32:28.2694196Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node
2026-01-14T09:32:28.2695316Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/utils.py:145: UserWarning: must run observer before calling calculate_qparams. Returning default values.
2026-01-14T09:32:28.2696167Z     warnings.warn(
2026-01-14T09:32:28.2696304Z 
2026-01-14T09:32:28.2696555Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T09:32:28.2697710Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:1360: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point 
2026-01-14T09:32:28.2698688Z     warnings.warn(
2026-01-14T09:32:28.2698821Z 
2026-01-14T09:32:28.2699216Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T09:32:28.2700175Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T09:32:28.2701154Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype
2026-01-14T09:32:28.2702065Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T09:32:28.2703014Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T09:32:28.2703940Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype
2026-01-14T09:32:28.2704794Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec
2026-01-14T09:32:28.2706139Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:263: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
2026-01-14T09:32:28.2707232Z     warnings.warn(
2026-01-14T09:32:28.2707370Z 
2026-01-14T09:32:28.2707558Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 48 warnings
2026-01-14T09:32:28.2708377Z   /pytorch/ao/test/quantization/pt2e/test_quantize_pt2e_qat.py:169: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T09:32:28.2709128Z   For migrations of users: 
2026-01-14T09:32:28.2709882Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T09:32:28.2711416Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T09:32:28.2712749Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T09:32:28.2713441Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T09:32:28.2713868Z     model_fx = prepare_qat_fx(
2026-01-14T09:32:28.2714044Z 
2026-01-14T09:32:28.2714230Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 48 warnings
2026-01-14T09:32:28.2715159Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/ao/quantization/fx/prepare.py:464: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T09:32:28.2716007Z   For migrations of users: 
2026-01-14T09:32:28.2716764Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T09:32:28.2718250Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T09:32:28.2719530Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T09:32:28.2720219Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T09:32:28.2720751Z     convert(root, mapping=module_to_qat_module, inplace=True, remove_qconfig=False)
2026-01-14T09:32:28.2721110Z 
2026-01-14T09:32:28.2721405Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_3
2026-01-14T09:32:28.2722189Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe
2026-01-14T09:32:28.2727015Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:1325: UserWarning: The input of maxpool2d is not quantized, skip annotate maxpool2d with config QuantizationConfig(input_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), output_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), weight=QuantizationSpec(dtype=torch.int8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.PerChannelMinMaxObserver'>, eps=0.000244140625){}, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, ch_axis=0, is_dynamic=False), bias=None, is_qat=False).
2026-01-14T09:32:28.2731687Z     warnings.warn(
2026-01-14T09:32:28.2731820Z 
2026-01-14T09:32:28.2732172Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block
2026-01-14T09:32:28.2732965Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block
2026-01-14T09:32:28.2733833Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qconv2d_maxpool2d_linear_dynamic_cpu
2026-01-14T09:32:28.2735404Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/_inductor/mkldnn_lowerings.py:731: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
2026-01-14T09:32:28.2736750Z     torch.tensor(w_zp_tensor, dtype=torch.int32), name=w_zp.get_name()
2026-01-14T09:32:28.2737057Z 
2026-01-14T09:32:28.2737557Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T09:33:02.0351063Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:484: UserWarning: Mixed dynamic and static quantization config is not supported.
2026-01-14T09:33:02.0352763Z     warnings.warn(
2026-01-14T09:33:02.0352988Z 
2026-01-14T09:33:02.0353749Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T09:33:02.0355710Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:383: UserWarning: Skip the quantization config for <class 'torch.nn.modules.linear.Linear'>.
2026-01-14T09:33:02.0356975Z     warnings.warn(
2026-01-14T09:33:02.0357167Z 
2026-01-14T09:33:02.0357466Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T09:33:02.0358818Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'IntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T09:33:02.0359901Z   
2026-01-14T09:33:02.0360234Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T09:33:02.0360738Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T09:33:02.0361107Z       # train (not shown)
2026-01-14T09:33:02.0361423Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T09:33:02.0361777Z   
2026-01-14T09:33:02.0362085Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T09:33:02.0362477Z   
2026-01-14T09:33:02.0362949Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T09:33:02.0363569Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T09:33:02.0363981Z       qat_config = QATConfig(
2026-01-14T09:33:02.0364268Z           activation_config=activation_config,
2026-01-14T09:33:02.0364590Z           weight_config=weight_config,
2026-01-14T09:33:02.0364874Z           step="prepare",
2026-01-14T09:33:02.0365114Z       )
2026-01-14T09:33:02.0365435Z       quantize_(model, qat_config)
2026-01-14T09:33:02.0365709Z   
2026-01-14T09:33:02.0366028Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T09:33:02.0366442Z           
2026-01-14T09:33:02.0366646Z     warnings.warn(
2026-01-14T09:33:02.0366784Z 
2026-01-14T09:33:02.0367001Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T09:33:02.0368328Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'FromIntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T09:33:02.0369407Z   
2026-01-14T09:33:02.0369733Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T09:33:02.0370235Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T09:33:02.0370603Z       # train (not shown)
2026-01-14T09:33:02.0370933Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T09:33:02.0371271Z   
2026-01-14T09:33:02.0371582Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T09:33:02.0371968Z   
2026-01-14T09:33:02.0372367Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T09:33:02.0372981Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T09:33:02.0373398Z       qat_config = QATConfig(
2026-01-14T09:33:02.0373696Z           activation_config=activation_config,
2026-01-14T09:33:02.0374012Z           weight_config=weight_config,
2026-01-14T09:33:02.0374307Z           step="prepare",
2026-01-14T09:33:02.0374533Z       )
2026-01-14T09:33:02.0374735Z       quantize_(model, qat_config)
2026-01-14T09:33:02.0374988Z   
2026-01-14T09:33:02.0375298Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T09:33:02.0375693Z           
2026-01-14T09:33:02.0375894Z     warnings.warn(
2026-01-14T09:33:02.0376082Z 
2026-01-14T09:33:02.0376412Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T09:33:02.0378206Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/blocksparse.py:198: UserWarning: Sparse BSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)
2026-01-14T09:33:02.0379842Z     bsr_tensor = dense_tensor.to_sparse_bsr(blocksize)
2026-01-14T09:33:02.0380092Z 
2026-01-14T09:33:02.0380438Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T09:33:02.0382052Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=2048 K=1024 N=1 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:33:02.0383382Z     warn_once(
2026-01-14T09:33:02.0383507Z 
2026-01-14T09:33:02.0383826Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T09:33:02.0385394Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=1024 K=2048 N=1 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:33:02.0386716Z     warn_once(
2026-01-14T09:33:02.0386840Z 
2026-01-14T09:33:02.0387173Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024
2026-01-14T09:33:02.0388824Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=2048 K=1024 N=1024 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:33:02.0390168Z     warn_once(
2026-01-14T09:33:02.0390295Z 
2026-01-14T09:33:02.0390657Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024
2026-01-14T09:33:02.0392321Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=1024 K=2048 N=1024 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:33:02.0393660Z     warn_once(
2026-01-14T09:33:02.0393783Z 
2026-01-14T09:33:02.0394068Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False
2026-01-14T09:33:02.0395611Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=256 K=128 N=256 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.int8 out_dtype=torch.bfloat16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:33:02.0396929Z     warn_once(
2026-01-14T09:33:02.0397058Z 
2026-01-14T09:33:02.0397341Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False
2026-01-14T09:33:02.0398873Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=128 K=256 N=256 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.int8 out_dtype=torch.bfloat16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:33:02.0400177Z     warn_once(
2026-01-14T09:33:02.0400305Z 
2026-01-14T09:33:02.0400537Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4
2026-01-14T09:33:02.0401584Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/wanda.py:46: UserWarning: WandaSparsifier got semi_structured_bock_size=4, sparsity_level fixed to 50% (2:4) sparsity
2026-01-14T09:33:02.0402438Z     warnings.warn(
2026-01-14T09:33:02.0402688Z 
2026-01-14T09:33:02.0402923Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4
2026-01-14T09:33:02.0403525Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_unstructured
2026-01-14T09:33:02.0404210Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_prepare
2026-01-14T09:33:02.0404719Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_squash_mask
2026-01-14T09:33:02.0405283Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured
2026-01-14T09:33:02.0405988Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured_custom_config
2026-01-14T09:33:02.0407028Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/wanda.py:75: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T09:33:02.0407843Z   For migrations of users: 
2026-01-14T09:33:02.0408634Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T09:33:02.0410135Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T09:33:02.0411449Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T09:33:02.0412164Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T09:33:02.0412615Z     torch.ao.quantization.prepare(model, inplace=True)
2026-01-14T09:33:02.0412882Z 
2026-01-14T09:33:02.0413115Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-01-14T09:33:02.0414214Z [33m======== [32m2532 passed[0m, [33m[1m6438 skipped[0m, [33m[1m828 warnings[0m[33m in 3594.68s (0:59:54)[0m[33m =========[0m
2026-01-14T09:33:02.0470093Z ##[group]Run pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1
2026-01-14T09:33:02.0470588Z with:
2026-01-14T09:33:02.0470875Z   path: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:02.0471352Z   fail-on-empty: false
2026-01-14T09:33:02.0471566Z env:
2026-01-14T09:33:02.0471806Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:02.0472141Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:02.0472383Z   PR_NUMBER: 3500
2026-01-14T09:33:02.0473918Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:02.0475652Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:02.0476209Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:02.0476747Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:02.0477133Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:02.0477429Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:02.0477773Z ##[endgroup]
2026-01-14T09:33:02.1090404Z Prepare all required actions
2026-01-14T09:33:02.1135896Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T09:33:02.1136262Z with:
2026-01-14T09:33:02.1136552Z   directory: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T09:33:02.1137028Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:33:02.1137433Z env:
2026-01-14T09:33:02.1137686Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:02.1138040Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:02.1138289Z   PR_NUMBER: 3500
2026-01-14T09:33:02.1140237Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:02.1142166Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:02.1142741Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:02.1143293Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:02.1143680Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:02.1144003Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:02.1144364Z ##[endgroup]
2026-01-14T09:33:02.1171931Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T09:33:02.1172640Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T09:33:02.1187513Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:33:02.1187876Z env:
2026-01-14T09:33:02.1188126Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:02.1188476Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:02.1188725Z   PR_NUMBER: 3500
2026-01-14T09:33:02.1190285Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:02.1192039Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:02.1192629Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:02.1193176Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:02.1193569Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:02.1193880Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:02.1194470Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:33:02.1194963Z   DIRECTORY: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T09:33:02.1195314Z ##[endgroup]
2026-01-14T09:33:02.1453996Z Unable to find image '308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest' locally
2026-01-14T09:33:02.3556708Z latest: Pulling from tool/alpine
2026-01-14T09:33:02.3557036Z 540db60ca938: Pulling fs layer
2026-01-14T09:33:02.4432868Z 540db60ca938: Verifying Checksum
2026-01-14T09:33:02.4433183Z 540db60ca938: Download complete
2026-01-14T09:33:02.5580062Z 540db60ca938: Pull complete
2026-01-14T09:33:02.5692686Z Digest: sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T09:33:02.5735356Z Status: Downloaded newer image for 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T09:33:03.6572595Z Prepare all required actions
2026-01-14T09:33:03.6618308Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T09:33:03.6618672Z with:
2026-01-14T09:33:03.6618944Z   directory: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T09:33:03.6619427Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:33:03.6619834Z env:
2026-01-14T09:33:03.6620090Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:03.6620444Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:03.6620698Z   PR_NUMBER: 3500
2026-01-14T09:33:03.6622288Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:03.6624171Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:03.6624749Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:03.6625296Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:03.6625678Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:03.6625993Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:03.6626336Z ##[endgroup]
2026-01-14T09:33:03.6648636Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T09:33:03.6649341Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T09:33:03.6663626Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:33:03.6664024Z env:
2026-01-14T09:33:03.6664287Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:03.6664686Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:03.6664954Z   PR_NUMBER: 3500
2026-01-14T09:33:03.6666484Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:03.6668217Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:03.6668797Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:03.6669340Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:03.6669726Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:03.6670030Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:03.6670506Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:33:03.6670992Z   DIRECTORY: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T09:33:03.6671382Z ##[endgroup]
2026-01-14T09:33:04.7598721Z ##[group]Run # Only do these steps if we actually want to upload an artifact
2026-01-14T09:33:04.7599320Z [36;1m# Only do these steps if we actually want to upload an artifact[0m
2026-01-14T09:33:04.7599779Z [36;1mif [[ -n "${UPLOAD_ARTIFACT_NAME}" ]]; then[0m
2026-01-14T09:33:04.7600325Z [36;1m  # If the default execution path is followed then we should get a wheel in the dist/ folder[0m
2026-01-14T09:33:04.7600952Z [36;1m  # attempt to just grab whatever is in there and scoop it all up[0m
2026-01-14T09:33:04.7601464Z [36;1m  if find "dist/" -name "*.whl" >/dev/null 2>/dev/null; then[0m
2026-01-14T09:33:04.7601898Z [36;1m    mv -v dist/*.whl "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T09:33:04.7602223Z [36;1m  fi[0m
2026-01-14T09:33:04.7602497Z [36;1m  if [[ -d "artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T09:33:04.7603026Z [36;1m    mv -v artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T09:33:04.7603421Z [36;1m  fi[0m
2026-01-14T09:33:04.7603760Z [36;1m  if [[ -d "${RUNNER_TEMP}/artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T09:33:04.7604309Z [36;1m    mv -v "${RUNNER_TEMP}"/artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T09:33:04.7604773Z [36;1m  fi[0m
2026-01-14T09:33:04.7604972Z [36;1mfi[0m
2026-01-14T09:33:04.7605180Z [36;1m[0m
2026-01-14T09:33:04.7605393Z [36;1mupload_docs=0[0m
2026-01-14T09:33:04.7605794Z [36;1m# Check if there are files in the documentation folder to upload, note that[0m
2026-01-14T09:33:04.7606263Z [36;1m# empty folders do not count[0m
2026-01-14T09:33:04.7606706Z [36;1mif find "${RUNNER_DOCS_DIR}" -mindepth 1 -maxdepth 1 -type f | read -r; then[0m
2026-01-14T09:33:04.7607323Z [36;1m  # TODO: Add a check here to test if on ec2 because if we're not on ec2 then this[0m
2026-01-14T09:33:04.7607832Z [36;1m  # upload will probably not work correctly[0m
2026-01-14T09:33:04.7608289Z [36;1m  upload_docs=1[0m
2026-01-14T09:33:04.7608532Z [36;1mfi[0m
2026-01-14T09:33:04.7608838Z [36;1mecho "upload-docs=${upload_docs}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T09:33:04.7619420Z shell: /usr/bin/bash -e {0}
2026-01-14T09:33:04.7619678Z env:
2026-01-14T09:33:04.7619935Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:04.7620276Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:04.7620528Z   PR_NUMBER: 3500
2026-01-14T09:33:04.7622119Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:04.7623844Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:04.7624427Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:04.7624969Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:04.7625360Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:04.7625673Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:04.7626027Z   UPLOAD_ARTIFACT_NAME: 
2026-01-14T09:33:04.7626280Z ##[endgroup]
2026-01-14T09:33:04.7733930Z Prepare all required actions
2026-01-14T09:33:04.7776531Z ##[group]Run ./test-infra/.github/actions/teardown-linux
2026-01-14T09:33:04.7776884Z with:
2026-01-14T09:33:04.7777076Z env:
2026-01-14T09:33:04.7777335Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:04.7777682Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:04.7777941Z   PR_NUMBER: 3500
2026-01-14T09:33:04.7779488Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:04.7781358Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:04.7781976Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:04.7782521Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:04.7796267Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:04.7796628Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:04.7796974Z ##[endgroup]
2026-01-14T09:33:04.7825734Z ##[group]Run set -eou pipefail
2026-01-14T09:33:04.7826030Z [36;1mset -eou pipefail[0m
2026-01-14T09:33:04.7826285Z [36;1m[0m
2026-01-14T09:33:04.7826647Z [36;1mecho "Holding runner for 2 hours until all ssh sessions have logged out"[0m
2026-01-14T09:33:04.7827096Z [36;1mfor _ in $(seq 1440); do[0m
2026-01-14T09:33:04.7827422Z [36;1m    # Break if no ssh session exists anymore[0m
2026-01-14T09:33:04.7827763Z [36;1m    if [ "$(who)" = "" ]; then[0m
2026-01-14T09:33:04.7828059Z [36;1m      break[0m
2026-01-14T09:33:04.7828284Z [36;1m    fi[0m
2026-01-14T09:33:04.7828500Z [36;1m    echo "."[0m
2026-01-14T09:33:04.7828725Z [36;1m    sleep 5[0m
2026-01-14T09:33:04.7828959Z [36;1mdone[0m
2026-01-14T09:33:04.7840925Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:33:04.7841289Z env:
2026-01-14T09:33:04.7841537Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:04.7841880Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:04.7842128Z   PR_NUMBER: 3500
2026-01-14T09:33:04.7843741Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:04.7845599Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:04.7846183Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:04.7846729Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:04.7847123Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:04.7847435Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:04.7847795Z ##[endgroup]
2026-01-14T09:33:04.7881317Z Holding runner for 2 hours until all ssh sessions have logged out
2026-01-14T09:33:04.7980776Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T09:33:04.7981314Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T09:33:04.7981738Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T09:33:04.7982072Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T09:33:04.7982411Z [36;1m# Prune all of the docker images[0m
2026-01-14T09:33:04.7982733Z [36;1mdocker system prune -af[0m
2026-01-14T09:33:04.7991938Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:33:04.7992320Z env:
2026-01-14T09:33:04.7992576Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:04.7993110Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:04.7993361Z   PR_NUMBER: 3500
2026-01-14T09:33:04.7994904Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:04.7996638Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:04.7997218Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:04.7997762Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:04.7998229Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:04.7998544Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:04.7998887Z ##[endgroup]
2026-01-14T09:33:06.1936306Z 4db5761fa996
2026-01-14T09:33:13.9870858Z Deleted Containers:
2026-01-14T09:33:13.9871262Z 4db5761fa99698ce26f570affb4f6bad002151a35d2ebe70166fe05eb60c3afb
2026-01-14T09:33:13.9871586Z 
2026-01-14T09:33:22.1994413Z Deleted Images:
2026-01-14T09:33:22.1995197Z untagged: public.ecr.aws/docker/library/python:3.13
2026-01-14T09:33:22.1996627Z untagged: public.ecr.aws/docker/library/python@sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T09:33:22.1997670Z deleted: sha256:6b1b86f270ccdb848adf78330c7a27041a2f8e971cfd9c808e1ad503d236f9ae
2026-01-14T09:33:22.1998342Z deleted: sha256:ab3ff5992dd09a2d006ef37d701d92e11590962848a698a0824ab2129505b946
2026-01-14T09:33:22.1999076Z deleted: sha256:c839d2b1d0949c101d8e022855435eedb0179697af77be6012f911dfcb69742c
2026-01-14T09:33:22.1999792Z deleted: sha256:b3fb8a2c0606137f473565b54a51bb1e18dfca24cbc417e0f7a0b3d68395d9ea
2026-01-14T09:33:22.2000506Z deleted: sha256:a643465a85469890e6e498fe0d0ac4e6a251e77c92a179ac27085d4ffeb4c8da
2026-01-14T09:33:22.2001226Z deleted: sha256:09db7ba2ba0ebb76125f8bf37573369eb90202594586d30c6f9c202d968f4d00
2026-01-14T09:33:22.2001953Z deleted: sha256:ba4e59af8cdbb2e2cd899773f1cdbcb3027d48d9be333f5a823d9cccfd5c4a15
2026-01-14T09:33:22.2002758Z deleted: sha256:da7213941eca995ecec09e85fe1affcac44194792b48cbacdd3c0d9038bbaf9e
2026-01-14T09:33:22.2003362Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T09:33:22.2004197Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine@sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T09:33:22.2007089Z deleted: sha256:6dbb9cc54074106d46d4ccb330f2a40a682d49dda5f4844962b7dce9fe44aaec
2026-01-14T09:33:22.2007715Z deleted: sha256:b2d5eeeaba3a22b9b8aa97261957974a6bd65274ebd43e1d81d0a7b8b752b116
2026-01-14T09:33:22.2008235Z untagged: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:22.2008835Z untagged: pytorch/almalinux-builder@sha256:38e012b20747e9f72b4c4dc2ffb4134a450ad6e57e64886e7daf42b9a8ffa9f2
2026-01-14T09:33:22.2009593Z deleted: sha256:bb1a1950b861327b13d8893bffd39e26f8e80f9318971babe6b3f9bab8d65d21
2026-01-14T09:33:22.2010210Z deleted: sha256:a54dbc7bc094481efb3d7798f26feac4f04f2c7d3b16372162cacf83ed2388ce
2026-01-14T09:33:22.2010839Z deleted: sha256:645a24a13a583a58c04ea348b38daba4a40b2bbe09eb2012e9d33e823ff99c8e
2026-01-14T09:33:22.2011449Z deleted: sha256:74c5765839aa7e92b734630a11e6a02dc4f9932142efb4becedf62941283e0cd
2026-01-14T09:33:22.2012055Z deleted: sha256:7a626ac79b7f4d3436fb97d7a7ca125845805c133303239c31f4eed62b556453
2026-01-14T09:33:22.2012664Z deleted: sha256:31c03ed8c3f72312100269f048fea1b331a93b53b496ce34be4bac621109f901
2026-01-14T09:33:22.2013271Z deleted: sha256:c32b905bbd58816c78ef90a77285dd4d9b1cdafdbaa7332cd398891b30feee8e
2026-01-14T09:33:22.2013893Z deleted: sha256:4dc58665c3bd3ca188c201fdcfdeb41b0118191cd6843ddeda62495ba0c15986
2026-01-14T09:33:22.2014513Z deleted: sha256:dad808738bccf06931c05520f69d148be75a61afd28065e9aee100d5af6133bd
2026-01-14T09:33:22.2015491Z deleted: sha256:6e036a485561034f6c52610c6a2c7f11e64060ce9e2f10b3d4064a87d091745a
2026-01-14T09:33:22.2016139Z deleted: sha256:ef2ba6b1ca100c37739c13afedd9c52143448d948239c375f611f5bbe19f175d
2026-01-14T09:33:22.2016780Z deleted: sha256:37d850998e8d82d40ffce6b7020d480daecaa091b6fbac01c04a0da1f90f7e8f
2026-01-14T09:33:22.2017393Z deleted: sha256:16a70495db3a28a89c3250c0824d0e3e08c22dced61a31110ef1c7f8c5b127cd
2026-01-14T09:33:22.2017992Z deleted: sha256:b7982627380d2b6bc6a223770c8c18cb45dcc8229c32e1160fcb416a32fc969a
2026-01-14T09:33:22.2018597Z deleted: sha256:a4d99473e3f02923cf34c61996bf5a25863e8ee02801d6634174d671e0ac7367
2026-01-14T09:33:22.2019207Z deleted: sha256:2c683ce33d69b13bbcfe1f405137ff2aea4213c8228876ff55a791116cdcf2e2
2026-01-14T09:33:22.2019817Z deleted: sha256:ffaa389b629375310a946fd02f2f26fcf3678b2c23d94f4aab82a0fc46214892
2026-01-14T09:33:22.2020555Z deleted: sha256:e7ce15ca67e07966f2da85c8d2242c7535a7c9ab1f63b2069834ffba95a5978c
2026-01-14T09:33:22.2021173Z deleted: sha256:63b0fcbf70a9ee9ece0aeb6610359975830e1646da68f5f7722c2e64426bd4c7
2026-01-14T09:33:22.2021785Z deleted: sha256:5c48134bdee035683ad0d4846f19aa135bd7b8735e8c0b6420d13e5779f720e4
2026-01-14T09:33:22.2022393Z deleted: sha256:badca1798f4ace2b0179b607780a5cce32170bedeb23d076335fc973ec72f34c
2026-01-14T09:33:22.2023009Z deleted: sha256:ae88b0e9396996f876f32bf01d80534d3cf5c06c395eba64f7dd66dda56fa55f
2026-01-14T09:33:22.2023626Z deleted: sha256:b52e19c766f22b187f4fcd4e90cfb1e4e3c547dfe7484bf5423db65775cf352f
2026-01-14T09:33:22.2024241Z deleted: sha256:1d80070b73e86e9afa159ca72ee6fc6bcf7f387d21c1d6dcd065fa877e678592
2026-01-14T09:33:22.2024850Z deleted: sha256:ff4f19608a1944c0c2807cd533515673285a9632dc74bf020e83e18630d1ae35
2026-01-14T09:33:22.2025204Z 
2026-01-14T09:33:22.2025319Z Total reclaimed space: 30.4GB
2026-01-14T09:33:22.2093002Z ##[group]Run set +e
2026-01-14T09:33:22.2093272Z [36;1mset +e[0m
2026-01-14T09:33:22.2093509Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T09:33:22.2093910Z [36;1m  sudo rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T09:33:22.2094272Z [36;1melse[0m
2026-01-14T09:33:22.2094550Z [36;1m  rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T09:33:22.2094889Z [36;1mfi[0m
2026-01-14T09:33:22.2095090Z [36;1mset -e[0m
2026-01-14T09:33:22.2105471Z shell: /usr/bin/bash -e {0}
2026-01-14T09:33:22.2105724Z env:
2026-01-14T09:33:22.2105977Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:33:22.2106314Z   REPOSITORY: pytorch/ao
2026-01-14T09:33:22.2106564Z   PR_NUMBER: 3500
2026-01-14T09:33:22.2108126Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.8.0
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:33:22.2110013Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:33:22.2110589Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:33:22.2111137Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:33:22.2111526Z   HAS_NVIDIA_GPU: true
2026-01-14T09:33:22.2111845Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:33:22.2112192Z   NO_SUDO: false
2026-01-14T09:33:22.2112416Z ##[endgroup]
2026-01-14T09:33:22.6996594Z Post job cleanup.
2026-01-14T09:33:22.8102095Z Post job cleanup.
2026-01-14T09:33:22.9098380Z [command]/usr/bin/git version
2026-01-14T09:33:22.9148659Z git version 2.50.1
2026-01-14T09:33:22.9195105Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/b715ecc8-e542-469c-bb34-2f72035bac5c' before making global git config changes
2026-01-14T09:33:22.9196038Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T09:33:22.9200737Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T09:33:22.9243646Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T09:33:22.9285899Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T09:33:22.9710546Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T09:33:22.9741452Z http.https://github.com/.extraheader
2026-01-14T09:33:22.9754114Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader
2026-01-14T09:33:22.9794488Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T09:33:23.0296643Z A job completed hook has been configured by the self-hosted runner administrator
2026-01-14T09:33:23.0330221Z ##[group]Run '/home/ec2-user/runner-scripts/after_job.sh'
2026-01-14T09:33:23.0338358Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:33:23.0338728Z ##[endgroup]
2026-01-14T09:33:23.0454834Z [!ALERT!] Swap in detected! [!ALERT!]
2026-01-14T09:33:34.6716613Z [!ALERT!] Swap out detected [!ALERT!]
2026-01-14T09:33:53.6663451Z Cleaning up orphan processes
