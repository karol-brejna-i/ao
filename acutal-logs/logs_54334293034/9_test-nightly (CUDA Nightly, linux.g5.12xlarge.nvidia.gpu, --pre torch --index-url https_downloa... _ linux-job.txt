2026-01-14T08:14:57.3591419Z Current runner version: '2.331.0'
2026-01-14T08:14:57.3597804Z Runner name: 'i-05a1870e2d4417545'
2026-01-14T08:14:57.3598555Z Runner group name: 'default'
2026-01-14T08:14:57.3599375Z Machine name: 'ip-10-0-36-94'
2026-01-14T08:14:57.3602052Z ##[group]GITHUB_TOKEN Permissions
2026-01-14T08:14:57.3604263Z Contents: read
2026-01-14T08:14:57.3604783Z Metadata: read
2026-01-14T08:14:57.3605276Z ##[endgroup]
2026-01-14T08:14:57.3607116Z Secret source: None
2026-01-14T08:14:57.3607718Z Prepare workflow directory
2026-01-14T08:14:57.4154930Z Prepare all required actions
2026-01-14T08:14:57.4192132Z Getting action download info
2026-01-14T08:14:57.7225432Z Download action repository 'actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683' (SHA:11bd71901bbe5b1630ceea73d27597364c9af683)
2026-01-14T08:14:58.0194691Z Download action repository 'pytorch/pytorch@main' (SHA:b321605fc7207c672be72497ceeb20cbb6367319)
2026-01-14T08:15:14.1951326Z Download action repository 'actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093' (SHA:d3f86a106a0bac45b974a628896c90dbdf5c8093)
2026-01-14T08:15:14.5608279Z Download action repository 'pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1' (SHA:a2c1430e2bddadbad9f49a6f9b879f062c6b19b1)
2026-01-14T08:15:14.6969358Z Download action repository 'actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02' (SHA:ea165f8d65b6e75b540449e92b4886f43607fa02)
2026-01-14T08:15:15.2741188Z Getting action download info
2026-01-14T08:15:15.4134594Z Getting action download info
2026-01-14T08:15:15.5799405Z Download action repository 'aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722' (SHA:ececac1a45f3b08a01d2dd070d28d111c5fe6722)
2026-01-14T08:15:15.8304123Z Download action repository 'aws-actions/amazon-ecr-login@062b18b96a7aff071d4dc91bc00c4c1a7945b076' (SHA:062b18b96a7aff071d4dc91bc00c4c1a7945b076)
2026-01-14T08:15:16.0714160Z Uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@refs/heads/main (479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:15:16.0718041Z ##[group] Inputs
2026-01-14T08:15:16.0719853Z   script: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:16.0722067Z   timeout: 180
2026-01-14T08:15:16.0722325Z   runner: linux.g5.12xlarge.nvidia.gpu
2026-01-14T08:15:16.0722652Z   upload-artifact: 
2026-01-14T08:15:16.0723211Z   upload-artifact-to-s3: false
2026-01-14T08:15:16.0723500Z   download-artifact: 
2026-01-14T08:15:16.0723740Z   repository: 
2026-01-14T08:15:16.0723996Z   fetch-depth: 1
2026-01-14T08:15:16.0724228Z   submodules: recursive
2026-01-14T08:15:16.0724478Z   ref: 
2026-01-14T08:15:16.0724731Z   test-infra-repository: pytorch/test-infra
2026-01-14T08:15:16.0725060Z   test-infra-ref: 
2026-01-14T08:15:16.0725335Z   use-custom-docker-registry: true
2026-01-14T08:15:16.0725650Z   docker-image: pytorch/almalinux-builder
2026-01-14T08:15:16.0725974Z   docker-build-dir: .ci/docker
2026-01-14T08:15:16.0726250Z   gpu-arch-type: cuda
2026-01-14T08:15:16.0726505Z   gpu-arch-version: 12.6
2026-01-14T08:15:16.0726757Z   job-name: linux-job
2026-01-14T08:15:16.0727018Z   continue-on-error: false
2026-01-14T08:15:16.0727313Z   binary-matrix: 
2026-01-14T08:15:16.0727555Z   run-with-docker: true
2026-01-14T08:15:16.0727797Z   secrets-env: 
2026-01-14T08:15:16.0728022Z   no-sudo: false
2026-01-14T08:15:16.0728252Z ##[endgroup]
2026-01-14T08:15:16.0728843Z Complete job name: test-nightly (CUDA Nightly, linux.g5.12xlarge.nvidia.gpu, --pre torch --index-url https://downloa... / linux-job
2026-01-14T08:15:16.1877749Z A job started hook has been configured by the self-hosted runner administrator
2026-01-14T08:15:16.1987499Z ##[group]Run '/home/ec2-user/runner-scripts/before_job.sh'
2026-01-14T08:15:16.1999272Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:16.1999864Z ##[endgroup]
2026-01-14T08:15:17.6642063Z Runner Type: linux.g5.12xlarge.nvidia.gpu
2026-01-14T08:15:17.6642553Z Instance Type: g5.12xlarge
2026-01-14T08:15:17.6642805Z AMI Name: unknown
2026-01-14T08:15:17.6687496Z AMI ID: ami-068c0051b15cdb816
2026-01-14T08:15:23.4735695Z ##[group]Run set -euxo pipefail
2026-01-14T08:15:23.4736084Z [36;1mset -euxo pipefail[0m
2026-01-14T08:15:23.4736399Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T08:15:23.4736805Z [36;1m  echo "::group::Cleanup with-sudo debug output"[0m
2026-01-14T08:15:23.4737217Z [36;1m  sudo rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:23.4737540Z [36;1melse[0m
2026-01-14T08:15:23.4737823Z [36;1m  echo "::group::Cleanup no-sudo debug output"[0m
2026-01-14T08:15:23.4738198Z [36;1m  rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:23.4738493Z [36;1mfi[0m
2026-01-14T08:15:23.4738719Z [36;1m[0m
2026-01-14T08:15:23.4738962Z [36;1mmkdir -p "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:23.4739305Z [36;1mecho "::endgroup::"[0m
2026-01-14T08:15:23.4754479Z shell: /usr/bin/bash -e {0}
2026-01-14T08:15:23.4754739Z env:
2026-01-14T08:15:23.4755082Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:23.4755474Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:23.4755787Z   PR_NUMBER: 3500
2026-01-14T08:15:23.4757518Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:23.4759346Z   NO_SUDO: false
2026-01-14T08:15:23.4759576Z ##[endgroup]
2026-01-14T08:15:23.4801122Z + [[ false == \f\a\l\s\e ]]
2026-01-14T08:15:23.4810473Z + echo '::group::Cleanup with-sudo debug output'
2026-01-14T08:15:23.4810920Z + sudo rm -rfv /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:15:23.4816703Z ##[group]Cleanup with-sudo debug output
2026-01-14T08:15:23.6058557Z removed directory '/home/ec2-user/actions-runner/_work/ao/ao'
2026-01-14T08:15:23.6082056Z + mkdir -p /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:15:23.6098895Z + echo ::endgroup::
2026-01-14T08:15:23.6099392Z ##[endgroup]
2026-01-14T08:15:23.6228450Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:15:23.6228891Z with:
2026-01-14T08:15:23.6229125Z   repository: pytorch/test-infra
2026-01-14T08:15:23.6229422Z   path: test-infra
2026-01-14T08:15:23.6229662Z   submodules: recursive
2026-01-14T08:15:23.6230103Z   token: ***
2026-01-14T08:15:23.6230345Z   ssh-strict: true
2026-01-14T08:15:23.6230567Z   ssh-user: git
2026-01-14T08:15:23.6230809Z   persist-credentials: true
2026-01-14T08:15:23.6231066Z   clean: true
2026-01-14T08:15:23.6231325Z   sparse-checkout-cone-mode: true
2026-01-14T08:15:23.6231606Z   fetch-depth: 1
2026-01-14T08:15:23.6231847Z   fetch-tags: false
2026-01-14T08:15:23.6232084Z   show-progress: true
2026-01-14T08:15:23.6232315Z   lfs: false
2026-01-14T08:15:23.6232545Z   set-safe-directory: true
2026-01-14T08:15:23.6232791Z env:
2026-01-14T08:15:23.6233042Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:23.6233395Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:23.6233673Z   PR_NUMBER: 3500
2026-01-14T08:15:23.6235455Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:23.6237253Z ##[endgroup]
2026-01-14T08:15:23.7672704Z Syncing repository: pytorch/test-infra
2026-01-14T08:15:23.7673322Z ##[group]Getting Git version info
2026-01-14T08:15:23.7673759Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/test-infra'
2026-01-14T08:15:23.7674386Z [command]/usr/bin/git version
2026-01-14T08:15:23.7683044Z git version 2.50.1
2026-01-14T08:15:23.7709671Z ##[endgroup]
2026-01-14T08:15:23.7733842Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/a7d43eec-4a61-4c36-9521-9114370b55a2' before making global git config changes
2026-01-14T08:15:23.7734784Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:15:23.7739342Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:15:23.7778614Z ##[group]Initializing the repository
2026-01-14T08:15:23.7783208Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:15:23.7829527Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:15:23.7830165Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:15:23.7830722Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:15:23.7831129Z hint:
2026-01-14T08:15:23.7831432Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:15:23.7831790Z hint:
2026-01-14T08:15:23.7832126Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:15:23.7832695Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:15:23.7833121Z hint:
2026-01-14T08:15:23.7833356Z hint: 	git branch -m <name>
2026-01-14T08:15:23.7833611Z hint:
2026-01-14T08:15:23.7833985Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:15:23.7834683Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.git/
2026-01-14T08:15:23.7842157Z [command]/usr/bin/git remote add origin https://github.com/pytorch/test-infra
2026-01-14T08:15:23.7880904Z ##[endgroup]
2026-01-14T08:15:23.7881383Z ##[group]Disabling automatic garbage collection
2026-01-14T08:15:23.7884971Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:15:23.8100371Z ##[endgroup]
2026-01-14T08:15:23.8100774Z ##[group]Setting up auth
2026-01-14T08:15:23.8105950Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:15:23.8157640Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:15:23.8618114Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:15:23.8653874Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:15:23.9082388Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:15:23.9127835Z ##[endgroup]
2026-01-14T08:15:23.9128263Z ##[group]Determining the default branch
2026-01-14T08:15:23.9130924Z Retrieving the default branch name
2026-01-14T08:15:24.1854428Z Default branch 'main'
2026-01-14T08:15:24.1855241Z ##[endgroup]
2026-01-14T08:15:24.1856196Z ##[group]Fetching the repository
2026-01-14T08:15:24.1860785Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/heads/main:refs/remotes/origin/main
2026-01-14T08:15:24.5609173Z From https://github.com/pytorch/test-infra
2026-01-14T08:15:24.5609571Z  * [new branch]      main       -> origin/main
2026-01-14T08:15:24.5641049Z ##[endgroup]
2026-01-14T08:15:24.5641461Z ##[group]Determining the checkout info
2026-01-14T08:15:24.5642617Z ##[endgroup]
2026-01-14T08:15:24.5647403Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:15:24.5693807Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:15:24.5728324Z ##[group]Checking out the ref
2026-01-14T08:15:24.5731202Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-01-14T08:15:24.7747517Z Switched to a new branch 'main'
2026-01-14T08:15:24.7750322Z branch 'main' set up to track 'origin/main'.
2026-01-14T08:15:24.7764375Z ##[endgroup]
2026-01-14T08:15:24.7764802Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:15:24.7770235Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:15:24.7822343Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:15:24.7858502Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:15:24.7895423Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:15:24.7928778Z ##[endgroup]
2026-01-14T08:15:24.7929194Z ##[group]Fetching submodules
2026-01-14T08:15:24.7932342Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:15:24.8343068Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:15:24.8750019Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:15:24.9158763Z ##[endgroup]
2026-01-14T08:15:24.9159188Z ##[group]Persisting credentials for submodules
2026-01-14T08:15:24.9163830Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:15:24.9570249Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:15:24.9978391Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:15:25.0381009Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:15:25.0777176Z ##[endgroup]
2026-01-14T08:15:25.0829722Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:15:25.0861662Z 479ee761cd164688ad6fe63fbc0f27d255b35fe1
2026-01-14T08:15:25.1093202Z Prepare all required actions
2026-01-14T08:15:25.1093797Z Getting action download info
2026-01-14T08:15:25.2563730Z Download action repository 'pytorch/test-infra@main' (SHA:479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:15:26.9241568Z Getting action download info
2026-01-14T08:15:27.0773170Z Download action repository 'nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482' (SHA:3e91a01664abd3c5cd539100d10d33b9c5b68482)
2026-01-14T08:15:27.2860399Z ##[group]Run ./test-infra/.github/actions/setup-linux
2026-01-14T08:15:27.2860739Z env:
2026-01-14T08:15:27.2861002Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:27.2861352Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:27.2861613Z   PR_NUMBER: 3500
2026-01-14T08:15:27.2863326Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:27.2865041Z ##[endgroup]
2026-01-14T08:15:27.2950206Z ##[group]Run set -euo pipefail
2026-01-14T08:15:27.2950530Z [36;1mset -euo pipefail[0m
2026-01-14T08:15:27.2950811Z [36;1mfunction get_ec2_metadata() {[0m
2026-01-14T08:15:27.2951177Z [36;1m  # Pulled from instance metadata endpoint for EC2[0m
2026-01-14T08:15:27.2951994Z [36;1m  # see https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html[0m
2026-01-14T08:15:27.2952553Z [36;1m  category=$1[0m
2026-01-14T08:15:27.2953457Z [36;1m  curl -H "X-aws-ec2-metadata-token: $(curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 30")" -fsSL "http://169.254.169.254/latest/meta-data/${category}"[0m
2026-01-14T08:15:27.2954402Z [36;1m}[0m
2026-01-14T08:15:27.2954666Z [36;1mecho "ami-id: $(get_ec2_metadata ami-id)"[0m
2026-01-14T08:15:27.2955266Z [36;1mecho "instance-id: $(get_ec2_metadata instance-id)"[0m
2026-01-14T08:15:27.2955755Z [36;1mecho "instance-type: $(get_ec2_metadata instance-type)"[0m
2026-01-14T08:15:27.2956168Z [36;1mecho "system info $(uname -a)"[0m
2026-01-14T08:15:27.2965829Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:27.2966205Z env:
2026-01-14T08:15:27.2966515Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:27.2966906Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:27.2967178Z   PR_NUMBER: 3500
2026-01-14T08:15:27.2968905Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:27.2970678Z ##[endgroup]
2026-01-14T08:15:27.3135467Z ami-id: ami-068c0051b15cdb816
2026-01-14T08:15:27.3270824Z instance-id: i-05a1870e2d4417545
2026-01-14T08:15:27.3401835Z instance-type: g5.12xlarge
2026-01-14T08:15:27.3418769Z system info Linux ip-10-0-36-94.ec2.internal 6.1.158-180.294.amzn2023.x86_64 #1 SMP PREEMPT_DYNAMIC Mon Dec  1 05:36:50 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
2026-01-14T08:15:27.3466390Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:15:27.3467380Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:27.3477129Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:27.3477505Z env:
2026-01-14T08:15:27.3477765Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:27.3478344Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:27.3478599Z   PR_NUMBER: 3500
2026-01-14T08:15:27.3480299Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:27.3482027Z ##[endgroup]
2026-01-14T08:15:27.3572321Z ##[group]Run if ! docker version >/dev/null 2>/dev/null; then
2026-01-14T08:15:27.3572801Z [36;1mif ! docker version >/dev/null 2>/dev/null; then[0m
2026-01-14T08:15:27.3573217Z [36;1m  if systemctl is-active --quiet docker; then[0m
2026-01-14T08:15:27.3573606Z [36;1m      echo "Docker daemon is running...";[0m
2026-01-14T08:15:27.3573934Z [36;1m  else[0m
2026-01-14T08:15:27.3574307Z [36;1m      echo "Starting docker daemon..." && sudo systemctl start docker;[0m
2026-01-14T08:15:27.3574729Z [36;1m  fi[0m
2026-01-14T08:15:27.3574928Z [36;1mfi[0m
2026-01-14T08:15:27.3583956Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:27.3584910Z env:
2026-01-14T08:15:27.3585220Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:27.3585588Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:27.3585843Z   PR_NUMBER: 3500
2026-01-14T08:15:27.3587774Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:27.3589486Z ##[endgroup]
2026-01-14T08:15:27.4153201Z ##[group]Run AWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")
2026-01-14T08:15:27.4153870Z [36;1mAWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")[0m
2026-01-14T08:15:27.4154405Z [36;1mretry () { "$@"  || (sleep 1 && "$@") || (sleep 2 && "$@") }[0m
2026-01-14T08:15:27.4155112Z [36;1mretry aws ecr get-login-password --region "$AWS_DEFAULT_REGION" | docker login --username AWS \[0m
2026-01-14T08:15:27.4155858Z [36;1m    --password-stdin "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com"[0m
2026-01-14T08:15:27.4165692Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:27.4166058Z env:
2026-01-14T08:15:27.4166319Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:27.4166675Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:27.4166928Z   PR_NUMBER: 3500
2026-01-14T08:15:27.4168647Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:27.4170408Z   AWS_RETRY_MODE: standard
2026-01-14T08:15:27.4170673Z   AWS_MAX_ATTEMPTS: 5
2026-01-14T08:15:27.4170920Z   AWS_DEFAULT_REGION: us-east-1
2026-01-14T08:15:27.4171182Z ##[endgroup]
2026-01-14T08:15:28.4936458Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:15:28.4937317Z Configure a credential helper to remove this warning. See
2026-01-14T08:15:28.4937948Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:15:28.4938320Z 
2026-01-14T08:15:28.4938758Z Login Succeeded
2026-01-14T08:15:28.5021650Z ##[group]Run env | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"
2026-01-14T08:15:28.5022253Z [36;1menv | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:15:28.5023064Z [36;1menv | grep '^CI' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:15:28.5023579Z [36;1menv | grep '^RUNNER' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:15:28.5032869Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:28.5033222Z env:
2026-01-14T08:15:28.5033479Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:28.5033818Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:28.5034075Z   PR_NUMBER: 3500
2026-01-14T08:15:28.5035831Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:28.5037544Z ##[endgroup]
2026-01-14T08:15:28.5175114Z ##[group]Run RUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"
2026-01-14T08:15:28.5175580Z [36;1mRUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"[0m
2026-01-14T08:15:28.5175982Z [36;1msudo rm -rf "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:15:28.5176343Z [36;1mmkdir -p "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:15:28.5176783Z [36;1mecho "RUNNER_ARTIFACT_DIR=${RUNNER_ARTIFACT_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:28.5177214Z [36;1m[0m
2026-01-14T08:15:28.5177695Z [36;1mRUNNER_TEST_RESULTS_DIR="${RUNNER_TEMP}/test-results"[0m
2026-01-14T08:15:28.5178125Z [36;1msudo rm -rf "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:15:28.5178496Z [36;1mmkdir -p "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:15:28.5178965Z [36;1mecho "RUNNER_TEST_RESULTS_DIR=${RUNNER_TEST_RESULTS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:28.5179410Z [36;1m[0m
2026-01-14T08:15:28.5179648Z [36;1mRUNNER_DOCS_DIR="${RUNNER_TEMP}/docs"[0m
2026-01-14T08:15:28.5179991Z [36;1msudo rm -rf "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:15:28.5180319Z [36;1mmkdir -p "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:15:28.5180721Z [36;1mecho "RUNNER_DOCS_DIR=${RUNNER_DOCS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:28.5189509Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:28.5189862Z env:
2026-01-14T08:15:28.5190117Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:28.5190463Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:28.5190726Z   PR_NUMBER: 3500
2026-01-14T08:15:28.5192385Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:28.5194089Z ##[endgroup]
2026-01-14T08:15:29.0426438Z ##[group]Run needs=0
2026-01-14T08:15:29.0426701Z [36;1mneeds=0[0m
2026-01-14T08:15:29.0427085Z [36;1mif lspci -v | grep -e 'controller.*NVIDIA' >/dev/null 2>/dev/null; then[0m
2026-01-14T08:15:29.0427511Z [36;1m  needs=1[0m
2026-01-14T08:15:29.0427747Z [36;1mfi[0m
2026-01-14T08:15:29.0428007Z [36;1mecho "does=${needs}" >> $GITHUB_OUTPUT[0m
2026-01-14T08:15:29.0436700Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:29.0437058Z env:
2026-01-14T08:15:29.0437319Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:29.0437676Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:29.0437924Z   PR_NUMBER: 3500
2026-01-14T08:15:29.0439784Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:29.0441661Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:29.0442253Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:29.0442799Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:29.0443188Z ##[endgroup]
2026-01-14T08:15:29.0857219Z ##[group]Run pytorch/test-infra/.github/actions/setup-nvidia@main
2026-01-14T08:15:29.0857618Z with:
2026-01-14T08:15:29.0857838Z   driver-version: 580.65.06
2026-01-14T08:15:29.0858081Z env:
2026-01-14T08:15:29.0858324Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:29.0858679Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:29.0858923Z   PR_NUMBER: 3500
2026-01-14T08:15:29.0860589Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:29.0862440Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:29.0863016Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:29.0863736Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:29.0864108Z ##[endgroup]
2026-01-14T08:15:29.0892574Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:15:29.0893517Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:29.0902375Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:29.0902732Z env:
2026-01-14T08:15:29.0902996Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:29.0903346Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:29.0903594Z   PR_NUMBER: 3500
2026-01-14T08:15:29.0905287Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:29.0907210Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:29.0907803Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:29.0908359Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:29.0908737Z ##[endgroup]
2026-01-14T08:15:29.1018092Z ##[group]Run set -euo pipefail
2026-01-14T08:15:29.1018400Z [36;1mset -euo pipefail[0m
2026-01-14T08:15:29.1018651Z [36;1m[0m
2026-01-14T08:15:29.1018850Z [36;1mhas_gpu=false[0m
2026-01-14T08:15:29.1019096Z [36;1mdevices=""[0m
2026-01-14T08:15:29.1019316Z [36;1m[0m
2026-01-14T08:15:29.1019590Z [36;1mif command -v nvidia-smi >/dev/null 2>&1; then[0m
2026-01-14T08:15:29.1020031Z [36;1m  if nvidia-smi -L >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:15:29.1020427Z [36;1m    has_gpu=true[0m
2026-01-14T08:15:29.1020718Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:15:29.1021027Z [36;1m  fi[0m
2026-01-14T08:15:29.1021239Z [36;1mfi[0m
2026-01-14T08:15:29.1021433Z [36;1m[0m
2026-01-14T08:15:29.1021653Z [36;1mif [ "$has_gpu" = false ]; then[0m
2026-01-14T08:15:29.1022041Z [36;1m  if ls /dev/nvidia* >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:15:29.1022419Z [36;1m    has_gpu=true[0m
2026-01-14T08:15:29.1022964Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:15:29.1023273Z [36;1m  fi[0m
2026-01-14T08:15:29.1023479Z [36;1mfi[0m
2026-01-14T08:15:29.1023672Z [36;1m[0m
2026-01-14T08:15:29.1023986Z [36;1mif [ "$has_gpu" = false ] && command -v lspci >/dev/null 2>&1; then[0m
2026-01-14T08:15:29.1024500Z [36;1m  if lspci | grep -i 'nvidia' >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:15:29.1024920Z [36;1m    has_gpu=true[0m
2026-01-14T08:15:29.1025206Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:15:29.1025515Z [36;1m  fi[0m
2026-01-14T08:15:29.1025749Z [36;1mfi[0m
2026-01-14T08:15:29.1025943Z [36;1m[0m
2026-01-14T08:15:29.1026239Z [36;1mprintf 'HAS_NVIDIA=%s\n' "$has_gpu" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:29.1026767Z [36;1mprintf 'DETECTED_DEVICES<<EOF\n%s\nEOF\n' "$devices" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:29.1035667Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:29.1036163Z env:
2026-01-14T08:15:29.1036516Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:29.1037018Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:29.1037370Z   PR_NUMBER: 3500
2026-01-14T08:15:29.1039348Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:29.1041433Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:29.1042025Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:29.1042588Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:29.1042964Z ##[endgroup]
2026-01-14T08:15:32.7049716Z ##[group]Run if [ "${HAS_NVIDIA}" = "true" ]; then
2026-01-14T08:15:32.7050122Z [36;1mif [ "${HAS_NVIDIA}" = "true" ]; then[0m
2026-01-14T08:15:32.7050496Z [36;1m  echo "HAS_NVIDIA_GPU=true" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:32.7051014Z [36;1m  echo "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:32.7051584Z [36;1melse[0m
2026-01-14T08:15:32.7051898Z [36;1m  echo "HAS_NVIDIA_GPU=false" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:32.7052233Z [36;1mfi[0m
2026-01-14T08:15:32.7062750Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:32.7063162Z env:
2026-01-14T08:15:32.7063416Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:32.7063777Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:32.7064025Z   PR_NUMBER: 3500
2026-01-14T08:15:32.7065681Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:32.7067557Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:32.7068283Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:32.7069042Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:32.7069562Z   HAS_NVIDIA: true
2026-01-14T08:15:32.7069824Z ##[endgroup]
2026-01-14T08:15:32.7177898Z ##[group]Run nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482
2026-01-14T08:15:32.7178476Z with:
2026-01-14T08:15:32.7178829Z   timeout_minutes: 10
2026-01-14T08:15:32.7179334Z   max_attempts: 3
2026-01-14T08:15:32.7212150Z   command: # Is it disgusting to have a full shell script here in this github action? Sure
# But is it the best way to make it so that this action relies on nothing else? Absolutely
set -eou pipefail

DISTRIBUTION=$(. /etc/os-release;echo $ID$VERSION_ID)
DRIVER_FN="NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"

install_nvidia_docker2_amzn2() {
    (
        set -x
        # Needed for yum-config-manager
        sudo yum install -y yum-utils
        if [[ "${DISTRIBUTION}" == "amzn2023" ]] ; then
          YUM_REPO_URL="https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo"
        else
          # Amazon Linux 2
          YUM_REPO_URL="https://nvidia.github.io/nvidia-docker/${DISTRIBUTION}/nvidia-docker.repo"
        fi

        sudo yum-config-manager --add-repo "${YUM_REPO_URL}"
        sudo yum install -y \
          nvidia-container-toolkit-1.17.8 \
          libnvidia-container-tools-1.17.8 \
          libnvidia-container1-1.17.8 \
          nvidia-container-toolkit-base-1.17.8
        sudo systemctl restart docker
    )
}

install_nvidia_docker2_ubuntu20() {
    (
        set -x
        # Install nvidia-driver package if not installed
        status="$(dpkg-query -W --showformat='${db:Status-Status}' nvidia-docker2 2>&1)"
        if [ ! $? = 0 ] || [ ! "$status" = installed ]; then
          sudo apt-get install -y nvidia-container-toolkit-1.17.8
          sudo systemctl restart docker
        fi
    )
}

pre_install_nvidia_driver_amzn2() {
    (
        # Purge any nvidia driver installed from RHEL repo
        sudo yum remove -y nvidia-driver-latest-dkms
    )
}

install_nvidia_driver_common() {
    (
        # Try to gather more information about the runner and its existing NVIDIA driver if any
        echo "Before installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        HAS_NVIDIA_DRIVER=0
        # Check if NVIDIA driver has already been installed
        if [ -x "$(command -v nvidia-smi)" ]; then
            set +e
            # The driver exists, check its version next. Also check only the first GPU if there are more than one of them
            # so that the same driver version is not print over multiple lines
            INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
            NVIDIA_SMI_STATUS=$?

            if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                echo "Failed to get NVIDIA driver version ($INSTALLED_DRIVER_VERSION). Continuing"
            elif [ "$INSTALLED_DRIVER_VERSION" != "$DRIVER_VERSION" ]; then
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has been installed, but we expect to have $DRIVER_VERSION instead. Continuing"

                # Turn off persistent mode so that the installation script can unload the kernel module
                sudo killall nvidia-persistenced || true
            else
                HAS_NVIDIA_DRIVER=1
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has already been installed. Skipping NVIDIA driver installation"
            fi
            set -e
        fi

        if [ "$HAS_NVIDIA_DRIVER" -eq 0 ]; then
            # CAUTION: this may need to be updated in future
            if [ "${DISTRIBUTION}" != ubuntu20.04 ]; then
                  sudo yum groupinstall -y "Development Tools"
                  # ensure our kernel install is the same as our underlying kernel,
                  # groupinstall "Development Tools" has a habit of mismatching kernel headers
                  sudo yum install -y "kernel-devel-uname-r == $(uname -r)"
                  sudo modprobe backlight
            fi
            sudo curl -fsL -o /tmp/nvidia_driver "https://s3.amazonaws.com/ossci-linux/nvidia_driver/$DRIVER_FN"

            set +e
            sudo /bin/bash /tmp/nvidia_driver -s --no-drm
            NVIDIA_INSTALLATION_STATUS=$?

            RESET_GPU=0
            if [ "$NVIDIA_INSTALLATION_STATUS" -ne 0 ]; then
                sudo cat /var/log/nvidia-installer.log
                # Fail to install NVIDIA driver, try to reset the GPU
                RESET_GPU=1
            elif [ -x "$(command -v nvidia-smi)" ]; then
                # Check again if nvidia-smi works even if the driver installation completes successfully
                INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
                NVIDIA_SMI_STATUS=$?

                if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                    RESET_GPU=1
                fi
            fi

            if [ "$RESET_GPU" -eq 1 ]; then
                NVIDIA_DEVICES=$(lspci -D | grep -i NVIDIA | cut -d' ' -f1)
                # The GPU can get stuck in a failure state if somehow the test crashs the GPU microcode. When this
                # happens, we'll try to reset all NVIDIA devices https://github.com/pytorch/pytorch/issues/88388
                for PCI_ID in $NVIDIA_DEVICES; do
                    DEVICE_ENABLED=$(cat /sys/bus/pci/devices/$PCI_ID/enable)

                    echo "Reseting $PCI_ID (enabled state: $DEVICE_ENABLED)"
                    # This requires sudo permission of course
                    echo "1" | sudo tee /sys/bus/pci/devices/$PCI_ID/reset
                    sleep 1
                done
            fi

            sudo rm -fv /tmp/nvidia_driver
            set -e
        fi
    )
}

post_install_nvidia_driver_common() {
    (
        sudo modprobe nvidia || true
        echo "After installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        (
            set +e

            nvidia-smi
            # NB: Annoyingly, nvidia-smi command returns successfully with return code 0 even in
            # the case where the driver has already crashed as it still can get the driver version
            # and some basic information like the bus ID.  However, the rest of the information
            # would be missing (ERR!), for example:
            #
            # +-----------------------------------------------------------------------------+
            # | NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |
            # |-------------------------------+----------------------+----------------------+
            # | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
            # | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
            # |                               |                      |               MIG M. |
            # |===============================+======================+======================|
            # |   0  ERR!                Off  | 00000000:00:1E.0 Off |                 ERR! |
            # |ERR!  ERR! ERR!    ERR! / ERR! |   4184MiB / 23028MiB |    ERR!      Default |
            # |                               |                      |                 ERR! |
            # +-------------------------------+----------------------+----------------------+
            #
            # +-----------------------------------------------------------------------------+
            # | Processes:                                                                  |
            # |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
            # |        ID   ID                                                   Usage      |
            # |=============================================================================|
            # +-----------------------------------------------------------------------------+
            #
            # This should be reported as a failure instead as it will guarantee to fail when
            # Docker tries to run with --gpus all
            #
            # So, the correct check here is to query one of the missing piece of info like
            # GPU name, so that the command can fail accordingly
            nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
            NVIDIA_SMI_STATUS=$?

            # Allowable exit statuses for nvidia-smi, see: https://github.com/NVIDIA/gpu-operator/issues/285
            if [ "$NVIDIA_SMI_STATUS" -eq 0 ] || [ "$NVIDIA_SMI_STATUS" -eq 14 ]; then
                echo "INFO: Ignoring allowed status ${NVIDIA_SMI_STATUS}"
            else
                echo "ERROR: nvidia-smi exited with unresolved status ${NVIDIA_SMI_STATUS}"
                exit ${NVIDIA_SMI_STATUS}
            fi
            set -e
        )
    )
}

install_nvidia_driver_amzn2() {
    (
        set -x
        pre_install_nvidia_driver_amzn2
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

install_nvidia_driver_ubuntu20() {
    (
        set -x
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

echo "== Installing nvidia driver ${DRIVER_FN} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_driver_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_driver_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Install container toolkit based on distribution
echo "== Installing nvidia container toolkit for ${DISTRIBUTION} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_docker2_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_docker2_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Fix https://github.com/NVIDIA/nvidia-docker/issues/1648 on runners with
# more than one GPUs. This just needs to be run once. The command fails
# on subsequent runs and complains that the mode is already on, but that's
# ok
sudo nvidia-persistenced || true
# This should show persistence mode ON
nvidia-smi

# check if the container-toolkit is correctly installed and CUDA is available inside a container
docker run --rm -t --gpus=all public.ecr.aws/docker/library/python:3.13 nvidia-smi

2026-01-14T08:15:32.7245006Z   retry_wait_seconds: 10
2026-01-14T08:15:32.7245390Z   polling_interval_seconds: 1
2026-01-14T08:15:32.7245800Z   warning_on_retry: true
2026-01-14T08:15:32.7246152Z   continue_on_error: false
2026-01-14T08:15:32.7246519Z env:
2026-01-14T08:15:32.7246893Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:32.7247571Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:32.7248065Z   PR_NUMBER: 3500
2026-01-14T08:15:32.7249827Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:32.7251754Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:32.7252491Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:32.7253204Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:32.7253650Z   HAS_NVIDIA_GPU: true
2026-01-14T08:15:32.7254125Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:15:32.7254567Z   DRIVER_VERSION: 580.65.06
2026-01-14T08:15:32.7254917Z ##[endgroup]
2026-01-14T08:15:32.8147990Z == Installing nvidia driver NVIDIA-Linux-x86_64-580.65.06.run ==
2026-01-14T08:15:32.8149116Z + pre_install_nvidia_driver_amzn2
2026-01-14T08:15:32.8152058Z + sudo yum remove -y nvidia-driver-latest-dkms
2026-01-14T08:15:33.2249296Z No match for argument: nvidia-driver-latest-dkms
2026-01-14T08:15:33.2250051Z No packages marked for removal.
2026-01-14T08:15:33.2317986Z Dependencies resolved.
2026-01-14T08:15:33.2327991Z Nothing to do.
2026-01-14T08:15:33.2328634Z Complete!
2026-01-14T08:15:33.2670324Z + install_nvidia_driver_common
2026-01-14T08:15:33.2674167Z + echo 'Before installing NVIDIA driver'
2026-01-14T08:15:33.2674672Z + lspci
2026-01-14T08:15:33.2675593Z Before installing NVIDIA driver
2026-01-14T08:15:33.2795009Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:15:33.2795746Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:15:33.2796801Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:15:33.2797503Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:15:33.2798051Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:15:33.2798780Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:15:33.2799374Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:33.2800011Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:33.2800638Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:33.2801178Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:33.2801767Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:15:33.2802321Z + lsmod
2026-01-14T08:15:33.2858288Z Module                  Size  Used by
2026-01-14T08:15:33.2859324Z nvidia_uvm           1925120  0
2026-01-14T08:15:33.2859982Z nvidia              14286848  1 nvidia_uvm
2026-01-14T08:15:33.2860793Z drm                   602112  1 nvidia
2026-01-14T08:15:33.2861594Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:15:33.2862479Z backlight              24576  1 drm
2026-01-14T08:15:33.2863165Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:15:33.2864071Z mgc                    86016  1
2026-01-14T08:15:33.2865134Z lustre               1085440  4
2026-01-14T08:15:33.2865772Z mdc                   294912  2 lustre
2026-01-14T08:15:33.2866583Z fid                    36864  1 mdc
2026-01-14T08:15:33.2867331Z lov                   356352  5 mdc,lustre
2026-01-14T08:15:33.2868077Z osc                   479232  5 mdc
2026-01-14T08:15:33.2868694Z lmv                   225280  2 lustre
2026-01-14T08:15:33.2869221Z fld                    49152  2 lov,lmv
2026-01-14T08:15:33.2869603Z ksocklnd              188416  1
2026-01-14T08:15:33.2870002Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:15:33.2870719Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:15:33.2871301Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:15:33.2872073Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:15:33.2872741Z xt_conntrack           16384  1
2026-01-14T08:15:33.2873117Z nft_chain_nat          16384  3
2026-01-14T08:15:33.2873474Z xt_MASQUERADE          20480  1
2026-01-14T08:15:33.2873948Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:15:33.2874398Z nf_conntrack_netlink    57344  0
2026-01-14T08:15:33.2874949Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:15:33.2875606Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:15:33.2875995Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:15:33.2876453Z xfrm_user              57344  1
2026-01-14T08:15:33.2891278Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:15:33.2891633Z xt_addrtype            16384  2
2026-01-14T08:15:33.2891918Z nft_compat             20480  4
2026-01-14T08:15:33.2892238Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:15:33.2892678Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:15:33.2893077Z br_netfilter           36864  0
2026-01-14T08:15:33.2893373Z bridge                323584  1 br_netfilter
2026-01-14T08:15:33.2893672Z stp                    16384  1 bridge
2026-01-14T08:15:33.2893961Z llc                    16384  2 bridge,stp
2026-01-14T08:15:33.2894244Z overlay               167936  0
2026-01-14T08:15:33.2894499Z tls                   139264  0
2026-01-14T08:15:33.2894748Z nls_ascii              16384  1
2026-01-14T08:15:33.2895007Z nls_cp437              20480  1
2026-01-14T08:15:33.2895260Z vfat                   24576  1
2026-01-14T08:15:33.2895696Z fat                    86016  1 vfat
2026-01-14T08:15:33.2895974Z sunrpc                700416  2 lnet
2026-01-14T08:15:33.2896250Z ghash_clmulni_intel    16384  0
2026-01-14T08:15:33.2896510Z i8042                  45056  0
2026-01-14T08:15:33.2896759Z serio                  28672  3 i8042
2026-01-14T08:15:33.2897033Z ena                   196608  0
2026-01-14T08:15:33.2897327Z button                 24576  0
2026-01-14T08:15:33.2897579Z sch_fq_codel           20480  33
2026-01-14T08:15:33.2897848Z fuse                  184320  1
2026-01-14T08:15:33.2898096Z loop                   36864  0
2026-01-14T08:15:33.2898354Z dm_mod                188416  0
2026-01-14T08:15:33.2898599Z configfs               57344  1
2026-01-14T08:15:33.2898853Z dmi_sysfs              20480  0
2026-01-14T08:15:33.2899108Z crc32_pclmul           16384  0
2026-01-14T08:15:33.2899357Z crc32c_intel           24576  0
2026-01-14T08:15:33.2899611Z efivarfs               24576  1
2026-01-14T08:15:33.2899858Z + modinfo nvidia
2026-01-14T08:15:33.2900262Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:15:33.2900727Z import_ns:      DMA_BUF
2026-01-14T08:15:33.2900982Z alias:          char-major-195-*
2026-01-14T08:15:33.2901244Z version:        580.82.07
2026-01-14T08:15:33.2901496Z supported:      external
2026-01-14T08:15:33.2901746Z license:        Dual MIT/GPL
2026-01-14T08:15:33.2902038Z firmware:       nvidia/580.82.07/gsp_tu10x.bin
2026-01-14T08:15:33.2902529Z firmware:       nvidia/580.82.07/gsp_ga10x.bin
2026-01-14T08:15:33.2902853Z srcversion:     BA7240A71DCF7DC6FE88C1D
2026-01-14T08:15:33.2903191Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:15:33.2903548Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:15:33.2903907Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:15:33.2904259Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:15:33.2904603Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:15:33.2904946Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:15:33.2905295Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:15:33.2905615Z depends:        i2c-core,drm
2026-01-14T08:15:33.2905875Z retpoline:      Y
2026-01-14T08:15:33.2906099Z name:           nvidia
2026-01-14T08:15:33.2906475Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:15:33.2906990Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:15:33.2907456Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:15:33.2907914Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:15:33.2908234Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:15:33.2908592Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:15:33.2908920Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:15:33.2909225Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:15:33.2909537Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:15:33.2909916Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:15:33.2910325Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:15:33.2910655Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:15:33.2910961Z parm:           NVreg_EnableMSI:int
2026-01-14T08:15:33.2911271Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:15:33.2911653Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:15:33.2912077Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:15:33.2912465Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:15:33.2912897Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:15:33.2913319Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:15:33.2913759Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:15:33.2914188Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:15:33.2914532Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:15:33.2915066Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:15:33.2915457Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:15:33.2915803Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:15:33.2916118Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:15:33.2916457Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:15:33.2916774Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:15:33.2917097Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:15:33.2917472Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:15:33.2917839Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:15:33.2918203Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:15:33.2918574Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:15:33.2918905Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:15:33.2919261Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:15:33.2919624Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:15:33.2919972Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:15:33.2920314Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:15:33.2920659Z parm:           NVreg_RmMsg:charp
2026-01-14T08:15:33.2920938Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:15:33.2921261Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:15:33.2921590Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:15:33.2921999Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:15:33.2922328Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:15:33.2922678Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:15:33.2923128Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:15:33.2923451Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:15:33.2923802Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:15:33.2924145Z parm:           rm_firmware_active:charp
2026-01-14T08:15:33.2924442Z + HAS_NVIDIA_DRIVER=0
2026-01-14T08:15:33.2924691Z ++ command -v nvidia-smi
2026-01-14T08:15:33.2924950Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:15:33.2925210Z + set +e
2026-01-14T08:15:33.2925537Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:15:36.7441124Z + INSTALLED_DRIVER_VERSION=580.82.07
2026-01-14T08:15:36.7441454Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:15:36.7441703Z + '[' 0 -ne 0 ']'
2026-01-14T08:15:36.7441951Z + '[' 580.82.07 '!=' 580.65.06 ']'
2026-01-14T08:15:36.7442451Z + echo 'NVIDIA driver (580.82.07) has been installed, but we expect to have 580.65.06 instead. Continuing'
2026-01-14T08:15:36.7443009Z + sudo killall nvidia-persistenced
2026-01-14T08:15:36.7443496Z NVIDIA driver (580.82.07) has been installed, but we expect to have 580.65.06 instead. Continuing
2026-01-14T08:15:36.8607596Z nvidia-persistenced: no process found
2026-01-14T08:15:36.8628764Z + true
2026-01-14T08:15:36.8629170Z + set -e
2026-01-14T08:15:36.8629398Z + '[' 0 -eq 0 ']'
2026-01-14T08:15:36.8629655Z + '[' amzn2023 '!=' ubuntu20.04 ']'
2026-01-14T08:15:36.8629997Z + sudo yum groupinstall -y 'Development Tools'
2026-01-14T08:15:37.3965339Z Last metadata expiration check: 0:01:05 ago on Wed Jan 14 08:14:32 2026.
2026-01-14T08:15:37.4362927Z No match for group package "system-rpm-config"
2026-01-14T08:15:37.4381049Z No match for group package "rcs"
2026-01-14T08:15:37.4405013Z No match for group package "pkgconfig"
2026-01-14T08:15:37.5013113Z Dependencies resolved.
2026-01-14T08:15:37.5376623Z ================================================================================
2026-01-14T08:15:37.5377129Z  Package           Architecture     Version             Repository         Size
2026-01-14T08:15:37.5377589Z ================================================================================
2026-01-14T08:15:37.5377936Z Installing Groups:
2026-01-14T08:15:37.5378259Z  Development Tools                                                             
2026-01-14T08:15:37.5378567Z 
2026-01-14T08:15:37.5378940Z Transaction Summary
2026-01-14T08:15:37.5379212Z ================================================================================
2026-01-14T08:15:37.5379461Z 
2026-01-14T08:15:37.7625822Z ================================================================================
2026-01-14T08:15:37.7626187Z WARNING:
2026-01-14T08:15:37.7626441Z   A newer release of "Amazon Linux" is available.
2026-01-14T08:15:37.7626684Z 
2026-01-14T08:15:37.7626823Z   Available Versions:
2026-01-14T08:15:37.7626982Z 
2026-01-14T08:15:37.7627080Z   Version 2023.10.20260105:
2026-01-14T08:15:37.7627415Z     Run the following command to upgrade to 2023.10.20260105:
2026-01-14T08:15:37.7627689Z 
2026-01-14T08:15:37.7627817Z       dnf upgrade --releasever=2023.10.20260105
2026-01-14T08:15:37.7628054Z 
2026-01-14T08:15:37.7628144Z     Release notes:
2026-01-14T08:15:37.7628572Z      https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.10.20260105.html
2026-01-14T08:15:37.7628984Z 
2026-01-14T08:15:37.7629124Z ================================================================================
2026-01-14T08:15:37.7635936Z Complete!
2026-01-14T08:15:37.8088266Z ++ uname -r
2026-01-14T08:15:37.8104282Z + sudo yum install -y 'kernel-devel-uname-r == 6.1.158-180.294.amzn2023.x86_64'
2026-01-14T08:15:38.2826149Z Last metadata expiration check: 0:01:06 ago on Wed Jan 14 08:14:32 2026.
2026-01-14T08:15:38.3082286Z Using '==' operator in reldeps can result in an undefined behavior. It is deprecated and the support will be dropped in future versions. Use '=' operator instead.
2026-01-14T08:15:38.3202147Z Package kernel-devel-1:6.1.158-180.294.amzn2023.x86_64 is already installed.
2026-01-14T08:15:38.3822734Z Dependencies resolved.
2026-01-14T08:15:38.4182075Z Nothing to do.
2026-01-14T08:15:38.4182351Z Complete!
2026-01-14T08:15:38.4591063Z + sudo modprobe backlight
2026-01-14T08:15:38.6486769Z + sudo curl -fsL -o /tmp/nvidia_driver https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-580.65.06.run
2026-01-14T08:15:42.8081613Z + set +e
2026-01-14T08:15:42.8081915Z + sudo /bin/bash /tmp/nvidia_driver -s --no-drm
2026-01-14T08:15:44.1932523Z Verifying archive integrity... OK
2026-01-14T08:15:47.0475324Z Uncompressing NVIDIA Accelerated Graphics Driver for Linux-x86_64 580.65.06....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
2026-01-14T08:15:47.6768863Z 
2026-01-14T08:15:47.6769732Z WARNING: The nvidia-drm module will not be installed. As a result, DRM-KMS will not function with this installation of the NVIDIA driver.
2026-01-14T08:15:47.6770319Z 
2026-01-14T08:16:10.5279565Z 
2026-01-14T08:16:10.5281901Z WARNING: nvidia-installer was forced to guess the X library path '/usr/lib64' and X module path '/usr/lib64/xorg/modules'; these paths were not queryable from the system.  If X fails to find the NVIDIA X driver module, please install the `pkg-config` utility and the X.Org SDK/development package for your distribution and reinstall the driver.
2026-01-14T08:16:10.5283300Z 
2026-01-14T08:16:10.5306378Z 
2026-01-14T08:16:10.5307923Z WARNING: This NVIDIA driver package includes Vulkan components, but no Vulkan ICD loader was detected on this system. The NVIDIA Vulkan ICD will not function without the loader. Most distributions package the Vulkan loader; try installing the "vulkan-loader", "vulkan-icd-loader", or "libvulkan1" package.
2026-01-14T08:16:10.5309179Z 
2026-01-14T08:16:23.3529005Z + NVIDIA_INSTALLATION_STATUS=0
2026-01-14T08:16:23.3529330Z + RESET_GPU=0
2026-01-14T08:16:23.3529563Z + '[' 0 -ne 0 ']'
2026-01-14T08:16:23.3532735Z ++ command -v nvidia-smi
2026-01-14T08:16:23.3535568Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:16:23.3541861Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:16:27.2064921Z + INSTALLED_DRIVER_VERSION=580.65.06
2026-01-14T08:16:27.2065256Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:16:27.2065511Z + '[' 0 -ne 0 ']'
2026-01-14T08:16:27.2065736Z + '[' 0 -eq 1 ']'
2026-01-14T08:16:27.2065972Z + sudo rm -fv /tmp/nvidia_driver
2026-01-14T08:16:27.4170668Z removed '/tmp/nvidia_driver'
2026-01-14T08:16:27.4194632Z + set -e
2026-01-14T08:16:27.4198314Z + post_install_nvidia_driver_common
2026-01-14T08:16:27.4203710Z + sudo modprobe nvidia
2026-01-14T08:16:27.6090047Z + echo 'After installing NVIDIA driver'
2026-01-14T08:16:27.6090380Z + lspci
2026-01-14T08:16:27.6090952Z After installing NVIDIA driver
2026-01-14T08:16:27.6207091Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:16:27.6207639Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:16:27.6208219Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:16:27.6208781Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:16:27.6209279Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:16:27.6209840Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:16:27.6210342Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:27.6210807Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:27.6211268Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:27.6211714Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:27.6212225Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:16:27.6212651Z + lsmod
2026-01-14T08:16:27.6257348Z Module                  Size  Used by
2026-01-14T08:16:27.6257639Z nvidia_uvm           1921024  0
2026-01-14T08:16:27.6257935Z nvidia              14274560  1 nvidia_uvm
2026-01-14T08:16:27.6258322Z drm                   602112  1 nvidia
2026-01-14T08:16:27.6258669Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:16:27.6258998Z backlight              24576  1 drm
2026-01-14T08:16:27.6259287Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:16:27.6259668Z mgc                    86016  1
2026-01-14T08:16:27.6259933Z lustre               1085440  4
2026-01-14T08:16:27.6260200Z mdc                   294912  2 lustre
2026-01-14T08:16:27.6260480Z fid                    36864  1 mdc
2026-01-14T08:16:27.6260807Z lov                   356352  5 mdc,lustre
2026-01-14T08:16:27.6261153Z osc                   479232  5 mdc
2026-01-14T08:16:27.6261427Z lmv                   225280  2 lustre
2026-01-14T08:16:27.6261743Z fld                    49152  2 lov,lmv
2026-01-14T08:16:27.6262071Z ksocklnd              188416  1
2026-01-14T08:16:27.6262426Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:16:27.6262999Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:16:27.6263519Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:16:27.6264389Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:16:27.6264914Z xt_conntrack           16384  1
2026-01-14T08:16:27.6265189Z nft_chain_nat          16384  3
2026-01-14T08:16:27.6265454Z xt_MASQUERADE          20480  1
2026-01-14T08:16:27.6265769Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:16:27.6266117Z nf_conntrack_netlink    57344  0
2026-01-14T08:16:27.6266526Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:16:27.6267000Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:16:27.6267319Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:16:27.6267622Z xfrm_user              57344  1
2026-01-14T08:16:27.6267884Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:16:27.6268175Z xt_addrtype            16384  2
2026-01-14T08:16:27.6268433Z nft_compat             20480  4
2026-01-14T08:16:27.6268745Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:16:27.6269191Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:16:27.6269586Z br_netfilter           36864  0
2026-01-14T08:16:27.6269868Z bridge                323584  1 br_netfilter
2026-01-14T08:16:27.6270162Z stp                    16384  1 bridge
2026-01-14T08:16:27.6270452Z llc                    16384  2 bridge,stp
2026-01-14T08:16:27.6270735Z overlay               167936  0
2026-01-14T08:16:27.6271160Z tls                   139264  0
2026-01-14T08:16:27.6271408Z nls_ascii              16384  1
2026-01-14T08:16:27.6271664Z nls_cp437              20480  1
2026-01-14T08:16:27.6271911Z vfat                   24576  1
2026-01-14T08:16:27.6272163Z fat                    86016  1 vfat
2026-01-14T08:16:27.6272438Z sunrpc                700416  2 lnet
2026-01-14T08:16:27.6272713Z ghash_clmulni_intel    16384  0
2026-01-14T08:16:27.6272970Z i8042                  45056  0
2026-01-14T08:16:27.6273221Z serio                  28672  3 i8042
2026-01-14T08:16:27.6273498Z ena                   196608  0
2026-01-14T08:16:27.6273740Z button                 24576  0
2026-01-14T08:16:27.6274002Z sch_fq_codel           20480  33
2026-01-14T08:16:27.6274257Z fuse                  184320  1
2026-01-14T08:16:27.6274507Z loop                   36864  0
2026-01-14T08:16:27.6274852Z dm_mod                188416  0
2026-01-14T08:16:27.6275110Z configfs               57344  1
2026-01-14T08:16:27.6275369Z dmi_sysfs              20480  0
2026-01-14T08:16:27.6275627Z crc32_pclmul           16384  0
2026-01-14T08:16:27.6275885Z crc32c_intel           24576  0
2026-01-14T08:16:27.6276141Z efivarfs               24576  1
2026-01-14T08:16:27.6276393Z + modinfo nvidia
2026-01-14T08:16:27.6280953Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:16:27.6281434Z import_ns:      DMA_BUF
2026-01-14T08:16:27.6281714Z alias:          char-major-195-*
2026-01-14T08:16:27.6282101Z version:        580.65.06
2026-01-14T08:16:27.6282393Z supported:      external
2026-01-14T08:16:27.6282644Z license:        Dual MIT/GPL
2026-01-14T08:16:27.6282938Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:16:27.6283278Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:16:27.6283629Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:16:27.6283970Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:16:27.6284608Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:16:27.6285007Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:16:27.6285394Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:16:27.6285774Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:16:27.6286149Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:16:27.6286525Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:16:27.6286863Z depends:        i2c-core,drm
2026-01-14T08:16:27.6287139Z retpoline:      Y
2026-01-14T08:16:27.6287366Z name:           nvidia
2026-01-14T08:16:27.6287986Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:16:27.6288502Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:16:27.6288972Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:16:27.6289415Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:16:27.6289731Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:16:27.6290041Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:16:27.6290365Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:16:27.6290680Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:16:27.6290992Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:16:27.6291366Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:16:27.6291777Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:16:27.6292114Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:16:27.6292430Z parm:           NVreg_EnableMSI:int
2026-01-14T08:16:27.6292753Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:16:27.6293137Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:16:27.6293557Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:16:27.6293963Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:16:27.6294406Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:16:27.6294837Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:16:27.6295404Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:16:27.6295834Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:16:27.6296191Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:16:27.6296622Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:16:27.6297021Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:16:27.6297378Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:16:27.6297711Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:16:27.6298064Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:16:27.6298406Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:16:27.6298719Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:16:27.6299088Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:16:27.6299464Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:16:27.6299838Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:16:27.6300218Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:16:27.6300566Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:16:27.6300921Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:16:27.6301294Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:16:27.6301654Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:16:27.6302006Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:16:27.6302351Z parm:           NVreg_RmMsg:charp
2026-01-14T08:16:27.6302650Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:16:27.6302991Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:16:27.6303323Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:16:27.6303652Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:16:27.6303987Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:16:27.6304361Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:16:27.6304727Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:16:27.6305064Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:16:27.6305425Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:16:27.6305777Z parm:           rm_firmware_active:charp
2026-01-14T08:16:27.6306070Z + set +e
2026-01-14T08:16:27.6306255Z + nvidia-smi
2026-01-14T08:16:29.9745540Z Wed Jan 14 08:16:29 2026       
2026-01-14T08:16:29.9746145Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:29.9747302Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:16:29.9747868Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:29.9748427Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:16:29.9749016Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:16:29.9749508Z |                                         |                        |               MIG M. |
2026-01-14T08:16:29.9749940Z |=========================================+========================+======================|
2026-01-14T08:16:30.0083528Z |   0  NVIDIA A10G                    Off |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:16:30.0085283Z |  0%   29C    P0             62W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:30.0086445Z |                                         |                        |                  N/A |
2026-01-14T08:16:30.0087090Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:30.0087612Z |   1  NVIDIA A10G                    Off |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:16:30.0088113Z |  0%   29C    P0             57W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:30.0088559Z |                                         |                        |                  N/A |
2026-01-14T08:16:30.0089235Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:30.0089742Z |   2  NVIDIA A10G                    Off |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:16:30.0090239Z |  0%   28C    P0             59W /  300W |       0MiB /  23028MiB |      2%      Default |
2026-01-14T08:16:30.0090881Z |                                         |                        |                  N/A |
2026-01-14T08:16:30.0091530Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:30.0092210Z |   3  NVIDIA A10G                    Off |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:16:30.0092703Z |  0%   29C    P0             57W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:30.0093148Z |                                         |                        |                  N/A |
2026-01-14T08:16:30.0093612Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:30.0093948Z 
2026-01-14T08:16:30.0094147Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:30.0094645Z | Processes:                                                                              |
2026-01-14T08:16:30.0095149Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:16:30.0095637Z |        ID   ID                                                               Usage      |
2026-01-14T08:16:30.0096060Z |=========================================================================================|
2026-01-14T08:16:30.0110916Z |  No running processes found                                                             |
2026-01-14T08:16:30.0111654Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:31.6730694Z + nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
2026-01-14T08:16:34.0004257Z NVIDIA A10G
2026-01-14T08:16:35.0972607Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:16:35.1004356Z + '[' 0 -eq 0 ']'
2026-01-14T08:16:35.1004659Z + echo 'INFO: Ignoring allowed status 0'
2026-01-14T08:16:35.1004999Z + set -e
2026-01-14T08:16:35.1005215Z INFO: Ignoring allowed status 0
2026-01-14T08:16:35.1005628Z == Installing nvidia container toolkit for amzn2023 ==
2026-01-14T08:16:35.1006062Z + sudo yum install -y yum-utils
2026-01-14T08:16:35.5751532Z Last metadata expiration check: 0:02:03 ago on Wed Jan 14 08:14:32 2026.
2026-01-14T08:16:35.6034396Z Package dnf-utils-4.3.0-13.amzn2023.0.5.noarch is already installed.
2026-01-14T08:16:35.6664918Z Dependencies resolved.
2026-01-14T08:16:35.7028773Z Nothing to do.
2026-01-14T08:16:35.7472348Z Complete!
2026-01-14T08:16:35.7472624Z + [[ amzn2023 == \a\m\z\n\2\0\2\3 ]]
2026-01-14T08:16:35.7473208Z + YUM_REPO_URL=https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:16:35.7474160Z + sudo yum-config-manager --add-repo https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:16:36.0279499Z Adding repo from: https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:16:36.0737296Z + sudo yum install -y nvidia-container-toolkit-1.17.8 libnvidia-container-tools-1.17.8 libnvidia-container1-1.17.8 nvidia-container-toolkit-base-1.17.8
2026-01-14T08:16:36.6461361Z nvidia-container-toolkit                         18 kB/s | 833  B     00:00    
2026-01-14T08:16:36.7401278Z Dependencies resolved.
2026-01-14T08:16:36.7763524Z ================================================================================
2026-01-14T08:16:36.7763990Z  Package                       Arch   Version    Repository                Size
2026-01-14T08:16:36.7764430Z ================================================================================
2026-01-14T08:16:36.7764765Z Downgrading:
2026-01-14T08:16:36.7765402Z  libnvidia-container-tools     x86_64 1.17.8-1   nvidia-container-toolkit  40 k
2026-01-14T08:16:36.7766004Z  libnvidia-container1          x86_64 1.17.8-1   nvidia-container-toolkit 1.0 M
2026-01-14T08:16:36.7766591Z  nvidia-container-toolkit      x86_64 1.17.8-1   nvidia-container-toolkit 1.2 M
2026-01-14T08:16:36.7767214Z  nvidia-container-toolkit-base x86_64 1.17.8-1   nvidia-container-toolkit 5.8 M
2026-01-14T08:16:36.7767592Z 
2026-01-14T08:16:36.7767684Z Transaction Summary
2026-01-14T08:16:36.7767964Z ================================================================================
2026-01-14T08:16:36.7768312Z Downgrade  4 Packages
2026-01-14T08:16:36.7768466Z 
2026-01-14T08:16:36.7768574Z Total download size: 8.0 M
2026-01-14T08:16:36.7768872Z Downloading Packages:
2026-01-14T08:16:36.7953906Z (1/4): libnvidia-container-tools-1.17.8-1.x86_6 2.3 MB/s |  40 kB     00:00    
2026-01-14T08:16:36.8209805Z (2/4): nvidia-container-toolkit-1.17.8-1.x86_64  29 MB/s | 1.2 MB     00:00    
2026-01-14T08:16:36.8277619Z (3/4): libnvidia-container1-1.17.8-1.x86_64.rpm  20 MB/s | 1.0 MB     00:00    
2026-01-14T08:16:36.8622506Z (4/4): nvidia-container-toolkit-base-1.17.8-1.x  87 MB/s | 5.8 MB     00:00    
2026-01-14T08:16:36.8633838Z --------------------------------------------------------------------------------
2026-01-14T08:16:36.8636587Z Total                                            93 MB/s | 8.0 MB     00:00     
2026-01-14T08:16:36.8639000Z Running transaction check
2026-01-14T08:16:36.8769933Z Transaction check succeeded.
2026-01-14T08:16:36.8770791Z Running transaction test
2026-01-14T08:16:36.9273925Z Transaction test succeeded.
2026-01-14T08:16:36.9276823Z Running transaction
2026-01-14T08:16:37.5193655Z   Preparing        :                                                        1/1 
2026-01-14T08:16:37.6088878Z   Downgrading      : nvidia-container-toolkit-base-1.17.8-1.x86_64          1/8 
2026-01-14T08:16:37.6125872Z   Downgrading      : libnvidia-container1-1.17.8-1.x86_64                   2/8 
2026-01-14T08:16:37.6427647Z   Running scriptlet: libnvidia-container1-1.17.8-1.x86_64                   2/8 
2026-01-14T08:16:37.7501616Z   Downgrading      : libnvidia-container-tools-1.17.8-1.x86_64              3/8 
2026-01-14T08:16:37.7544233Z   Downgrading      : nvidia-container-toolkit-1.17.8-1.x86_64               4/8 
2026-01-14T08:16:37.7757005Z   Running scriptlet: nvidia-container-toolkit-1.17.8-1.x86_64               4/8 
2026-01-14T08:16:37.7839413Z   Running scriptlet: nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:16:37.7840259Z   Cleanup          : nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:16:37.7973672Z   Running scriptlet: nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:16:37.8055877Z   Running scriptlet: libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:16:37.8056482Z   Cleanup          : libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:16:37.8181746Z   Running scriptlet: libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:16:37.8268720Z   Running scriptlet: libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:16:37.8269494Z   Cleanup          : libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:16:37.8409110Z   Running scriptlet: libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:16:37.8496649Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:16:37.8497319Z   Cleanup          : nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:16:37.8631877Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:16:37.9264368Z   Running scriptlet: nvidia-container-toolkit-1.17.8-1.x86_64               8/8 
2026-01-14T08:16:40.8560459Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:16:40.8561169Z   Verifying        : libnvidia-container-tools-1.17.8-1.x86_64              1/8 
2026-01-14T08:16:40.8562011Z   Verifying        : libnvidia-container-tools-1.18.1-1.x86_64              2/8 
2026-01-14T08:16:40.8562585Z   Verifying        : libnvidia-container1-1.17.8-1.x86_64                   3/8 
2026-01-14T08:16:40.8563139Z   Verifying        : libnvidia-container1-1.18.1-1.x86_64                   4/8 
2026-01-14T08:16:40.8563701Z   Verifying        : nvidia-container-toolkit-1.17.8-1.x86_64               5/8 
2026-01-14T08:16:40.8564282Z   Verifying        : nvidia-container-toolkit-1.18.1-1.x86_64               6/8 
2026-01-14T08:16:40.8564852Z   Verifying        : nvidia-container-toolkit-base-1.17.8-1.x86_64          7/8 
2026-01-14T08:16:41.0062615Z   Verifying        : nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8================================================================================
2026-01-14T08:16:41.0063858Z WARNING:
2026-01-14T08:16:41.0064349Z   A newer release of "Amazon Linux" is available.
2026-01-14T08:16:41.0064897Z 
2026-01-14T08:16:41.0065092Z   Available Versions:
2026-01-14T08:16:41.0065409Z 
2026-01-14T08:16:41.0065588Z   Version 2023.10.20260105:
2026-01-14T08:16:41.0066280Z     Run the following command to upgrade to 2023.10.20260105:
2026-01-14T08:16:41.0066884Z 
2026-01-14T08:16:41.0067135Z       dnf upgrade --releasever=2023.10.20260105
2026-01-14T08:16:41.0067639Z 
2026-01-14T08:16:41.0067808Z     Release notes:
2026-01-14T08:16:41.0068737Z      https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.10.20260105.html
2026-01-14T08:16:41.0069665Z 
2026-01-14T08:16:41.0069933Z ================================================================================
2026-01-14T08:16:41.0775653Z  
2026-01-14T08:16:41.0775790Z 
2026-01-14T08:16:41.0775898Z Downgraded:
2026-01-14T08:16:41.0776274Z   libnvidia-container-tools-1.17.8-1.x86_64                                     
2026-01-14T08:16:41.0776865Z   libnvidia-container1-1.17.8-1.x86_64                                          
2026-01-14T08:16:41.0777438Z   nvidia-container-toolkit-1.17.8-1.x86_64                                      
2026-01-14T08:16:41.0778039Z   nvidia-container-toolkit-base-1.17.8-1.x86_64                                 
2026-01-14T08:16:41.0778404Z 
2026-01-14T08:16:41.0778487Z Complete!
2026-01-14T08:16:41.1301134Z + sudo systemctl restart docker
2026-01-14T08:16:49.6037362Z Wed Jan 14 08:16:49 2026       
2026-01-14T08:16:49.6037812Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:49.6038696Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:16:49.6039257Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:49.6039822Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:16:49.6040413Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:16:49.6040921Z |                                         |                        |               MIG M. |
2026-01-14T08:16:49.6041330Z |=========================================+========================+======================|
2026-01-14T08:16:49.6390169Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:16:49.6390674Z |  0%   30C    P0             61W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:49.6391137Z |                                         |                        |                  N/A |
2026-01-14T08:16:49.6391606Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:49.6392117Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:16:49.6392603Z |  0%   29C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:49.6393045Z |                                         |                        |                  N/A |
2026-01-14T08:16:49.6395375Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:49.6395901Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:16:49.6396397Z |  0%   28C    P0             58W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:49.6396853Z |                                         |                        |                  N/A |
2026-01-14T08:16:49.6397325Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:49.6397833Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:16:49.6398327Z |  0%   29C    P0             53W /  300W |       0MiB /  23028MiB |      2%      Default |
2026-01-14T08:16:49.6398775Z |                                         |                        |                  N/A |
2026-01-14T08:16:49.6399254Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:49.6399588Z 
2026-01-14T08:16:49.6399796Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:49.6400291Z | Processes:                                                                              |
2026-01-14T08:16:49.6400797Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:16:49.6401273Z |        ID   ID                                                               Usage      |
2026-01-14T08:16:49.6401703Z |=========================================================================================|
2026-01-14T08:16:49.6418943Z |  No running processes found                                                             |
2026-01-14T08:16:49.6419494Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:50.2838019Z Unable to find image 'public.ecr.aws/docker/library/python:3.13' locally
2026-01-14T08:16:50.5176516Z 3.13: Pulling from docker/library/python
2026-01-14T08:16:50.6252221Z 2ca1bfae7ba8: Pulling fs layer
2026-01-14T08:16:50.6252503Z 82e18c5e1c15: Pulling fs layer
2026-01-14T08:16:50.6252803Z be442a7e0d6f: Pulling fs layer
2026-01-14T08:16:50.6253071Z 26d823e3848f: Pulling fs layer
2026-01-14T08:16:50.6253344Z ca4b54413202: Pulling fs layer
2026-01-14T08:16:50.6253601Z b6513238a015: Pulling fs layer
2026-01-14T08:16:50.6253865Z 9b57076d00d4: Pulling fs layer
2026-01-14T08:16:50.6254381Z ca4b54413202: Waiting
2026-01-14T08:16:50.6254606Z 9b57076d00d4: Waiting
2026-01-14T08:16:50.6254829Z b6513238a015: Waiting
2026-01-14T08:16:50.6255040Z 26d823e3848f: Waiting
2026-01-14T08:16:50.7447844Z 82e18c5e1c15: Verifying Checksum
2026-01-14T08:16:50.7448159Z 82e18c5e1c15: Download complete
2026-01-14T08:16:50.8008567Z 2ca1bfae7ba8: Download complete
2026-01-14T08:16:50.8563000Z be442a7e0d6f: Verifying Checksum
2026-01-14T08:16:50.8563383Z be442a7e0d6f: Download complete
2026-01-14T08:16:50.8672236Z ca4b54413202: Verifying Checksum
2026-01-14T08:16:50.8672555Z ca4b54413202: Download complete
2026-01-14T08:16:50.9150936Z 9b57076d00d4: Download complete
2026-01-14T08:16:50.9986950Z b6513238a015: Verifying Checksum
2026-01-14T08:16:50.9987290Z b6513238a015: Download complete
2026-01-14T08:16:51.4266489Z 26d823e3848f: Verifying Checksum
2026-01-14T08:16:51.4266849Z 26d823e3848f: Download complete
2026-01-14T08:16:52.5874512Z 2ca1bfae7ba8: Pull complete
2026-01-14T08:16:53.3261802Z 82e18c5e1c15: Pull complete
2026-01-14T08:16:55.8585881Z be442a7e0d6f: Pull complete
2026-01-14T08:17:03.1870773Z 26d823e3848f: Pull complete
2026-01-14T08:17:03.4760830Z ca4b54413202: Pull complete
2026-01-14T08:17:04.2481299Z b6513238a015: Pull complete
2026-01-14T08:17:04.2718117Z 9b57076d00d4: Pull complete
2026-01-14T08:17:04.2856773Z Digest: sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:17:04.2900470Z Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.13
2026-01-14T08:17:10.0561354Z Wed Jan 14 08:17:10 2026       
2026-01-14T08:17:10.0561912Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:10.0562566Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:17:10.0563191Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:10.0563886Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:17:10.0564478Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:17:10.0564977Z |                                         |                        |               MIG M. |
2026-01-14T08:17:10.0565387Z |=========================================+========================+======================|
2026-01-14T08:17:10.1189397Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:17:10.1190709Z |  0%   26C    P8             11W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:10.1191272Z |                                         |                        |                  N/A |
2026-01-14T08:17:10.1191783Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:10.1192302Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:17:10.1192793Z |  0%   26C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:10.1193267Z |                                         |                        |                  N/A |
2026-01-14T08:17:10.1193744Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:10.1194254Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:17:10.1194824Z |  0%   25C    P8             11W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:10.1195268Z |                                         |                        |                  N/A |
2026-01-14T08:17:10.1195738Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:10.1196250Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:17:10.1197051Z |  0%   26C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:10.1197515Z |                                         |                        |                  N/A |
2026-01-14T08:17:10.1197978Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:10.1214798Z 
2026-01-14T08:17:10.1215062Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:10.1215744Z | Processes:                                                                              |
2026-01-14T08:17:10.1216252Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:17:10.1216746Z |        ID   ID                                                               Usage      |
2026-01-14T08:17:10.1217164Z |=========================================================================================|
2026-01-14T08:17:10.1249670Z |  No running processes found                                                             |
2026-01-14T08:17:10.1250283Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:11.8699579Z Command completed after 1 attempt(s).
2026-01-14T08:17:11.8808659Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T08:17:11.8809228Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T08:17:11.8809652Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T08:17:11.8810167Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T08:17:11.8810513Z [36;1m# Prune all of the docker images[0m
2026-01-14T08:17:11.8810876Z [36;1mdocker system prune -af[0m
2026-01-14T08:17:11.8825823Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:11.8826179Z env:
2026-01-14T08:17:11.8826441Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:11.8826786Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:11.8827041Z   PR_NUMBER: 3500
2026-01-14T08:17:11.8828737Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:11.8830626Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:11.8831242Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:11.8831791Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:11.8832180Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:11.8832497Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:11.8832845Z ##[endgroup]
2026-01-14T08:17:11.9164648Z "docker stop" requires at least 1 argument.
2026-01-14T08:17:11.9165005Z See 'docker stop --help'.
2026-01-14T08:17:11.9165312Z 
2026-01-14T08:17:11.9165477Z Usage:  docker stop [OPTIONS] CONTAINER [CONTAINER...]
2026-01-14T08:17:11.9165750Z 
2026-01-14T08:17:13.1292753Z Stop one or more running containers
2026-01-14T08:17:13.1293094Z Deleted Images:
2026-01-14T08:17:13.1293403Z untagged: public.ecr.aws/docker/library/python:3.13
2026-01-14T08:17:13.1294074Z untagged: public.ecr.aws/docker/library/python@sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:17:13.1294887Z deleted: sha256:6b1b86f270ccdb848adf78330c7a27041a2f8e971cfd9c808e1ad503d236f9ae
2026-01-14T08:17:13.1295501Z deleted: sha256:ab3ff5992dd09a2d006ef37d701d92e11590962848a698a0824ab2129505b946
2026-01-14T08:17:13.1296114Z deleted: sha256:c839d2b1d0949c101d8e022855435eedb0179697af77be6012f911dfcb69742c
2026-01-14T08:17:13.1296726Z deleted: sha256:b3fb8a2c0606137f473565b54a51bb1e18dfca24cbc417e0f7a0b3d68395d9ea
2026-01-14T08:17:13.1297637Z deleted: sha256:a643465a85469890e6e498fe0d0ac4e6a251e77c92a179ac27085d4ffeb4c8da
2026-01-14T08:17:13.1298255Z deleted: sha256:09db7ba2ba0ebb76125f8bf37573369eb90202594586d30c6f9c202d968f4d00
2026-01-14T08:17:13.1298873Z deleted: sha256:ba4e59af8cdbb2e2cd899773f1cdbcb3027d48d9be333f5a823d9cccfd5c4a15
2026-01-14T08:17:13.1299500Z deleted: sha256:da7213941eca995ecec09e85fe1affcac44194792b48cbacdd3c0d9038bbaf9e
2026-01-14T08:17:13.1299873Z 
2026-01-14T08:17:13.2414570Z Total reclaimed space: 1.109GB
2026-01-14T08:17:13.2522618Z ##[group]Run ./test-infra/.github/actions/setup-ssh
2026-01-14T08:17:13.2522974Z with:
2026-01-14T08:17:13.2523567Z   github-secret: ***
2026-01-14T08:17:13.2524274Z   instructions: All testing is done inside the container, to start an interactive session run:
   docker exec -it $(docker container ps --format '{{.ID}}') bash

2026-01-14T08:17:13.2525026Z   activate-with-label: false
2026-01-14T08:17:13.2525293Z   label: with-ssh
2026-01-14T08:17:13.2525533Z   remove-existing-keys: true
2026-01-14T08:17:13.2525800Z   fail-silently: true
2026-01-14T08:17:13.2526025Z env:
2026-01-14T08:17:13.2526268Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:13.2526625Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:13.2526875Z   PR_NUMBER: 3500
2026-01-14T08:17:13.2528574Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:13.2530634Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:13.2531212Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:13.2531763Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:13.2532156Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:13.2532469Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:13.2532827Z ##[endgroup]
2026-01-14T08:17:13.3738029Z Please see https://github.com/pytorch/pytorch/wiki/Debugging-using-with-ssh-for-Github-Actions for more info.
2026-01-14T08:17:13.9939866Z Grabbing public ssh keys from https://github.com/zxd1997066.keys
2026-01-14T08:17:14.0750903Z ~/.ssh/authorized_keys file found on node, removing ~/.ssh and starting fresh
2026-01-14T08:17:14.0766597Z Public keys pulled and installed to /home/ec2-user/.ssh/authorized_keys
2026-01-14T08:17:14.0820016Z Login using: ssh ec2-user@ec2-3-90-15-86.compute-1.amazonaws.com
2026-01-14T08:17:14.0820642Z All testing is done inside the container, to start an interactive session run:
2026-01-14T08:17:14.0821177Z    docker exec -it $(docker container ps --format '{{.ID}}') bash
2026-01-14T08:17:14.0982673Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:17:14.0983090Z with:
2026-01-14T08:17:14.0983313Z   repository: pytorch/ao
2026-01-14T08:17:14.0983570Z   ref: refs/pull/3500/merge
2026-01-14T08:17:14.0983828Z   path: pytorch/ao
2026-01-14T08:17:14.0984053Z   fetch-depth: 1
2026-01-14T08:17:14.0984585Z   submodules: recursive
2026-01-14T08:17:14.0984929Z   token: ***
2026-01-14T08:17:14.0985145Z   ssh-strict: true
2026-01-14T08:17:14.0985369Z   ssh-user: git
2026-01-14T08:17:14.0985597Z   persist-credentials: true
2026-01-14T08:17:14.0985857Z   clean: true
2026-01-14T08:17:14.0986117Z   sparse-checkout-cone-mode: true
2026-01-14T08:17:14.0986412Z   fetch-tags: false
2026-01-14T08:17:14.0986640Z   show-progress: true
2026-01-14T08:17:14.0986871Z   lfs: false
2026-01-14T08:17:14.0987092Z   set-safe-directory: true
2026-01-14T08:17:14.0987345Z env:
2026-01-14T08:17:14.0987587Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:14.0987960Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:14.0988208Z   PR_NUMBER: 3500
2026-01-14T08:17:14.0989886Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:14.0991800Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:14.0992394Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:14.0992947Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:14.0993340Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:14.0993646Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:14.0993990Z ##[endgroup]
2026-01-14T08:17:14.1991256Z Syncing repository: pytorch/ao
2026-01-14T08:17:14.2000736Z ##[group]Getting Git version info
2026-01-14T08:17:14.2001181Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao'
2026-01-14T08:17:14.2028203Z [command]/usr/bin/git version
2026-01-14T08:17:14.2082825Z git version 2.50.1
2026-01-14T08:17:14.2110390Z ##[endgroup]
2026-01-14T08:17:14.2123975Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/c2d11ffe-5dee-4c5f-bf0c-07d5e9d4cf29' before making global git config changes
2026-01-14T08:17:14.2124917Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:17:14.2139642Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:17:14.2178592Z ##[group]Initializing the repository
2026-01-14T08:17:14.2183384Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:17:14.2232461Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:17:14.2233079Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:17:14.2233640Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:17:14.2234046Z hint:
2026-01-14T08:17:14.2234324Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:17:14.2234659Z hint:
2026-01-14T08:17:14.2235050Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:17:14.2235612Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:17:14.2236044Z hint:
2026-01-14T08:17:14.2236265Z hint: 	git branch -m <name>
2026-01-14T08:17:14.2236505Z hint:
2026-01-14T08:17:14.2236861Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:17:14.2237530Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/
2026-01-14T08:17:14.2244660Z [command]/usr/bin/git remote add origin https://github.com/pytorch/ao
2026-01-14T08:17:14.2291358Z ##[endgroup]
2026-01-14T08:17:14.2291782Z ##[group]Disabling automatic garbage collection
2026-01-14T08:17:14.2295639Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:17:14.2333559Z ##[endgroup]
2026-01-14T08:17:14.2333951Z ##[group]Setting up auth
2026-01-14T08:17:14.2339590Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:17:14.2374495Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:17:14.2790071Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:17:14.2825062Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:17:14.3245355Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:17:14.3299506Z ##[endgroup]
2026-01-14T08:17:14.3299926Z ##[group]Fetching the repository
2026-01-14T08:17:14.3307010Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/pull/3500/merge:refs/remotes/pull/3500/merge
2026-01-14T08:17:15.0324769Z From https://github.com/pytorch/ao
2026-01-14T08:17:15.0325187Z  * [new ref]         refs/pull/3500/merge -> pull/3500/merge
2026-01-14T08:17:15.0354663Z ##[endgroup]
2026-01-14T08:17:15.0355131Z ##[group]Determining the checkout info
2026-01-14T08:17:15.0357302Z ##[endgroup]
2026-01-14T08:17:15.0362247Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:17:15.0410600Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:17:15.0444284Z ##[group]Checking out the ref
2026-01-14T08:17:15.0447978Z [command]/usr/bin/git checkout --progress --force refs/remotes/pull/3500/merge
2026-01-14T08:17:15.1879517Z Note: switching to 'refs/remotes/pull/3500/merge'.
2026-01-14T08:17:15.1879789Z 
2026-01-14T08:17:15.1880013Z You are in 'detached HEAD' state. You can look around, make experimental
2026-01-14T08:17:15.1880562Z changes and commit them, and you can discard any commits you make in this
2026-01-14T08:17:15.1881099Z state without impacting any branches by switching back to a branch.
2026-01-14T08:17:15.1881416Z 
2026-01-14T08:17:15.1881620Z If you want to create a new branch to retain commits you create, you may
2026-01-14T08:17:15.1882365Z do so (now or later) by using -c with the switch command. Example:
2026-01-14T08:17:15.1882651Z 
2026-01-14T08:17:15.1882762Z   git switch -c <new-branch-name>
2026-01-14T08:17:15.1882968Z 
2026-01-14T08:17:15.1883073Z Or undo this operation with:
2026-01-14T08:17:15.1883253Z 
2026-01-14T08:17:15.1883346Z   git switch -
2026-01-14T08:17:15.1883479Z 
2026-01-14T08:17:15.1883722Z Turn off this advice by setting config variable advice.detachedHead to false
2026-01-14T08:17:15.1884070Z 
2026-01-14T08:17:15.1884671Z HEAD is now at b34f898 Merge f07387cd29b2a97703e501a48808c413bf9d95ea into 985d970b5e16b58c1e5b8bab440169d3da78cf16
2026-01-14T08:17:15.1901033Z ##[endgroup]
2026-01-14T08:17:15.1901455Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:17:15.1907341Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:17:15.1959894Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:17:15.2002013Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:17:15.2032377Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:17:15.2067037Z ##[endgroup]
2026-01-14T08:17:15.2067575Z ##[group]Fetching submodules
2026-01-14T08:17:15.2070715Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:17:15.2470078Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:17:15.2857037Z Submodule 'third_party/cutlass' (https://github.com/NVIDIA/cutlass) registered for path 'third_party/cutlass'
2026-01-14T08:17:15.2892753Z Cloning into '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/third_party/cutlass'...
2026-01-14T08:17:17.4893036Z From https://github.com/NVIDIA/cutlass
2026-01-14T08:17:17.4893528Z  * branch            e51efbfe18fe4f4cbb66ab814c55bf4aa0185491 -> FETCH_HEAD
2026-01-14T08:17:18.2844162Z Submodule path 'third_party/cutlass': checked out 'e51efbfe18fe4f4cbb66ab814c55bf4aa0185491'
2026-01-14T08:17:18.2899305Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:17:18.3287164Z Entering 'third_party/cutlass'
2026-01-14T08:17:18.3368660Z ##[endgroup]
2026-01-14T08:17:18.3369124Z ##[group]Persisting credentials for submodules
2026-01-14T08:17:18.3374685Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:17:18.3759715Z Entering 'third_party/cutlass'
2026-01-14T08:17:18.3871731Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:17:18.4260261Z Entering 'third_party/cutlass'
2026-01-14T08:17:18.4332848Z file:/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/modules/third_party/cutlass/config	remote.origin.url
2026-01-14T08:17:18.4398766Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:17:18.4782467Z Entering 'third_party/cutlass'
2026-01-14T08:17:18.4871972Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:17:18.5256112Z Entering 'third_party/cutlass'
2026-01-14T08:17:18.5455532Z ##[endgroup]
2026-01-14T08:17:18.5500358Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:17:18.5530299Z b34f89824bef6a4573349bfbefa82a7db14ede35
2026-01-14T08:17:18.5808894Z Prepare all required actions
2026-01-14T08:17:18.5809621Z Getting action download info
2026-01-14T08:17:18.7087159Z Download action repository 'nick-fields/retry@v3.0.0' (SHA:7152eba30c6575329ac0576536151aca5a72780e)
2026-01-14T08:17:18.8811903Z ##[group]Run ./test-infra/.github/actions/calculate-docker-image
2026-01-14T08:17:18.8812304Z with:
2026-01-14T08:17:18.8812538Z   use-custom-docker-registry: true
2026-01-14T08:17:18.8812927Z   docker-image-name: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:18.8813317Z   docker-build-dir: .ci/docker
2026-01-14T08:17:18.8813644Z   working-directory: pytorch/ao
2026-01-14T08:17:18.8813956Z   docker-build-script: ./build.sh
2026-01-14T08:17:18.8814345Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:18.8814745Z   force-push: false
2026-01-14T08:17:18.8814971Z env:
2026-01-14T08:17:18.8815230Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:18.8815581Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:18.8815875Z   PR_NUMBER: 3500
2026-01-14T08:17:18.8817550Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:18.8819442Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:18.8820047Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:18.8820596Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:18.8820997Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:18.8821325Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:18.8821675Z ##[endgroup]
2026-01-14T08:17:18.8861213Z ##[group]Run set -ex
2026-01-14T08:17:18.8861484Z [36;1mset -ex[0m
2026-01-14T08:17:18.8861706Z [36;1m[0m
2026-01-14T08:17:18.8862092Z [36;1m# If the docker build directory or the build script doesn't exist, the action will[0m
2026-01-14T08:17:18.8862764Z [36;1m# gracefully return the docker image name as it is.  Pulling docker image in Linux[0m
2026-01-14T08:17:18.8863390Z [36;1m# job could then download the pre-built image as usual[0m
2026-01-14T08:17:18.8864125Z [36;1mif [[ -d "${DOCKER_BUILD_DIR}" ]] && [[ -f "${DOCKER_BUILD_DIR}/${DOCKER_BUILD_SCRIPT}" ]] && [[ "${USE_CUSTOM_DOCKER_REGISTRY}" == "true" ]]; then[0m
2026-01-14T08:17:18.8864817Z [36;1m  echo "skip=false" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:18.8865139Z [36;1melse[0m
2026-01-14T08:17:18.8865406Z [36;1m  echo "skip=true" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:18.8865851Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:18.8866263Z [36;1m[0m
2026-01-14T08:17:18.8866824Z [36;1m  echo "Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ${REPO_NAME} repo..."[0m
2026-01-14T08:17:18.8867466Z [36;1m  exit 0[0m
2026-01-14T08:17:18.8867686Z [36;1mfi[0m
2026-01-14T08:17:18.8867879Z [36;1m[0m
2026-01-14T08:17:18.8868226Z [36;1mif [[ "${DOCKER_IMAGE_NAME}" == *"${DOCKER_REGISTRY}/${REPO_NAME}"* ]]; then[0m
2026-01-14T08:17:18.8868841Z [36;1m  # The docker image name already includes the ECR prefix and tag, so we can just[0m
2026-01-14T08:17:18.8869382Z [36;1m  # use it as it is, but first let's extract the tag[0m
2026-01-14T08:17:18.8869872Z [36;1m  DOCKER_TAG=$(echo "${DOCKER_IMAGE_NAME}" | awk -F '[:,]' '{print $2}')[0m
2026-01-14T08:17:18.8870371Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:18.8870867Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:18.8871278Z [36;1melse[0m
2026-01-14T08:17:18.8871748Z [36;1m  if [[ "${DOCKER_IMAGE_NAME}" == *:* ]]; then[0m
2026-01-14T08:17:18.8872140Z [36;1m    CUSTOM_TAG_PREFIX=${DOCKER_IMAGE_NAME#*:}[0m
2026-01-14T08:17:18.8872544Z [36;1m    DOCKER_IMAGE_NAME=${DOCKER_IMAGE_NAME%%:*}[0m
2026-01-14T08:17:18.8872878Z [36;1m  fi[0m
2026-01-14T08:17:18.8873495Z [36;1m  DOCKER_TAG=${CUSTOM_TAG_PREFIX:+${CUSTOM_TAG_PREFIX}-}$(git rev-parse HEAD:"${DOCKER_BUILD_DIR}")[0m
2026-01-14T08:17:18.8874183Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:18.8874922Z [36;1m  echo "docker-image=${DOCKER_REGISTRY}/${REPO_NAME}/${DOCKER_IMAGE_NAME}:${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:18.8875628Z [36;1m  echo "custom-tag-prefix=${CUSTOM_TAG_PREFIX}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:18.8876052Z [36;1mfi[0m
2026-01-14T08:17:18.8886079Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:18.8886439Z env:
2026-01-14T08:17:18.8886688Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:18.8887046Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:18.8887299Z   PR_NUMBER: 3500
2026-01-14T08:17:18.8888974Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:18.8890844Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:18.8891428Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:18.8891978Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:18.8892371Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:18.8892673Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:18.8893032Z   REPO_NAME: ao
2026-01-14T08:17:18.8893372Z   DOCKER_IMAGE_NAME: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:18.8893736Z   DOCKER_BUILD_DIR: .ci/docker
2026-01-14T08:17:18.8894018Z   DOCKER_BUILD_SCRIPT: ./build.sh
2026-01-14T08:17:18.8894388Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:18.8894791Z   USE_CUSTOM_DOCKER_REGISTRY: true
2026-01-14T08:17:18.8895065Z   CUSTOM_TAG_PREFIX: 
2026-01-14T08:17:18.8895301Z ##[endgroup]
2026-01-14T08:17:18.8927299Z + [[ -d .ci/docker ]]
2026-01-14T08:17:18.8927585Z + echo skip=true
2026-01-14T08:17:18.8927898Z + echo docker-image=pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:18.8928566Z + echo 'Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...'
2026-01-14T08:17:18.8929151Z + exit 0
2026-01-14T08:17:18.8929627Z Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...
2026-01-14T08:17:18.8971744Z ##[group]Run set -eux
2026-01-14T08:17:18.8972055Z [36;1mset -eux[0m
2026-01-14T08:17:18.8972498Z [36;1m# It's ok if this steps fails, it would then be an anonymous user like what we used to have[0m
2026-01-14T08:17:18.8973705Z [36;1maws secretsmanager get-secret-value --secret-id docker_hub_readonly_token | jq --raw-output '.SecretString' | jq -r .docker_hub_readonly_token | docker login --username pytorchbot --password-stdin || true[0m
2026-01-14T08:17:18.8983661Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:18.8984031Z env:
2026-01-14T08:17:18.8984496Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:18.8984860Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:18.8985127Z   PR_NUMBER: 3500
2026-01-14T08:17:18.8987002Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:18.8988900Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:18.8989638Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:18.8990188Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:18.8990588Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:18.8990904Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:18.8991266Z ##[endgroup]
2026-01-14T08:17:18.9026142Z + aws secretsmanager get-secret-value --secret-id docker_hub_readonly_token
2026-01-14T08:17:18.9028624Z + jq --raw-output .SecretString
2026-01-14T08:17:18.9028951Z + jq -r .docker_hub_readonly_token
2026-01-14T08:17:18.9029603Z + docker login --username pytorchbot --password-stdin
2026-01-14T08:17:19.5131831Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:17:19.5132458Z Configure a credential helper to remove this warning. See
2026-01-14T08:17:19.5133019Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:17:19.5133428Z 
2026-01-14T08:17:19.5133599Z Login Succeeded
2026-01-14T08:17:19.5217167Z Prepare all required actions
2026-01-14T08:17:19.5258088Z ##[group]Run ./test-infra/.github/actions/pull-docker-image
2026-01-14T08:17:19.5258454Z with:
2026-01-14T08:17:19.5258723Z   docker-image: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:19.5259167Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:19.5259541Z env:
2026-01-14T08:17:19.5259792Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:19.5260131Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:19.5260388Z   PR_NUMBER: 3500
2026-01-14T08:17:19.5262041Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:19.5263978Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:19.5264560Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:19.5265108Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:19.5265490Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:19.5265804Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:19.5266151Z ##[endgroup]
2026-01-14T08:17:19.5305948Z ##[group]Run set -x
2026-01-14T08:17:19.5306317Z [36;1mset -x[0m
2026-01-14T08:17:19.5306527Z [36;1mset +e[0m
2026-01-14T08:17:19.5306727Z [36;1m[0m
2026-01-14T08:17:19.5306924Z [36;1mlogin() {[0m
2026-01-14T08:17:19.5307392Z [36;1m  aws ecr get-login-password --region us-east-1 | docker login -u AWS --password-stdin "$1"[0m
2026-01-14T08:17:19.5307914Z [36;1m}[0m
2026-01-14T08:17:19.5308099Z [36;1m[0m
2026-01-14T08:17:19.5308292Z [36;1mretry () {[0m
2026-01-14T08:17:19.5308567Z [36;1m  $*  || (sleep 1 && $*) || (sleep 2 && $*)[0m
2026-01-14T08:17:19.5308859Z [36;1m}[0m
2026-01-14T08:17:19.5309059Z [36;1m[0m
2026-01-14T08:17:19.5309277Z [36;1mretry login "${DOCKER_REGISTRY}"[0m
2026-01-14T08:17:19.5309572Z [36;1m[0m
2026-01-14T08:17:19.5310046Z [36;1mIMAGE_SIZE=$(docker manifest inspect "${DOCKER_IMAGE}" | jq '[.layers[].size, .config.size] | add / 1024 / 1024')[0m
2026-01-14T08:17:19.5310714Z [36;1mecho "Compressed size of image in MB: ${IMAGE_SIZE}"[0m
2026-01-14T08:17:19.5311070Z [36;1m[0m
2026-01-14T08:17:19.5311271Z [36;1mset -e[0m
2026-01-14T08:17:19.5311604Z [36;1m# ignore output since only exit code is used for conditional[0m
2026-01-14T08:17:19.5312082Z [36;1m# only pull docker image if it's not available locally[0m
2026-01-14T08:17:19.5312621Z [36;1mif ! docker inspect --type=image "${DOCKER_IMAGE}" >/dev/null 2>/dev/null; then[0m
2026-01-14T08:17:19.5313118Z [36;1m  retry docker pull "${DOCKER_IMAGE}"[0m
2026-01-14T08:17:19.5313646Z [36;1mfi[0m
2026-01-14T08:17:19.5324511Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:19.5324873Z env:
2026-01-14T08:17:19.5325122Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:19.5325487Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:19.5325733Z   PR_NUMBER: 3500
2026-01-14T08:17:19.5327399Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:19.5329263Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:19.5329845Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:19.5330572Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:19.5330976Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:19.5331286Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:19.5331740Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:19.5332113Z ##[endgroup]
2026-01-14T08:17:19.5364412Z + set +e
2026-01-14T08:17:19.5364895Z + retry login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:19.5365311Z + login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:19.5368567Z + aws ecr get-login-password --region us-east-1
2026-01-14T08:17:19.5370264Z + docker login -u AWS --password-stdin 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:20.0942443Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:17:20.0943428Z Configure a credential helper to remove this warning. See
2026-01-14T08:17:20.0943950Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:17:20.0944345Z 
2026-01-14T08:17:20.0944473Z Login Succeeded
2026-01-14T08:17:20.0979113Z ++ jq '[.layers[].size, .config.size] | add / 1024 / 1024'
2026-01-14T08:17:20.0979566Z ++ docker manifest inspect pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:20.2970159Z + IMAGE_SIZE=7985.954789161682
2026-01-14T08:17:20.2970477Z Compressed size of image in MB: 7985.954789161682
2026-01-14T08:17:20.2970876Z + echo 'Compressed size of image in MB: 7985.954789161682'
2026-01-14T08:17:20.2971215Z + set -e
2026-01-14T08:17:20.2971528Z + docker inspect --type=image pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:20.3137863Z + retry docker pull pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:20.3138300Z + docker pull pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:20.4859583Z cuda12.6: Pulling from pytorch/almalinux-builder
2026-01-14T08:17:20.4859958Z 19877a9af8e3: Pulling fs layer
2026-01-14T08:17:20.4861153Z 7335f5694751: Pulling fs layer
2026-01-14T08:17:20.4861624Z e89b428500ef: Pulling fs layer
2026-01-14T08:17:20.4862006Z 2890bcc97ae2: Pulling fs layer
2026-01-14T08:17:20.4862271Z 8e7a9d654295: Pulling fs layer
2026-01-14T08:17:20.4862528Z 55070e1f6d59: Pulling fs layer
2026-01-14T08:17:20.4862795Z a6ffcda215dd: Pulling fs layer
2026-01-14T08:17:20.4863055Z 4f4fb700ef54: Pulling fs layer
2026-01-14T08:17:20.4863320Z d4e5a2339eb1: Pulling fs layer
2026-01-14T08:17:20.4863585Z 3b50177ed801: Pulling fs layer
2026-01-14T08:17:20.4863886Z 657cfc9d9d43: Pulling fs layer
2026-01-14T08:17:20.4864137Z 039239a19e2c: Pulling fs layer
2026-01-14T08:17:20.4864394Z 301a59dd8ea1: Pulling fs layer
2026-01-14T08:17:20.4864648Z 747a1c0117bc: Pulling fs layer
2026-01-14T08:17:20.4864910Z 2d6f0c29ad9f: Pulling fs layer
2026-01-14T08:17:20.4865169Z 5b7921a1b019: Pulling fs layer
2026-01-14T08:17:20.4865422Z a4392ccb83ef: Pulling fs layer
2026-01-14T08:17:20.4865685Z 3f0968dff130: Pulling fs layer
2026-01-14T08:17:20.4865926Z 8e7a9d654295: Waiting
2026-01-14T08:17:20.4866150Z 2890bcc97ae2: Waiting
2026-01-14T08:17:20.4866699Z 9323969b3930: Pulling fs layer
2026-01-14T08:17:20.4866965Z b9f6732b07f0: Pulling fs layer
2026-01-14T08:17:20.4867215Z 32117f6e66ab: Pulling fs layer
2026-01-14T08:17:20.4867466Z 4f4fb700ef54: Waiting
2026-01-14T08:17:20.4867681Z 55070e1f6d59: Waiting
2026-01-14T08:17:20.4867914Z bed95346686d: Pulling fs layer
2026-01-14T08:17:20.4868176Z a73f5cbdff4f: Pulling fs layer
2026-01-14T08:17:20.4868417Z 9323969b3930: Waiting
2026-01-14T08:17:20.4868635Z 301a59dd8ea1: Waiting
2026-01-14T08:17:20.4868852Z b9f6732b07f0: Waiting
2026-01-14T08:17:20.4869074Z 32117f6e66ab: Waiting
2026-01-14T08:17:20.4869288Z d4e5a2339eb1: Waiting
2026-01-14T08:17:20.4869507Z 747a1c0117bc: Waiting
2026-01-14T08:17:20.4869723Z bed95346686d: Waiting
2026-01-14T08:17:20.4869945Z a73f5cbdff4f: Waiting
2026-01-14T08:17:20.4870159Z 3b50177ed801: Waiting
2026-01-14T08:17:20.4870375Z 2d6f0c29ad9f: Waiting
2026-01-14T08:17:20.4870597Z a4392ccb83ef: Waiting
2026-01-14T08:17:20.4870831Z 657cfc9d9d43: Waiting
2026-01-14T08:17:20.4871289Z 5b7921a1b019: Waiting
2026-01-14T08:17:20.4871508Z 039239a19e2c: Waiting
2026-01-14T08:17:20.4871734Z 3f0968dff130: Waiting
2026-01-14T08:17:20.4871956Z a6ffcda215dd: Waiting
2026-01-14T08:17:20.6166491Z e89b428500ef: Verifying Checksum
2026-01-14T08:17:20.6166906Z e89b428500ef: Download complete
2026-01-14T08:17:20.9937776Z 2890bcc97ae2: Verifying Checksum
2026-01-14T08:17:20.9938101Z 2890bcc97ae2: Download complete
2026-01-14T08:17:21.2268068Z 19877a9af8e3: Verifying Checksum
2026-01-14T08:17:21.2268418Z 19877a9af8e3: Download complete
2026-01-14T08:17:21.2929505Z 55070e1f6d59: Download complete
2026-01-14T08:17:21.7814155Z a6ffcda215dd: Verifying Checksum
2026-01-14T08:17:21.7814530Z a6ffcda215dd: Download complete
2026-01-14T08:17:21.8419084Z 4f4fb700ef54: Verifying Checksum
2026-01-14T08:17:21.8419402Z 4f4fb700ef54: Download complete
2026-01-14T08:17:21.8862445Z d4e5a2339eb1: Verifying Checksum
2026-01-14T08:17:21.8862753Z d4e5a2339eb1: Download complete
2026-01-14T08:17:21.9291913Z 3b50177ed801: Verifying Checksum
2026-01-14T08:17:21.9292213Z 3b50177ed801: Download complete
2026-01-14T08:17:21.9771847Z 657cfc9d9d43: Verifying Checksum
2026-01-14T08:17:21.9772166Z 657cfc9d9d43: Download complete
2026-01-14T08:17:22.0211515Z 039239a19e2c: Download complete
2026-01-14T08:17:22.3666064Z 7335f5694751: Verifying Checksum
2026-01-14T08:17:22.3666412Z 7335f5694751: Download complete
2026-01-14T08:17:22.4874640Z 747a1c0117bc: Verifying Checksum
2026-01-14T08:17:22.4875118Z 747a1c0117bc: Download complete
2026-01-14T08:17:22.5312690Z 2d6f0c29ad9f: Verifying Checksum
2026-01-14T08:17:22.5313771Z 2d6f0c29ad9f: Download complete
2026-01-14T08:17:23.0827410Z 8e7a9d654295: Verifying Checksum
2026-01-14T08:17:23.0827758Z 8e7a9d654295: Download complete
2026-01-14T08:17:23.1301043Z a4392ccb83ef: Verifying Checksum
2026-01-14T08:17:23.1301372Z a4392ccb83ef: Download complete
2026-01-14T08:17:23.1744947Z 3f0968dff130: Download complete
2026-01-14T08:17:23.2256255Z 9323969b3930: Verifying Checksum
2026-01-14T08:17:23.2256582Z 9323969b3930: Download complete
2026-01-14T08:17:23.3839523Z b9f6732b07f0: Verifying Checksum
2026-01-14T08:17:23.3839861Z b9f6732b07f0: Download complete
2026-01-14T08:17:23.4272064Z 32117f6e66ab: Verifying Checksum
2026-01-14T08:17:23.4272378Z 32117f6e66ab: Download complete
2026-01-14T08:17:23.4760443Z bed95346686d: Verifying Checksum
2026-01-14T08:17:23.4760746Z bed95346686d: Download complete
2026-01-14T08:17:23.9606532Z 19877a9af8e3: Pull complete
2026-01-14T08:17:27.0899641Z 5b7921a1b019: Verifying Checksum
2026-01-14T08:17:27.0900106Z 5b7921a1b019: Download complete
2026-01-14T08:17:27.7700635Z 7335f5694751: Pull complete
2026-01-14T08:17:27.9563342Z e89b428500ef: Pull complete
2026-01-14T08:17:28.2486572Z 2890bcc97ae2: Pull complete
2026-01-14T08:17:29.6986236Z a73f5cbdff4f: Verifying Checksum
2026-01-14T08:17:29.6987039Z a73f5cbdff4f: Download complete
2026-01-14T08:17:34.4756321Z 8e7a9d654295: Pull complete
2026-01-14T08:17:34.4876452Z 55070e1f6d59: Pull complete
2026-01-14T08:17:35.7668817Z a6ffcda215dd: Pull complete
2026-01-14T08:17:35.7787239Z 4f4fb700ef54: Pull complete
2026-01-14T08:18:26.9596855Z d4e5a2339eb1: Pull complete
2026-01-14T08:18:26.9846377Z 3b50177ed801: Pull complete
2026-01-14T08:18:27.0073919Z 657cfc9d9d43: Pull complete
2026-01-14T08:18:27.0293561Z 039239a19e2c: Pull complete
2026-01-14T08:18:30.3407093Z 301a59dd8ea1: Verifying Checksum
2026-01-14T08:18:30.3407420Z 301a59dd8ea1: Download complete
2026-01-14T08:19:30.9519093Z 301a59dd8ea1: Pull complete
2026-01-14T08:19:31.5663290Z 747a1c0117bc: Pull complete
2026-01-14T08:19:32.0128768Z 2d6f0c29ad9f: Pull complete
2026-01-14T08:19:50.2611512Z 5b7921a1b019: Pull complete
2026-01-14T08:19:50.6280462Z a4392ccb83ef: Pull complete
2026-01-14T08:19:51.0979849Z 3f0968dff130: Pull complete
2026-01-14T08:19:51.6287947Z 9323969b3930: Pull complete
2026-01-14T08:19:52.3625060Z b9f6732b07f0: Pull complete
2026-01-14T08:19:52.8392497Z 32117f6e66ab: Pull complete
2026-01-14T08:19:53.3699694Z bed95346686d: Pull complete
2026-01-14T08:20:13.8325882Z a73f5cbdff4f: Pull complete
2026-01-14T08:20:14.0860692Z Digest: sha256:38e012b20747e9f72b4c4dc2ffb4134a450ad6e57e64886e7daf42b9a8ffa9f2
2026-01-14T08:20:14.1970144Z Status: Downloaded newer image for pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:14.2344946Z docker.io/pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:14.2413455Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:20:14.2414444Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:14.2425155Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:14.2425509Z env:
2026-01-14T08:20:14.2425760Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:14.2426100Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:14.2426353Z   PR_NUMBER: 3500
2026-01-14T08:20:14.2428071Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:14.2429957Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:14.2430531Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:14.2431092Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:14.2431475Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:14.2431786Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:14.2432134Z ##[endgroup]
2026-01-14T08:20:14.2638998Z Prepare all required actions
2026-01-14T08:20:14.2639329Z Getting action download info
2026-01-14T08:20:14.4687849Z ##[group]Run ./test-infra/.github/actions/setup-nvidia
2026-01-14T08:20:14.4688198Z with:
2026-01-14T08:20:14.4688410Z   driver-version: 580.65.06
2026-01-14T08:20:14.4688656Z env:
2026-01-14T08:20:14.4688909Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:14.4689258Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:14.4689509Z   PR_NUMBER: 3500
2026-01-14T08:20:14.4691168Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:14.4693053Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:14.4693628Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:14.4694376Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:14.4694762Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:14.4695061Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:14.4695413Z ##[endgroup]
2026-01-14T08:20:14.4835651Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:20:14.4836613Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:14.4846152Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:14.4846501Z env:
2026-01-14T08:20:14.4846758Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:14.4847098Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:14.4847356Z   PR_NUMBER: 3500
2026-01-14T08:20:14.4849033Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:14.4850920Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:14.4851549Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:14.4852103Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:14.4852497Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:14.4852818Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:14.4853150Z ##[endgroup]
2026-01-14T08:20:14.4992732Z ##[group]Run set -euo pipefail
2026-01-14T08:20:14.4993060Z [36;1mset -euo pipefail[0m
2026-01-14T08:20:14.4993313Z [36;1m[0m
2026-01-14T08:20:14.4993537Z [36;1mhas_gpu=false[0m
2026-01-14T08:20:14.4993778Z [36;1mdevices=""[0m
2026-01-14T08:20:14.4994007Z [36;1m[0m
2026-01-14T08:20:14.4994273Z [36;1mif command -v nvidia-smi >/dev/null 2>&1; then[0m
2026-01-14T08:20:14.4994728Z [36;1m  if nvidia-smi -L >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:14.4995181Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:14.4995472Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:14.4995781Z [36;1m  fi[0m
2026-01-14T08:20:14.4995981Z [36;1mfi[0m
2026-01-14T08:20:14.4996170Z [36;1m[0m
2026-01-14T08:20:14.4996408Z [36;1mif [ "$has_gpu" = false ]; then[0m
2026-01-14T08:20:14.4996801Z [36;1m  if ls /dev/nvidia* >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:14.4997176Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:14.4997472Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:14.4997995Z [36;1m  fi[0m
2026-01-14T08:20:14.4998209Z [36;1mfi[0m
2026-01-14T08:20:14.4998408Z [36;1m[0m
2026-01-14T08:20:14.4998726Z [36;1mif [ "$has_gpu" = false ] && command -v lspci >/dev/null 2>&1; then[0m
2026-01-14T08:20:14.4999252Z [36;1m  if lspci | grep -i 'nvidia' >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:14.4999676Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:14.5000008Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:14.5000339Z [36;1m  fi[0m
2026-01-14T08:20:14.5000547Z [36;1mfi[0m
2026-01-14T08:20:14.5013358Z [36;1m[0m
2026-01-14T08:20:14.5013677Z [36;1mprintf 'HAS_NVIDIA=%s\n' "$has_gpu" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:14.5014193Z [36;1mprintf 'DETECTED_DEVICES<<EOF\n%s\nEOF\n' "$devices" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:14.5023539Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:14.5023887Z env:
2026-01-14T08:20:14.5024148Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:14.5024501Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:14.5024755Z   PR_NUMBER: 3500
2026-01-14T08:20:14.5026587Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:14.5028436Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:14.5029004Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:14.5029545Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:14.5029947Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:14.5030297Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:14.5030646Z ##[endgroup]
2026-01-14T08:20:14.5936733Z ##[group]Run if [ "${HAS_NVIDIA}" = "true" ]; then
2026-01-14T08:20:14.5937117Z [36;1mif [ "${HAS_NVIDIA}" = "true" ]; then[0m
2026-01-14T08:20:14.5937496Z [36;1m  echo "HAS_NVIDIA_GPU=true" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:14.5938032Z [36;1m  echo "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:14.5938500Z [36;1melse[0m
2026-01-14T08:20:14.5938784Z [36;1m  echo "HAS_NVIDIA_GPU=false" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:14.5939116Z [36;1mfi[0m
2026-01-14T08:20:14.5947393Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:14.5947752Z env:
2026-01-14T08:20:14.5948028Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:14.5948375Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:14.5948628Z   PR_NUMBER: 3500
2026-01-14T08:20:14.5950333Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:14.5952256Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:14.5952836Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:14.5953396Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:14.5953786Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:14.5954120Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:14.5954464Z   HAS_NVIDIA: true
2026-01-14T08:20:14.5954700Z ##[endgroup]
2026-01-14T08:20:14.6101333Z ##[group]Run nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482
2026-01-14T08:20:14.6101787Z with:
2026-01-14T08:20:14.6101991Z   timeout_minutes: 10
2026-01-14T08:20:14.6102418Z   max_attempts: 3
2026-01-14T08:20:14.6133322Z   command: # Is it disgusting to have a full shell script here in this github action? Sure
# But is it the best way to make it so that this action relies on nothing else? Absolutely
set -eou pipefail

DISTRIBUTION=$(. /etc/os-release;echo $ID$VERSION_ID)
DRIVER_FN="NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"

install_nvidia_docker2_amzn2() {
    (
        set -x
        # Needed for yum-config-manager
        sudo yum install -y yum-utils
        if [[ "${DISTRIBUTION}" == "amzn2023" ]] ; then
          YUM_REPO_URL="https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo"
        else
          # Amazon Linux 2
          YUM_REPO_URL="https://nvidia.github.io/nvidia-docker/${DISTRIBUTION}/nvidia-docker.repo"
        fi

        sudo yum-config-manager --add-repo "${YUM_REPO_URL}"
        sudo yum install -y \
          nvidia-container-toolkit-1.17.8 \
          libnvidia-container-tools-1.17.8 \
          libnvidia-container1-1.17.8 \
          nvidia-container-toolkit-base-1.17.8
        sudo systemctl restart docker
    )
}

install_nvidia_docker2_ubuntu20() {
    (
        set -x
        # Install nvidia-driver package if not installed
        status="$(dpkg-query -W --showformat='${db:Status-Status}' nvidia-docker2 2>&1)"
        if [ ! $? = 0 ] || [ ! "$status" = installed ]; then
          sudo apt-get install -y nvidia-container-toolkit-1.17.8
          sudo systemctl restart docker
        fi
    )
}

pre_install_nvidia_driver_amzn2() {
    (
        # Purge any nvidia driver installed from RHEL repo
        sudo yum remove -y nvidia-driver-latest-dkms
    )
}

install_nvidia_driver_common() {
    (
        # Try to gather more information about the runner and its existing NVIDIA driver if any
        echo "Before installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        HAS_NVIDIA_DRIVER=0
        # Check if NVIDIA driver has already been installed
        if [ -x "$(command -v nvidia-smi)" ]; then
            set +e
            # The driver exists, check its version next. Also check only the first GPU if there are more than one of them
            # so that the same driver version is not print over multiple lines
            INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
            NVIDIA_SMI_STATUS=$?

            if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                echo "Failed to get NVIDIA driver version ($INSTALLED_DRIVER_VERSION). Continuing"
            elif [ "$INSTALLED_DRIVER_VERSION" != "$DRIVER_VERSION" ]; then
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has been installed, but we expect to have $DRIVER_VERSION instead. Continuing"

                # Turn off persistent mode so that the installation script can unload the kernel module
                sudo killall nvidia-persistenced || true
            else
                HAS_NVIDIA_DRIVER=1
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has already been installed. Skipping NVIDIA driver installation"
            fi
            set -e
        fi

        if [ "$HAS_NVIDIA_DRIVER" -eq 0 ]; then
            # CAUTION: this may need to be updated in future
            if [ "${DISTRIBUTION}" != ubuntu20.04 ]; then
                  sudo yum groupinstall -y "Development Tools"
                  # ensure our kernel install is the same as our underlying kernel,
                  # groupinstall "Development Tools" has a habit of mismatching kernel headers
                  sudo yum install -y "kernel-devel-uname-r == $(uname -r)"
                  sudo modprobe backlight
            fi
            sudo curl -fsL -o /tmp/nvidia_driver "https://s3.amazonaws.com/ossci-linux/nvidia_driver/$DRIVER_FN"

            set +e
            sudo /bin/bash /tmp/nvidia_driver -s --no-drm
            NVIDIA_INSTALLATION_STATUS=$?

            RESET_GPU=0
            if [ "$NVIDIA_INSTALLATION_STATUS" -ne 0 ]; then
                sudo cat /var/log/nvidia-installer.log
                # Fail to install NVIDIA driver, try to reset the GPU
                RESET_GPU=1
            elif [ -x "$(command -v nvidia-smi)" ]; then
                # Check again if nvidia-smi works even if the driver installation completes successfully
                INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
                NVIDIA_SMI_STATUS=$?

                if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                    RESET_GPU=1
                fi
            fi

            if [ "$RESET_GPU" -eq 1 ]; then
                NVIDIA_DEVICES=$(lspci -D | grep -i NVIDIA | cut -d' ' -f1)
                # The GPU can get stuck in a failure state if somehow the test crashs the GPU microcode. When this
                # happens, we'll try to reset all NVIDIA devices https://github.com/pytorch/pytorch/issues/88388
                for PCI_ID in $NVIDIA_DEVICES; do
                    DEVICE_ENABLED=$(cat /sys/bus/pci/devices/$PCI_ID/enable)

                    echo "Reseting $PCI_ID (enabled state: $DEVICE_ENABLED)"
                    # This requires sudo permission of course
                    echo "1" | sudo tee /sys/bus/pci/devices/$PCI_ID/reset
                    sleep 1
                done
            fi

            sudo rm -fv /tmp/nvidia_driver
            set -e
        fi
    )
}

post_install_nvidia_driver_common() {
    (
        sudo modprobe nvidia || true
        echo "After installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        (
            set +e

            nvidia-smi
            # NB: Annoyingly, nvidia-smi command returns successfully with return code 0 even in
            # the case where the driver has already crashed as it still can get the driver version
            # and some basic information like the bus ID.  However, the rest of the information
            # would be missing (ERR!), for example:
            #
            # +-----------------------------------------------------------------------------+
            # | NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |
            # |-------------------------------+----------------------+----------------------+
            # | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
            # | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
            # |                               |                      |               MIG M. |
            # |===============================+======================+======================|
            # |   0  ERR!                Off  | 00000000:00:1E.0 Off |                 ERR! |
            # |ERR!  ERR! ERR!    ERR! / ERR! |   4184MiB / 23028MiB |    ERR!      Default |
            # |                               |                      |                 ERR! |
            # +-------------------------------+----------------------+----------------------+
            #
            # +-----------------------------------------------------------------------------+
            # | Processes:                                                                  |
            # |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
            # |        ID   ID                                                   Usage      |
            # |=============================================================================|
            # +-----------------------------------------------------------------------------+
            #
            # This should be reported as a failure instead as it will guarantee to fail when
            # Docker tries to run with --gpus all
            #
            # So, the correct check here is to query one of the missing piece of info like
            # GPU name, so that the command can fail accordingly
            nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
            NVIDIA_SMI_STATUS=$?

            # Allowable exit statuses for nvidia-smi, see: https://github.com/NVIDIA/gpu-operator/issues/285
            if [ "$NVIDIA_SMI_STATUS" -eq 0 ] || [ "$NVIDIA_SMI_STATUS" -eq 14 ]; then
                echo "INFO: Ignoring allowed status ${NVIDIA_SMI_STATUS}"
            else
                echo "ERROR: nvidia-smi exited with unresolved status ${NVIDIA_SMI_STATUS}"
                exit ${NVIDIA_SMI_STATUS}
            fi
            set -e
        )
    )
}

install_nvidia_driver_amzn2() {
    (
        set -x
        pre_install_nvidia_driver_amzn2
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

install_nvidia_driver_ubuntu20() {
    (
        set -x
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

echo "== Installing nvidia driver ${DRIVER_FN} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_driver_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_driver_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Install container toolkit based on distribution
echo "== Installing nvidia container toolkit for ${DISTRIBUTION} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_docker2_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_docker2_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Fix https://github.com/NVIDIA/nvidia-docker/issues/1648 on runners with
# more than one GPUs. This just needs to be run once. The command fails
# on subsequent runs and complains that the mode is already on, but that's
# ok
sudo nvidia-persistenced || true
# This should show persistence mode ON
nvidia-smi

# check if the container-toolkit is correctly installed and CUDA is available inside a container
docker run --rm -t --gpus=all public.ecr.aws/docker/library/python:3.13 nvidia-smi

2026-01-14T08:20:14.6165130Z   retry_wait_seconds: 10
2026-01-14T08:20:14.6165398Z   polling_interval_seconds: 1
2026-01-14T08:20:14.6165666Z   warning_on_retry: true
2026-01-14T08:20:14.6165919Z   continue_on_error: false
2026-01-14T08:20:14.6166176Z env:
2026-01-14T08:20:14.6166427Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:14.6166791Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:14.6167051Z   PR_NUMBER: 3500
2026-01-14T08:20:14.6168722Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:14.6170578Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:14.6171155Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:14.6171703Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:14.6172100Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:14.6172403Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:14.6172770Z   DRIVER_VERSION: 580.65.06
2026-01-14T08:20:14.6173025Z ##[endgroup]
2026-01-14T08:20:14.7269097Z == Installing nvidia driver NVIDIA-Linux-x86_64-580.65.06.run ==
2026-01-14T08:20:14.7274101Z + pre_install_nvidia_driver_amzn2
2026-01-14T08:20:14.7275323Z + sudo yum remove -y nvidia-driver-latest-dkms
2026-01-14T08:20:15.0978256Z No match for argument: nvidia-driver-latest-dkms
2026-01-14T08:20:15.0979053Z No packages marked for removal.
2026-01-14T08:20:15.1030752Z Dependencies resolved.
2026-01-14T08:20:15.1040260Z Nothing to do.
2026-01-14T08:20:15.1040877Z Complete!
2026-01-14T08:20:15.2398218Z + install_nvidia_driver_common
2026-01-14T08:20:15.2402974Z + echo 'Before installing NVIDIA driver'
2026-01-14T08:20:15.2403280Z + lspci
2026-01-14T08:20:15.2405021Z Before installing NVIDIA driver
2026-01-14T08:20:15.2529228Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:20:15.2529765Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:20:15.2530354Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:20:15.2530908Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:20:15.2531412Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:20:15.2531966Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:20:15.2532477Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:15.2532935Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:15.2533389Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:15.2533845Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:15.2534343Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:20:15.2534966Z + lsmod
2026-01-14T08:20:15.2595770Z Module                  Size  Used by
2026-01-14T08:20:15.2596092Z veth                   36864  0
2026-01-14T08:20:15.2596350Z nvidia_modeset       1740800  0
2026-01-14T08:20:15.2596634Z video                  65536  1 nvidia_modeset
2026-01-14T08:20:15.2596940Z wmi                    36864  1 video
2026-01-14T08:20:15.2597210Z nvidia_uvm           1921024  0
2026-01-14T08:20:15.2597524Z nvidia              14274560  19 nvidia_uvm,nvidia_modeset
2026-01-14T08:20:15.2597860Z drm                   602112  1 nvidia
2026-01-14T08:20:15.2598172Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:20:15.2598539Z backlight              24576  3 video,drm,nvidia_modeset
2026-01-14T08:20:15.2598894Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:20:15.2599179Z mgc                    86016  1
2026-01-14T08:20:15.2599446Z lustre               1085440  4
2026-01-14T08:20:15.2599708Z mdc                   294912  2 lustre
2026-01-14T08:20:15.2599985Z fid                    36864  1 mdc
2026-01-14T08:20:15.2600268Z lov                   356352  5 mdc,lustre
2026-01-14T08:20:15.2600597Z osc                   479232  5 mdc
2026-01-14T08:20:15.2600868Z lmv                   225280  2 lustre
2026-01-14T08:20:15.2601148Z fld                    49152  2 lov,lmv
2026-01-14T08:20:15.2601439Z ksocklnd              188416  1
2026-01-14T08:20:15.2601782Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:15.2602271Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:15.2602793Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:20:15.2603401Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:20:15.2603913Z xt_conntrack           16384  1
2026-01-14T08:20:15.2604182Z nft_chain_nat          16384  3
2026-01-14T08:20:15.2604448Z xt_MASQUERADE          20480  1
2026-01-14T08:20:15.2604762Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:20:15.2605105Z nf_conntrack_netlink    57344  0
2026-01-14T08:20:15.2605517Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:20:15.2606028Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:20:15.2606351Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:20:15.2606642Z xfrm_user              57344  1
2026-01-14T08:20:15.2606913Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:20:15.2607200Z xt_addrtype            16384  2
2026-01-14T08:20:15.2607462Z nft_compat             20480  4
2026-01-14T08:20:15.2607778Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:20:15.2608205Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:20:15.2608600Z br_netfilter           36864  0
2026-01-14T08:20:15.2609040Z bridge                323584  1 br_netfilter
2026-01-14T08:20:15.2609346Z stp                    16384  1 bridge
2026-01-14T08:20:15.2609636Z llc                    16384  2 bridge,stp
2026-01-14T08:20:15.2609928Z overlay               167936  0
2026-01-14T08:20:15.2610223Z tls                   139264  0
2026-01-14T08:20:15.2610496Z nls_ascii              16384  1
2026-01-14T08:20:15.2610754Z nls_cp437              20480  1
2026-01-14T08:20:15.2611001Z vfat                   24576  1
2026-01-14T08:20:15.2611253Z fat                    86016  1 vfat
2026-01-14T08:20:15.2611530Z sunrpc                700416  2 lnet
2026-01-14T08:20:15.2611808Z ghash_clmulni_intel    16384  0
2026-01-14T08:20:15.2612070Z i8042                  45056  0
2026-01-14T08:20:15.2612320Z serio                  28672  3 i8042
2026-01-14T08:20:15.2612594Z ena                   196608  0
2026-01-14T08:20:15.2612844Z button                 24576  0
2026-01-14T08:20:15.2613101Z sch_fq_codel           20480  33
2026-01-14T08:20:15.2613366Z fuse                  184320  1
2026-01-14T08:20:15.2613618Z loop                   36864  0
2026-01-14T08:20:15.2613986Z dm_mod                188416  0
2026-01-14T08:20:15.2614244Z configfs               57344  1
2026-01-14T08:20:15.2614502Z dmi_sysfs              20480  0
2026-01-14T08:20:15.2614754Z crc32_pclmul           16384  0
2026-01-14T08:20:15.2615010Z crc32c_intel           24576  0
2026-01-14T08:20:15.2615340Z efivarfs               24576  1
2026-01-14T08:20:15.2615716Z + modinfo nvidia
2026-01-14T08:20:15.2632934Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:20:15.2633487Z import_ns:      DMA_BUF
2026-01-14T08:20:15.2633743Z alias:          char-major-195-*
2026-01-14T08:20:15.2634024Z version:        580.65.06
2026-01-14T08:20:15.2634269Z supported:      external
2026-01-14T08:20:15.2634525Z license:        Dual MIT/GPL
2026-01-14T08:20:15.2634919Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:20:15.2635270Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:20:15.2635600Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:20:15.2635947Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:20:15.2636300Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:20:15.2636664Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:20:15.2637019Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:20:15.2637361Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:20:15.2637705Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:20:15.2638042Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:20:15.2638354Z depends:        i2c-core,drm
2026-01-14T08:20:15.2638607Z retpoline:      Y
2026-01-14T08:20:15.2638831Z name:           nvidia
2026-01-14T08:20:15.2639204Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:20:15.2639717Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:20:15.2640186Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:20:15.2640624Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:20:15.2640938Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:20:15.2641235Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:20:15.2641552Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:20:15.2641851Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:20:15.2642161Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:20:15.2642525Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:20:15.2642925Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:20:15.2643258Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:20:15.2643552Z parm:           NVreg_EnableMSI:int
2026-01-14T08:20:15.2643867Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:20:15.2644229Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:20:15.2644778Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:20:15.2645168Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:20:15.2645604Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:15.2646029Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:20:15.2646460Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:15.2646885Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:20:15.2647218Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:20:15.2647597Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:20:15.2647983Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:20:15.2648327Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:20:15.2648649Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:20:15.2648980Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:20:15.2649300Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:20:15.2649618Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:20:15.2649964Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:20:15.2650411Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:20:15.2650773Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:20:15.2651138Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:20:15.2651486Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:20:15.2651828Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:20:15.2652191Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:20:15.2652542Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:20:15.2652882Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:20:15.2653230Z parm:           NVreg_RmMsg:charp
2026-01-14T08:20:15.2653508Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:20:15.2653835Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:20:15.2654162Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:20:15.2654482Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:20:15.2654813Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:20:15.2655193Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:20:15.2655552Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:20:15.2655890Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:20:15.2656246Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:20:15.2656595Z parm:           rm_firmware_active:charp
2026-01-14T08:20:15.2656889Z + HAS_NVIDIA_DRIVER=0
2026-01-14T08:20:15.2657125Z ++ command -v nvidia-smi
2026-01-14T08:20:15.2657387Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:20:15.2657640Z + set +e
2026-01-14T08:20:15.2657964Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:20:15.3165804Z + INSTALLED_DRIVER_VERSION=580.65.06
2026-01-14T08:20:15.3166131Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:20:15.3166419Z + '[' 0 -ne 0 ']'
2026-01-14T08:20:15.3166655Z + '[' 580.65.06 '!=' 580.65.06 ']'
2026-01-14T08:20:15.3166926Z + HAS_NVIDIA_DRIVER=1
2026-01-14T08:20:15.3167371Z + echo 'NVIDIA driver (580.65.06) has already been installed. Skipping NVIDIA driver installation'
2026-01-14T08:20:15.3167879Z + set -e
2026-01-14T08:20:15.3168073Z + '[' 1 -eq 0 ']'
2026-01-14T08:20:15.3168473Z NVIDIA driver (580.65.06) has already been installed. Skipping NVIDIA driver installation
2026-01-14T08:20:15.3169547Z + post_install_nvidia_driver_common
2026-01-14T08:20:15.3173990Z + sudo modprobe nvidia
2026-01-14T08:20:15.4388481Z + echo 'After installing NVIDIA driver'
2026-01-14T08:20:15.4389297Z + lspci
2026-01-14T08:20:15.4389763Z After installing NVIDIA driver
2026-01-14T08:20:15.4506549Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:20:15.4507593Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:20:15.4508738Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:20:15.4511459Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:20:15.4511983Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:20:15.4512543Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:20:15.4513067Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:15.4513522Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:15.4513976Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:15.4514424Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:15.4514991Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:20:15.4515425Z + lsmod
2026-01-14T08:20:15.4559025Z Module                  Size  Used by
2026-01-14T08:20:15.4559648Z veth                   36864  0
2026-01-14T08:20:15.4560175Z nvidia_modeset       1740800  0
2026-01-14T08:20:15.4560526Z video                  65536  1 nvidia_modeset
2026-01-14T08:20:15.4560860Z wmi                    36864  1 video
2026-01-14T08:20:15.4561285Z nvidia_uvm           1921024  0
2026-01-14T08:20:15.4561597Z nvidia              14274560  19 nvidia_uvm,nvidia_modeset
2026-01-14T08:20:15.4561935Z drm                   602112  1 nvidia
2026-01-14T08:20:15.4562247Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:20:15.4562620Z backlight              24576  3 video,drm,nvidia_modeset
2026-01-14T08:20:15.4562977Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:20:15.4563270Z mgc                    86016  1
2026-01-14T08:20:15.4563526Z lustre               1085440  4
2026-01-14T08:20:15.4563790Z mdc                   294912  2 lustre
2026-01-14T08:20:15.4564063Z fid                    36864  1 mdc
2026-01-14T08:20:15.4564338Z lov                   356352  5 mdc,lustre
2026-01-14T08:20:15.4564617Z osc                   479232  5 mdc
2026-01-14T08:20:15.4564890Z lmv                   225280  2 lustre
2026-01-14T08:20:15.4565164Z fld                    49152  2 lov,lmv
2026-01-14T08:20:15.4565442Z ksocklnd              188416  1
2026-01-14T08:20:15.4565789Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:15.4566272Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:15.4566787Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:20:15.4567390Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:20:15.4567904Z xt_conntrack           16384  1
2026-01-14T08:20:15.4568172Z nft_chain_nat          16384  3
2026-01-14T08:20:15.4568447Z xt_MASQUERADE          20480  1
2026-01-14T08:20:15.4568757Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:20:15.4569103Z nf_conntrack_netlink    57344  0
2026-01-14T08:20:15.4569531Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:20:15.4569995Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:20:15.4570321Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:20:15.4570618Z xfrm_user              57344  1
2026-01-14T08:20:15.4570892Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:20:15.4571184Z xt_addrtype            16384  2
2026-01-14T08:20:15.4571450Z nft_compat             20480  4
2026-01-14T08:20:15.4571762Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:20:15.4572210Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:20:15.4572610Z br_netfilter           36864  0
2026-01-14T08:20:15.4572891Z bridge                323584  1 br_netfilter
2026-01-14T08:20:15.4573204Z stp                    16384  1 bridge
2026-01-14T08:20:15.4573490Z llc                    16384  2 bridge,stp
2026-01-14T08:20:15.4573779Z overlay               167936  0
2026-01-14T08:20:15.4574027Z tls                   139264  0
2026-01-14T08:20:15.4574386Z nls_ascii              16384  1
2026-01-14T08:20:15.4574643Z nls_cp437              20480  1
2026-01-14T08:20:15.4574905Z vfat                   24576  1
2026-01-14T08:20:15.4575153Z fat                    86016  1 vfat
2026-01-14T08:20:15.4575431Z sunrpc                700416  2 lnet
2026-01-14T08:20:15.4575712Z ghash_clmulni_intel    16384  0
2026-01-14T08:20:15.4575971Z i8042                  45056  0
2026-01-14T08:20:15.4576232Z serio                  28672  3 i8042
2026-01-14T08:20:15.4576508Z ena                   196608  0
2026-01-14T08:20:15.4576761Z button                 24576  0
2026-01-14T08:20:15.4577012Z sch_fq_codel           20480  33
2026-01-14T08:20:15.4577274Z fuse                  184320  1
2026-01-14T08:20:15.4577520Z loop                   36864  0
2026-01-14T08:20:15.4577769Z dm_mod                188416  0
2026-01-14T08:20:15.4578026Z configfs               57344  1
2026-01-14T08:20:15.4578276Z dmi_sysfs              20480  0
2026-01-14T08:20:15.4578544Z crc32_pclmul           16384  0
2026-01-14T08:20:15.4578797Z crc32c_intel           24576  0
2026-01-14T08:20:15.4579053Z efivarfs               24576  1
2026-01-14T08:20:15.4579393Z + modinfo nvidia
2026-01-14T08:20:15.4580267Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:20:15.4580790Z import_ns:      DMA_BUF
2026-01-14T08:20:15.4581066Z alias:          char-major-195-*
2026-01-14T08:20:15.4581337Z version:        580.65.06
2026-01-14T08:20:15.4581584Z supported:      external
2026-01-14T08:20:15.4581836Z license:        Dual MIT/GPL
2026-01-14T08:20:15.4582121Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:20:15.4582467Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:20:15.4582805Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:20:15.4583136Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:20:15.4583508Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:20:15.4583866Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:20:15.4584377Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:20:15.4584720Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:20:15.4585098Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:20:15.4585436Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:20:15.4585755Z depends:        i2c-core,drm
2026-01-14T08:20:15.4586018Z retpoline:      Y
2026-01-14T08:20:15.4586234Z name:           nvidia
2026-01-14T08:20:15.4586613Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:20:15.4587116Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:20:15.4587586Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:20:15.4588020Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:20:15.4588337Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:20:15.4588636Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:20:15.4588958Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:20:15.4589262Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:20:15.4589567Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:20:15.4589944Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:20:15.4590340Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:20:15.4590681Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:20:15.4590981Z parm:           NVreg_EnableMSI:int
2026-01-14T08:20:15.4591289Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:20:15.4591663Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:20:15.4592074Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:20:15.4592467Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:20:15.4592891Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:15.4593327Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:20:15.4593932Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:15.4594373Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:20:15.4594722Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:20:15.4595140Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:20:15.4595526Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:20:15.4595876Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:20:15.4596200Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:20:15.4596527Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:20:15.4596851Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:20:15.4597163Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:20:15.4597517Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:20:15.4597887Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:20:15.4598241Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:20:15.4598615Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:20:15.4598953Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:20:15.4599301Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:20:15.4599781Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:20:15.4600130Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:20:15.4600482Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:20:15.4600825Z parm:           NVreg_RmMsg:charp
2026-01-14T08:20:15.4601115Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:20:15.4601439Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:20:15.4601772Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:20:15.4602085Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:20:15.4602430Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:20:15.4602794Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:20:15.4603155Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:20:15.4603491Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:20:15.4603839Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:20:15.4604193Z parm:           rm_firmware_active:charp
2026-01-14T08:20:15.4604474Z + set +e
2026-01-14T08:20:15.4604669Z + nvidia-smi
2026-01-14T08:20:15.5028840Z Wed Jan 14 08:20:15 2026       
2026-01-14T08:20:15.5029243Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:15.5029798Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:20:15.5030340Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:15.5030899Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:20:15.5031480Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:20:15.5031981Z |                                         |                        |               MIG M. |
2026-01-14T08:20:15.5032401Z |=========================================+========================+======================|
2026-01-14T08:20:15.5629198Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:20:15.5629714Z |  0%   23C    P8             11W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:15.5630172Z |                                         |                        |                  N/A |
2026-01-14T08:20:15.5630779Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:15.5631828Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:20:15.5632798Z |  0%   23C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:15.5633684Z |                                         |                        |                  N/A |
2026-01-14T08:20:15.5634976Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:15.5636003Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:20:15.5636991Z |  0%   22C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:15.5637870Z |                                         |                        |                  N/A |
2026-01-14T08:20:15.5638807Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:15.5639815Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:20:15.5640599Z |  0%   23C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:15.5641062Z |                                         |                        |                  N/A |
2026-01-14T08:20:15.5641532Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:15.5657147Z 
2026-01-14T08:20:15.5657666Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:15.5658394Z | Processes:                                                                              |
2026-01-14T08:20:15.5658910Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:20:15.5659405Z |        ID   ID                                                               Usage      |
2026-01-14T08:20:15.5659814Z |=========================================================================================|
2026-01-14T08:20:15.5696042Z |  No running processes found                                                             |
2026-01-14T08:20:15.5696587Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:16.6553119Z + nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
2026-01-14T08:20:16.6741260Z NVIDIA A10G
2026-01-14T08:20:16.7014030Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:20:16.7014375Z + '[' 0 -eq 0 ']'
2026-01-14T08:20:16.7014639Z + echo 'INFO: Ignoring allowed status 0'
2026-01-14T08:20:16.7014929Z + set -e
2026-01-14T08:20:16.7015149Z INFO: Ignoring allowed status 0
2026-01-14T08:20:16.7025602Z == Installing nvidia container toolkit for amzn2023 ==
2026-01-14T08:20:16.7031400Z + sudo yum install -y yum-utils
2026-01-14T08:20:17.2111949Z Last metadata expiration check: 0:03:41 ago on Wed Jan 14 08:16:36 2026.
2026-01-14T08:20:17.2399566Z Package dnf-utils-4.3.0-13.amzn2023.0.5.noarch is already installed.
2026-01-14T08:20:17.3031212Z Dependencies resolved.
2026-01-14T08:20:17.3394610Z Nothing to do.
2026-01-14T08:20:17.3394988Z Complete!
2026-01-14T08:20:17.4688847Z + [[ amzn2023 == \a\m\z\n\2\0\2\3 ]]
2026-01-14T08:20:17.4689569Z + YUM_REPO_URL=https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:17.4690521Z + sudo yum-config-manager --add-repo https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:17.8009741Z Adding repo from: https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:17.8516240Z + sudo yum install -y nvidia-container-toolkit-1.17.8 libnvidia-container-tools-1.17.8 libnvidia-container1-1.17.8 nvidia-container-toolkit-base-1.17.8
2026-01-14T08:20:18.4550111Z nvidia-container-toolkit                         18 kB/s | 833  B     00:00    
2026-01-14T08:20:18.4834991Z Package nvidia-container-toolkit-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:18.4842371Z Package libnvidia-container-tools-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:18.4847252Z Package libnvidia-container1-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:18.4856656Z Package nvidia-container-toolkit-base-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:18.5495335Z Dependencies resolved.
2026-01-14T08:20:18.5864927Z Nothing to do.
2026-01-14T08:20:18.5865586Z Complete!
2026-01-14T08:20:18.7220334Z + sudo systemctl restart docker
2026-01-14T08:21:02.5668112Z nvidia-persistenced failed to initialize. Check syslog for more details.
2026-01-14T08:21:02.6132833Z Wed Jan 14 08:21:02 2026       
2026-01-14T08:21:02.6137267Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:02.6138042Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:21:02.6138588Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:02.6139152Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:21:02.6139745Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:21:02.6140243Z |                                         |                        |               MIG M. |
2026-01-14T08:21:02.6140661Z |=========================================+========================+======================|
2026-01-14T08:21:02.6733782Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:21:02.6734697Z |  0%   23C    P8             11W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:02.6735222Z |                                         |                        |                  N/A |
2026-01-14T08:21:02.6735861Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:02.6736434Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:21:02.6737107Z |  0%   23C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:02.6737713Z |                                         |                        |                  N/A |
2026-01-14T08:21:02.6738308Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:02.6738812Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:21:02.6739304Z |  0%   22C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:02.6739735Z |                                         |                        |                  N/A |
2026-01-14T08:21:02.6740198Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:02.6740707Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:21:02.6741183Z |  0%   23C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:02.6741621Z |                                         |                        |                  N/A |
2026-01-14T08:21:02.6742080Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:02.6762566Z 
2026-01-14T08:21:02.6763065Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:02.6763760Z | Processes:                                                                              |
2026-01-14T08:21:02.6764334Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:21:02.6764811Z |        ID   ID                                                               Usage      |
2026-01-14T08:21:02.6765224Z |=========================================================================================|
2026-01-14T08:21:02.6800455Z |  No running processes found                                                             |
2026-01-14T08:21:02.6801200Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:03.8244549Z Unable to find image 'public.ecr.aws/docker/library/python:3.13' locally
2026-01-14T08:21:04.0393824Z 3.13: Pulling from docker/library/python
2026-01-14T08:21:04.1389709Z 2ca1bfae7ba8: Pulling fs layer
2026-01-14T08:21:04.1390030Z 82e18c5e1c15: Pulling fs layer
2026-01-14T08:21:04.1390315Z be442a7e0d6f: Pulling fs layer
2026-01-14T08:21:04.1390589Z 26d823e3848f: Pulling fs layer
2026-01-14T08:21:04.1390847Z ca4b54413202: Pulling fs layer
2026-01-14T08:21:04.1391112Z b6513238a015: Pulling fs layer
2026-01-14T08:21:04.1391367Z 9b57076d00d4: Pulling fs layer
2026-01-14T08:21:04.1391619Z 26d823e3848f: Waiting
2026-01-14T08:21:04.1391840Z ca4b54413202: Waiting
2026-01-14T08:21:04.1392061Z b6513238a015: Waiting
2026-01-14T08:21:04.1392274Z 9b57076d00d4: Waiting
2026-01-14T08:21:04.2362823Z 82e18c5e1c15: Verifying Checksum
2026-01-14T08:21:04.2363217Z 82e18c5e1c15: Download complete
2026-01-14T08:21:04.3114424Z 2ca1bfae7ba8: Verifying Checksum
2026-01-14T08:21:04.3114809Z 2ca1bfae7ba8: Download complete
2026-01-14T08:21:04.3358300Z be442a7e0d6f: Verifying Checksum
2026-01-14T08:21:04.3358643Z be442a7e0d6f: Download complete
2026-01-14T08:21:04.3754104Z ca4b54413202: Download complete
2026-01-14T08:21:04.4205823Z 9b57076d00d4: Verifying Checksum
2026-01-14T08:21:04.4206131Z 9b57076d00d4: Download complete
2026-01-14T08:21:04.4368996Z b6513238a015: Verifying Checksum
2026-01-14T08:21:04.4369289Z b6513238a015: Download complete
2026-01-14T08:21:04.8747292Z 26d823e3848f: Verifying Checksum
2026-01-14T08:21:04.8747626Z 26d823e3848f: Download complete
2026-01-14T08:21:06.1174865Z 2ca1bfae7ba8: Pull complete
2026-01-14T08:21:06.8549360Z 82e18c5e1c15: Pull complete
2026-01-14T08:21:09.4373679Z be442a7e0d6f: Pull complete
2026-01-14T08:21:16.2143413Z 26d823e3848f: Pull complete
2026-01-14T08:21:16.5094991Z ca4b54413202: Pull complete
2026-01-14T08:21:17.2973668Z b6513238a015: Pull complete
2026-01-14T08:21:17.3212111Z 9b57076d00d4: Pull complete
2026-01-14T08:21:17.3353286Z Digest: sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:21:17.3396114Z Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.13
2026-01-14T08:21:24.4930446Z Wed Jan 14 08:21:24 2026       
2026-01-14T08:21:24.4930896Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:24.4931488Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:21:24.4932041Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:24.4932621Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:21:24.4933229Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:21:24.4933722Z |                                         |                        |               MIG M. |
2026-01-14T08:21:24.4934136Z |=========================================+========================+======================|
2026-01-14T08:21:24.5542069Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:21:24.5542634Z |  0%   23C    P8             11W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:24.5543088Z |                                         |                        |                  N/A |
2026-01-14T08:21:24.5543566Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:24.5544080Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:21:24.5544567Z |  0%   23C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:24.5545030Z |                                         |                        |                  N/A |
2026-01-14T08:21:24.5545501Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:24.5546005Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:21:24.5546808Z |  0%   22C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:24.5547258Z |                                         |                        |                  N/A |
2026-01-14T08:21:24.5547756Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:24.5548270Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:21:24.5548764Z |  0%   23C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:24.5549212Z |                                         |                        |                  N/A |
2026-01-14T08:21:24.5549684Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:24.5571333Z 
2026-01-14T08:21:24.5571703Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:24.5572218Z | Processes:                                                                              |
2026-01-14T08:21:24.5572728Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:21:24.5573424Z |        ID   ID                                                               Usage      |
2026-01-14T08:21:24.5573839Z |=========================================================================================|
2026-01-14T08:21:24.5608156Z |  No running processes found                                                             |
2026-01-14T08:21:24.5608709Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:26.7292899Z Command completed after 1 attempt(s).
2026-01-14T08:21:26.7407791Z ##[group]Run set -ex
2026-01-14T08:21:26.7408062Z [36;1mset -ex[0m
2026-01-14T08:21:26.7408276Z [36;1m{[0m
2026-01-14T08:21:26.7408502Z [36;1m  echo "#!/usr/bin/env bash";[0m
2026-01-14T08:21:26.7408823Z [36;1m  echo "set -eou pipefail";[0m
2026-01-14T08:21:26.7409144Z [36;1m  # shellcheck disable=SC2016[0m
2026-01-14T08:21:26.7409472Z [36;1m  echo 'eval "$(conda shell.bash hook)"';[0m
2026-01-14T08:21:26.7409829Z [36;1m  echo "set -x";[0m
2026-01-14T08:21:26.7410089Z [36;1m  echo "${SCRIPT}";[0m
2026-01-14T08:21:26.7410375Z [36;1m} > "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:21:26.7410708Z [36;1mchmod +x "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:21:26.7411334Z [36;1mpython3 "/home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py" ""[0m
2026-01-14T08:21:26.7426482Z shell: /usr/bin/bash -e {0}
2026-01-14T08:21:26.7426742Z env:
2026-01-14T08:21:26.7426994Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:21:26.7427369Z   REPOSITORY: pytorch/ao
2026-01-14T08:21:26.7427617Z   PR_NUMBER: 3500
2026-01-14T08:21:26.7429298Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:21:26.7431166Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:21:26.7431732Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:21:26.7432282Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:21:26.7432671Z   HAS_NVIDIA_GPU: true
2026-01-14T08:21:26.7432970Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:21:26.7433570Z   ALL_SECRETS: {
  "github_token": "***"
}
2026-01-14T08:21:26.7433869Z ##[endgroup]
2026-01-14T08:21:26.7478994Z + echo '#!/usr/bin/env bash'
2026-01-14T08:21:26.7479284Z + echo 'set -eou pipefail'
2026-01-14T08:21:26.7479743Z + echo 'eval "$(conda shell.bash hook)"'
2026-01-14T08:21:26.7480061Z + echo 'set -x'
2026-01-14T08:21:26.7480429Z + echo 'conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:21:26.7480868Z conda activate venv
2026-01-14T08:21:26.7481138Z python -m pip install --upgrade pip
2026-01-14T08:21:26.7481613Z pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
2026-01-14T08:21:26.7482097Z pip install -r dev-requirements.txt
2026-01-14T08:21:26.7482415Z pip install . --no-build-isolation
2026-01-14T08:21:26.7482748Z export CONDA=$(dirname $(dirname $(which conda)))
2026-01-14T08:21:26.7483113Z export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
2026-01-14T08:21:26.7483459Z pytest test --verbose -s
2026-01-14T08:21:26.7483696Z '
2026-01-14T08:21:26.7484003Z + chmod +x /home/ec2-user/actions-runner/_work/_temp/exec_script
2026-01-14T08:21:26.7498568Z + python3 /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py ''
2026-01-14T08:21:47.2027778Z Running command: 
2026-01-14T08:21:47.2033607Z         docker run             -e PR_NUMBER             -e RUNNER_ARTIFACT_DIR=/artifacts             -e RUNNER_DOCS_DIR=/docs             -e RUNNER_TEST_RESULTS_DIR=/test-results             --env-file="/home/ec2-user/actions-runner/_work/_temp/github_env_20985547555"             `# It is unknown why the container sees a different value for this.`             -e GITHUB_STEP_SUMMARY             -e SECRET_GITHUB_TOKEN             --cap-add=SYS_PTRACE             --detach             --ipc=host             --security-opt seccomp=unconfined             --shm-size=2g             --tty             --ulimit stack=10485760:83886080             --ulimit core=0             --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all             -v "/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao:/pytorch/ao"             -v "/home/ec2-user/actions-runner/_work/ao/ao/test-infra:/test-infra"             -v "/home/ec2-user/actions-runner/_work/_temp/artifacts:/artifacts"             -v "/home/ec2-user/actions-runner/_work/_temp/docs:/docs"             -v "/home/ec2-user/actions-runner/_work/_temp/test-results:/test-results"             -v "/home/ec2-user/actions-runner/_work/_temp/exec_script:/exec"             -v "/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_0eeaa851-5b41-444f-abb0-65e0ba94a582":"/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_0eeaa851-5b41-444f-abb0-65e0ba94a582"             -w /pytorch/ao             "pytorch/almalinux-builder:cuda12.6"
2026-01-14T08:21:47.2039806Z         
2026-01-14T08:21:47.2040135Z 18321e05e6d62478d0afb639811f60e8bbfed2aefc0290c47f1e3b30aefd4d85
2026-01-14T08:21:47.2040801Z Running command: docker exec -t 18321e05e6d62478d0afb639811f60e8bbfed2aefc0290c47f1e3b30aefd4d85 /exec
2026-01-14T08:21:47.2041495Z + conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:21:47.2041962Z + local cmd=create
2026-01-14T08:21:47.2042177Z + case "$cmd" in
2026-01-14T08:21:47.2042542Z + __conda_exe create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:21:47.2043152Z + /opt/conda/bin/conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:21:47.2043655Z Could not load conda plugin `menuinst`:
2026-01-14T08:21:47.2043873Z 
2026-01-14T08:21:47.2043998Z Plugin requires `conda` to be installed.
2026-01-14T08:21:47.2045039Z Collecting package metadata (current_repodata.json): - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / done
2026-01-14T08:21:47.2046188Z Solving environment: \ unsuccessful attempt using repodata from current_repodata.json, retrying with next repodata source.
2026-01-14T08:21:47.2047638Z Collecting package metadata (repodata.json): / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | done
2026-01-14T08:21:47.2048639Z Solving environment: - \ | / - \ done
2026-01-14T08:21:47.2048885Z 
2026-01-14T08:21:47.2048890Z 
2026-01-14T08:21:47.2049028Z ==> WARNING: A newer version of conda exists. <==
2026-01-14T08:21:47.2049371Z   current version: 23.5.2
2026-01-14T08:21:47.2049624Z   latest version: 25.11.1
2026-01-14T08:21:47.2049784Z 
2026-01-14T08:21:47.2049896Z Please update conda by running
2026-01-14T08:21:47.2050081Z 
2026-01-14T08:21:47.2050207Z     $ conda update -n base -c defaults conda
2026-01-14T08:21:47.2050432Z 
2026-01-14T08:21:47.2050646Z Or to minimize the number of packages updated during conda update use
2026-01-14T08:21:47.2050963Z 
2026-01-14T08:21:47.2051079Z      conda install conda=25.11.1
2026-01-14T08:21:47.2051265Z 
2026-01-14T08:21:47.2051269Z 
2026-01-14T08:21:47.2051273Z 
2026-01-14T08:21:47.2051363Z ## Package Plan ##
2026-01-14T08:21:47.2051512Z 
2026-01-14T08:21:47.2051637Z   environment location: /opt/conda/envs/venv
2026-01-14T08:21:47.2051862Z 
2026-01-14T08:21:47.2051958Z   added / updated specs:
2026-01-14T08:21:47.2052322Z     - libgcc-ng=11.2.0
2026-01-14T08:21:47.2052565Z     - libstdcxx-ng=11.2.0
2026-01-14T08:21:47.2052815Z     - python=3.10
2026-01-14T08:21:47.2052949Z 
2026-01-14T08:21:47.2052953Z 
2026-01-14T08:21:47.2053082Z The following packages will be downloaded:
2026-01-14T08:21:47.2053306Z 
2026-01-14T08:21:47.2053421Z     package                    |            build
2026-01-14T08:21:47.2053755Z     ---------------------------|-----------------
2026-01-14T08:21:47.2054120Z     bzip2-1.0.8                |       h5eee18b_6         262 KB
2026-01-14T08:21:47.2054660Z     ld_impl_linux-64-2.44      |       h153f514_2         672 KB
2026-01-14T08:21:47.2055077Z     libffi-3.4.4               |       h6a678d5_1         141 KB
2026-01-14T08:21:47.2055489Z     libnsl-2.0.0               |       h5eee18b_0          31 KB
2026-01-14T08:21:47.2055900Z     libxcb-1.17.0              |       h9b100fa_0         430 KB
2026-01-14T08:21:47.2056302Z     libzlib-1.3.1              |       hb25bd0a_0          59 KB
2026-01-14T08:21:47.2056716Z     ncurses-6.5                |       h7934f7d_0         1.1 MB
2026-01-14T08:21:47.2057108Z     pip-25.3                   |     pyhc872135_0         1.1 MB
2026-01-14T08:21:47.2057522Z     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
2026-01-14T08:21:47.2057938Z     python-3.10.19             |       h6fa692b_0        24.5 MB
2026-01-14T08:21:47.2058356Z     readline-8.3               |       hc2a1206_0         471 KB
2026-01-14T08:21:47.2058783Z     setuptools-80.9.0          |  py310h06a4308_0         1.4 MB
2026-01-14T08:21:47.2059192Z     sqlite-3.51.0              |       h2a70700_0         1.2 MB
2026-01-14T08:21:47.2059588Z     tk-8.6.15                  |       h54e0aa7_0         3.4 MB
2026-01-14T08:21:47.2059975Z     tzdata-2025b               |       h04d1e81_0         116 KB
2026-01-14T08:21:47.2060379Z     wheel-0.45.1               |  py310h06a4308_0         115 KB
2026-01-14T08:21:47.2060792Z     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
2026-01-14T08:21:47.2061229Z     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
2026-01-14T08:21:47.2061665Z     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
2026-01-14T08:21:47.2062109Z     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
2026-01-14T08:21:47.2062525Z     xz-5.6.4                   |       h5eee18b_1         567 KB
2026-01-14T08:21:47.2062908Z     zlib-1.3.1                 |       hb25bd0a_0          96 KB
2026-01-14T08:21:47.2063307Z     ------------------------------------------------------------
2026-01-14T08:21:47.2063669Z                                            Total:        37.1 MB
2026-01-14T08:21:47.2063907Z 
2026-01-14T08:21:47.2064038Z The following NEW packages will be INSTALLED:
2026-01-14T08:21:47.2064272Z 
2026-01-14T08:21:47.2064486Z   _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main 
2026-01-14T08:21:47.2064956Z   _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu 
2026-01-14T08:21:47.2065418Z   bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 
2026-01-14T08:21:47.2065926Z   ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 
2026-01-14T08:21:47.2066441Z   expat              pkgs/main/linux-64::expat-2.7.3-h3385a95_0 
2026-01-14T08:21:47.2066922Z   ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 
2026-01-14T08:21:47.2067409Z   libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 
2026-01-14T08:21:47.2067871Z   libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 
2026-01-14T08:21:47.2068333Z   libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 
2026-01-14T08:21:47.2068786Z   libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 
2026-01-14T08:21:47.2069269Z   libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 
2026-01-14T08:21:47.2069760Z   libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 
2026-01-14T08:21:47.2070216Z   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
2026-01-14T08:21:47.2070747Z   libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 
2026-01-14T08:21:47.2071203Z   ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 
2026-01-14T08:21:47.2071707Z   openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 
2026-01-14T08:21:47.2072150Z   pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 
2026-01-14T08:21:47.2072633Z   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
2026-01-14T08:21:47.2073203Z   python             pkgs/main/linux-64::python-3.10.19-h6fa692b_0 
2026-01-14T08:21:47.2073670Z   readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 
2026-01-14T08:21:47.2074165Z   setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 
2026-01-14T08:21:47.2074664Z   sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 
2026-01-14T08:21:47.2075082Z   tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 
2026-01-14T08:21:47.2075586Z   tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 
2026-01-14T08:21:47.2076031Z   wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 
2026-01-14T08:21:47.2076504Z   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
2026-01-14T08:21:47.2077008Z   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
2026-01-14T08:21:47.2077523Z   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
2026-01-14T08:21:47.2078066Z   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
2026-01-14T08:21:47.2078718Z   xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 
2026-01-14T08:21:47.2079115Z   zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 
2026-01-14T08:21:47.2079379Z 
2026-01-14T08:21:47.2079384Z 
2026-01-14T08:21:47.2079388Z 
2026-01-14T08:21:47.2079499Z Downloading and Extracting Packages
2026-01-14T08:21:47.2079702Z 
2026-01-14T08:21:47.2079853Z bzip2-1.0.8          | 262 KB    | :   0% 0/1 [00:00<?, ?it/s]
2026-01-14T08:21:47.2080109Z 
2026-01-14T08:21:47.2080354Z zlib-1.3.1           | 96 KB     | :   0% 0/1 [00:00<?, ?it/s][A
2026-01-14T08:21:47.2080621Z 
2026-01-14T08:21:47.2080626Z 
2026-01-14T08:21:47.2080881Z tk-8.6.15            | 3.4 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A
2026-01-14T08:21:47.2081148Z 
2026-01-14T08:21:47.2081152Z 
2026-01-14T08:21:47.2081156Z 
2026-01-14T08:21:47.2081397Z libffi-3.4.4         | 141 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A
2026-01-14T08:21:47.2081669Z 
2026-01-14T08:21:47.2081672Z 
2026-01-14T08:21:47.2081681Z 
2026-01-14T08:21:47.2081685Z 
2026-01-14T08:21:47.2081949Z xorg-libxdmcp-1.1.5  | 19 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A
2026-01-14T08:21:47.2082257Z 
2026-01-14T08:21:47.2082260Z 
2026-01-14T08:21:47.2082264Z 
2026-01-14T08:21:47.2082267Z 
2026-01-14T08:21:47.2082271Z 
2026-01-14T08:21:47.2082552Z xorg-xorgproto-2024. | 580 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A
2026-01-14T08:21:47.2082878Z 
2026-01-14T08:21:47.2082882Z 
2026-01-14T08:21:47.2082890Z 
2026-01-14T08:21:47.2082893Z 
2026-01-14T08:21:47.2082897Z 
2026-01-14T08:21:47.2082900Z 
2026-01-14T08:21:47.2083161Z python-3.10.19       | 24.5 MB   | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A
2026-01-14T08:21:47.2083457Z 
2026-01-14T08:21:47.2083460Z 
2026-01-14T08:21:47.2083464Z 
2026-01-14T08:21:47.2083467Z 
2026-01-14T08:21:47.2083477Z 
2026-01-14T08:21:47.2083481Z 
2026-01-14T08:21:47.2083484Z 
2026-01-14T08:21:47.2083745Z sqlite-3.51.0        | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A
2026-01-14T08:21:47.2084046Z 
2026-01-14T08:21:47.2084050Z 
2026-01-14T08:21:47.2084053Z 
2026-01-14T08:21:47.2084057Z 
2026-01-14T08:21:47.2084060Z 
2026-01-14T08:21:47.2084064Z 
2026-01-14T08:21:47.2084067Z 
2026-01-14T08:21:47.2084465Z 
2026-01-14T08:21:47.2084768Z ld_impl_linux-64-2.4 | 672 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A
2026-01-14T08:21:47.2085094Z 
2026-01-14T08:21:47.2085098Z 
2026-01-14T08:21:47.2085102Z 
2026-01-14T08:21:47.2085294Z 
2026-01-14T08:21:47.2085298Z 
2026-01-14T08:21:47.2085301Z 
2026-01-14T08:21:47.2085305Z 
2026-01-14T08:21:47.2085308Z 
2026-01-14T08:21:47.2085312Z 
2026-01-14T08:21:47.2085610Z tzdata-2025b         | 116 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A
2026-01-14T08:21:47.2085931Z 
2026-01-14T08:21:47.2085934Z 
2026-01-14T08:21:47.2085938Z 
2026-01-14T08:21:47.2085941Z 
2026-01-14T08:21:47.2085945Z 
2026-01-14T08:21:47.2085949Z 
2026-01-14T08:21:47.2085952Z 
2026-01-14T08:21:47.2085956Z 
2026-01-14T08:21:47.2085959Z 
2026-01-14T08:21:47.2086080Z 
2026-01-14T08:21:47.2086393Z xorg-libxau-1.0.12   | 13 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:47.2086728Z 
2026-01-14T08:21:47.2086732Z 
2026-01-14T08:21:47.2086735Z 
2026-01-14T08:21:47.2086739Z 
2026-01-14T08:21:47.2086742Z 
2026-01-14T08:21:47.2086746Z 
2026-01-14T08:21:47.2086750Z 
2026-01-14T08:21:47.2086753Z 
2026-01-14T08:21:47.2086757Z 
2026-01-14T08:21:47.2086760Z 
2026-01-14T08:21:47.2086775Z 
2026-01-14T08:21:49.4236702Z libxcb-1.17.0        | 430 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4237081Z 
2026-01-14T08:21:49.4237085Z 
2026-01-14T08:21:49.4237089Z 
2026-01-14T08:21:49.4237093Z 
2026-01-14T08:21:49.4237097Z 
2026-01-14T08:21:49.4237102Z 
2026-01-14T08:21:49.4237105Z 
2026-01-14T08:21:49.4237109Z 
2026-01-14T08:21:49.4237113Z 
2026-01-14T08:21:49.4237116Z 
2026-01-14T08:21:49.4237120Z 
2026-01-14T08:21:49.4237124Z 
2026-01-14T08:21:49.4237473Z xz-5.6.4             | 567 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4237813Z 
2026-01-14T08:21:49.4237817Z 
2026-01-14T08:21:49.4237821Z 
2026-01-14T08:21:49.4237824Z 
2026-01-14T08:21:49.4237828Z 
2026-01-14T08:21:49.4237832Z 
2026-01-14T08:21:49.4237835Z 
2026-01-14T08:21:49.4237839Z 
2026-01-14T08:21:49.4237843Z 
2026-01-14T08:21:49.4237846Z 
2026-01-14T08:21:49.4237850Z 
2026-01-14T08:21:49.4237854Z 
2026-01-14T08:21:49.4237857Z 
2026-01-14T08:21:49.4238202Z wheel-0.45.1         | 115 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4238547Z 
2026-01-14T08:21:49.4238551Z 
2026-01-14T08:21:49.4238555Z 
2026-01-14T08:21:49.4238558Z 
2026-01-14T08:21:49.4238562Z 
2026-01-14T08:21:49.4238566Z 
2026-01-14T08:21:49.4238569Z 
2026-01-14T08:21:49.4238573Z 
2026-01-14T08:21:49.4238576Z 
2026-01-14T08:21:49.4238586Z 
2026-01-14T08:21:49.4238590Z 
2026-01-14T08:21:49.4238593Z 
2026-01-14T08:21:49.4238597Z 
2026-01-14T08:21:49.4238600Z 
2026-01-14T08:21:49.4238950Z xorg-libx11-1.8.12   | 895 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4239433Z 
2026-01-14T08:21:49.4239436Z 
2026-01-14T08:21:49.4239440Z 
2026-01-14T08:21:49.4239444Z 
2026-01-14T08:21:49.4239454Z 
2026-01-14T08:21:49.4239457Z 
2026-01-14T08:21:49.4239461Z 
2026-01-14T08:21:49.4239465Z 
2026-01-14T08:21:49.4239468Z 
2026-01-14T08:21:49.4239472Z 
2026-01-14T08:21:49.4239475Z 
2026-01-14T08:21:49.4239485Z 
2026-01-14T08:21:49.4239488Z 
2026-01-14T08:21:49.4239492Z 
2026-01-14T08:21:49.4239495Z 
2026-01-14T08:21:49.4239828Z libzlib-1.3.1        | 59 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4240200Z 
2026-01-14T08:21:49.4240204Z 
2026-01-14T08:21:49.4240208Z 
2026-01-14T08:21:49.4240211Z 
2026-01-14T08:21:49.4240215Z 
2026-01-14T08:21:49.4240219Z 
2026-01-14T08:21:49.4240222Z 
2026-01-14T08:21:49.4240226Z 
2026-01-14T08:21:49.4240229Z 
2026-01-14T08:21:49.4240233Z 
2026-01-14T08:21:49.4240237Z 
2026-01-14T08:21:49.4240246Z 
2026-01-14T08:21:49.4240250Z 
2026-01-14T08:21:49.4240253Z 
2026-01-14T08:21:49.4240257Z 
2026-01-14T08:21:49.4240260Z 
2026-01-14T08:21:49.4240643Z pthread-stubs-0.3    | 5 KB      | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4241034Z 
2026-01-14T08:21:49.4241038Z 
2026-01-14T08:21:49.4241041Z 
2026-01-14T08:21:49.4241045Z 
2026-01-14T08:21:49.4241049Z 
2026-01-14T08:21:49.4241304Z 
2026-01-14T08:21:49.4241308Z 
2026-01-14T08:21:49.4241311Z 
2026-01-14T08:21:49.4241315Z 
2026-01-14T08:21:49.4241318Z 
2026-01-14T08:21:49.4241322Z 
2026-01-14T08:21:49.4241325Z 
2026-01-14T08:21:49.4241329Z 
2026-01-14T08:21:49.4241333Z 
2026-01-14T08:21:49.4241336Z 
2026-01-14T08:21:49.4241340Z 
2026-01-14T08:21:49.4241351Z 
2026-01-14T08:21:49.4241697Z pip-25.3             | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4242061Z 
2026-01-14T08:21:49.4242065Z 
2026-01-14T08:21:49.4242216Z 
2026-01-14T08:21:49.4242221Z 
2026-01-14T08:21:49.4242225Z 
2026-01-14T08:21:49.4242228Z 
2026-01-14T08:21:49.4242232Z 
2026-01-14T08:21:49.4242235Z 
2026-01-14T08:21:49.4242245Z 
2026-01-14T08:21:49.4242249Z 
2026-01-14T08:21:49.4242253Z 
2026-01-14T08:21:49.4242256Z 
2026-01-14T08:21:49.4242260Z 
2026-01-14T08:21:49.4242263Z 
2026-01-14T08:21:49.4242267Z 
2026-01-14T08:21:49.4242271Z 
2026-01-14T08:21:49.4242274Z 
2026-01-14T08:21:49.4242278Z 
2026-01-14T08:21:49.4242643Z libnsl-2.0.0         | 31 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4243028Z 
2026-01-14T08:21:49.4243032Z 
2026-01-14T08:21:49.4243035Z 
2026-01-14T08:21:49.4243039Z 
2026-01-14T08:21:49.4243043Z 
2026-01-14T08:21:49.4243046Z 
2026-01-14T08:21:49.4243050Z 
2026-01-14T08:21:49.4243053Z 
2026-01-14T08:21:49.4243057Z 
2026-01-14T08:21:49.4243061Z 
2026-01-14T08:21:49.4243064Z 
2026-01-14T08:21:49.4243068Z 
2026-01-14T08:21:49.4243071Z 
2026-01-14T08:21:49.4243075Z 
2026-01-14T08:21:49.4243082Z 
2026-01-14T08:21:49.4243086Z 
2026-01-14T08:21:49.4243089Z 
2026-01-14T08:21:49.4243093Z 
2026-01-14T08:21:49.4243097Z 
2026-01-14T08:21:49.4243368Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4243674Z 
2026-01-14T08:21:49.4243969Z zlib-1.3.1           | 96 KB     | :  17% 0.16692817116658176/1 [00:00<00:00,  1.11s/it][A
2026-01-14T08:21:49.4244291Z 
2026-01-14T08:21:49.4244300Z 
2026-01-14T08:21:49.4244595Z tk-8.6.15            | 3.4 MB    | :   0% 0.00453827661272385/1 [00:00<00:41, 41.61s/it][A[A
2026-01-14T08:21:49.4244912Z 
2026-01-14T08:21:49.4244916Z 
2026-01-14T08:21:49.4244920Z 
2026-01-14T08:21:49.4244924Z 
2026-01-14T08:21:49.4245273Z xorg-libxdmcp-1.1.5  | 19 KB     | :  85% 0.85067497403946/1 [00:00<00:00,  4.53it/s][A[A[A[A
2026-01-14T08:21:49.4245822Z bzip2-1.0.8          | 262 KB    | :   6% 0.06104685823297961/1 [00:00<00:03,  3.31s/it]
2026-01-14T08:21:49.4246142Z 
2026-01-14T08:21:49.4246146Z 
2026-01-14T08:21:49.4246154Z 
2026-01-14T08:21:49.4246476Z libffi-3.4.4         | 141 KB    | :  11% 0.11323440988036575/1 [00:00<00:01,  1.83s/it][A[A[A
2026-01-14T08:21:49.4246818Z 
2026-01-14T08:21:49.4246822Z 
2026-01-14T08:21:49.4246826Z 
2026-01-14T08:21:49.4246829Z 
2026-01-14T08:21:49.4246833Z 
2026-01-14T08:21:49.4246842Z 
2026-01-14T08:21:49.4247222Z python-3.10.19       | 24.5 MB   | :   0% 0.0006386825426160966/1 [00:00<06:01, 361.58s/it][A[A[A[A[A[A
2026-01-14T08:21:49.4247612Z 
2026-01-14T08:21:49.4247615Z 
2026-01-14T08:21:49.4247619Z 
2026-01-14T08:21:49.4247623Z 
2026-01-14T08:21:49.4247960Z xorg-libxdmcp-1.1.5  | 19 KB     | : 100% 1.0/1 [00:00<00:00,  4.53it/s]             [A[A[A[A
2026-01-14T08:21:49.4248318Z 
2026-01-14T08:21:49.4248604Z zlib-1.3.1           | 96 KB     | : 100% 1.0/1 [00:00<00:00,  1.11s/it]                [A
2026-01-14T08:21:49.4248927Z 
2026-01-14T08:21:49.4248930Z 
2026-01-14T08:21:49.4248934Z 
2026-01-14T08:21:49.4248937Z 
2026-01-14T08:21:49.4248941Z 
2026-01-14T08:21:49.4249323Z xorg-xorgproto-2024. | 580 KB    | :   3% 0.02757436782092818/1 [00:00<00:08,  8.95s/it][A[A[A[A[A
2026-01-14T08:21:49.4249719Z 
2026-01-14T08:21:49.4249722Z 
2026-01-14T08:21:49.4249726Z 
2026-01-14T08:21:49.4249730Z 
2026-01-14T08:21:49.4249740Z 
2026-01-14T08:21:49.4249743Z 
2026-01-14T08:21:49.4249747Z 
2026-01-14T08:21:49.4250122Z sqlite-3.51.0        | 1.2 MB    | :   1% 0.013350140517073497/1 [00:00<00:18, 18.74s/it][A[A[A[A[A[A[A
2026-01-14T08:21:49.4250597Z 
2026-01-14T08:21:49.4250600Z 
2026-01-14T08:21:49.4250604Z 
2026-01-14T08:21:49.4250607Z 
2026-01-14T08:21:49.4250611Z 
2026-01-14T08:21:49.4250615Z 
2026-01-14T08:21:49.4250624Z 
2026-01-14T08:21:49.4250628Z 
2026-01-14T08:21:49.4251030Z ld_impl_linux-64-2.4 | 672 KB    | :   2% 0.02380578754961961/1 [00:00<00:10, 10.71s/it][A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4251444Z 
2026-01-14T08:21:49.4251448Z 
2026-01-14T08:21:49.4251829Z tk-8.6.15            | 3.4 MB    | :  75% 0.753353917712159/1 [00:00<00:00,  3.24it/s]  [A[A
2026-01-14T08:21:49.4252152Z 
2026-01-14T08:21:49.4252155Z 
2026-01-14T08:21:49.4252159Z 
2026-01-14T08:21:49.4252163Z 
2026-01-14T08:21:49.4252166Z 
2026-01-14T08:21:49.4252170Z 
2026-01-14T08:21:49.4252173Z 
2026-01-14T08:21:49.4252177Z 
2026-01-14T08:21:49.4252181Z 
2026-01-14T08:21:49.4252580Z tzdata-2025b         | 116 KB    | :  14% 0.13742430088406501/1 [00:00<00:02,  2.34s/it][A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4252999Z 
2026-01-14T08:21:49.4253003Z 
2026-01-14T08:21:49.4253007Z 
2026-01-14T08:21:49.4253010Z 
2026-01-14T08:21:49.4253014Z 
2026-01-14T08:21:49.4253017Z 
2026-01-14T08:21:49.4253390Z python-3.10.19       | 24.5 MB   | :   8% 0.08111268291224426/1 [00:00<00:02,  3.25s/it]   [A[A[A[A[A[A
2026-01-14T08:21:49.4253965Z bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:00<00:00,  3.49it/s]                
2026-01-14T08:21:49.4254280Z 
2026-01-14T08:21:49.4254284Z 
2026-01-14T08:21:49.4254287Z 
2026-01-14T08:21:49.4254291Z 
2026-01-14T08:21:49.4254295Z 
2026-01-14T08:21:49.4254303Z 
2026-01-14T08:21:49.4254313Z 
2026-01-14T08:21:49.4254316Z 
2026-01-14T08:21:49.4254320Z 
2026-01-14T08:21:49.4254323Z 
2026-01-14T08:21:49.4254663Z xorg-libxau-1.0.12   | 13 KB     | : 100% 1.0/1 [00:00<00:00,  3.01it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4255191Z bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:00<00:00,  3.49it/s]
2026-01-14T08:21:49.4255463Z 
2026-01-14T08:21:49.4255466Z 
2026-01-14T08:21:49.4255474Z 
2026-01-14T08:21:49.4255478Z 
2026-01-14T08:21:49.4255481Z 
2026-01-14T08:21:49.4255485Z 
2026-01-14T08:21:49.4255488Z 
2026-01-14T08:21:49.4255492Z 
2026-01-14T08:21:49.4255495Z 
2026-01-14T08:21:49.4255499Z 
2026-01-14T08:21:49.4255502Z 
2026-01-14T08:21:49.4255924Z libxcb-1.17.0        | 430 KB    | :   4% 0.03717806167600808/1 [00:00<00:09,  9.54s/it][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4256343Z 
2026-01-14T08:21:49.4256346Z 
2026-01-14T08:21:49.4256350Z 
2026-01-14T08:21:49.4256354Z 
2026-01-14T08:21:49.4256357Z 
2026-01-14T08:21:49.4256365Z 
2026-01-14T08:21:49.4256368Z 
2026-01-14T08:21:49.4256372Z 
2026-01-14T08:21:49.4256376Z 
2026-01-14T08:21:49.4256379Z 
2026-01-14T08:21:49.4256383Z 
2026-01-14T08:21:49.4256386Z 
2026-01-14T08:21:49.4256801Z xz-5.6.4             | 567 KB    | :   3% 0.028233137059266496/1 [00:00<00:12, 12.75s/it][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4257219Z 
2026-01-14T08:21:49.4257222Z 
2026-01-14T08:21:49.4257226Z 
2026-01-14T08:21:49.4257233Z 
2026-01-14T08:21:49.4257237Z 
2026-01-14T08:21:49.4257240Z 
2026-01-14T08:21:49.4257244Z 
2026-01-14T08:21:49.4257248Z 
2026-01-14T08:21:49.4257251Z 
2026-01-14T08:21:49.4257255Z 
2026-01-14T08:21:49.4257258Z 
2026-01-14T08:21:49.4257269Z 
2026-01-14T08:21:49.4257272Z 
2026-01-14T08:21:49.4257697Z wheel-0.45.1         | 115 KB    | :  14% 0.13956539146286406/1 [00:00<00:02,  2.66s/it][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4258124Z 
2026-01-14T08:21:49.4258128Z 
2026-01-14T08:21:49.4258131Z 
2026-01-14T08:21:49.4258135Z 
2026-01-14T08:21:49.4258142Z 
2026-01-14T08:21:49.4258145Z 
2026-01-14T08:21:49.4258149Z 
2026-01-14T08:21:49.4258160Z 
2026-01-14T08:21:49.4258164Z 
2026-01-14T08:21:49.4258168Z 
2026-01-14T08:21:49.4258171Z 
2026-01-14T08:21:49.4258175Z 
2026-01-14T08:21:49.4258178Z 
2026-01-14T08:21:49.4258182Z 
2026-01-14T08:21:49.4258644Z xorg-libx11-1.8.12   | 895 KB    | :   2% 0.017882324178246957/1 [00:00<00:21, 21.73s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4259187Z 
2026-01-14T08:21:49.4259190Z 
2026-01-14T08:21:49.4259200Z 
2026-01-14T08:21:49.4259204Z 
2026-01-14T08:21:49.4259207Z 
2026-01-14T08:21:49.4259211Z 
2026-01-14T08:21:49.4259573Z python-3.10.19       | 24.5 MB   | :  18% 0.1839405722734358/1 [00:00<00:01,  1.78s/it] [A[A[A[A[A[A
2026-01-14T08:21:49.4259943Z 
2026-01-14T08:21:49.4259946Z 
2026-01-14T08:21:49.4259950Z 
2026-01-14T08:21:49.4259954Z 
2026-01-14T08:21:49.4259957Z 
2026-01-14T08:21:49.4259966Z 
2026-01-14T08:21:49.4259970Z 
2026-01-14T08:21:49.4259974Z 
2026-01-14T08:21:49.4260837Z 
2026-01-14T08:21:49.4260843Z 
2026-01-14T08:21:49.4260847Z 
2026-01-14T08:21:49.4260851Z 
2026-01-14T08:21:49.4260854Z 
2026-01-14T08:21:49.4260858Z 
2026-01-14T08:21:49.4260861Z 
2026-01-14T08:21:49.4260865Z 
2026-01-14T08:21:49.4260869Z 
2026-01-14T08:21:49.4261334Z pip-25.3             | 1.1 MB    | :   1% 0.013906347741873605/1 [00:00<00:30, 31.09s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4261790Z 
2026-01-14T08:21:49.4261800Z 
2026-01-14T08:21:49.4261803Z 
2026-01-14T08:21:49.4261807Z 
2026-01-14T08:21:49.4261810Z 
2026-01-14T08:21:49.4261814Z 
2026-01-14T08:21:49.4261817Z 
2026-01-14T08:21:49.4261821Z 
2026-01-14T08:21:49.4261824Z 
2026-01-14T08:21:49.4261828Z 
2026-01-14T08:21:49.4261831Z 
2026-01-14T08:21:49.4261835Z 
2026-01-14T08:21:49.4261840Z 
2026-01-14T08:21:49.4261844Z 
2026-01-14T08:21:49.4261849Z 
2026-01-14T08:21:49.4262302Z libzlib-1.3.1        | 59 KB     | :  27% 0.2699309685816432/1 [00:00<00:01,  1.62s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4262751Z 
2026-01-14T08:21:49.4262755Z 
2026-01-14T08:21:49.4262758Z 
2026-01-14T08:21:49.4262762Z 
2026-01-14T08:21:49.4262766Z 
2026-01-14T08:21:49.4262769Z 
2026-01-14T08:21:49.4262773Z 
2026-01-14T08:21:49.4262777Z 
2026-01-14T08:21:49.4262780Z 
2026-01-14T08:21:49.4262784Z 
2026-01-14T08:21:49.4262787Z 
2026-01-14T08:21:49.4262791Z 
2026-01-14T08:21:49.4262795Z 
2026-01-14T08:21:49.4262798Z 
2026-01-14T08:21:49.4262805Z 
2026-01-14T08:21:49.4262814Z 
2026-01-14T08:21:49.4263216Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  2.22it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4263624Z 
2026-01-14T08:21:49.4263628Z 
2026-01-14T08:21:49.4263631Z 
2026-01-14T08:21:49.4263635Z 
2026-01-14T08:21:49.4263638Z 
2026-01-14T08:21:49.4263642Z 
2026-01-14T08:21:49.4263645Z 
2026-01-14T08:21:49.4263649Z 
2026-01-14T08:21:49.4263652Z 
2026-01-14T08:21:49.4263662Z 
2026-01-14T08:21:49.4263666Z 
2026-01-14T08:21:49.4263669Z 
2026-01-14T08:21:49.4263677Z 
2026-01-14T08:21:49.4263680Z 
2026-01-14T08:21:49.4263684Z 
2026-01-14T08:21:49.4263687Z 
2026-01-14T08:21:49.4263691Z 
2026-01-14T08:21:49.4263695Z 
2026-01-14T08:21:49.4264153Z libnsl-2.0.0         | 31 KB     | :  52% 0.515966492410405/1 [00:00<00:00,  1.12it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4264617Z 
2026-01-14T08:21:49.4264620Z 
2026-01-14T08:21:49.4264624Z 
2026-01-14T08:21:49.4264628Z 
2026-01-14T08:21:49.4264636Z 
2026-01-14T08:21:49.4264639Z 
2026-01-14T08:21:49.4264643Z 
2026-01-14T08:21:49.4264646Z 
2026-01-14T08:21:49.4264650Z 
2026-01-14T08:21:49.4264654Z 
2026-01-14T08:21:49.4264657Z 
2026-01-14T08:21:49.4264661Z 
2026-01-14T08:21:49.4264664Z 
2026-01-14T08:21:49.4264668Z 
2026-01-14T08:21:49.4264672Z 
2026-01-14T08:21:49.4264675Z 
2026-01-14T08:21:49.4264679Z 
2026-01-14T08:21:49.4264682Z 
2026-01-14T08:21:49.4264686Z 
2026-01-14T08:21:49.4264948Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4265261Z 
2026-01-14T08:21:49.4265264Z 
2026-01-14T08:21:49.4265268Z 
2026-01-14T08:21:49.4265272Z 
2026-01-14T08:21:49.4265275Z 
2026-01-14T08:21:49.4265279Z 
2026-01-14T08:21:49.4265282Z 
2026-01-14T08:21:49.4265286Z 
2026-01-14T08:21:49.4265671Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:00<00:00,  2.39it/s]                [A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4266061Z 
2026-01-14T08:21:49.4266065Z 
2026-01-14T08:21:49.4266068Z 
2026-01-14T08:21:49.4266181Z 
2026-01-14T08:21:49.4266185Z 
2026-01-14T08:21:49.4266188Z 
2026-01-14T08:21:49.4266192Z 
2026-01-14T08:21:49.4266195Z 
2026-01-14T08:21:49.4266529Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:00<00:00,  2.39it/s][A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4266890Z 
2026-01-14T08:21:49.4266893Z 
2026-01-14T08:21:49.4266897Z 
2026-01-14T08:21:49.4266900Z 
2026-01-14T08:21:49.4266904Z 
2026-01-14T08:21:49.4266907Z 
2026-01-14T08:21:49.4267358Z python-3.10.19       | 24.5 MB   | :  29% 0.28549109654939514/1 [00:00<00:01,  1.40s/it][A[A[A[A[A[A
2026-01-14T08:21:49.4267736Z 
2026-01-14T08:21:49.4267739Z 
2026-01-14T08:21:49.4267743Z 
2026-01-14T08:21:49.4267747Z 
2026-01-14T08:21:49.4267750Z 
2026-01-14T08:21:49.4267754Z 
2026-01-14T08:21:49.4267757Z 
2026-01-14T08:21:49.4268115Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.84it/s]                 [A[A[A[A[A[A[A
2026-01-14T08:21:49.4268489Z 
2026-01-14T08:21:49.4268493Z 
2026-01-14T08:21:49.4268501Z 
2026-01-14T08:21:49.4268504Z 
2026-01-14T08:21:49.4268508Z 
2026-01-14T08:21:49.4268511Z 
2026-01-14T08:21:49.4268515Z 
2026-01-14T08:21:49.4268814Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.84it/s][A[A[A[A[A[A[A
2026-01-14T08:21:49.4269142Z 
2026-01-14T08:21:49.4269146Z 
2026-01-14T08:21:49.4269156Z 
2026-01-14T08:21:49.4269160Z 
2026-01-14T08:21:49.4269163Z 
2026-01-14T08:21:49.4269167Z 
2026-01-14T08:21:49.4269524Z python-3.10.19       | 24.5 MB   | :  41% 0.41450497015784665/1 [00:00<00:00,  1.11s/it][A[A[A[A[A[A
2026-01-14T08:21:49.4269897Z 
2026-01-14T08:21:49.4269901Z 
2026-01-14T08:21:49.4269904Z 
2026-01-14T08:21:49.4269908Z 
2026-01-14T08:21:49.4269911Z 
2026-01-14T08:21:49.4269915Z 
2026-01-14T08:21:49.4270291Z python-3.10.19       | 24.5 MB   | :  56% 0.5607632724169328/1 [00:00<00:00,  1.08it/s] [A[A[A[A[A[A
2026-01-14T08:21:49.4270668Z 
2026-01-14T08:21:49.4270672Z 
2026-01-14T08:21:49.4270676Z 
2026-01-14T08:21:49.4281768Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  1.37it/s]                [A[A[A
2026-01-14T08:21:49.4282160Z 
2026-01-14T08:21:49.4282165Z 
2026-01-14T08:21:49.4282168Z 
2026-01-14T08:21:49.4282478Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  1.37it/s][A[A[A
2026-01-14T08:21:49.4282785Z 
2026-01-14T08:21:49.4282789Z 
2026-01-14T08:21:49.4282793Z 
2026-01-14T08:21:49.4282797Z 
2026-01-14T08:21:49.4282800Z 
2026-01-14T08:21:49.4282804Z 
2026-01-14T08:21:49.4283165Z python-3.10.19       | 24.5 MB   | :  69% 0.6910545111106164/1 [00:00<00:00,  1.15it/s][A[A[A[A[A[A
2026-01-14T08:21:49.4283541Z 
2026-01-14T08:21:49.4283545Z 
2026-01-14T08:21:49.4283549Z 
2026-01-14T08:21:49.4283553Z 
2026-01-14T08:21:49.4283556Z 
2026-01-14T08:21:49.4283915Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:00<00:00,  1.21it/s]                [A[A[A[A[A
2026-01-14T08:21:49.4284764Z 
2026-01-14T08:21:49.4284767Z 
2026-01-14T08:21:49.4284771Z 
2026-01-14T08:21:49.4284774Z 
2026-01-14T08:21:49.4284788Z 
2026-01-14T08:21:49.4285113Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:00<00:00,  1.21it/s][A[A[A[A[A
2026-01-14T08:21:49.4285466Z 
2026-01-14T08:21:49.4285470Z 
2026-01-14T08:21:49.4285473Z 
2026-01-14T08:21:49.4285477Z 
2026-01-14T08:21:49.4285480Z 
2026-01-14T08:21:49.4285484Z 
2026-01-14T08:21:49.4285488Z 
2026-01-14T08:21:49.4285491Z 
2026-01-14T08:21:49.4285502Z 
2026-01-14T08:21:49.4285506Z 
2026-01-14T08:21:49.4285847Z xorg-libxau-1.0.12   | 13 KB     | : 100% 1.0/1 [00:00<00:00,  3.01it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4286222Z 
2026-01-14T08:21:49.4286226Z 
2026-01-14T08:21:49.4286229Z 
2026-01-14T08:21:49.4286233Z 
2026-01-14T08:21:49.4286236Z 
2026-01-14T08:21:49.4286240Z 
2026-01-14T08:21:49.4286608Z python-3.10.19       | 24.5 MB   | :  81% 0.8117655116650587/1 [00:00<00:00,  1.15it/s][A[A[A[A[A[A
2026-01-14T08:21:49.4286981Z 
2026-01-14T08:21:49.4286985Z 
2026-01-14T08:21:49.4286988Z 
2026-01-14T08:21:49.4286992Z 
2026-01-14T08:21:49.4286995Z 
2026-01-14T08:21:49.4287165Z 
2026-01-14T08:21:49.4287529Z python-3.10.19       | 24.5 MB   | :  93% 0.9343925598473493/1 [00:01<00:00,  1.17it/s][A[A[A[A[A[A
2026-01-14T08:21:49.4287904Z 
2026-01-14T08:21:49.4287907Z 
2026-01-14T08:21:49.4287911Z 
2026-01-14T08:21:49.4287915Z 
2026-01-14T08:21:49.4287918Z 
2026-01-14T08:21:49.4287922Z 
2026-01-14T08:21:49.4287925Z 
2026-01-14T08:21:49.4287929Z 
2026-01-14T08:21:49.4287933Z 
2026-01-14T08:21:49.4287936Z 
2026-01-14T08:21:49.4287940Z 
2026-01-14T08:21:49.4288453Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]                [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4288854Z 
2026-01-14T08:21:49.4288858Z 
2026-01-14T08:21:49.4288861Z 
2026-01-14T08:21:49.4288865Z 
2026-01-14T08:21:49.4288868Z 
2026-01-14T08:21:49.4288872Z 
2026-01-14T08:21:49.4288876Z 
2026-01-14T08:21:49.4288879Z 
2026-01-14T08:21:49.4288883Z 
2026-01-14T08:21:49.4288886Z 
2026-01-14T08:21:49.4288890Z 
2026-01-14T08:21:49.4289231Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4289600Z 
2026-01-14T08:21:49.4289604Z 
2026-01-14T08:21:49.4289607Z 
2026-01-14T08:21:49.4289611Z 
2026-01-14T08:21:49.4289614Z 
2026-01-14T08:21:49.4289618Z 
2026-01-14T08:21:49.4289622Z 
2026-01-14T08:21:49.4289625Z 
2026-01-14T08:21:49.4289629Z 
2026-01-14T08:21:49.4289632Z 
2026-01-14T08:21:49.4289636Z 
2026-01-14T08:21:49.4289640Z 
2026-01-14T08:21:49.4289651Z 
2026-01-14T08:21:49.4290046Z wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:01<00:00,  1.20s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4290452Z 
2026-01-14T08:21:49.4290456Z 
2026-01-14T08:21:49.4290459Z 
2026-01-14T08:21:49.4290463Z 
2026-01-14T08:21:49.4290467Z 
2026-01-14T08:21:49.4290470Z 
2026-01-14T08:21:49.4290474Z 
2026-01-14T08:21:49.4290477Z 
2026-01-14T08:21:49.4290487Z 
2026-01-14T08:21:49.4290490Z 
2026-01-14T08:21:49.4290494Z 
2026-01-14T08:21:49.4290498Z 
2026-01-14T08:21:49.4290501Z 
2026-01-14T08:21:49.4290858Z wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:01<00:00,  1.20s/it][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4291231Z 
2026-01-14T08:21:49.4291235Z 
2026-01-14T08:21:49.4291523Z tk-8.6.15            | 3.4 MB    | : 100% 1.0/1 [00:01<00:00,  3.24it/s]              [A[A
2026-01-14T08:21:49.4291840Z 
2026-01-14T08:21:49.4291843Z 
2026-01-14T08:21:49.4291847Z 
2026-01-14T08:21:49.4291851Z 
2026-01-14T08:21:49.4291854Z 
2026-01-14T08:21:49.4291858Z 
2026-01-14T08:21:49.4291862Z 
2026-01-14T08:21:49.4291865Z 
2026-01-14T08:21:49.4291873Z 
2026-01-14T08:21:49.4291877Z 
2026-01-14T08:21:49.4291880Z 
2026-01-14T08:21:49.4291884Z 
2026-01-14T08:21:49.4292261Z xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:01<00:00,  1.44s/it]                 [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4292646Z 
2026-01-14T08:21:49.4292650Z 
2026-01-14T08:21:49.4292654Z 
2026-01-14T08:21:49.4292657Z 
2026-01-14T08:21:49.4292661Z 
2026-01-14T08:21:49.4292664Z 
2026-01-14T08:21:49.4292673Z 
2026-01-14T08:21:49.4292676Z 
2026-01-14T08:21:49.4292680Z 
2026-01-14T08:21:49.4292691Z 
2026-01-14T08:21:49.4292695Z 
2026-01-14T08:21:49.4292698Z 
2026-01-14T08:21:49.4293027Z xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:01<00:00,  1.44s/it][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4293384Z 
2026-01-14T08:21:49.4293387Z 
2026-01-14T08:21:49.4293391Z 
2026-01-14T08:21:49.4293395Z 
2026-01-14T08:21:49.4293398Z 
2026-01-14T08:21:49.4293402Z 
2026-01-14T08:21:49.4293405Z 
2026-01-14T08:21:49.4293416Z 
2026-01-14T08:21:49.4293424Z 
2026-01-14T08:21:49.4293793Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.52s/it]                [A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4294182Z 
2026-01-14T08:21:49.4294186Z 
2026-01-14T08:21:49.4294189Z 
2026-01-14T08:21:49.4294193Z 
2026-01-14T08:21:49.4294197Z 
2026-01-14T08:21:49.4294200Z 
2026-01-14T08:21:49.4294204Z 
2026-01-14T08:21:49.4294215Z 
2026-01-14T08:21:49.4294219Z 
2026-01-14T08:21:49.4294537Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.52s/it][A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4294977Z 
2026-01-14T08:21:49.4294981Z 
2026-01-14T08:21:49.4294984Z 
2026-01-14T08:21:49.4294988Z 
2026-01-14T08:21:49.4294991Z 
2026-01-14T08:21:49.4294995Z 
2026-01-14T08:21:49.4294999Z 
2026-01-14T08:21:49.4295002Z 
2026-01-14T08:21:49.4295013Z 
2026-01-14T08:21:49.4295017Z 
2026-01-14T08:21:49.4295020Z 
2026-01-14T08:21:49.4295024Z 
2026-01-14T08:21:49.4295028Z 
2026-01-14T08:21:49.4295031Z 
2026-01-14T08:21:49.4295035Z 
2026-01-14T08:21:49.4295525Z libzlib-1.3.1        | 59 KB     | : 100% 1.0/1 [00:01<00:00,  1.56s/it]               [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4295950Z 
2026-01-14T08:21:49.4295954Z 
2026-01-14T08:21:49.4295966Z 
2026-01-14T08:21:49.4295969Z 
2026-01-14T08:21:49.4295973Z 
2026-01-14T08:21:49.4295977Z 
2026-01-14T08:21:49.4295980Z 
2026-01-14T08:21:49.4295984Z 
2026-01-14T08:21:49.4295987Z 
2026-01-14T08:21:49.4295991Z 
2026-01-14T08:21:49.4295999Z 
2026-01-14T08:21:49.4296002Z 
2026-01-14T08:21:49.4296006Z 
2026-01-14T08:21:49.4296010Z 
2026-01-14T08:21:49.4296013Z 
2026-01-14T08:21:49.4296381Z libzlib-1.3.1        | 59 KB     | : 100% 1.0/1 [00:01<00:00,  1.56s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4296777Z 
2026-01-14T08:21:49.4296780Z 
2026-01-14T08:21:49.4296784Z 
2026-01-14T08:21:49.4296788Z 
2026-01-14T08:21:49.4296791Z 
2026-01-14T08:21:49.4296795Z 
2026-01-14T08:21:49.4296798Z 
2026-01-14T08:21:49.4296802Z 
2026-01-14T08:21:49.4296805Z 
2026-01-14T08:21:49.4296815Z 
2026-01-14T08:21:49.4296818Z 
2026-01-14T08:21:49.4296822Z 
2026-01-14T08:21:49.4296825Z 
2026-01-14T08:21:49.4296829Z 
2026-01-14T08:21:49.4296833Z 
2026-01-14T08:21:49.4296836Z 
2026-01-14T08:21:49.4297244Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:01<00:00,  2.22it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4297664Z 
2026-01-14T08:21:49.4297668Z 
2026-01-14T08:21:49.4297671Z 
2026-01-14T08:21:49.4297678Z 
2026-01-14T08:21:49.4297682Z 
2026-01-14T08:21:49.4297685Z 
2026-01-14T08:21:49.4297689Z 
2026-01-14T08:21:49.4297693Z 
2026-01-14T08:21:49.4297696Z 
2026-01-14T08:21:49.4297700Z 
2026-01-14T08:21:49.4297703Z 
2026-01-14T08:21:49.4297707Z 
2026-01-14T08:21:49.4297710Z 
2026-01-14T08:21:49.4297714Z 
2026-01-14T08:21:49.4297724Z 
2026-01-14T08:21:49.4297728Z 
2026-01-14T08:21:49.4297731Z 
2026-01-14T08:21:49.4297735Z 
2026-01-14T08:21:49.4298164Z libnsl-2.0.0         | 31 KB     | : 100% 1.0/1 [00:01<00:00,  1.72s/it]              [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4298603Z 
2026-01-14T08:21:49.4298607Z 
2026-01-14T08:21:49.4298611Z 
2026-01-14T08:21:49.4298614Z 
2026-01-14T08:21:49.4298626Z 
2026-01-14T08:21:49.4298630Z 
2026-01-14T08:21:49.4298633Z 
2026-01-14T08:21:49.4298637Z 
2026-01-14T08:21:49.4298641Z 
2026-01-14T08:21:49.4298644Z 
2026-01-14T08:21:49.4298648Z 
2026-01-14T08:21:49.4298651Z 
2026-01-14T08:21:49.4298655Z 
2026-01-14T08:21:49.4298658Z 
2026-01-14T08:21:49.4298666Z 
2026-01-14T08:21:49.4298669Z 
2026-01-14T08:21:49.4298673Z 
2026-01-14T08:21:49.4298676Z 
2026-01-14T08:21:49.4299070Z libnsl-2.0.0         | 31 KB     | : 100% 1.0/1 [00:01<00:00,  1.72s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4299491Z 
2026-01-14T08:21:49.4299495Z 
2026-01-14T08:21:49.4299498Z 
2026-01-14T08:21:49.4299502Z 
2026-01-14T08:21:49.4299505Z 
2026-01-14T08:21:49.4299509Z 
2026-01-14T08:21:49.4299512Z 
2026-01-14T08:21:49.4299516Z 
2026-01-14T08:21:49.4299520Z 
2026-01-14T08:21:49.4299523Z 
2026-01-14T08:21:49.4299531Z 
2026-01-14T08:21:49.4299534Z 
2026-01-14T08:21:49.4299538Z 
2026-01-14T08:21:49.4299541Z 
2026-01-14T08:21:49.4299545Z 
2026-01-14T08:21:49.4299548Z 
2026-01-14T08:21:49.4299552Z 
2026-01-14T08:21:49.4299556Z 
2026-01-14T08:21:49.4299559Z 
2026-01-14T08:21:49.4299826Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4300135Z 
2026-01-14T08:21:49.4300138Z 
2026-01-14T08:21:49.4300220Z 
2026-01-14T08:21:49.4300223Z 
2026-01-14T08:21:49.4300227Z 
2026-01-14T08:21:49.4300230Z 
2026-01-14T08:21:49.4300234Z 
2026-01-14T08:21:49.4300237Z 
2026-01-14T08:21:49.4300241Z 
2026-01-14T08:21:49.4300245Z 
2026-01-14T08:21:49.4300255Z 
2026-01-14T08:21:49.4300259Z 
2026-01-14T08:21:49.4300262Z 
2026-01-14T08:21:49.4300266Z 
2026-01-14T08:21:49.4300270Z 
2026-01-14T08:21:49.4300273Z 
2026-01-14T08:21:49.4300277Z 
2026-01-14T08:21:49.4300280Z 
2026-01-14T08:21:49.4300284Z 
2026-01-14T08:21:49.4300641Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4300953Z 
2026-01-14T08:21:49.4300965Z 
2026-01-14T08:21:49.4300969Z 
2026-01-14T08:21:49.4300972Z 
2026-01-14T08:21:49.4300976Z 
2026-01-14T08:21:49.4300979Z 
2026-01-14T08:21:49.4300983Z 
2026-01-14T08:21:49.4300987Z 
2026-01-14T08:21:49.4300990Z 
2026-01-14T08:21:49.4300994Z 
2026-01-14T08:21:49.4300997Z 
2026-01-14T08:21:49.4301001Z 
2026-01-14T08:21:49.4301004Z 
2026-01-14T08:21:49.4301008Z 
2026-01-14T08:21:49.4301437Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.63s/it]                 [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4301883Z 
2026-01-14T08:21:49.4301887Z 
2026-01-14T08:21:49.4301890Z 
2026-01-14T08:21:49.4301894Z 
2026-01-14T08:21:49.4301898Z 
2026-01-14T08:21:49.4301901Z 
2026-01-14T08:21:49.4301905Z 
2026-01-14T08:21:49.4301909Z 
2026-01-14T08:21:49.4301912Z 
2026-01-14T08:21:49.4301916Z 
2026-01-14T08:21:49.4301919Z 
2026-01-14T08:21:49.4301923Z 
2026-01-14T08:21:49.4301927Z 
2026-01-14T08:21:49.4301935Z 
2026-01-14T08:21:49.4302314Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.63s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:49.4302712Z 
2026-01-14T08:21:49.4302715Z 
2026-01-14T08:21:49.4302719Z 
2026-01-14T08:21:49.4302723Z 
2026-01-14T08:21:49.4302726Z 
2026-01-14T08:21:49.4302730Z 
2026-01-14T08:21:49.4302733Z 
2026-01-14T08:21:49.4302737Z 
2026-01-14T08:21:49.4302741Z 
2026-01-14T08:21:49.4302744Z 
2026-01-14T08:21:49.4302752Z 
2026-01-14T08:21:49.4302756Z 
2026-01-14T08:21:49.4302759Z 
2026-01-14T08:21:49.4302763Z 
2026-01-14T08:21:49.4302767Z 
2026-01-14T08:21:49.4302770Z 
2026-01-14T08:21:49.4302780Z 
2026-01-14T08:21:58.7908828Z pip-25.3             | 1.1 MB    | : 100% 1.0/1 [00:02<00:00,  2.10s/it]                 [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7909306Z 
2026-01-14T08:21:58.7909311Z 
2026-01-14T08:21:58.7909314Z 
2026-01-14T08:21:58.7909318Z 
2026-01-14T08:21:58.7909322Z 
2026-01-14T08:21:58.7909326Z 
2026-01-14T08:21:58.7909356Z 
2026-01-14T08:21:58.7909361Z 
2026-01-14T08:21:58.7909364Z 
2026-01-14T08:21:58.7909368Z 
2026-01-14T08:21:58.7909372Z 
2026-01-14T08:21:58.7909376Z 
2026-01-14T08:21:58.7909379Z 
2026-01-14T08:21:58.7909383Z 
2026-01-14T08:21:58.7909387Z 
2026-01-14T08:21:58.7909390Z 
2026-01-14T08:21:58.7909394Z 
2026-01-14T08:21:58.7909783Z pip-25.3             | 1.1 MB    | : 100% 1.0/1 [00:02<00:00,  2.10s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7910190Z 
2026-01-14T08:21:58.7910194Z 
2026-01-14T08:21:58.7910198Z 
2026-01-14T08:21:58.7910202Z 
2026-01-14T08:21:58.7910205Z 
2026-01-14T08:21:58.7910209Z 
2026-01-14T08:21:58.7910570Z python-3.10.19       | 24.5 MB   | : 100% 1.0/1 [00:04<00:00,  1.17it/s]               [A[A[A[A[A[A
2026-01-14T08:21:58.7910924Z 
2026-01-14T08:21:58.7910928Z 
2026-01-14T08:21:58.7910932Z 
2026-01-14T08:21:58.7910935Z 
2026-01-14T08:21:58.7910939Z 
2026-01-14T08:21:58.7910943Z 
2026-01-14T08:21:58.7910946Z 
2026-01-14T08:21:58.7910955Z 
2026-01-14T08:21:58.7910959Z 
2026-01-14T08:21:58.7911016Z 
2026-01-14T08:21:58.7911020Z 
2026-01-14T08:21:58.7911023Z 
2026-01-14T08:21:58.7911035Z 
2026-01-14T08:21:58.7911038Z 
2026-01-14T08:21:58.7911042Z 
2026-01-14T08:21:58.7911045Z 
2026-01-14T08:21:58.7911049Z 
2026-01-14T08:21:58.7911053Z 
2026-01-14T08:21:58.7911056Z 
2026-01-14T08:21:58.7911146Z                       
2026-01-14T08:21:58.7911475Z [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7912200Z                                                                         
2026-01-14T08:21:58.7912438Z 
2026-01-14T08:21:58.7912455Z 
2026-01-14T08:21:58.7912656Z                                                                         [A
2026-01-14T08:21:58.7912903Z 
2026-01-14T08:21:58.7912907Z 
2026-01-14T08:21:58.7913100Z                                                                         [A[A
2026-01-14T08:21:58.7913350Z 
2026-01-14T08:21:58.7913353Z 
2026-01-14T08:21:58.7913357Z 
2026-01-14T08:21:58.7913728Z                                                                         [A[A[A
2026-01-14T08:21:58.7913994Z 
2026-01-14T08:21:58.7913998Z 
2026-01-14T08:21:58.7914002Z 
2026-01-14T08:21:58.7914005Z 
2026-01-14T08:21:58.7914212Z                                                                         [A[A[A[A
2026-01-14T08:21:58.7914470Z 
2026-01-14T08:21:58.7914473Z 
2026-01-14T08:21:58.7914477Z 
2026-01-14T08:21:58.7914480Z 
2026-01-14T08:21:58.7914490Z 
2026-01-14T08:21:58.7914709Z                                                                         [A[A[A[A[A
2026-01-14T08:21:58.7915044Z 
2026-01-14T08:21:58.7915047Z 
2026-01-14T08:21:58.7915051Z 
2026-01-14T08:21:58.7915055Z 
2026-01-14T08:21:58.7915058Z 
2026-01-14T08:21:58.7915062Z 
2026-01-14T08:21:58.7915284Z                                                                         [A[A[A[A[A[A
2026-01-14T08:21:58.7915552Z 
2026-01-14T08:21:58.7915556Z 
2026-01-14T08:21:58.7915559Z 
2026-01-14T08:21:58.7915563Z 
2026-01-14T08:21:58.7915575Z 
2026-01-14T08:21:58.7915579Z 
2026-01-14T08:21:58.7915583Z 
2026-01-14T08:21:58.7915806Z                                                                         [A[A[A[A[A[A[A
2026-01-14T08:21:58.7916085Z 
2026-01-14T08:21:58.7916088Z 
2026-01-14T08:21:58.7916092Z 
2026-01-14T08:21:58.7916096Z 
2026-01-14T08:21:58.7916099Z 
2026-01-14T08:21:58.7916103Z 
2026-01-14T08:21:58.7916106Z 
2026-01-14T08:21:58.7916110Z 
2026-01-14T08:21:58.7916343Z                                                                         [A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7916624Z 
2026-01-14T08:21:58.7916628Z 
2026-01-14T08:21:58.7916631Z 
2026-01-14T08:21:58.7916635Z 
2026-01-14T08:21:58.7916639Z 
2026-01-14T08:21:58.7916642Z 
2026-01-14T08:21:58.7916646Z 
2026-01-14T08:21:58.7916649Z 
2026-01-14T08:21:58.7916653Z 
2026-01-14T08:21:58.7916887Z                                                                         [A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7917176Z 
2026-01-14T08:21:58.7917180Z 
2026-01-14T08:21:58.7917188Z 
2026-01-14T08:21:58.7917192Z 
2026-01-14T08:21:58.7917195Z 
2026-01-14T08:21:58.7917199Z 
2026-01-14T08:21:58.7917202Z 
2026-01-14T08:21:58.7917206Z 
2026-01-14T08:21:58.7917209Z 
2026-01-14T08:21:58.7917213Z 
2026-01-14T08:21:58.7917452Z                                                                         [A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7917740Z 
2026-01-14T08:21:58.7917744Z 
2026-01-14T08:21:58.7917747Z 
2026-01-14T08:21:58.7917756Z 
2026-01-14T08:21:58.7917759Z 
2026-01-14T08:21:58.7917763Z 
2026-01-14T08:21:58.7917767Z 
2026-01-14T08:21:58.7917770Z 
2026-01-14T08:21:58.7917774Z 
2026-01-14T08:21:58.7917777Z 
2026-01-14T08:21:58.7917781Z 
2026-01-14T08:21:58.7918025Z                                                                         [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7918323Z 
2026-01-14T08:21:58.7918326Z 
2026-01-14T08:21:58.7918330Z 
2026-01-14T08:21:58.7918333Z 
2026-01-14T08:21:58.7918337Z 
2026-01-14T08:21:58.7918341Z 
2026-01-14T08:21:58.7918348Z 
2026-01-14T08:21:58.7918352Z 
2026-01-14T08:21:58.7918355Z 
2026-01-14T08:21:58.7918359Z 
2026-01-14T08:21:58.7918363Z 
2026-01-14T08:21:58.7918366Z 
2026-01-14T08:21:58.7918626Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7918917Z 
2026-01-14T08:21:58.7918920Z 
2026-01-14T08:21:58.7918924Z 
2026-01-14T08:21:58.7918927Z 
2026-01-14T08:21:58.7918931Z 
2026-01-14T08:21:58.7919023Z 
2026-01-14T08:21:58.7919027Z 
2026-01-14T08:21:58.7919030Z 
2026-01-14T08:21:58.7919034Z 
2026-01-14T08:21:58.7919038Z 
2026-01-14T08:21:58.7919041Z 
2026-01-14T08:21:58.7919045Z 
2026-01-14T08:21:58.7919048Z 
2026-01-14T08:21:58.7919317Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7919612Z 
2026-01-14T08:21:58.7919615Z 
2026-01-14T08:21:58.7919619Z 
2026-01-14T08:21:58.7919623Z 
2026-01-14T08:21:58.7919626Z 
2026-01-14T08:21:58.7919630Z 
2026-01-14T08:21:58.7919721Z 
2026-01-14T08:21:58.7919725Z 
2026-01-14T08:21:58.7919728Z 
2026-01-14T08:21:58.7919732Z 
2026-01-14T08:21:58.7919736Z 
2026-01-14T08:21:58.7919739Z 
2026-01-14T08:21:58.7919751Z 
2026-01-14T08:21:58.7919755Z 
2026-01-14T08:21:58.7920028Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7920335Z 
2026-01-14T08:21:58.7920338Z 
2026-01-14T08:21:58.7920347Z 
2026-01-14T08:21:58.7920350Z 
2026-01-14T08:21:58.7920354Z 
2026-01-14T08:21:58.7920357Z 
2026-01-14T08:21:58.7920361Z 
2026-01-14T08:21:58.7920372Z 
2026-01-14T08:21:58.7920375Z 
2026-01-14T08:21:58.7920379Z 
2026-01-14T08:21:58.7920382Z 
2026-01-14T08:21:58.7920386Z 
2026-01-14T08:21:58.7920390Z 
2026-01-14T08:21:58.7920393Z 
2026-01-14T08:21:58.7920397Z 
2026-01-14T08:21:58.7920675Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7920990Z 
2026-01-14T08:21:58.7920999Z 
2026-01-14T08:21:58.7921011Z 
2026-01-14T08:21:58.7921015Z 
2026-01-14T08:21:58.7921018Z 
2026-01-14T08:21:58.7921022Z 
2026-01-14T08:21:58.7921026Z 
2026-01-14T08:21:58.7921029Z 
2026-01-14T08:21:58.7921033Z 
2026-01-14T08:21:58.7921036Z 
2026-01-14T08:21:58.7921040Z 
2026-01-14T08:21:58.7921044Z 
2026-01-14T08:21:58.7921047Z 
2026-01-14T08:21:58.7921051Z 
2026-01-14T08:21:58.7921054Z 
2026-01-14T08:21:58.7921058Z 
2026-01-14T08:21:58.7921345Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7921674Z 
2026-01-14T08:21:58.7921677Z 
2026-01-14T08:21:58.7921681Z 
2026-01-14T08:21:58.7921685Z 
2026-01-14T08:21:58.7921688Z 
2026-01-14T08:21:58.7921692Z 
2026-01-14T08:21:58.7921695Z 
2026-01-14T08:21:58.7921699Z 
2026-01-14T08:21:58.7921703Z 
2026-01-14T08:21:58.7921706Z 
2026-01-14T08:21:58.7921710Z 
2026-01-14T08:21:58.7921713Z 
2026-01-14T08:21:58.7921717Z 
2026-01-14T08:21:58.7921720Z 
2026-01-14T08:21:58.7921732Z 
2026-01-14T08:21:58.7921736Z 
2026-01-14T08:21:58.7921739Z 
2026-01-14T08:21:58.7922040Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7922367Z 
2026-01-14T08:21:58.7922371Z 
2026-01-14T08:21:58.7922375Z 
2026-01-14T08:21:58.7922378Z 
2026-01-14T08:21:58.7922382Z 
2026-01-14T08:21:58.7922385Z 
2026-01-14T08:21:58.7922389Z 
2026-01-14T08:21:58.7922393Z 
2026-01-14T08:21:58.7922400Z 
2026-01-14T08:21:58.7922404Z 
2026-01-14T08:21:58.7922408Z 
2026-01-14T08:21:58.7922419Z 
2026-01-14T08:21:58.7922423Z 
2026-01-14T08:21:58.7922427Z 
2026-01-14T08:21:58.7922430Z 
2026-01-14T08:21:58.7922434Z 
2026-01-14T08:21:58.7922438Z 
2026-01-14T08:21:58.7922441Z 
2026-01-14T08:21:58.7922735Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:21:58.7923068Z 
2026-01-14T08:21:58.7923071Z 
2026-01-14T08:21:58.7923082Z 
2026-01-14T08:21:58.7923188Z [A
2026-01-14T08:21:58.7923292Z 
2026-01-14T08:21:58.7923295Z 
2026-01-14T08:21:58.7923397Z [A[A
2026-01-14T08:21:58.7923514Z 
2026-01-14T08:21:58.7923673Z Preparing transaction: / - \ done
2026-01-14T08:21:58.7924209Z Verifying transaction: / - \ | / - \ | / - \ | / - \ | done
2026-01-14T08:21:58.7924916Z Executing transaction: - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / done
2026-01-14T08:21:58.7925465Z #
2026-01-14T08:21:58.7925672Z # To activate this environment, use
2026-01-14T08:21:58.7925949Z #
2026-01-14T08:21:58.7926141Z #     $ conda activate venv
2026-01-14T08:21:58.7926381Z #
2026-01-14T08:21:58.7926594Z # To deactivate an active environment, use
2026-01-14T08:21:58.7926889Z #
2026-01-14T08:21:58.7927078Z #     $ conda deactivate
2026-01-14T08:21:58.7927243Z 
2026-01-14T08:21:58.7927332Z + conda activate venv
2026-01-14T08:21:58.7927567Z + local cmd=activate
2026-01-14T08:21:58.7927870Z + case "$cmd" in
2026-01-14T08:21:58.7928107Z + __conda_activate activate venv
2026-01-14T08:21:58.7928368Z + '[' -n '' ']'
2026-01-14T08:21:58.7928577Z + local ask_conda
2026-01-14T08:21:58.7928791Z ++ PS1='(base) '
2026-01-14T08:21:58.7929035Z ++ __conda_exe shell.posix activate venv
2026-01-14T08:21:58.7929380Z ++ /opt/conda/bin/conda shell.posix activate venv
2026-01-14T08:21:58.7929723Z + ask_conda='PS1='\''(venv) '\''
2026-01-14T08:21:58.7930745Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:21:58.7931837Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:21:58.7932180Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:21:58.7932460Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:21:58.7932787Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:21:58.7933130Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:21:58.7933471Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:21:58.7933778Z export _CE_M='\'''\''
2026-01-14T08:21:58.7934023Z export _CE_CONDA='\'''\''
2026-01-14T08:21:58.7934371Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:21:58.7934740Z + eval 'PS1='\''(venv) '\''
2026-01-14T08:21:58.7935729Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:21:58.7936789Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:21:58.7937134Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:21:58.7937414Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:21:58.7937750Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:21:58.7938092Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:21:58.7938419Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:21:58.7938750Z export _CE_M='\'''\''
2026-01-14T08:21:58.7938986Z export _CE_CONDA='\'''\''
2026-01-14T08:21:58.7939304Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:21:58.7939643Z ++ PS1='(venv) '
2026-01-14T08:21:58.7940577Z ++ export PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:21:58.7942269Z ++ PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:21:58.7943268Z ++ export CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:21:58.7943605Z ++ CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:21:58.7943899Z ++ export CONDA_SHLVL=2
2026-01-14T08:21:58.7944145Z ++ CONDA_SHLVL=2
2026-01-14T08:21:58.7944380Z ++ export CONDA_DEFAULT_ENV=venv
2026-01-14T08:21:58.7944661Z ++ CONDA_DEFAULT_ENV=venv
2026-01-14T08:21:58.7944939Z ++ export 'CONDA_PROMPT_MODIFIER=(venv) '
2026-01-14T08:21:58.7945262Z ++ CONDA_PROMPT_MODIFIER='(venv) '
2026-01-14T08:21:58.7945571Z ++ export CONDA_PREFIX_1=/opt/conda
2026-01-14T08:21:58.7945860Z ++ CONDA_PREFIX_1=/opt/conda
2026-01-14T08:21:58.7946148Z ++ export CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:21:58.7946453Z ++ CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:21:58.7946814Z ++ export _CE_M=
2026-01-14T08:21:58.7947022Z ++ _CE_M=
2026-01-14T08:21:58.7947223Z ++ export _CE_CONDA=
2026-01-14T08:21:58.7947440Z ++ _CE_CONDA=
2026-01-14T08:21:58.7947699Z ++ export CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:21:58.7948046Z ++ CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:21:58.7948352Z + __conda_hashr
2026-01-14T08:21:58.7948568Z + '[' -n '' ']'
2026-01-14T08:21:58.7948770Z + '[' -n '' ']'
2026-01-14T08:21:58.7948986Z + hash -r
2026-01-14T08:21:58.7949321Z + python -m pip install --upgrade pip
2026-01-14T08:21:58.7949844Z Requirement already satisfied: pip in /opt/conda/envs/venv/lib/python3.10/site-packages (25.3)
2026-01-14T08:21:58.7951979Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:21:58.7953897Z [0m+ pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
2026-01-14T08:21:58.7954573Z Looking in indexes: https://download.pytorch.org/whl/nightly/cu126
2026-01-14T08:21:58.7955028Z Collecting torch
2026-01-14T08:21:58.7955703Z   Downloading https://download.pytorch.org/whl/nightly/cu126/torch-2.11.0.dev20260113%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)
2026-01-14T08:21:58.7956456Z Collecting filelock (from torch)
2026-01-14T08:21:58.7956856Z   Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)
2026-01-14T08:21:58.7957315Z Collecting typing-extensions>=4.10.0 (from torch)
2026-01-14T08:21:58.7957977Z   Downloading https://download.pytorch.org/whl/nightly/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:21:58.7958620Z Collecting sympy>=1.13.3 (from torch)
2026-01-14T08:21:58.7959006Z   Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:21:58.7959422Z Collecting networkx>=2.5.1 (from torch)
2026-01-14T08:21:58.7959827Z   Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:21:58.7960245Z Collecting jinja2 (from torch)
2026-01-14T08:21:58.7960778Z   Downloading https://download.pytorch.org/whl/nightly/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
2026-01-14T08:21:58.7961364Z Collecting fsspec>=0.8.5 (from torch)
2026-01-14T08:21:58.7961767Z   Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:21:58.7962205Z Collecting cuda-bindings==12.9.4 (from torch)
2026-01-14T08:21:58.7963031Z   Downloading https://download.pytorch.org/whl/nightly/cu126/cuda_bindings-12.9.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)
2026-01-14T08:21:58.7963891Z Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)
2026-01-14T08:21:58.7964702Z   Downloading https://pypi.nvidia.com/nvidia-cuda-nvrtc-cu12/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)
2026-01-14T08:21:58.7966068Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/23.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:21:58.7966861Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m23.7/23.7 MB[0m [31m318.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:21:58.7967527Z [?25hCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)
2026-01-14T08:21:58.7968436Z   Downloading https://pypi.nvidia.com/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)
2026-01-14T08:22:04.4358872Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/897.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:04.4359727Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m897.7/897.7 kB[0m [31m335.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:04.4360386Z [?25hCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)
2026-01-14T08:22:04.4361571Z   Downloading https://pypi.nvidia.com/nvidia-cuda-cupti-cu12/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)
2026-01-14T08:22:04.4362642Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.9 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:04.4365489Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.9/8.9 MB[0m [31m394.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:04.4366096Z [?25hCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch)
2026-01-14T08:22:04.4367015Z   Downloading https://pypi.nvidia.com/nvidia-cudnn-cu12/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)
2026-01-14T08:22:04.4367957Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/706.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:04.4368820Z [2K     [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m87.3/706.8 MB[0m [31m437.7 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:04.4369750Z [2K     [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m175.4/706.8 MB[0m [31m437.1 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:04.4370662Z [2K     [91m━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m263.7/706.8 MB[0m [31m437.7 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:04.4371588Z [2K     [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m352.1/706.8 MB[0m [31m438.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4372530Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━[0m [32m440.4/706.8 MB[0m [31m439.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4373430Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━[0m [32m528.2/706.8 MB[0m [31m438.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4374341Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m616.6/706.8 MB[0m [31m438.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4375223Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m704.4/706.8 MB[0m [31m437.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4376057Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m706.8/706.8 MB[0m [31m356.5 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:22:04.4376675Z [?25hCollecting nvidia-cublas-cu12==12.6.4.1 (from torch)
2026-01-14T08:22:04.4377486Z   Downloading https://pypi.nvidia.com/nvidia-cublas-cu12/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)
2026-01-14T08:22:04.4378534Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/393.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:04.4379372Z [2K     [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m86.0/393.1 MB[0m [31m430.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4380265Z [2K     [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m172.2/393.1 MB[0m [31m429.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4381339Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m260.0/393.1 MB[0m [31m431.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4382240Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m348.7/393.1 MB[0m [31m435.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4383201Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m393.1/393.1 MB[0m [31m386.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:04.4383947Z [?25hCollecting nvidia-cufft-cu12==11.3.0.4 (from torch)
2026-01-14T08:22:04.4385032Z   Downloading https://pypi.nvidia.com/nvidia-cufft-cu12/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)
2026-01-14T08:22:04.4386059Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/200.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:04.4386920Z [2K     [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m85.7/200.2 MB[0m [31m429.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4387846Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m173.3/200.2 MB[0m [31m431.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4388694Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m200.2/200.2 MB[0m [31m396.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:04.4389314Z [?25hCollecting nvidia-curand-cu12==10.3.7.77 (from torch)
2026-01-14T08:22:04.4390148Z   Downloading https://pypi.nvidia.com/nvidia-curand-cu12/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)
2026-01-14T08:22:04.4391172Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/56.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:04.4391926Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m56.3/56.3 MB[0m [31m375.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:04.4392582Z [?25hCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch)
2026-01-14T08:22:04.4393433Z   Downloading https://pypi.nvidia.com/nvidia-cusolver-cu12/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)
2026-01-14T08:22:04.4394482Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/158.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:04.4395384Z [2K     [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m73.4/158.2 MB[0m [31m367.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4396271Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m158.1/158.2 MB[0m [31m398.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:04.4397092Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m158.2/158.2 MB[0m [31m369.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:04.4397718Z [?25hCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch)
2026-01-14T08:22:04.4398554Z   Downloading https://pypi.nvidia.com/nvidia-cusparse-cu12/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)
2026-01-14T08:22:04.4399763Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/216.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:04.4400590Z [2K     [91m━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m85.5/216.6 MB[0m [31m428.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5701398Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m172.5/216.6 MB[0m [31m430.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5702609Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m216.6/216.6 MB[0m [31m398.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:09.5703257Z [?25hCollecting nvidia-cusparselt-cu12==0.7.1 (from torch)
2026-01-14T08:22:09.5704046Z   Downloading https://pypi.nvidia.com/nvidia-cusparselt-cu12/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)
2026-01-14T08:22:09.5705010Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/287.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:09.5705870Z [2K     [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m86.0/287.2 MB[0m [31m430.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5706777Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━[0m [32m172.0/287.2 MB[0m [31m428.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5707698Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m259.5/287.2 MB[0m [31m430.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5708576Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m287.2/287.2 MB[0m [31m395.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:09.5709170Z [?25hCollecting nvidia-nccl-cu12==2.28.9 (from torch)
2026-01-14T08:22:09.5709849Z   Downloading https://pypi.nvidia.com/nvidia-nccl-cu12/nvidia_nccl_cu12-2.28.9-py3-none-manylinux_2_18_x86_64.whl (296.8 MB)
2026-01-14T08:22:09.5710764Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/296.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:09.5711605Z [2K     [91m━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m79.4/296.8 MB[0m [31m397.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5712507Z [2K     [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━[0m [32m166.7/296.8 MB[0m [31m415.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5713404Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m254.8/296.8 MB[0m [31m422.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5714249Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m296.8/296.8 MB[0m [31m393.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:09.5714860Z [?25hCollecting nvidia-nvshmem-cu12==3.4.5 (from torch)
2026-01-14T08:22:09.5715726Z   Downloading https://pypi.nvidia.com/nvidia-nvshmem-cu12/nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (139.1 MB)
2026-01-14T08:22:09.5716744Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/139.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:09.5717793Z [2K     [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m87.0/139.1 MB[0m [31m436.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5718662Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m139.1/139.1 MB[0m [31m401.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:09.5719264Z [?25hCollecting nvidia-nvtx-cu12==12.6.77 (from torch)
2026-01-14T08:22:09.5720110Z   Downloading https://pypi.nvidia.com/nvidia-nvtx-cu12/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)
2026-01-14T08:22:09.5720888Z Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)
2026-01-14T08:22:09.5721703Z   Downloading https://pypi.nvidia.com/nvidia-nvjitlink-cu12/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)
2026-01-14T08:22:09.5722727Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/19.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:09.5723497Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m19.7/19.7 MB[0m [31m393.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:09.5724099Z [?25hCollecting nvidia-cufile-cu12==1.11.1.6 (from torch)
2026-01-14T08:22:09.5724886Z   Downloading https://pypi.nvidia.com/nvidia-cufile-cu12/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)
2026-01-14T08:22:09.5725894Z [?25l     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:09.5726631Z [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.1/1.1 MB[0m [31m361.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:09.5727222Z [?25hCollecting triton==3.6.0+git9844da95 (from torch)
2026-01-14T08:22:09.5728055Z   Downloading https://download.pytorch.org/whl/nightly/triton-3.6.0%2Bgit9844da95-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:09.5728968Z Collecting cuda-pathfinder~=1.1 (from cuda-bindings==12.9.4->torch)
2026-01-14T08:22:09.5729681Z   Downloading https://download.pytorch.org/whl/nightly/cuda_pathfinder-1.2.2-py3-none-any.whl.metadata (3.2 kB)
2026-01-14T08:22:09.5730353Z Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)
2026-01-14T08:22:09.5730818Z   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
2026-01-14T08:22:09.5731249Z Collecting MarkupSafe>=2.0 (from jinja2->torch)
2026-01-14T08:22:09.5732028Z   Downloading https://download.pytorch.org/whl/nightly/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)
2026-01-14T08:22:09.5733170Z Downloading https://download.pytorch.org/whl/nightly/cu126/torch-2.11.0.dev20260113%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl (824.6 MB)
2026-01-14T08:22:09.5734137Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/824.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:09.5735074Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m89.7/824.6 MB[0m [31m449.9 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:09.5735973Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m180.9/824.6 MB[0m [31m450.2 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:09.5736873Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m271.6/824.6 MB[0m [31m449.9 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:09.5737871Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m363.1/824.6 MB[0m [31m452.4 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:09.5738770Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m454.6/824.6 MB[0m [31m453.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5739671Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━[0m [32m546.0/824.6 MB[0m [31m455.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5740572Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m637.3/824.6 MB[0m [31m454.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5741495Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m728.8/824.6 MB[0m [31m454.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:09.5742366Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m820.0/824.6 MB[0m [31m454.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6744591Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6745508Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6746357Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6747211Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6748081Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6748913Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6749760Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6750608Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6751457Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6752308Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6753403Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6754248Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6755171Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6756170Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6757024Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6757865Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6758716Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6759574Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6760458Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6761299Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6762158Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6762995Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6763830Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6764677Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6765522Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6766360Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6767210Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6768054Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6768885Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6769729Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6770722Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6771554Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m824.4/824.6 MB[0m [31m453.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6772443Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m824.6/824.6 MB[0m [31m36.4 MB/s[0m  [33m0:00:08[0m
2026-01-14T08:22:16.6773529Z [?25hDownloading https://download.pytorch.org/whl/nightly/cu126/cuda_bindings-12.9.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.1 MB)
2026-01-14T08:22:16.6774554Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:16.6775298Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.1/12.1 MB[0m [31m214.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:16.6776370Z [?25hDownloading https://download.pytorch.org/whl/nightly/triton-3.6.0%2Bgit9844da95-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.1 MB)
2026-01-14T08:22:16.6777402Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/188.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:16.6778236Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m53.7/188.1 MB[0m [31m269.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:16.6779146Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━[0m [32m133.2/188.1 MB[0m [31m332.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:22.4018418Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m188.0/188.1 MB[0m [31m349.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:22.4019315Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m188.0/188.1 MB[0m [31m349.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:22.4020227Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m188.0/188.1 MB[0m [31m349.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:22.4021088Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m188.0/188.1 MB[0m [31m349.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:22.4021939Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m188.1/188.1 MB[0m [31m135.5 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:22:22.4023182Z [?25hDownloading https://download.pytorch.org/whl/nightly/cuda_pathfinder-1.2.2-py3-none-any.whl (23 kB)
2026-01-14T08:22:22.4023838Z Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)
2026-01-14T08:22:22.4024265Z Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)
2026-01-14T08:22:22.4024905Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:22.4025646Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m117.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:22.4026409Z [?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)
2026-01-14T08:22:22.4027038Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:22.4027778Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.3/6.3 MB[0m [31m161.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:22.4028380Z [?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)
2026-01-14T08:22:22.4029016Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/536.2 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:22.4029779Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m536.2/536.2 kB[0m [31m51.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:22.4030626Z [?25hDownloading https://download.pytorch.org/whl/nightly/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
2026-01-14T08:22:22.4031281Z Downloading filelock-3.20.3-py3-none-any.whl (16 kB)
2026-01-14T08:22:22.4031853Z Downloading https://download.pytorch.org/whl/nightly/jinja2-3.1.6-py3-none-any.whl (134 kB)
2026-01-14T08:22:22.4032832Z Downloading https://download.pytorch.org/whl/nightly/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)
2026-01-14T08:22:22.4035462Z Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, cuda-pathfinder, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, cuda-bindings, nvidia-cusolver-cu12, torch
2026-01-14T08:22:22.4037707Z [?25l
2026-01-14T08:22:22.4038149Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4038824Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4039499Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4040167Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4040824Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4041471Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4042262Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4042917Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4043567Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4044218Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4044964Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4045619Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4046275Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4046925Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/27[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:22.4047611Z [2K   [91m━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 1/27[0m [mpmath]
2026-01-14T08:22:22.4048264Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4048915Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4049568Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4050233Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4050882Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4051524Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4052227Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4052892Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4053534Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4054185Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:22.4054838Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:30.0445723Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:30.0446455Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:30.0447105Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:30.0447743Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:30.0448790Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:30.0449438Z [2K   [91m━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/27[0m [triton]
2026-01-14T08:22:30.0450072Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0450717Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0451383Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0452027Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0452662Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0453287Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0453945Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0454576Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0455220Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0455850Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0465223Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0465914Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0466546Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0467181Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0467934Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0468580Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0469221Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0469851Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0470488Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0471293Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0471933Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0472574Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0473229Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0473869Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0474525Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0475276Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/27[0m [sympy]
2026-01-14T08:22:30.0475983Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/27[0m [nvidia-nvshmem-cu12]
2026-01-14T08:22:30.0476749Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/27[0m [nvidia-nvshmem-cu12]
2026-01-14T08:22:30.0477495Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/27[0m [nvidia-nvshmem-cu12]
2026-01-14T08:22:30.0478231Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/27[0m [nvidia-nvshmem-cu12]
2026-01-14T08:22:30.0478997Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/27[0m [nvidia-nvshmem-cu12]
2026-01-14T08:22:30.0479740Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/27[0m [nvidia-nvshmem-cu12]
2026-01-14T08:22:30.0480473Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/27[0m [nvidia-nvshmem-cu12]
2026-01-14T08:22:30.0481226Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/27[0m [nvidia-nvshmem-cu12]
2026-01-14T08:22:30.0482075Z [2K   [91m━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/27[0m [nvidia-nvjitlink-cu12]
2026-01-14T08:22:30.0482818Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:30.0483540Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:30.0484588Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:30.0485321Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2542560Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2544124Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2545634Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2546776Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2547507Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2548229Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2548978Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2549695Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2550412Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2551130Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2551866Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2552590Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2553305Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/27[0m [nvidia-nccl-cu12]
2026-01-14T08:22:37.2554288Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 9/27[0m [nvidia-curand-cu12]
2026-01-14T08:22:37.2555116Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 9/27[0m [nvidia-curand-cu12]
2026-01-14T08:22:37.2555871Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m12/27[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:22:37.2556647Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m12/27[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:22:37.2557592Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m13/27[0m [nvidia-cuda-cupti-cu12]
2026-01-14T08:22:37.2558367Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m13/27[0m [nvidia-cuda-cupti-cu12]
2026-01-14T08:22:37.2559122Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2559881Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2560618Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2561342Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2562077Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2562841Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2563564Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2564310Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2565046Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2565802Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2566581Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2567329Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2568070Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2568910Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2569661Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2570404Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2571227Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2571974Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2572706Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2573444Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2574202Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2574932Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m14/27[0m [nvidia-cublas-cu12]
2026-01-14T08:22:37.2575644Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m15/27[0m [networkx]
2026-01-14T08:22:37.2576330Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m15/27[0m [networkx]
2026-01-14T08:22:44.4603970Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m15/27[0m [networkx]
2026-01-14T08:22:44.4604656Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m15/27[0m [networkx]
2026-01-14T08:22:44.4605320Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m15/27[0m [networkx]
2026-01-14T08:22:44.4605970Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m15/27[0m [networkx]
2026-01-14T08:22:44.4606676Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━[0m [32m16/27[0m [MarkupSafe]
2026-01-14T08:22:44.4607349Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━[0m [32m17/27[0m [fsspec]
2026-01-14T08:22:44.4607999Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━[0m [32m17/27[0m [fsspec]
2026-01-14T08:22:44.4609556Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m19/27[0m [cuda-pathfinder]
2026-01-14T08:22:44.4610303Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4611050Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4611803Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4612755Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4613511Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4614258Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4615020Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4615767Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4616513Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4617259Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4618023Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4618782Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4619566Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m20/27[0m [nvidia-cusparse-cu12]
2026-01-14T08:22:44.4620295Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4621039Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4621766Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4622478Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4623198Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4624010Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4624728Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4625447Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4626244Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4626962Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m21/27[0m [nvidia-cufft-cu12]
2026-01-14T08:22:44.4627677Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4628404Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4629146Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4629868Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4630591Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4631328Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4632055Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4632787Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4633499Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4634239Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4635041Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:44.4635760Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6634973Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6635762Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6636508Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6637233Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6637969Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6638977Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6639700Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6640444Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6641363Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6642102Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6642834Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6643552Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6644316Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6645042Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6645782Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6646556Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6647282Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6648029Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6648753Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6649631Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6650361Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6651083Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6651819Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6652661Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6653399Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6654133Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6654856Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6655617Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m22/27[0m [nvidia-cudnn-cu12]
2026-01-14T08:22:51.6656294Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m23/27[0m [jinja2]
2026-01-14T08:22:51.6656991Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m24/27[0m [cuda-bindings]
2026-01-14T08:22:51.6657723Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m24/27[0m [cuda-bindings]
2026-01-14T08:22:51.6658410Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m24/27[0m [cuda-bindings]
2026-01-14T08:22:51.6659139Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6659897Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6660667Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6661423Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6662176Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6662918Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6663688Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6664433Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6665184Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6665937Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m25/27[0m [nvidia-cusolver-cu12]
2026-01-14T08:22:51.6666725Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3706971Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3708324Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3710076Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3711347Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3712584Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3713788Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3714469Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3715243Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3715870Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3716492Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3717144Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3717765Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3718390Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3719013Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3719637Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3720463Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3721089Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3721721Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3723301Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3723947Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3724577Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3725196Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3725828Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3726471Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3727105Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3727736Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3728376Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3729011Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3729630Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3730256Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3730885Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3731520Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3732144Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3732762Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3733406Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3734032Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3734650Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3735274Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3735891Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3736622Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3737244Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3737869Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3738583Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3739206Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3739833Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:22:59.3740455Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2899680Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2900410Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2901052Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2901663Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2902293Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2902941Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2903554Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2904177Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2904789Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2905702Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2906326Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2906943Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2907570Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2908355Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2908992Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2909613Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2910242Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2910884Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2911504Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2912133Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2912759Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2913398Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2914020Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2914638Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2915336Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2915985Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2916655Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2917279Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2917895Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2918622Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2919241Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2919862Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2920486Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2921203Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2921823Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2922436Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2923054Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2923700Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2924318Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2924935Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2925549Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2926200Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2926888Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2927513Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2928152Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:07.2928798Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:18.6794418Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:18.6795193Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:18.6795839Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m26/27[0m [torch]
2026-01-14T08:23:18.6797628Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27/27[0m [torch]
2026-01-14T08:23:18.6798062Z [?25h
2026-01-14T08:23:18.6801687Z [1A[2KSuccessfully installed MarkupSafe-3.0.2 cuda-bindings-12.9.4 cuda-pathfinder-1.2.2 filelock-3.20.3 fsspec-2026.1.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.28.9 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvshmem-cu12-3.4.5 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.11.0.dev20260113+cu126 triton-3.6.0+git9844da95 typing-extensions-4.15.0
2026-01-14T08:23:18.6806871Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:23:18.6808582Z [0m+ pip install -r dev-requirements.txt
2026-01-14T08:23:18.6809025Z Collecting pytest==8.4.2 (from -r dev-requirements.txt (line 2))
2026-01-14T08:23:18.6809557Z   Downloading pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)
2026-01-14T08:23:18.6810116Z Collecting unittest-xml-reporting (from -r dev-requirements.txt (line 3))
2026-01-14T08:23:18.6810756Z   Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl.metadata (11 kB)
2026-01-14T08:23:18.6811371Z Collecting parameterized (from -r dev-requirements.txt (line 4))
2026-01-14T08:23:18.6811941Z   Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)
2026-01-14T08:23:18.6812502Z Collecting packaging (from -r dev-requirements.txt (line 5))
2026-01-14T08:23:18.6813018Z   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:23:18.6813534Z Collecting transformers (from -r dev-requirements.txt (line 6))
2026-01-14T08:23:18.6814060Z   Downloading transformers-4.57.5-py3-none-any.whl.metadata (43 kB)
2026-01-14T08:23:18.6814595Z Collecting hypothesis (from -r dev-requirements.txt (line 7))
2026-01-14T08:23:18.6815119Z   Downloading hypothesis-6.150.2-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:23:18.6815652Z Collecting sentencepiece (from -r dev-requirements.txt (line 8))
2026-01-14T08:23:18.6816382Z   Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)
2026-01-14T08:23:18.6817079Z Collecting expecttest (from -r dev-requirements.txt (line 9))
2026-01-14T08:23:18.6817611Z   Downloading expecttest-0.3.0-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:23:18.6818113Z Collecting pyyaml (from -r dev-requirements.txt (line 10))
2026-01-14T08:23:18.6818845Z   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
2026-01-14T08:23:18.6819615Z Collecting bitsandbytes (from -r dev-requirements.txt (line 13))
2026-01-14T08:23:18.6820196Z   Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)
2026-01-14T08:23:18.6820787Z Collecting matplotlib (from -r dev-requirements.txt (line 14))
2026-01-14T08:23:18.6821457Z   Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)
2026-01-14T08:23:18.6822146Z Collecting pandas (from -r dev-requirements.txt (line 15))
2026-01-14T08:23:18.6822795Z   Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)
2026-01-14T08:23:18.6823415Z Collecting fire (from -r dev-requirements.txt (line 16))
2026-01-14T08:23:18.6823882Z   Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)
2026-01-14T08:23:18.6824364Z Collecting tabulate (from -r dev-requirements.txt (line 17))
2026-01-14T08:23:18.6824960Z   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
2026-01-14T08:23:18.6825456Z Collecting tiktoken (from -r dev-requirements.txt (line 18))
2026-01-14T08:23:18.6826031Z   Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.7 kB)
2026-01-14T08:23:18.6826621Z Collecting blobfile (from -r dev-requirements.txt (line 19))
2026-01-14T08:23:18.6827110Z   Downloading blobfile-3.1.0-py3-none-any.whl.metadata (15 kB)
2026-01-14T08:23:18.6827605Z Collecting lm_eval (from -r dev-requirements.txt (line 20))
2026-01-14T08:23:18.6828165Z   Downloading lm_eval-0.4.9.2-py3-none-any.whl.metadata (53 kB)
2026-01-14T08:23:18.6828674Z Collecting diskcache (from -r dev-requirements.txt (line 22))
2026-01-14T08:23:18.6829178Z   Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
2026-01-14T08:23:18.6829708Z Collecting pycocotools (from -r dev-requirements.txt (line 23))
2026-01-14T08:23:18.6830532Z   Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.3 kB)
2026-01-14T08:23:18.6831276Z Collecting tqdm (from -r dev-requirements.txt (line 24))
2026-01-14T08:23:18.6831749Z   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
2026-01-14T08:23:18.6832257Z Collecting importlib_metadata (from -r dev-requirements.txt (line 25))
2026-01-14T08:23:18.6832862Z   Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:23:18.6833387Z Collecting ninja (from -r dev-requirements.txt (line 28))
2026-01-14T08:23:18.6834015Z   Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)
2026-01-14T08:23:18.6834744Z Collecting cmake<4.0.0,>=3.19.0 (from -r dev-requirements.txt (line 31))
2026-01-14T08:23:18.6835406Z   Downloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:23:18.6836065Z Collecting ruff==0.11.6 (from -r dev-requirements.txt (line 34))
2026-01-14T08:23:18.6836686Z   Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)
2026-01-14T08:23:18.6837338Z Collecting pre-commit (from -r dev-requirements.txt (line 35))
2026-01-14T08:23:18.6837866Z   Downloading pre_commit-4.5.1-py2.py3-none-any.whl.metadata (1.2 kB)
2026-01-14T08:23:18.6838508Z Collecting exceptiongroup>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:18.6839136Z   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)
2026-01-14T08:23:18.6839732Z Collecting iniconfig>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:18.6840301Z   Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:23:18.6840851Z Collecting pluggy<2,>=1.5 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:18.6841404Z   Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)
2026-01-14T08:23:18.6841957Z Collecting pygments>=2.7.2 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:18.6842552Z   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:23:18.6843081Z Collecting tomli>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:18.6843593Z   Downloading tomli-2.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:23:18.6844160Z Collecting lxml (from unittest-xml-reporting->-r dev-requirements.txt (line 3))
2026-01-14T08:23:18.6844870Z   Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)
2026-01-14T08:23:18.6845896Z Requirement already satisfied: filelock in /opt/conda/envs/venv/lib/python3.10/site-packages (from transformers->-r dev-requirements.txt (line 6)) (3.20.3)
2026-01-14T08:23:18.6846881Z Collecting huggingface-hub<1.0,>=0.34.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:18.6847530Z   Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:23:18.6848114Z Collecting numpy>=1.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:18.6848895Z   Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
2026-01-14T08:23:18.6849610Z Collecting regex!=2019.12.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:18.6850457Z   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
2026-01-14T08:23:18.6851243Z Collecting requests (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:18.6851897Z   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
2026-01-14T08:23:18.6852478Z Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:18.6853251Z   Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
2026-01-14T08:23:18.6853990Z Collecting safetensors>=0.4.3 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:18.6854734Z   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
2026-01-14T08:23:18.6855917Z Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (2026.1.0)
2026-01-14T08:23:18.6857437Z Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (4.15.0)
2026-01-14T08:23:18.6858668Z Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:25.9106494Z   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
2026-01-14T08:23:25.9107282Z Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis->-r dev-requirements.txt (line 7))
2026-01-14T08:23:25.9107964Z   Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)
2026-01-14T08:23:25.9109036Z Requirement already satisfied: torch<3,>=2.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from bitsandbytes->-r dev-requirements.txt (line 13)) (2.11.0.dev20260113+cu126)
2026-01-14T08:23:25.9110398Z Requirement already satisfied: sympy>=1.13.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.14.0)
2026-01-14T08:23:25.9111736Z Requirement already satisfied: networkx>=2.5.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.4.2)
2026-01-14T08:23:25.9113090Z Requirement already satisfied: jinja2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.1.6)
2026-01-14T08:23:25.9114433Z Requirement already satisfied: cuda-bindings==12.9.4 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.9.4)
2026-01-14T08:23:25.9115936Z Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.77)
2026-01-14T08:23:25.9117422Z Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.77)
2026-01-14T08:23:25.9118906Z Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.80)
2026-01-14T08:23:25.9120374Z Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (9.10.2.21)
2026-01-14T08:23:25.9121842Z Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.4.1)
2026-01-14T08:23:25.9133098Z Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (11.3.0.4)
2026-01-14T08:23:25.9134823Z Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (10.3.7.77)
2026-01-14T08:23:25.9136306Z Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (11.7.1.2)
2026-01-14T08:23:25.9137775Z Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.5.4.2)
2026-01-14T08:23:25.9139259Z Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (0.7.1)
2026-01-14T08:23:25.9140684Z Requirement already satisfied: nvidia-nccl-cu12==2.28.9 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (2.28.9)
2026-01-14T08:23:25.9142112Z Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.4.5)
2026-01-14T08:23:25.9143593Z Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.77)
2026-01-14T08:23:25.9145036Z Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.85)
2026-01-14T08:23:25.9146514Z Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.11.1.6)
2026-01-14T08:23:25.9147991Z Requirement already satisfied: triton==3.6.0+git9844da95 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.6.0+git9844da95)
2026-01-14T08:23:25.9149506Z Requirement already satisfied: cuda-pathfinder~=1.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from cuda-bindings==12.9.4->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.2.2)
2026-01-14T08:23:25.9150576Z Collecting contourpy>=1.0.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:25.9151294Z   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)
2026-01-14T08:23:25.9152005Z Collecting cycler>=0.10 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:25.9152543Z   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:23:25.9153089Z Collecting fonttools>=4.22.0 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:25.9153818Z   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)
2026-01-14T08:23:25.9154544Z Collecting kiwisolver>=1.3.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:25.9155434Z   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:23:25.9156127Z Collecting pillow>=8 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:25.9156801Z   Downloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)
2026-01-14T08:23:25.9157496Z Collecting pyparsing>=3 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:25.9158137Z   Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:23:25.9158721Z Collecting python-dateutil>=2.7 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:25.9159372Z   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:23:25.9159977Z Collecting pytz>=2020.1 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:23:25.9160505Z   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
2026-01-14T08:23:25.9161107Z Collecting tzdata>=2022.7 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:23:25.9161659Z   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)
2026-01-14T08:23:25.9162182Z Collecting termcolor (from fire->-r dev-requirements.txt (line 16))
2026-01-14T08:23:25.9162710Z   Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)
2026-01-14T08:23:25.9163265Z Collecting pycryptodomex>=3.8 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:23:25.9164005Z   Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)
2026-01-14T08:23:25.9164716Z Collecting urllib3<3,>=1.25.3 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:23:25.9165241Z   Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)
2026-01-14T08:23:25.9165782Z Collecting accelerate>=0.26.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9166332Z   Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:23:25.9166870Z Collecting evaluate (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9167395Z   Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)
2026-01-14T08:23:25.9167937Z Collecting datasets>=2.16.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9168485Z   Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:23:25.9169005Z Collecting jsonlines (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9169551Z   Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)
2026-01-14T08:23:25.9170067Z Collecting numexpr (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9170728Z   Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)
2026-01-14T08:23:25.9171407Z Collecting peft>=0.2.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9171898Z   Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:23:25.9172416Z Collecting pybind11>=2.6.2 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9172940Z   Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)
2026-01-14T08:23:25.9173477Z Collecting pytablewriter (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9174040Z   Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)
2026-01-14T08:23:25.9174619Z Collecting rouge-score>=0.0.4 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9175115Z   Downloading rouge_score-0.1.2.tar.gz (17 kB)
2026-01-14T08:23:25.9175737Z   Installing build dependencies ... [?25l- \ | done
2026-01-14T08:23:25.9176257Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:23:25.9176757Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:23:25.9177369Z [?25hCollecting sacrebleu>=1.5.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:25.9177931Z   Downloading sacrebleu-2.6.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:23:25.9178503Z Collecting scikit-learn>=0.24.1 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6427893Z   Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
2026-01-14T08:23:33.6428996Z Collecting sqlitedict (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6429477Z   Downloading sqlitedict-2.1.0.tar.gz (21 kB)
2026-01-14T08:23:33.6430124Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:23:33.6430991Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:23:33.6431510Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:23:33.6432130Z [?25hCollecting tqdm-multiprocess (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6432902Z   Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)
2026-01-14T08:23:33.6433482Z Collecting zstandard (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6434352Z   Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)
2026-01-14T08:23:33.6435123Z Collecting dill (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6435601Z   Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:23:33.6436111Z Collecting word2number (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6436568Z   Downloading word2number-1.1.zip (9.7 kB)
2026-01-14T08:23:33.6437011Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:23:33.6437485Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:23:33.6437992Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:23:33.6438581Z [?25hCollecting more_itertools (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6439178Z   Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:23:33.6439771Z Collecting zipp>=3.20 (from importlib_metadata->-r dev-requirements.txt (line 25))
2026-01-14T08:23:33.6440323Z   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)
2026-01-14T08:23:33.6440849Z Collecting cfgv>=2.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:23:33.6441372Z   Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)
2026-01-14T08:23:33.6441932Z Collecting identify>=1.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:23:33.6442513Z   Downloading identify-2.6.16-py2.py3-none-any.whl.metadata (4.4 kB)
2026-01-14T08:23:33.6443066Z Collecting nodeenv>=0.11.1 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:23:33.6443627Z   Downloading nodeenv-1.10.0-py2.py3-none-any.whl.metadata (24 kB)
2026-01-14T08:23:33.6444191Z Collecting virtualenv>=20.10.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:23:33.6444776Z   Downloading virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:23:33.6445365Z Collecting psutil (from accelerate>=0.26.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6446165Z   Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)
2026-01-14T08:23:33.6446983Z Collecting pyarrow>=21.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6447633Z   Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)
2026-01-14T08:23:33.6448292Z Collecting httpx<1.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6448869Z   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
2026-01-14T08:23:33.6449445Z Collecting xxhash (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6450259Z   Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:23:33.6451107Z Collecting multiprocess<0.70.19 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6451784Z   Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)
2026-01-14T08:23:33.6452483Z Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:33.6453171Z   Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:23:33.6453914Z Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6455111Z   Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
2026-01-14T08:23:33.6456181Z Collecting anyio (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6456927Z   Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:23:33.6457634Z Collecting certifi (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6458272Z   Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:23:33.6458913Z Collecting httpcore==1.* (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6459568Z   Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
2026-01-14T08:23:33.6460172Z Collecting idna (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6460775Z   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:23:33.6461418Z Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6462080Z   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
2026-01-14T08:23:33.6462904Z Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6463802Z   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
2026-01-14T08:23:33.6464749Z Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6465765Z   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:23:33.6466768Z Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6467638Z   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)
2026-01-14T08:23:33.6468441Z Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6469225Z   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:23:33.6470013Z Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6471064Z   Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)
2026-01-14T08:23:33.6472104Z Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6473157Z   Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)
2026-01-14T08:23:33.6474209Z Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6475304Z   Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:23:33.6476322Z Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6477336Z   Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)
2026-01-14T08:23:33.6478146Z Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:33.6478763Z   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
2026-01-14T08:23:33.6479500Z Collecting charset_normalizer<4,>=2 (from requests->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:33.6480413Z   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
2026-01-14T08:23:33.6481292Z Collecting absl-py (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6481891Z   Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:23:33.6482542Z Collecting nltk (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6483127Z   Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)
2026-01-14T08:23:33.6483711Z Collecting portalocker (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6484524Z   Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)
2026-01-14T08:23:33.6485120Z Collecting colorama (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6485766Z   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
2026-01-14T08:23:33.6486389Z Collecting scipy>=1.8.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6487160Z   Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
2026-01-14T08:23:33.6487931Z Collecting joblib>=1.2.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6488562Z   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)
2026-01-14T08:23:33.6489222Z Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:33.6490052Z   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
2026-01-14T08:23:33.6491086Z Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.3.0)
2026-01-14T08:23:33.6492306Z Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:23:38.8009337Z   Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)
2026-01-14T08:23:38.8010190Z Collecting platformdirs<5,>=3.9.1 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:23:38.8010870Z   Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:23:38.8011887Z Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.0.2)
2026-01-14T08:23:38.8012945Z Collecting click (from nltk->rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:38.8013532Z   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
2026-01-14T08:23:38.8014449Z Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20)) (80.9.0)
2026-01-14T08:23:38.8015490Z Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:38.8016148Z   Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)
2026-01-14T08:23:38.8016776Z Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:38.8017417Z   Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:23:38.8018055Z Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:38.8018689Z   Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:23:38.8019305Z Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:38.8019906Z   Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:23:38.8020510Z Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:38.8021394Z   Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:23:38.8022083Z Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:38.8022776Z   Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)
2026-01-14T08:23:38.8023433Z Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:38.8024271Z   Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)
2026-01-14T08:23:38.8024724Z Downloading pytest-8.4.2-py3-none-any.whl (365 kB)
2026-01-14T08:23:38.8025262Z Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)
2026-01-14T08:23:38.8026173Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/11.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8026995Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m11.3/11.5 MB[0m [31m322.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:38.8027803Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m11.5/11.5 MB[0m [31m39.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:38.8028572Z [?25hDownloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)
2026-01-14T08:23:38.8029349Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/27.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8030145Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m27.8/27.8 MB[0m [31m258.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:38.8030985Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m27.8/27.8 MB[0m [31m258.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:38.8031768Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27.8/27.8 MB[0m [31m53.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:38.8032372Z [?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)
2026-01-14T08:23:38.8032871Z Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:23:38.8033398Z Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:23:38.8033850Z Downloading packaging-25.0-py3-none-any.whl (66 kB)
2026-01-14T08:23:38.8034289Z Downloading transformers-4.57.5-py3-none-any.whl (12.0 MB)
2026-01-14T08:23:38.8034999Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8035814Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m11.8/12.0 MB[0m [31m451.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:38.8036640Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.0/12.0 MB[0m [31m46.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:38.8037296Z [?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
2026-01-14T08:23:38.8038069Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/566.1 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8039225Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m566.1/566.1 kB[0m [31m3.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:38.8040248Z [?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:23:38.8041177Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8042621Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m20.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:38.8043417Z [?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:23:38.8044222Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8044940Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m20.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:38.8045567Z [?25hDownloading hypothesis-6.150.2-py3-none-any.whl (542 kB)
2026-01-14T08:23:38.8046223Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/542.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8046959Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m542.7/542.7 kB[0m [31m3.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:38.8047624Z [?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
2026-01-14T08:23:38.8048307Z Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)
2026-01-14T08:23:38.8049196Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.4 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8050186Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.4/1.4 MB[0m [31m11.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:38.8050940Z [?25hDownloading expecttest-0.3.0-py3-none-any.whl (8.2 kB)
2026-01-14T08:23:38.8051630Z Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)
2026-01-14T08:23:38.8052494Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/770.3 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8053233Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m770.3/770.3 kB[0m [31m5.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:38.8053950Z [?25hDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)
2026-01-14T08:23:38.8054696Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/59.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:38.8055481Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m59.0/59.1 MB[0m [31m445.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:38.8056319Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m59.0/59.1 MB[0m [31m445.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:44.0887425Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m59.0/59.1 MB[0m [31m445.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:44.0888834Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m59.1/59.1 MB[0m [31m83.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0889685Z [?25hDownloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)
2026-01-14T08:23:44.0890514Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0891444Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.7/8.7 MB[0m [31m45.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0892251Z [?25hDownloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)
2026-01-14T08:23:44.0893056Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0893868Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m12.6/12.8 MB[0m [31m438.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:44.0894698Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.8/12.8 MB[0m [31m39.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0895312Z [?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)
2026-01-14T08:23:44.0895749Z Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)
2026-01-14T08:23:44.0896236Z Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.2 MB)
2026-01-14T08:23:44.0896971Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0897717Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m8.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0898346Z [?25hDownloading blobfile-3.1.0-py3-none-any.whl (75 kB)
2026-01-14T08:23:44.0898785Z Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)
2026-01-14T08:23:44.0899194Z Downloading lm_eval-0.4.9.2-py3-none-any.whl (8.2 MB)
2026-01-14T08:23:44.0899823Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0900608Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m8.1/8.2 MB[0m [31m330.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:44.0901402Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.2/8.2 MB[0m [31m35.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0902018Z [?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)
2026-01-14T08:23:44.0902723Z Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (472 kB)
2026-01-14T08:23:44.0903398Z Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
2026-01-14T08:23:44.0903832Z Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)
2026-01-14T08:23:44.0904415Z Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)
2026-01-14T08:23:44.0904982Z Downloading pre_commit-4.5.1-py2.py3-none-any.whl (226 kB)
2026-01-14T08:23:44.0905533Z Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)
2026-01-14T08:23:44.0905951Z Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)
2026-01-14T08:23:44.0906510Z Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
2026-01-14T08:23:44.0907088Z Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
2026-01-14T08:23:44.0907483Z Downloading datasets-4.4.2-py3-none-any.whl (512 kB)
2026-01-14T08:23:44.0907882Z Downloading dill-0.4.0-py3-none-any.whl (119 kB)
2026-01-14T08:23:44.0908384Z Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)
2026-01-14T08:23:44.0908791Z Downloading httpx-0.28.1-py3-none-any.whl (73 kB)
2026-01-14T08:23:44.0909180Z Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)
2026-01-14T08:23:44.0909632Z Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)
2026-01-14T08:23:44.0910322Z Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)
2026-01-14T08:23:44.0911193Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0911929Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m13.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0912545Z [?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)
2026-01-14T08:23:44.0913242Z Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)
2026-01-14T08:23:44.0914137Z Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)
2026-01-14T08:23:44.0914921Z Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
2026-01-14T08:23:44.0915563Z Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:23:44.0916119Z Downloading attrs-25.4.0-py3-none-any.whl (67 kB)
2026-01-14T08:23:44.0916665Z Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)
2026-01-14T08:23:44.0917281Z Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)
2026-01-14T08:23:44.0918131Z Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)
2026-01-14T08:23:44.0919263Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/4.9 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0920184Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m4.9/4.9 MB[0m [31m24.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0921088Z [?25hDownloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)
2026-01-14T08:23:44.0921741Z Downloading h11-0.16.0-py3-none-any.whl (37 kB)
2026-01-14T08:23:44.0922159Z Downloading identify-2.6.16-py2.py3-none-any.whl (99 kB)
2026-01-14T08:23:44.0922579Z Downloading idna-3.11-py3-none-any.whl (71 kB)
2026-01-14T08:23:44.0922973Z Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:23:44.0923553Z Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
2026-01-14T08:23:44.0924353Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0925102Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m11.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0925868Z [?25hDownloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)
2026-01-14T08:23:44.0926766Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0927499Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.3/5.3 MB[0m [31m27.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0928114Z [?25hDownloading nodeenv-1.10.0-py2.py3-none-any.whl (23 kB)
2026-01-14T08:23:44.0928710Z Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)
2026-01-14T08:23:44.0929495Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/16.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0930399Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m16.8/16.8 MB[0m [31m430.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:44.0931216Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m16.8/16.8 MB[0m [31m51.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0931820Z [?25hDownloading peft-0.18.1-py3-none-any.whl (556 kB)
2026-01-14T08:23:44.0932484Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/557.0 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:44.0933246Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m557.0/557.0 kB[0m [31m3.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:44.0934056Z [?25hDownloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)
2026-01-14T08:23:49.5914229Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/7.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:49.5915206Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m6.8/7.0 MB[0m [31m430.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:49.5916037Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m7.0/7.0 MB[0m [31m33.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:49.5916990Z [?25hDownloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)
2026-01-14T08:23:49.5917803Z Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)
2026-01-14T08:23:49.5918520Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/47.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:49.5919365Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m47.4/47.6 MB[0m [31m424.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:49.5920225Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m47.4/47.6 MB[0m [31m424.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:49.5921325Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m47.4/47.6 MB[0m [31m424.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:49.5922179Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m47.4/47.6 MB[0m [31m424.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:49.5922984Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m47.6/47.6 MB[0m [31m55.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:49.5923618Z [?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)
2026-01-14T08:23:49.5924405Z Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)
2026-01-14T08:23:49.5925254Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/2.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:49.5926006Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2.3/2.3 MB[0m [31m15.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:49.5926631Z [?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)
2026-01-14T08:23:49.5927307Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:49.5928055Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m10.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:49.5928695Z [?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)
2026-01-14T08:23:49.5929238Z Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
2026-01-14T08:23:49.5929776Z Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)
2026-01-14T08:23:49.5930465Z Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)
2026-01-14T08:23:49.5931348Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/791.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:49.5932127Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m791.7/791.7 kB[0m [31m5.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:49.5932769Z [?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)
2026-01-14T08:23:49.5933495Z Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)
2026-01-14T08:23:49.5934247Z Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)
2026-01-14T08:23:49.5934693Z Downloading sacrebleu-2.6.0-py3-none-any.whl (100 kB)
2026-01-14T08:23:49.5935296Z Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)
2026-01-14T08:23:49.5936084Z Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)
2026-01-14T08:23:49.5936919Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/9.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:49.5937733Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m9.4/9.7 MB[0m [31m243.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:49.5938537Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m9.7/9.7 MB[0m [31m43.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:49.5939159Z [?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)
2026-01-14T08:23:49.5939741Z Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)
2026-01-14T08:23:49.5940553Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/37.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:49.5941466Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m37.5/37.7 MB[0m [31m411.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:49.5942347Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m37.5/37.7 MB[0m [31m411.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:49.5943209Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m37.5/37.7 MB[0m [31m411.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:49.5944025Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m37.7/37.7 MB[0m [31m55.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:49.5944739Z [?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)
2026-01-14T08:23:49.5945210Z Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
2026-01-14T08:23:49.5945656Z Downloading tomli-2.4.0-py3-none-any.whl (14 kB)
2026-01-14T08:23:49.5946093Z Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)
2026-01-14T08:23:49.5946547Z Downloading virtualenv-20.36.1-py3-none-any.whl (6.0 MB)
2026-01-14T08:23:49.5947223Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:49.5947989Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.0/6.0 MB[0m [31m34.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:49.5948626Z [?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)
2026-01-14T08:23:49.5949117Z Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)
2026-01-14T08:23:49.5949535Z Downloading zipp-3.23.0-py3-none-any.whl (10 kB)
2026-01-14T08:23:49.5949946Z Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)
2026-01-14T08:23:49.5950357Z Downloading anyio-4.12.1-py3-none-any.whl (113 kB)
2026-01-14T08:23:49.5950786Z Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
2026-01-14T08:23:49.5951226Z Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)
2026-01-14T08:23:49.5951680Z Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)
2026-01-14T08:23:49.5952134Z Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)
2026-01-14T08:23:49.5952764Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:49.5953527Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.5/1.5 MB[0m [31m11.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:49.5954130Z [?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)
2026-01-14T08:23:49.5954733Z Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (440 kB)
2026-01-14T08:23:49.5955403Z Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)
2026-01-14T08:23:49.5956067Z Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)
2026-01-14T08:23:49.5956764Z Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)
2026-01-14T08:23:49.5957230Z Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)
2026-01-14T08:23:49.5957709Z Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)
2026-01-14T08:23:49.5958145Z Downloading chardet-5.2.0-py3-none-any.whl (199 kB)
2026-01-14T08:23:49.5958591Z Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)
2026-01-14T08:23:49.5959044Z Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)
2026-01-14T08:23:49.5959478Z Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)
2026-01-14T08:23:57.0558859Z Downloading typepy-1.3.4-py3-none-any.whl (31 kB)
2026-01-14T08:23:57.0559309Z Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)
2026-01-14T08:23:57.0559772Z Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)
2026-01-14T08:23:57.0560483Z Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)
2026-01-14T08:23:57.0561569Z Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)
2026-01-14T08:23:57.0562600Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:57.0563356Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.6/5.6 MB[0m [31m29.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:57.0564233Z [?25hBuilding wheels for collected packages: rouge-score, sqlitedict, word2number
2026-01-14T08:23:57.0564875Z   Building wheel for rouge-score (pyproject.toml) ... [?25l- done
2026-01-14T08:23:57.0577984Z [?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=1c2fb876cded71ed3197c8004835a381dbeac22c75e2f53b846650b4fd6e0e89
2026-01-14T08:23:57.0579024Z   Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4
2026-01-14T08:23:57.0579739Z   Building wheel for sqlitedict (pyproject.toml) ... [?25l- done
2026-01-14T08:23:57.0580730Z [?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16957 sha256=4b494de13648bb2b61578132a48de48d3eb422caade8bdf7ab7170b13faa34e1
2026-01-14T08:23:57.0581729Z   Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd
2026-01-14T08:23:57.0582435Z   Building wheel for word2number (pyproject.toml) ... [?25l- done
2026-01-14T08:23:57.0583430Z [?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5659 sha256=c8a00b45e851455238f94ceb65540d7148f5c3db0177be538bba6213b74f799e
2026-01-14T08:23:57.0584740Z   Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b
2026-01-14T08:23:57.0585359Z Successfully built rouge-score sqlitedict word2number
2026-01-14T08:23:57.0590399Z Installing collected packages: word2number, sqlitedict, sortedcontainers, pytz, distlib, zstandard, zipp, xxhash, urllib3, tzdata, tqdm, tomli, threadpoolctl, termcolor, tcolorpy, tabulate, six, sentencepiece, safetensors, ruff, regex, pyyaml, pyparsing, pygments, pycryptodomex, pybind11, pyarrow, psutil, propcache, portalocker, pluggy, platformdirs, pillow, pathvalidate, parameterized, packaging, numpy, nodeenv, ninja, multidict, more_itertools, lxml, kiwisolver, joblib, iniconfig, idna, identify, hf-xet, h11, fsspec, frozenlist, fonttools, expecttest, exceptiongroup, diskcache, dill, cycler, colorama, cmake, click, charset_normalizer, chardet, cfgv, certifi, attrs, async-timeout, aiohappyeyeballs, absl-py, yarl, virtualenv, unittest-xml-reporting, tqdm-multiprocess, scipy, sacrebleu, requests, python-dateutil, pytest, pycocotools, numexpr, nltk, multiprocess, mbstrdecoder, jsonlines, importlib_metadata, hypothesis, httpcore, fire, contourpy, blobfile, anyio, aiosignal, typepy, tiktoken, scikit-learn, rouge-score, pre-commit, pandas, matplotlib, huggingface-hub, httpx, aiohttp, tokenizers, bitsandbytes, accelerate, transformers, datasets, DataProperty, tabledata, peft, evaluate, pytablewriter, lm_eval
2026-01-14T08:23:57.0595687Z [?25l
2026-01-14T08:23:57.0596148Z [2K   [91m━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  3/112[0m [pytz]
2026-01-14T08:23:57.0596821Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  5/112[0m [zstandard]
2026-01-14T08:23:57.0597670Z [2K   [91m━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  9/112[0m [tzdata]
2026-01-14T08:23:57.0598312Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 16/112[0m [six]
2026-01-14T08:23:57.0598944Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 19/112[0m [ruff]
2026-01-14T08:23:57.0599585Z [2K   [91m━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 21/112[0m [pyyaml]
2026-01-14T08:23:57.0600246Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:23:57.0601058Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:23:57.0601712Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:23:57.0602391Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/112[0m [pycryptodomex]
2026-01-14T08:23:57.0603104Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/112[0m [pycryptodomex]
2026-01-14T08:23:57.0603800Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/112[0m [pycryptodomex]
2026-01-14T08:23:57.0604473Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:23:57.0605118Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:23:57.0605796Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:23:57.0606446Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:23:57.0607096Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:23:57.0607758Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:23:57.0608428Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:23:57.0609080Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/112[0m [pillow]
2026-01-14T08:23:57.0609725Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/112[0m [pillow]
2026-01-14T08:23:57.0610380Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:23:57.0611138Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:23:57.0611778Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:23:57.0612544Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:23:57.0613337Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:23:57.0614251Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:03.8456929Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:03.8457828Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:03.8458591Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:03.8459352Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:03.8460054Z [2K   [91m━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 41/112[0m [lxml]
2026-01-14T08:24:03.8460804Z [2K   [91m━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 43/112[0m [joblib]
2026-01-14T08:24:03.8461550Z [2K   [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:03.8462179Z [2K  Attempting uninstall: fsspec
2026-01-14T08:24:03.8462721Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:03.8463350Z [2K    Found existing installation: fsspec 2026.1.0
2026-01-14T08:24:03.8464005Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:03.8464564Z [2K    Uninstalling fsspec-2026.1.0:
2026-01-14T08:24:03.8465162Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:03.8465777Z [2K      Successfully uninstalled fsspec-2026.1.0
2026-01-14T08:24:03.8466421Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:03.8467101Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m 49/112[0m [fsspec]
2026-01-14T08:24:03.8467907Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:03.8468707Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:03.8469486Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:03.8470277Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:03.8471049Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 52/112[0m [expecttest]
2026-01-14T08:24:03.8472176Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:03.8472919Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:03.8473647Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:03.8474574Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:03.8475509Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:03.8476251Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:03.8476945Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:03.8477661Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m 61/112[0m [chardet]
2026-01-14T08:24:03.8478449Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━[0m [32m 64/112[0m [attrs]
2026-01-14T08:24:03.8479208Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━[0m [32m 69/112[0m [virtualenv]
2026-01-14T08:24:03.8479978Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8480749Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8481475Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8482172Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8482906Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8483818Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8484892Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8485645Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8486398Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8487328Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8488110Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8488859Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8489563Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8490307Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8491052Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8491803Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:03.8492550Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:11.3140710Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:11.3141415Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━[0m [32m 73/112[0m [sacrebleu]
2026-01-14T08:24:11.3142088Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m 76/112[0m [pytest]
2026-01-14T08:24:11.3142757Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━[0m [32m 78/112[0m [numexpr]
2026-01-14T08:24:11.3143437Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:11.3144088Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:11.3144739Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:11.3145381Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:11.3146314Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m 84/112[0m [hypothesis]
2026-01-14T08:24:11.3147012Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m 84/112[0m [hypothesis]
2026-01-14T08:24:11.3147681Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m 87/112[0m [contourpy]
2026-01-14T08:24:11.3148348Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m 91/112[0m [typepy]
2026-01-14T08:24:11.3149186Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3149884Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3150577Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3151265Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3151978Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3152660Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3153351Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3154049Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3154748Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3155522Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:11.3156185Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3156854Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3157499Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3158141Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3158785Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3159539Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3160192Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3160838Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3161476Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3162255Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3162898Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3163550Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3164198Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3164859Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3165511Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3166159Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3166805Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3167522Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3168165Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3168813Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3169456Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:11.3170120Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:18.5941853Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:18.5942834Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:18.5943626Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:18.5944590Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:18.5945303Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:18.5945998Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:18.5946685Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:18.5947583Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m 98/112[0m [huggingface-hub]
2026-01-14T08:24:18.5948281Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m100/112[0m [aiohttp]
2026-01-14T08:24:18.5948967Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m101/112[0m [tokenizers]
2026-01-14T08:24:18.5949714Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:18.5950411Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:18.5951111Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:18.5951805Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:18.5952518Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:18.5953216Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m103/112[0m [accelerate]
2026-01-14T08:24:18.5953899Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5954599Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5955405Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5956096Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5956793Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5957483Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5959003Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5959735Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5960440Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5961229Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5961921Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5962630Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5963323Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5964056Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5964752Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5965446Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5966129Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5966836Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5967526Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5968214Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5968908Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5969607Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5970298Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5970991Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5971775Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5972470Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:18.5973158Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:31:33.9864526Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:31:33.9865290Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:31:33.9866475Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:31:33.9867167Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:31:33.9867849Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:31:33.9868552Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m105/112[0m [datasets]
2026-01-14T08:31:33.9869238Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m106/112[0m [DataProperty]
2026-01-14T08:31:33.9869905Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m108/112[0m [peft]
2026-01-14T08:31:33.9870567Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m109/112[0m [evaluate]
2026-01-14T08:31:33.9871218Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9871823Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9872427Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9873016Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9873639Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9874230Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9874946Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9875784Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9876600Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9877568Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9878381Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9879210Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9880275Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9881119Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9881990Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9882827Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9883651Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9884725Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9885449Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:31:33.9886034Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m112/112[0m [lm_eval]
2026-01-14T08:31:33.9886430Z [?25h
2026-01-14T08:31:33.9894702Z [1A[2KSuccessfully installed DataProperty-1.1.0 absl-py-2.3.1 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 anyio-4.12.1 async-timeout-5.0.1 attrs-25.4.0 bitsandbytes-0.49.1 blobfile-3.1.0 certifi-2026.1.4 cfgv-3.5.0 chardet-5.2.0 charset_normalizer-3.4.4 click-8.3.1 cmake-3.31.10 colorama-0.4.6 contourpy-1.3.2 cycler-0.12.1 datasets-4.4.2 dill-0.4.0 diskcache-5.6.3 distlib-0.4.0 evaluate-0.4.6 exceptiongroup-1.3.1 expecttest-0.3.0 fire-0.7.1 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 hypothesis-6.150.2 identify-2.6.16 idna-3.11 importlib_metadata-8.7.1 iniconfig-2.3.0 joblib-1.5.3 jsonlines-4.0.0 kiwisolver-1.4.9 lm_eval-0.4.9.2 lxml-6.0.2 matplotlib-3.10.8 mbstrdecoder-1.1.4 more_itertools-10.8.0 multidict-6.7.0 multiprocess-0.70.18 ninja-1.13.0 nltk-3.9.2 nodeenv-1.10.0 numexpr-2.14.1 numpy-2.2.6 packaging-25.0 pandas-2.3.3 parameterized-0.9.0 pathvalidate-3.3.1 peft-0.18.1 pillow-12.1.0 platformdirs-4.5.1 pluggy-1.6.0 portalocker-3.2.0 pre-commit-4.5.1 propcache-0.4.1 psutil-7.2.1 pyarrow-22.0.0 pybind11-3.0.1 pycocotools-2.0.11 pycryptodomex-3.23.0 pygments-2.19.2 pyparsing-3.3.1 pytablewriter-1.2.1 pytest-8.4.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 rouge-score-0.1.2 ruff-0.11.6 sacrebleu-2.6.0 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentencepiece-0.2.1 six-1.17.0 sortedcontainers-2.4.0 sqlitedict-2.1.0 tabledata-1.3.4 tabulate-0.9.0 tcolorpy-0.1.7 termcolor-3.3.0 threadpoolctl-3.6.0 tiktoken-0.12.0 tokenizers-0.22.2 tomli-2.4.0 tqdm-4.67.1 tqdm-multiprocess-0.0.11 transformers-4.57.5 typepy-1.3.4 tzdata-2025.3 unittest-xml-reporting-4.0.0 urllib3-2.6.3 virtualenv-20.36.1 word2number-1.1 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0 zstandard-0.25.0
2026-01-14T08:31:33.9904869Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:31:33.9906547Z [0m+ pip install . --no-build-isolation
2026-01-14T08:31:33.9906865Z Processing /pytorch/ao
2026-01-14T08:31:33.9907254Z   Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:31:33.9907723Z [?25hBuilding wheels for collected packages: torchao
2026-01-14T08:31:33.9908431Z   Building wheel for torchao (pyproject.toml) ... [?25l- \ | / - \ | / - \ | / - \ | / - \ | done
2026-01-14T08:31:33.9909698Z [?25h  Created wheel for torchao: filename=torchao-0.16.0+gitb34f898-cp310-abi3-linux_x86_64.whl size=4841399 sha256=c8c94b9851c714690bce6dd67e6e2a5e266088c1e4e19772769a95e709facfca
2026-01-14T08:31:33.9910905Z   Stored in directory: /tmp/pip-ephem-wheel-cache-8lw0ppna/wheels/d2/8b/29/aa26bc7679794c5ecae292c3b064b585980cbedb836e694414
2026-01-14T08:31:33.9911571Z Successfully built torchao
2026-01-14T08:31:33.9911863Z Installing collected packages: torchao
2026-01-14T08:31:33.9912221Z Successfully installed torchao-0.16.0+gitb34f898
2026-01-14T08:31:48.9275877Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:31:48.9277970Z [0m++++ which conda
2026-01-14T08:31:48.9278232Z +++ dirname /opt/conda/condabin/conda
2026-01-14T08:31:48.9278552Z ++ dirname /opt/conda/condabin
2026-01-14T08:31:48.9278825Z + export CONDA=/opt/conda
2026-01-14T08:31:48.9279080Z + CONDA=/opt/conda
2026-01-14T08:31:48.9279592Z + export LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:31:48.9280442Z + LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:31:48.9281004Z + pytest test --verbose -s
2026-01-14T08:31:48.9281425Z [1m============================= test session starts ==============================[0m
2026-01-14T08:31:48.9282042Z platform linux -- Python 3.10.19, pytest-8.4.2, pluggy-1.6.0 -- /opt/conda/envs/venv/bin/python3.10
2026-01-14T08:31:48.9282542Z cachedir: .pytest_cache
2026-01-14T08:31:48.9283163Z hypothesis profile 'ci' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=(HealthCheck.too_slow,)
2026-01-14T08:31:48.9283821Z rootdir: /pytorch/ao
2026-01-14T08:31:48.9284248Z configfile: pyproject.toml
2026-01-14T08:31:48.9284543Z plugins: hypothesis-6.150.2, anyio-4.12.1
2026-01-14T08:31:48.9284900Z [1mcollecting ... [0m[1m
2026-01-14T08:31:48.9285339Z collecting 0 items                                                             [0m[1m
2026-01-14T08:31:48.9285916Z collecting 28 items                                                            [0m[1m
2026-01-14T08:31:48.9287013Z collecting 177 items                                                           [0mW0114 08:31:39.504000 1007 site-packages/torch/_library/triton.py:222] _dequant_mxfp8_kernel not in collector.assignments
2026-01-14T08:31:48.9287782Z [1m
2026-01-14T08:31:48.9288667Z collecting 872 items / 3 skipped                                               [0mW0114 08:31:41.650000 1007 site-packages/torch/_library/triton.py:222] triton_scale_swizzle_M_groups not in collector.assignments
2026-01-14T08:31:48.9290092Z W0114 08:31:41.675000 1007 site-packages/torch/_library/triton.py:222] triton_scale_swizzle_per_group_3d not in collector.assignments
2026-01-14T08:31:48.9291045Z W0114 08:31:41.698000 1007 site-packages/torch/_library/triton.py:222] triton_scale_swizzle_2d_K_groups not in collector.assignments
2026-01-14T08:31:48.9291693Z [1m
2026-01-14T08:31:48.9292098Z collecting 927 items / 5 skipped                                               [0m[1m
2026-01-14T08:31:48.9292905Z collecting 3471 items / 16 skipped                                             [0m[1m
2026-01-14T08:31:48.9293546Z collecting 5481 items / 17 skipped                                             [0m[1m
2026-01-14T08:31:48.9294171Z collecting 6020 items / 17 skipped                                             [0m[1m
2026-01-14T08:31:48.9294806Z collecting 7449 items / 17 skipped                                             [0m[1m
2026-01-14T08:31:48.9295437Z collected 8953 items / 17 skipped                                              [0m
2026-01-14T08:31:48.9295773Z 
2026-01-14T08:31:48.9296174Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config0] [32mPASSED[0m
2026-01-14T08:31:48.9296966Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config1] [32mPASSED[0m
2026-01-14T08:31:48.9297753Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config2] [32mPASSED[0m
2026-01-14T08:31:48.9298519Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config3] [32mPASSED[0m
2026-01-14T08:31:48.9299271Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config4] [32mPASSED[0m
2026-01-14T08:31:48.9300032Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config5] [32mPASSED[0m
2026-01-14T08:31:48.9300797Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config6] [32mPASSED[0m
2026-01-14T08:31:48.9301547Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7] [32mPASSED[0m
2026-01-14T08:31:48.9302319Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config8] [32mPASSED[0m
2026-01-14T08:31:48.9303071Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config9] [32mPASSED[0m
2026-01-14T08:31:48.9303844Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config10] [32mPASSED[0m
2026-01-14T08:31:48.9304624Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config11] [32mPASSED[0m
2026-01-14T08:31:48.9305384Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config12] [32mPASSED[0m
2026-01-14T08:31:48.9306156Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config13] [32mPASSED[0m
2026-01-14T08:31:48.9306921Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14] [32mPASSED[0m
2026-01-14T08:31:48.9307691Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config15] [32mPASSED[0m
2026-01-14T08:31:48.9308459Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config16] [32mPASSED[0m
2026-01-14T08:31:48.9309226Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config17] [32mPASSED[0m
2026-01-14T08:31:48.9310002Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config18] [32mPASSED[0m
2026-01-14T08:31:48.9310762Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config19] [32mPASSED[0m
2026-01-14T08:31:48.9311539Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config20] [32mPASSED[0m
2026-01-14T08:31:48.9312298Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config21] [32mPASSED[0m
2026-01-14T08:31:48.9313057Z test/core/test_config.py::test_granularity_serialization[granularity0] [33mSKIPPED[0m
2026-01-14T08:31:48.9313782Z test/core/test_config.py::test_granularity_serialization[granularity1] [33mSKIPPED[0m
2026-01-14T08:31:48.9314586Z test/core/test_config.py::test_granularity_serialization[granularity2] [33mSKIPPED[0m
2026-01-14T08:31:48.9315297Z test/core/test_config.py::test_disallowed_modules [32mPASSED[0m
2026-01-14T08:31:48.9315836Z test/core/test_config.py::test_version_mismatch [32mPASSED[0m
2026-01-14T08:31:48.9316374Z test/core/test_config.py::test_default_version [32mPASSED[0m
2026-01-14T08:31:48.9317210Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant0 [32mPASSED[0m
2026-01-14T08:31:48.9322352Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant1 [32mPASSED[0m
2026-01-14T08:31:48.9323365Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant2 [32mPASSED[0m
2026-01-14T08:31:48.9324374Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant3 [32mPASSED[0m
2026-01-14T08:31:48.9325386Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant4 [32mPASSED[0m
2026-01-14T08:31:48.9326344Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_print_quantized_module [32mPASSED[0m
2026-01-14T08:31:48.9327227Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_register_new_dispatch [32mPASSED[0m
2026-01-14T08:31:48.9328151Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_tensor_core_layout_transpose [32mPASSED[0m
2026-01-14T08:31:48.9329102Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant0 [32mPASSED[0m
2026-01-14T08:31:48.9330052Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant1 [32mPASSED[0m
2026-01-14T08:31:48.9331001Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant2 [32mPASSED[0m
2026-01-14T08:31:48.9331942Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant3 [32mPASSED[0m
2026-01-14T08:31:48.9332895Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant4 [32mPASSED[0m
2026-01-14T08:31:48.9333848Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_affine_quantized_intx_static [32mPASSED[0m
2026-01-14T08:31:48.9334774Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant0 [32mPASSED[0m
2026-01-14T08:31:48.9335667Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant1 [32mPASSED[0m
2026-01-14T08:31:48.9336551Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant2 [32mPASSED[0m
2026-01-14T08:31:48.9337435Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant3 [32mPASSED[0m
2026-01-14T08:31:48.9338266Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_weights_only [32mPASSED[0m
2026-01-14T08:31:48.9339149Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_alias_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:31:48.9340125Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_alias_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:31:48.9341149Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:31:48.9342230Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:31:48.9343231Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_matmul_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:31:48.9344173Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_mm_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:31:48.9345180Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_and_copy_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:31:48.9346203Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_cuda_bfloat16 [33mSKIPPED[0m
2026-01-14T08:31:57.1584867Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_cuda_float16 [33mSKIPPED[0m
2026-01-14T08:31:57.1585880Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:31:57.1587035Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_bfloat16 [32mPASSED[0m
2026-01-14T08:31:57.1588581Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_float32 [32mPASSED[0m
2026-01-14T08:31:57.1589869Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_bfloat16 [32mPASSED[0m
2026-01-14T08:31:57.1591150Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_float32 [32mPASSED[0m
2026-01-14T08:31:57.1592488Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size0 [32mPASSED[0m
2026-01-14T08:31:57.1593874Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size1 [32mPASSED[0m
2026-01-14T08:31:57.1595337Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size2 [32mPASSED[0m
2026-01-14T08:31:57.1596712Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size3 [32mPASSED[0m
2026-01-14T08:31:57.1598085Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size0 [32mPASSED[0m
2026-01-14T08:31:57.1599456Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size1 [32mPASSED[0m
2026-01-14T08:31:57.1600825Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size2 [32mPASSED[0m
2026-01-14T08:31:57.1602199Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size3 [32mPASSED[0m
2026-01-14T08:31:57.1603563Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size0 [32mPASSED[0m
2026-01-14T08:31:57.1604925Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size1 [32mPASSED[0m
2026-01-14T08:31:57.1606282Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size2 [32mPASSED[0m
2026-01-14T08:31:57.1607643Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size3 [32mPASSED[0m
2026-01-14T08:31:57.1609004Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size0 [32mPASSED[0m
2026-01-14T08:31:57.1610362Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size1 [32mPASSED[0m
2026-01-14T08:31:57.1611708Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size2 [32mPASSED[0m
2026-01-14T08:31:57.1613066Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size3 [32mPASSED[0m
2026-01-14T08:31:57.1614370Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_scale_broadcasting [32mPASSED[0m
2026-01-14T08:31:57.1615774Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity0 [33mSKIPPED[0m
2026-01-14T08:31:57.1616989Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity1 [33mSKIPPED[0m
2026-01-14T08:31:57.1618439Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:31:57.1620039Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:31:57.1621561Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:31:57.1623082Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:31:57.1624590Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:31:57.1626103Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:31:57.1627602Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:31:57.1629107Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:31:57.1630614Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:31:57.1632112Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:31:57.1633628Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:31:57.1635177Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:31:57.1636671Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:31:57.1638173Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:31:57.1639669Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:31:57.1641161Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:31:57.1642423Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_invalid_granularity [32mPASSED[0m
2026-01-14T08:31:57.1643496Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_mismatched_granularity [32mPASSED[0m
2026-01-14T08:31:57.1644565Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_per_row_with_float32 [33mSKIPPED[0m
2026-01-14T08:31:57.1645736Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_preprocess_scale_3d_reshape [32mPASSED[0m
2026-01-14T08:31:57.1646929Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:31:57.1647808Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:31:57.1648225Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:31:57.1648836Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:31:57.1649314Z graph_break []
2026-01-14T08:31:57.1649569Z [32mPASSED[0m
2026-01-14T08:31:57.1650378Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:31:57.1651245Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:31:57.1651772Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:31:57.1652321Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:31:57.1652667Z graph_break []
2026-01-14T08:31:57.1652913Z [32mPASSED[0m
2026-01-14T08:31:57.1653656Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:31:57.1654528Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:31:57.1655034Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:32:47.3531983Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:32:47.3532402Z graph_break []
2026-01-14T08:32:47.3532862Z [32mPASSED[0m
2026-01-14T08:32:47.3533632Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:32:47.3534531Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:32:47.3535048Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:32:47.3535606Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:32:47.3535966Z graph_break []
2026-01-14T08:32:47.3536226Z [32mPASSED[0m
2026-01-14T08:32:47.3536935Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_serialization_mode_static [33mSKIPPED[0m
2026-01-14T08:32:47.3538049Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_unsupported_granularity [32mPASSED[0m
2026-01-14T08:32:47.3539511Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_bfloat16 I0114 08:31:58.102000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 0 with pid 1247
2026-01-14T08:32:47.3540931Z I0114 08:31:58.103000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 1 with pid 1248
2026-01-14T08:32:47.3541847Z I0114 08:31:58.104000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 2 with pid 1249
2026-01-14T08:32:47.3542756Z I0114 08:31:58.105000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 3 with pid 1250
2026-01-14T08:32:47.3544254Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3545448Z   warnings.warn(
2026-01-14T08:32:47.3546596Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3548134Z   warnings.warn(
2026-01-14T08:32:47.3549256Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3550408Z   warnings.warn(
2026-01-14T08:32:47.3551673Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3552831Z   warnings.warn(
2026-01-14T08:32:47.3553090Z [32mPASSED[0m
2026-01-14T08:32:47.3554102Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float16 I0114 08:32:08.125000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 0 with pid 1988
2026-01-14T08:32:47.3555559Z I0114 08:32:08.126000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 1 with pid 1989
2026-01-14T08:32:47.3556486Z I0114 08:32:08.127000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 2 with pid 1990
2026-01-14T08:32:47.3557397Z I0114 08:32:08.128000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 3 with pid 1991
2026-01-14T08:32:47.3558860Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3560043Z   warnings.warn(
2026-01-14T08:32:47.3561148Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3562306Z   warnings.warn(
2026-01-14T08:32:47.3563400Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3564552Z   warnings.warn(
2026-01-14T08:32:47.3565647Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3566852Z   warnings.warn(
2026-01-14T08:32:47.3567103Z [32mPASSED[0m
2026-01-14T08:32:47.3568128Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float32 I0114 08:32:20.051000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 0 with pid 2896
2026-01-14T08:32:47.3569508Z I0114 08:32:20.052000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 1 with pid 2897
2026-01-14T08:32:47.3570411Z I0114 08:32:20.053000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 2 with pid 2898
2026-01-14T08:32:47.3571337Z I0114 08:32:20.054000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 3 with pid 2899
2026-01-14T08:32:47.3572802Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3573980Z   warnings.warn(
2026-01-14T08:32:47.3575177Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3576344Z   warnings.warn(
2026-01-14T08:32:47.3577537Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3578717Z   warnings.warn(
2026-01-14T08:32:47.3579823Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:32:47.3581001Z   warnings.warn(
2026-01-14T08:32:47.3581260Z [32mPASSED[0m
2026-01-14T08:32:47.3581975Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt4woAffineQuantizedTensorParallel::test_tp_bfloat16 [33mSKIPPED[0m
2026-01-14T08:32:47.3583138Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestGemliteLayoutTensorParallel::test_tp_gemlite_float16 [33mSKIPPED[0m
2026-01-14T08:32:47.3584757Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8dqAffineQuantizedTensorParallel::test_tp_bfloat16 I0114 08:32:32.380000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 0 with pid 3833
2026-01-14T08:32:47.3586162Z I0114 08:32:32.381000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 1 with pid 3834
2026-01-14T08:32:47.3587065Z I0114 08:32:32.381000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 2 with pid 3835
2026-01-14T08:32:47.3587974Z I0114 08:32:32.382000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 3 with pid 3836
2026-01-14T08:32:47.3588609Z [32mPASSED[0m
2026-01-14T08:32:47.3588994Z test/dtypes/test_bitpacking.py::test_CPU[0-1] [32mPASSED[0m
2026-01-14T08:32:47.3589524Z test/dtypes/test_bitpacking.py::test_CPU[0-2] [32mPASSED[0m
2026-01-14T08:32:47.3590049Z test/dtypes/test_bitpacking.py::test_CPU[0-3] [32mPASSED[0m
2026-01-14T08:32:47.3590581Z test/dtypes/test_bitpacking.py::test_CPU[0-4] [32mPASSED[0m
2026-01-14T08:32:47.3591112Z test/dtypes/test_bitpacking.py::test_CPU[0-5] [32mPASSED[0m
2026-01-14T08:32:47.3591647Z test/dtypes/test_bitpacking.py::test_CPU[0-6] [32mPASSED[0m
2026-01-14T08:32:47.3592182Z test/dtypes/test_bitpacking.py::test_CPU[0-7] [32mPASSED[0m
2026-01-14T08:32:47.3592730Z test/dtypes/test_bitpacking.py::test_CPU[-1-1] [32mPASSED[0m
2026-01-14T08:32:47.3593335Z test/dtypes/test_bitpacking.py::test_CPU[-1-2] [32mPASSED[0m
2026-01-14T08:32:47.3593930Z test/dtypes/test_bitpacking.py::test_CPU[-1-3] [32mPASSED[0m
2026-01-14T08:32:47.3594538Z test/dtypes/test_bitpacking.py::test_CPU[-1-4] [32mPASSED[0m
2026-01-14T08:32:47.3595140Z test/dtypes/test_bitpacking.py::test_CPU[-1-5] [32mPASSED[0m
2026-01-14T08:32:47.3595685Z test/dtypes/test_bitpacking.py::test_CPU[-1-6] [32mPASSED[0m
2026-01-14T08:32:47.3596274Z test/dtypes/test_bitpacking.py::test_CPU[-1-7] [32mPASSED[0m
2026-01-14T08:32:47.3596803Z test/dtypes/test_bitpacking.py::test_CPU[1-1] [32mPASSED[0m
2026-01-14T08:32:47.3597337Z test/dtypes/test_bitpacking.py::test_CPU[1-2] [32mPASSED[0m
2026-01-14T08:32:47.3597868Z test/dtypes/test_bitpacking.py::test_CPU[1-3] [32mPASSED[0m
2026-01-14T08:32:47.3598398Z test/dtypes/test_bitpacking.py::test_CPU[1-4] [32mPASSED[0m
2026-01-14T08:32:47.3598926Z test/dtypes/test_bitpacking.py::test_CPU[1-5] [32mPASSED[0m
2026-01-14T08:32:47.3599463Z test/dtypes/test_bitpacking.py::test_CPU[1-6] [32mPASSED[0m
2026-01-14T08:32:51.2675088Z test/dtypes/test_bitpacking.py::test_CPU[1-7] [32mPASSED[0m
2026-01-14T08:32:51.2676354Z test/dtypes/test_bitpacking.py::test_GPU[0-1] [32mPASSED[0m
2026-01-14T08:32:51.2677100Z test/dtypes/test_bitpacking.py::test_GPU[0-2] [32mPASSED[0m
2026-01-14T08:32:51.2677847Z test/dtypes/test_bitpacking.py::test_GPU[0-3] [32mPASSED[0m
2026-01-14T08:32:51.2678575Z test/dtypes/test_bitpacking.py::test_GPU[0-4] [32mPASSED[0m
2026-01-14T08:32:51.2679313Z test/dtypes/test_bitpacking.py::test_GPU[0-5] [32mPASSED[0m
2026-01-14T08:32:51.2680033Z test/dtypes/test_bitpacking.py::test_GPU[0-6] [32mPASSED[0m
2026-01-14T08:32:51.2680982Z test/dtypes/test_bitpacking.py::test_GPU[0-7] [32mPASSED[0m
2026-01-14T08:32:51.2681735Z test/dtypes/test_bitpacking.py::test_GPU[-1-1] [32mPASSED[0m
2026-01-14T08:32:51.2682475Z test/dtypes/test_bitpacking.py::test_GPU[-1-2] [32mPASSED[0m
2026-01-14T08:32:51.2683026Z test/dtypes/test_bitpacking.py::test_GPU[-1-3] [32mPASSED[0m
2026-01-14T08:32:51.2683558Z test/dtypes/test_bitpacking.py::test_GPU[-1-4] [32mPASSED[0m
2026-01-14T08:32:51.2684314Z test/dtypes/test_bitpacking.py::test_GPU[-1-5] [32mPASSED[0m
2026-01-14T08:32:51.2684902Z test/dtypes/test_bitpacking.py::test_GPU[-1-6] [32mPASSED[0m
2026-01-14T08:32:51.2685424Z test/dtypes/test_bitpacking.py::test_GPU[-1-7] [32mPASSED[0m
2026-01-14T08:32:51.2685945Z test/dtypes/test_bitpacking.py::test_GPU[1-1] [32mPASSED[0m
2026-01-14T08:32:51.2686471Z test/dtypes/test_bitpacking.py::test_GPU[1-2] [32mPASSED[0m
2026-01-14T08:32:51.2686995Z test/dtypes/test_bitpacking.py::test_GPU[1-3] [32mPASSED[0m
2026-01-14T08:32:51.2687516Z test/dtypes/test_bitpacking.py::test_GPU[1-4] [32mPASSED[0m
2026-01-14T08:32:51.2688038Z test/dtypes/test_bitpacking.py::test_GPU[1-5] [32mPASSED[0m
2026-01-14T08:32:51.2688558Z test/dtypes/test_bitpacking.py::test_GPU[1-6] [32mPASSED[0m
2026-01-14T08:32:51.2689080Z test/dtypes/test_bitpacking.py::test_GPU[1-7] [32mPASSED[0m
2026-01-14T08:32:51.2689619Z test/dtypes/test_bitpacking.py::test_compile[0-1] [32mPASSED[0m
2026-01-14T08:32:51.2690178Z test/dtypes/test_bitpacking.py::test_compile[0-2] [32mPASSED[0m
2026-01-14T08:32:51.2690746Z test/dtypes/test_bitpacking.py::test_compile[0-3] [32mPASSED[0m
2026-01-14T08:32:51.2691301Z test/dtypes/test_bitpacking.py::test_compile[0-4] [32mPASSED[0m
2026-01-14T08:32:51.2691861Z test/dtypes/test_bitpacking.py::test_compile[0-5] [32mPASSED[0m
2026-01-14T08:32:51.2692417Z test/dtypes/test_bitpacking.py::test_compile[0-6] [32mPASSED[0m
2026-01-14T08:32:51.2692981Z test/dtypes/test_bitpacking.py::test_compile[0-7] [32mPASSED[0m
2026-01-14T08:32:51.2693547Z test/dtypes/test_bitpacking.py::test_compile[-1-1] [32mPASSED[0m
2026-01-14T08:32:51.2694123Z test/dtypes/test_bitpacking.py::test_compile[-1-2] [32mPASSED[0m
2026-01-14T08:32:51.2694696Z test/dtypes/test_bitpacking.py::test_compile[-1-3] [32mPASSED[0m
2026-01-14T08:32:51.2695263Z test/dtypes/test_bitpacking.py::test_compile[-1-4] [32mPASSED[0m
2026-01-14T08:32:51.2695832Z test/dtypes/test_bitpacking.py::test_compile[-1-5] [32mPASSED[0m
2026-01-14T08:32:51.2696399Z test/dtypes/test_bitpacking.py::test_compile[-1-6] [32mPASSED[0m
2026-01-14T08:32:51.2696970Z test/dtypes/test_bitpacking.py::test_compile[-1-7] [32mPASSED[0m
2026-01-14T08:32:51.2697535Z test/dtypes/test_bitpacking.py::test_compile[1-1] [32mPASSED[0m
2026-01-14T08:32:51.2698100Z test/dtypes/test_bitpacking.py::test_compile[1-2] [32mPASSED[0m
2026-01-14T08:32:51.2698664Z test/dtypes/test_bitpacking.py::test_compile[1-3] [32mPASSED[0m
2026-01-14T08:32:51.2699220Z test/dtypes/test_bitpacking.py::test_compile[1-4] [32mPASSED[0m
2026-01-14T08:32:51.2699788Z test/dtypes/test_bitpacking.py::test_compile[1-5] [32mPASSED[0m
2026-01-14T08:32:51.2700346Z test/dtypes/test_bitpacking.py::test_compile[1-6] [32mPASSED[0m
2026-01-14T08:32:51.2700906Z test/dtypes/test_bitpacking.py::test_compile[1-7] [32mPASSED[0m
2026-01-14T08:32:51.2701741Z test/dtypes/test_bitpacking.py::test_pack_example tensor([  0, 105, 151,  37], device='cuda:0', dtype=torch.uint8) tensor([ 39, 146], device='cuda:0', dtype=torch.uint8)
2026-01-14T08:32:51.2702688Z [32mPASSED[0m
2026-01-14T08:32:51.2703270Z test/dtypes/test_bitpacking.py::test_pack_example_CPU tensor([  0, 105, 151,  37], dtype=torch.uint8) tensor([ 39, 146], dtype=torch.uint8)
2026-01-14T08:32:51.2703931Z [32mPASSED[0m
2026-01-14T08:32:51.2704438Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:32:51.2705190Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:32:51.2706058Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:32:51.2706933Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:32:51.2707930Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:32:51.2708884Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:32:51.2709838Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:32:51.2710783Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:32:51.2711727Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:32:51.2712669Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:32:51.2713605Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:32:51.2714531Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:32:51.2715529Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:32:51.2716471Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:32:51.2717396Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:32:51.2718332Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:32:51.2719266Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:32:51.2720201Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:32:51.2721127Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:32:51.2722062Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:32:51.2722992Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:32:51.2723800Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size0 [32mPASSED[0m
2026-01-14T08:32:51.2724502Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size1 [32mPASSED[0m
2026-01-14T08:32:51.2725242Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:32:51.2726013Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float16 [32mPASSED[0m
2026-01-14T08:32:51.2726778Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float32 [32mPASSED[0m
2026-01-14T08:32:51.2727537Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:32:51.2728304Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float16 [32mPASSED[0m
2026-01-14T08:32:51.2729068Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float32 [32mPASSED[0m
2026-01-14T08:32:51.2729945Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_bfloat16 [32mPASSED[0m
2026-01-14T08:32:51.2730703Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float16 [32mPASSED[0m
2026-01-14T08:32:51.2731446Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float32 [32mPASSED[0m
2026-01-14T08:32:51.2732179Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_bfloat16 [33mSKIPPED[0m
2026-01-14T08:32:51.2732978Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float16 [33mSKIPPED[0m
2026-01-14T08:32:51.2733680Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float32 [33mSKIPPED[0m
2026-01-14T08:32:51.2734404Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:32:51.2735138Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:32:51.2735870Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:32:51.2736600Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_False [32mPASSED[0m
2026-01-14T08:32:51.2737382Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_True [32mPASSED[0m
2026-01-14T08:32:51.2738175Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_bfloat16 [33mSKIPPED[0m
2026-01-14T08:32:51.2738996Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float16 [33mSKIPPED[0m
2026-01-14T08:32:51.2739826Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float32 [33mSKIPPED[0m
2026-01-14T08:32:51.2740610Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_bfloat16 [32mPASSED[0m
2026-01-14T08:32:51.2741371Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float16 [32mPASSED[0m
2026-01-14T08:32:51.2742124Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float32 [32mPASSED[0m
2026-01-14T08:32:51.2742857Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_bfloat16 [32mPASSED[0m
2026-01-14T08:32:51.2743573Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_bfloat16 Autotune Choices Stats:
2026-01-14T08:32:51.2745006Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_3", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:32:58.4201307Z AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:32:58.4201694Z strides: [32, 1], [1, 32]
2026-01-14T08:32:58.4201982Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:32:58.4202770Z   triton_mm_3 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:32:58.4204013Z   triton_mm_10 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:32:58.4205223Z   triton_mm_11 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:32:58.4206435Z   triton_mm_0 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:32:58.4207622Z   triton_mm_1 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:32:58.4208807Z   triton_mm_2 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:32:58.4210419Z   triton_mm_4 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:32:58.4211598Z   triton_mm_5 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:32:58.4212934Z   triton_mm_6 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:32:58.4214108Z   triton_mm_7 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:32:58.4215111Z SingleProcess AUTOTUNE benchmarking takes 0.1628 seconds and 0.1993 seconds precompiling for 13 choices
2026-01-14T08:32:58.4215914Z [32mPASSED[0m
2026-01-14T08:32:58.4216406Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float16 Autotune Choices Stats:
2026-01-14T08:32:58.4217834Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_17", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:32:58.4219028Z AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:32:58.4219285Z strides: [32, 1], [1, 32]
2026-01-14T08:32:58.4219560Z dtypes: torch.float16, torch.float16
2026-01-14T08:32:58.4220320Z   triton_mm_17 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:32:58.4221520Z   triton_mm_14 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:32:58.4222709Z   triton_mm_18 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:32:58.4223879Z   triton_mm_19 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:32:58.4225059Z   triton_mm_12 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:32:58.4226261Z   triton_mm_13 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:32:58.4236026Z   triton_mm_15 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:32:58.4237215Z   triton_mm_16 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:32:58.4238386Z   triton_mm_20 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:32:58.4239567Z   triton_mm_21 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:32:58.4240559Z SingleProcess AUTOTUNE benchmarking takes 0.2889 seconds and 0.2210 seconds precompiling for 13 choices
2026-01-14T08:32:58.4241176Z [32mPASSED[0m
2026-01-14T08:32:58.4241655Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float32 Autotune Choices Stats:
2026-01-14T08:32:58.4243075Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_26", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:32:58.4244378Z AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:32:58.4244634Z strides: [32, 1], [1, 32]
2026-01-14T08:32:58.4244904Z dtypes: torch.float32, torch.float32
2026-01-14T08:32:58.4245739Z   triton_mm_26 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:32:58.4246928Z   triton_mm_28 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:32:58.4248106Z   triton_mm_30 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:32:58.4249300Z   triton_mm_34 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:32:58.4250470Z   triton_mm_24 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:32:58.4251656Z   triton_mm_25 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:32:58.4252840Z   triton_mm_32 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:32:58.4254000Z   triton_mm_33 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:32:58.4255181Z   triton_mm_35 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:32:58.4256369Z   triton_mm_29 0.0266 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:32:58.4257349Z SingleProcess AUTOTUNE benchmarking takes 0.1623 seconds and 0.2158 seconds precompiling for 13 choices
2026-01-14T08:32:58.4257932Z [32mPASSED[0m
2026-01-14T08:32:58.4258416Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float16 [32mPASSED[0m
2026-01-14T08:32:58.4259129Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float32 [32mPASSED[0m
2026-01-14T08:32:58.4259817Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16 [32mPASSED[0m
2026-01-14T08:32:58.4260446Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_device [32mPASSED[0m
2026-01-14T08:32:58.4261083Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16 [32mPASSED[0m
2026-01-14T08:32:58.4261708Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32 [32mPASSED[0m
2026-01-14T08:32:58.4262353Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_bfloat16 [32mPASSED[0m
2026-01-14T08:32:58.4262989Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float16 [32mPASSED[0m
2026-01-14T08:32:58.4263634Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float32 [32mPASSED[0m
2026-01-14T08:32:58.4264263Z test/dtypes/test_nf4.py::TestFSDPOps::test_pin_memory [32mPASSED[0m
2026-01-14T08:32:58.4264934Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_2d_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:32:58.4265719Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:32:58.4266519Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:32:58.4267405Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size1 [32mPASSED[0m
2026-01-14T08:32:58.4268180Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size2 [32mPASSED[0m
2026-01-14T08:32:58.4268979Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:51.4928568Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size1 [32mPASSED[0m
2026-01-14T08:35:51.4929686Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size2 [32mPASSED[0m
2026-01-14T08:35:51.4930453Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:51.4931244Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:35:51.4932030Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size2 [32mPASSED[0m
2026-01-14T08:35:51.4933190Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:51.4934119Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:51.4934895Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size2 [32mPASSED[0m
2026-01-14T08:35:51.4935693Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:51.4936502Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_1d_invalid [32mPASSED[0m
2026-01-14T08:35:51.4937195Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_2d_invalid [32mPASSED[0m
2026-01-14T08:35:51.4937903Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:51.4938646Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size2 [32mPASSED[0m
2026-01-14T08:35:51.4939413Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:51.4940180Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:35:51.4940924Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:35:51.4941652Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:51.4942307Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cpu [32mPASSED[0m
2026-01-14T08:35:51.4942874Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cuda [32mPASSED[0m
2026-01-14T08:35:51.4943452Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_module [32mPASSED[0m
2026-01-14T08:35:51.4944133Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_3d_input_size0 [32mPASSED[0m
2026-01-14T08:35:51.4944921Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size1 [32mPASSED[0m
2026-01-14T08:35:51.4945736Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size2 [32mPASSED[0m
2026-01-14T08:35:51.4946624Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size_261632 [32mPASSED[0m
2026-01-14T08:35:51.4947423Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:51.4948163Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size2 [32mPASSED[0m
2026-01-14T08:35:51.4948922Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:51.4949648Z test/dtypes/test_nf4.py::TestQLoRA::test_qlora_fsdp2 [33mSKIPPED[0m (torch ...)
2026-01-14T08:35:51.4950581Z test/dtypes/test_nf4.py::TestComm::test_comm I0114 08:32:59.444000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 0 with pid 5181
2026-01-14T08:35:51.4951668Z I0114 08:32:59.445000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 1 with pid 5182
2026-01-14T08:35:51.4952495Z dist init r=1, world=2
2026-01-14T08:35:51.4952732Z dist init r=0, world=2
2026-01-14T08:35:51.4954052Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py:1013: UserWarning: To construct DTensor from torch.Tensor, it's recommended to use local_tensor.detach() and make requires_grad consistent. (Triggered internally at /pytorch/torch/csrc/autograd/python_variable.cpp:1682.)
2026-01-14T08:35:51.4955506Z   return dtensor.DTensor(
2026-01-14T08:35:51.4956957Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/tensor/_redistribute.py:1013: UserWarning: To construct DTensor from torch.Tensor, it's recommended to use local_tensor.detach() and make requires_grad consistent. (Triggered internally at /pytorch/torch/csrc/autograd/python_variable.cpp:1682.)
2026-01-14T08:35:51.4958307Z   return dtensor.DTensor(
2026-01-14T08:35:51.4959280Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:35:51.4960276Z   return func(*args, **kwargs)
2026-01-14T08:35:51.4960578Z [32mPASSED[0m
2026-01-14T08:35:51.4961087Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype0] [32mPASSED[0m
2026-01-14T08:35:51.4961880Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype1] [32mPASSED[0m
2026-01-14T08:35:51.4962664Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype2] [32mPASSED[0m
2026-01-14T08:35:51.4963442Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype3] [32mPASSED[0m
2026-01-14T08:35:51.4964215Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype4] [32mPASSED[0m
2026-01-14T08:35:51.4964993Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype5] [32mPASSED[0m
2026-01-14T08:35:51.4965771Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype6] [32mPASSED[0m
2026-01-14T08:35:51.4966549Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype0] [32mPASSED[0m
2026-01-14T08:35:51.4967334Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype1] [32mPASSED[0m
2026-01-14T08:35:51.4968103Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype2] [32mPASSED[0m
2026-01-14T08:35:51.4968894Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype3] [32mPASSED[0m
2026-01-14T08:35:51.4969676Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype4] [32mPASSED[0m
2026-01-14T08:35:51.4970447Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype5] [32mPASSED[0m
2026-01-14T08:35:51.4971226Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype6] [32mPASSED[0m
2026-01-14T08:35:51.4972000Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype0] [32mPASSED[0m
2026-01-14T08:35:51.4972789Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype1] [32mPASSED[0m
2026-01-14T08:35:51.4973574Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype2] [32mPASSED[0m
2026-01-14T08:35:51.4974352Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype3] [32mPASSED[0m
2026-01-14T08:35:51.4975140Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype4] [32mPASSED[0m
2026-01-14T08:35:51.4975915Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype5] [32mPASSED[0m
2026-01-14T08:35:51.4976701Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype6] [32mPASSED[0m
2026-01-14T08:35:51.4977470Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype0] [32mPASSED[0m
2026-01-14T08:35:51.4978236Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype1] [32mPASSED[0m
2026-01-14T08:35:51.4979093Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype2] [32mPASSED[0m
2026-01-14T08:35:51.4979851Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype3] [32mPASSED[0m
2026-01-14T08:35:51.4980615Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype4] [32mPASSED[0m
2026-01-14T08:35:51.4981369Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype5] [32mPASSED[0m
2026-01-14T08:35:51.4982210Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype6] [32mPASSED[0m
2026-01-14T08:35:51.4982974Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype0] [32mPASSED[0m
2026-01-14T08:35:51.4983728Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype1] [32mPASSED[0m
2026-01-14T08:35:51.4984830Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype2] [32mPASSED[0m
2026-01-14T08:35:51.4985586Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype3] [32mPASSED[0m
2026-01-14T08:35:51.4986383Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype4] [32mPASSED[0m
2026-01-14T08:35:51.4987164Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype5] [32mPASSED[0m
2026-01-14T08:35:51.4987919Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype6] [32mPASSED[0m
2026-01-14T08:35:51.4988696Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype0] [32mPASSED[0m
2026-01-14T08:35:51.4989464Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype1] [32mPASSED[0m
2026-01-14T08:35:51.4990239Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype2] [32mPASSED[0m
2026-01-14T08:35:51.4991016Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype3] [32mPASSED[0m
2026-01-14T08:35:51.4991769Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype4] [32mPASSED[0m
2026-01-14T08:35:51.4992545Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype5] [32mPASSED[0m
2026-01-14T08:35:51.4993326Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype6] [32mPASSED[0m
2026-01-14T08:35:51.4994106Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype0] [32mPASSED[0m
2026-01-14T08:35:51.4995057Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype1] [32mPASSED[0m
2026-01-14T08:35:51.4996219Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype2] [32mPASSED[0m
2026-01-14T08:35:51.4997355Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6038692Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6039879Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6040994Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6042106Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6042944Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6043742Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6044552Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6045343Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6046140Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6046927Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6048217Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6049025Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6049823Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6050620Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6051629Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6052444Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6053242Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6053994Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6054710Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6055419Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6056133Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6056841Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6057569Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6058283Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6058988Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6059700Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6060397Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6061114Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6061830Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6062540Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6063254Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6063971Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6064697Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6065420Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6066136Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6066856Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6067575Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6068292Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6069026Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6069782Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6070542Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6071288Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6072037Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6072830Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6073676Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6074416Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6075261Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6076017Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6076848Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6077595Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6078346Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6079090Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6079847Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6080610Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6081370Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6082125Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6082883Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6083651Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6084727Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6085426Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6086051Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6086679Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6087307Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6087927Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6088561Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6097066Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6097741Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6098423Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6099104Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6099773Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6100454Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6101132Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6101813Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6102459Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype0] [32mPASSED[0m
2026-01-14T08:43:18.6103065Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype1] [32mPASSED[0m
2026-01-14T08:43:18.6103677Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype2] [32mPASSED[0m
2026-01-14T08:43:18.6104288Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype3] [32mPASSED[0m
2026-01-14T08:43:18.6104895Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype4] [32mPASSED[0m
2026-01-14T08:43:18.6105499Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype5] [32mPASSED[0m
2026-01-14T08:43:18.6106117Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype6] [32mPASSED[0m
2026-01-14T08:43:18.6106723Z test/dtypes/test_uintx.py::test_uintx_api_deprecation [32mPASSED[0m
2026-01-14T08:43:18.6107773Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims0-valid.layer-filter_fqns0-True] [32mPASSED[0m
2026-01-14T08:43:18.6108929Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims1-skip_layer.linear-filter_fqns1-False] [32mPASSED[0m
2026-01-14T08:43:18.6110071Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims2-valid.layer-filter_fqns2-False] [32mPASSED[0m
2026-01-14T08:43:18.6111285Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims3-valid.layer-filter_fqns3-True] [32mPASSED[0m
2026-01-14T08:43:18.6112412Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims4-skip_layer.linear-filter_fqns4-False] [32mPASSED[0m
2026-01-14T08:43:18.6113505Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims5-valid.layer-filter_fqns5-False] [32mPASSED[0m
2026-01-14T08:43:18.6114399Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_rowwise [32mPASSED[0m
2026-01-14T08:43:18.6115208Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_tensorwise [32mPASSED[0m
2026-01-14T08:43:18.6115889Z test/float8/test_auto_filter.py::test_partial_fqn_matching [32mPASSED[0m
2026-01-14T08:43:18.8603336Z test/float8/test_base.py::TestFloat8TrainingTensor::test_preserves_dtype [32mPASSED[0m
2026-01-14T08:43:18.8604201Z test/float8/test_base.py::TestFloat8TrainingTensor::test_differentiable_casts [32mPASSED[0m
2026-01-14T08:43:18.8604995Z test/float8/test_base.py::TestFloat8TrainingTensor::test_split_cat [32mPASSED[0m
2026-01-14T08:43:18.8605714Z test/float8/test_base.py::TestFloat8TrainingTensor::test_index_put [32mPASSED[0m
2026-01-14T08:43:18.8606414Z test/float8/test_base.py::TestFloat8TrainingTensor::test_copy_ [32mPASSED[0m
2026-01-14T08:43:18.8607108Z test/float8/test_base.py::TestFloat8TrainingTensor::test_transpose [32mPASSED[0m
2026-01-14T08:43:18.8607948Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape0] [32mPASSED[0m
2026-01-14T08:43:18.8608905Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape1] [32mPASSED[0m
2026-01-14T08:43:18.8609856Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape2] [32mPASSED[0m
2026-01-14T08:43:18.8610815Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape0] [32mPASSED[0m
2026-01-14T08:43:18.8611769Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape1] [32mPASSED[0m
2026-01-14T08:43:18.8612722Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape2] [32mPASSED[0m
2026-01-14T08:43:18.8613671Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape0] [32mPASSED[0m
2026-01-14T08:43:18.8614626Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape1] [32mPASSED[0m
2026-01-14T08:43:18.8615590Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape2] [32mPASSED[0m
2026-01-14T08:43:18.8616544Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape0] [32mPASSED[0m
2026-01-14T08:43:18.8617514Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape1] [32mPASSED[0m
2026-01-14T08:43:18.8618479Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape2] [32mPASSED[0m
2026-01-14T08:43:18.8619349Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_reshape [32mPASSED[0m
2026-01-14T08:43:18.8620495Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:43:18.8621925Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:43:18.8624521Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:43:18.8625962Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:43:18.8627582Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:43:18.8629047Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:43:18.8630498Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:43:18.8631960Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:43:18.8633416Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:43:18.8634472Z test/float8/test_base.py::TestFloat8TrainingTensor::test_fp8_dtype [32mPASSED[0m
2026-01-14T08:43:18.8635873Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:43:18.8637678Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:43:18.8639463Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:43:18.8641258Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:43:18.8643105Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:43:18.8644894Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:43:18.8646681Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:43:18.8648458Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:43:18.8650232Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:43:18.8652020Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:43:18.8653793Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:43:18.8655565Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:43:18.8657444Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:43:18.8659226Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:43:18.8661073Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:43:18.8662856Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:43:18.8664633Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:43:18.8666428Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:43:18.8668204Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:43:18.8669976Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:43:18.8671750Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:43:18.8673573Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:43:18.8675394Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:43:18.8677171Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:43:18.8678688Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0265608Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0267329Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0269154Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0270517Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0271875Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0273232Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0274592Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0276234Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0277589Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0278920Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0280392Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0281734Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0283112Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0284761Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0286094Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0287407Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0288715Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0290025Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0291337Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0292701Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0294006Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0295321Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0296642Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0297935Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0299244Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0300536Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0301875Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0303506Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0304939Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0306244Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0307730Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0309031Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0310485Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0311832Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:19.0313448Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:19.0314851Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:43:19.0316122Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:43:19.0317313Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:43:19.0318502Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:43:19.0319644Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:43:19.0320794Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:43:19.0321992Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:43:19.0323289Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:43:19.0324536Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:43:19.0325429Z test/float8/test_base.py::TestFloat8Linear::test_repr [32mPASSED[0m
2026-01-14T08:43:19.0326071Z test/float8/test_base.py::TestFloat8Linear::test_inference_mode [33mSKIPPED[0m
2026-01-14T08:43:19.0326741Z test/float8/test_base.py::TestFloat8Linear::test_quantize [33mSKIPPED[0m (C...)
2026-01-14T08:43:19.0327514Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:43:19.0328351Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:43:19.0329187Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:43:19.0330029Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:43:19.0330865Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:43:19.0331703Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:43:19.0332494Z test/float8/test_base.py::TestScaledMM::test_different_configs_error [33mSKIPPED[0m
2026-01-14T08:43:19.0333235Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:43:19.0334014Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:43:19.0334776Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:43:19.0335553Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:43:19.0336449Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:43:19.0337215Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:43:19.0337990Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype0] [32mPASSED[0m
2026-01-14T08:43:26.8370848Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype1] [32mPASSED[0m
2026-01-14T08:43:26.8372008Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype2] [32mPASSED[0m
2026-01-14T08:43:26.8372916Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype3] [32mPASSED[0m
2026-01-14T08:43:26.8373965Z test/float8/test_base.py::TestFloat8LinearUtils::test_fp8_tensor_statistics [32mPASSED[0m
2026-01-14T08:43:26.8374868Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_linears_with_filters [32mPASSED[0m
2026-01-14T08:43:26.8375970Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear [32mPASSED[0m
2026-01-14T08:43:26.8376824Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear_with_children_raises [32mPASSED[0m
2026-01-14T08:43:26.8377664Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears [32mPASSED[0m
2026-01-14T08:43:26.8378497Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears_with_skip [32mPASSED[0m
2026-01-14T08:43:26.8379618Z test/float8/test_compile.py::test_eager_only[dtype0-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [32mPASSED[0m
2026-01-14T08:43:26.8380968Z test/float8/test_compile.py::test_eager_only[dtype1-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [32mPASSED[0m
2026-01-14T08:43:26.8382307Z test/float8/test_compile.py::test_aot_eager[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [32mPASSED[0m
2026-01-14T08:43:26.8383612Z test/float8/test_compile.py::test_aot_eager[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [32mPASSED[0m
2026-01-14T08:43:26.8385637Z test/float8/test_compile.py::test_inductor_from_config_params[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:43:26.8387145Z test/float8/test_compile.py::test_inductor_from_config_params[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:43:26.8388332Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:26.8389301Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:26.8390166Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_input [33mSKIPPED[0m
2026-01-14T08:43:26.8390910Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_output [33mSKIPPED[0m
2026-01-14T08:43:26.8391746Z test/float8/test_compile.py::TestGraphBreaks::test_float8_with_graph_break_in_the_middle [33mSKIPPED[0m
2026-01-14T08:43:26.8392571Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype0] [33mSKIPPED[0m
2026-01-14T08:43:26.8393350Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype1] [33mSKIPPED[0m
2026-01-14T08:43:26.8394117Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype2] [33mSKIPPED[0m
2026-01-14T08:43:26.8394993Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype0] [33mSKIPPED[0m
2026-01-14T08:43:26.8395771Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype1] [33mSKIPPED[0m
2026-01-14T08:43:26.8396548Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype2] [33mSKIPPED[0m
2026-01-14T08:43:26.8397389Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case0] [32mPASSED[0m
2026-01-14T08:43:26.8398516Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case1] [32mPASSED[0m
2026-01-14T08:43:26.8399402Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case2] [32mPASSED[0m
2026-01-14T08:43:26.8400280Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case3] [32mPASSED[0m
2026-01-14T08:43:26.8401293Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case4] [32mPASSED[0m
2026-01-14T08:43:26.8402178Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case5] [32mPASSED[0m
2026-01-14T08:43:26.8403047Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case6] [32mPASSED[0m
2026-01-14T08:43:26.8403928Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case7] [32mPASSED[0m
2026-01-14T08:43:26.8404730Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype0] [32mPASSED[0m
2026-01-14T08:43:26.8405444Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype1] [32mPASSED[0m
2026-01-14T08:43:26.8406155Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype2] [32mPASSED[0m
2026-01-14T08:43:26.8406862Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype3] [32mPASSED[0m
2026-01-14T08:43:26.8407584Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype4] [32mPASSED[0m
2026-01-14T08:43:26.8408284Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype5] [32mPASSED[0m
2026-01-14T08:43:26.8409001Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype6] [32mPASSED[0m
2026-01-14T08:43:26.8409709Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype7] [32mPASSED[0m
2026-01-14T08:43:26.8410985Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_config_params[ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC] [33mSKIPPED[0m
2026-01-14T08:43:26.8412546Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:43:26.8413975Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:43:26.8414989Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_2bit [32mPASSED[0m
2026-01-14T08:43:26.8415598Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_3bit [32mPASSED[0m
2026-01-14T08:43:26.8416194Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_4bit [32mPASSED[0m
2026-01-14T08:43:26.8416798Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_5bit [32mPASSED[0m
2026-01-14T08:43:26.8417395Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_6bit [32mPASSED[0m
2026-01-14T08:43:26.8418004Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_7bit [32mPASSED[0m
2026-01-14T08:43:26.8418605Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_8bit [32mPASSED[0m
2026-01-14T08:43:26.8419274Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm Autotune Choices Stats:
2026-01-14T08:43:26.8420714Z {"num_choices": 5, "num_triton_choices": 4, "best_kernel": "triton_mm_36", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:43:26.8421901Z AUTOTUNE int_mm(32x32, 32x16)
2026-01-14T08:43:26.8422172Z strides: [32, 1], [16, 1]
2026-01-14T08:43:26.8422441Z dtypes: torch.int8, torch.int8
2026-01-14T08:43:26.8423157Z   triton_mm_36 0.0256 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:43:26.8424427Z   triton_mm_38 0.0256 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2
2026-01-14T08:43:26.8425597Z   triton_mm_37 0.0266 ms 96.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=2
2026-01-14T08:43:26.8426874Z   triton_mm_39 0.0266 ms 96.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:43:26.8427608Z   _int_mm 0.0369 ms 69.4% 
2026-01-14T08:43:26.8428108Z SingleProcess AUTOTUNE benchmarking takes 0.0695 seconds and 0.1292 seconds precompiling for 5 choices
2026-01-14T08:43:26.8428695Z [32mPASSED[0m
2026-01-14T08:43:26.8429305Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm_eager_and_torch_compile_numerics Autotune Choices Stats:
2026-01-14T08:43:26.8430871Z {"num_choices": 12, "num_triton_choices": 11, "best_kernel": "triton_mm_49", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.07577600330114365, "best_triton_pos": 0}
2026-01-14T08:43:26.8432053Z AUTOTUNE int_mm(17x1536, 1536x1536)
2026-01-14T08:43:26.8432333Z strides: [s15, 1], [s21, 1]
2026-01-14T08:43:26.8432599Z dtypes: torch.int8, torch.int8
2026-01-14T08:43:26.8433334Z   triton_mm_49 0.0758 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:26.8434513Z   triton_mm_52 0.0809 ms 93.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:26.8435786Z   triton_mm_48 0.0952 ms 79.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:26.8436962Z   triton_mm_50 0.0952 ms 79.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:46.4532282Z   triton_mm_44 0.1014 ms 74.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:46.4533948Z   triton_mm_46 0.1014 ms 74.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:46.4534890Z   _int_mm 0.1219 ms 62.2% 
2026-01-14T08:43:46.4535759Z   triton_mm_54 0.1434 ms 52.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:46.4537252Z   triton_mm_47 0.1618 ms 46.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:46.4538707Z   triton_mm_51 0.1618 ms 46.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:43:46.4539932Z SingleProcess AUTOTUNE benchmarking takes 0.2638 seconds and 0.8075 seconds precompiling for 12 choices
2026-01-14T08:43:46.4540618Z Autotune Choices Stats:
2026-01-14T08:43:46.4542047Z {"num_choices": 12, "num_triton_choices": 11, "best_kernel": "triton_mm_60", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.2088959962129593, "best_triton_pos": 0}
2026-01-14T08:43:46.4543523Z AUTOTUNE int_mm(136x4096, 4096x1536)
2026-01-14T08:43:46.4544227Z strides: [s15, 1], [s21, 1]
2026-01-14T08:43:46.4544552Z dtypes: torch.int8, torch.int8
2026-01-14T08:43:46.4545429Z   triton_mm_60 0.2089 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:46.4546910Z   triton_mm_63 0.2304 ms 90.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:43:46.4548550Z   triton_mm_55 0.2642 ms 79.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:46.4550008Z   triton_mm_59 0.2908 ms 71.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:46.4551473Z   triton_mm_57 0.3052 ms 68.5% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:46.4552399Z   _int_mm 0.3144 ms 66.4% 
2026-01-14T08:43:46.4553259Z   triton_mm_61 0.3492 ms 59.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:43:46.4554724Z   triton_mm_58 0.4393 ms 47.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:43:46.4556319Z   triton_mm_56 0.4516 ms 46.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:46.4557802Z   triton_mm_62 0.4966 ms 42.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:43:46.4559056Z SingleProcess AUTOTUNE benchmarking takes 0.4090 seconds and 1.4533 seconds precompiling for 12 choices
2026-01-14T08:43:46.4559980Z [32mPASSED[0m
2026-01-14T08:43:46.4560857Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cpu [32mPASSED[0m
2026-01-14T08:43:46.4562252Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cuda [33mSKIPPED[0m
2026-01-14T08:43:46.4563538Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cpu [32mPASSED[0m
2026-01-14T08:43:46.4564722Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cuda [32mPASSED[0m
2026-01-14T08:43:46.4565914Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cpu [32mPASSED[0m
2026-01-14T08:43:46.4567118Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cuda [32mPASSED[0m
2026-01-14T08:43:46.4568436Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:43:46.4569806Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:43:46.4571197Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:43:46.4572583Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:43:46.4573898Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:43:46.4575227Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:43:46.4576592Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:43:46.4578109Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:43:46.4579511Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:43:46.4580881Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:43:46.4582321Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:43:46.4583683Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:43:46.4585234Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:43:46.4586480Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:43:46.4587711Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:43:46.4588923Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:43:46.4590117Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:43:46.4591307Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:43:46.4592483Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_0_cpu [32mPASSED[0m
2026-01-14T08:43:46.4593636Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_1_cpu [32mPASSED[0m
2026-01-14T08:43:46.4594793Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_2_cpu [32mPASSED[0m
2026-01-14T08:43:46.4595941Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_3 Autotune Choices Stats:
2026-01-14T08:43:46.4597761Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_66", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:43:46.4599222Z AUTOTUNE int_mm(32x64, 64x32)
2026-01-14T08:43:46.4599543Z strides: [64, 1], [1, 64]
2026-01-14T08:43:46.4599849Z dtypes: torch.int8, torch.int8
2026-01-14T08:43:46.4600733Z   triton_mm_66 0.0256 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:43:46.4602195Z   triton_mm_68 0.0256 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:43:46.4603671Z   triton_mm_69 0.0256 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:43:46.4605128Z   triton_mm_67 0.0257 ms 99.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:46.4606488Z   triton_mm_70 0.0266 ms 96.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:43:46.4607214Z   _int_mm 0.0399 ms 64.1% 
2026-01-14T08:43:46.4607705Z SingleProcess AUTOTUNE benchmarking takes 0.0775 seconds and 0.1715 seconds precompiling for 6 choices
2026-01-14T08:43:46.4608276Z [32mPASSED[0m
2026-01-14T08:43:46.4608838Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_4 [32mPASSED[0m
2026-01-14T08:44:05.3585561Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_5 [32mPASSED[0m
2026-01-14T08:44:05.3586565Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_0_cpu [32mPASSED[0m
2026-01-14T08:44:05.3587541Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_1_cpu [32mPASSED[0m
2026-01-14T08:44:05.3588916Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_2_cpu [32mPASSED[0m
2026-01-14T08:44:05.3589870Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_3 [32mPASSED[0m
2026-01-14T08:44:05.3590799Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_4 [32mPASSED[0m
2026-01-14T08:44:05.3591719Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_5 [32mPASSED[0m
2026-01-14T08:44:05.3592616Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_0_cpu Autotune Choices Stats:
2026-01-14T08:44:05.3593430Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.03261100005147455}
2026-01-14T08:44:05.3593922Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:44:05.3594205Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:44:05.3594526Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:44:05.3594872Z   addmm 0.0326 ms 100.0% 
2026-01-14T08:44:05.3595295Z   bias_addmm 0.0739 ms 44.2% 
2026-01-14T08:44:05.3596026Z SingleProcess AUTOTUNE benchmarking takes 0.2437 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:44:05.3596850Z [32mPASSED[0m
2026-01-14T08:44:05.3597634Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_1_cpu Autotune Choices Stats:
2026-01-14T08:44:05.3598844Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.0737420000405109}
2026-01-14T08:44:05.3599534Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:44:05.3599917Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:44:05.3600350Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:44:05.3600732Z   addmm 0.0737 ms 100.0% 
2026-01-14T08:44:05.3600981Z   bias_addmm 0.0993 ms 74.2% 
2026-01-14T08:44:05.3601493Z SingleProcess AUTOTUNE benchmarking takes 0.2436 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:44:05.3611038Z [32mPASSED[0m
2026-01-14T08:44:05.3611658Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_2_cpu Autotune Choices Stats:
2026-01-14T08:44:05.3612482Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.0688309999077319}
2026-01-14T08:44:05.3612975Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:44:05.3613266Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:44:05.3613605Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:05.3613963Z   addmm 0.0688 ms 100.0% 
2026-01-14T08:44:05.3614212Z   bias_addmm 0.0945 ms 72.9% 
2026-01-14T08:44:05.3614724Z SingleProcess AUTOTUNE benchmarking takes 0.2436 seconds and 0.0014 seconds precompiling for 2 choices
2026-01-14T08:44:05.3615304Z [32mPASSED[0m
2026-01-14T08:44:05.3615834Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_3 Autotune Choices Stats:
2026-01-14T08:44:05.3617330Z {"num_choices": 12, "num_triton_choices": 10, "best_kernel": "triton_mm_87", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:44:05.3618598Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:44:05.3618880Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:44:05.3619207Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:44:05.3620223Z   triton_mm_87 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:05.3621406Z   triton_mm_81 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:05.3622667Z   triton_mm_82 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:05.3623836Z   triton_mm_83 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:05.3625009Z   triton_mm_84 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:05.3626191Z   triton_mm_85 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:05.3627362Z   triton_mm_86 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:05.3628539Z   triton_mm_88 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:05.3629719Z   triton_mm_89 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:05.3630891Z   triton_mm_90 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:05.3631884Z SingleProcess AUTOTUNE benchmarking takes 0.1695 seconds and 0.2334 seconds precompiling for 12 choices
2026-01-14T08:44:05.3632464Z [32mPASSED[0m
2026-01-14T08:44:05.3632992Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_4 Autotune Choices Stats:
2026-01-14T08:44:05.3634487Z {"num_choices": 12, "num_triton_choices": 10, "best_kernel": "triton_mm_95", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.027615999802947044, "best_triton_pos": 0}
2026-01-14T08:44:05.3636128Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:44:05.3636526Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:44:05.3636955Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:44:05.3637909Z   triton_mm_95 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:05.3639112Z   triton_mm_96 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:05.3640285Z   triton_mm_94 0.0276 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:05.3641473Z   triton_mm_98 0.0276 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:05.3642647Z   triton_mm_99 0.0276 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:05.3643798Z   triton_mm_91 0.0287 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:05.3645059Z   triton_mm_92 0.0287 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:05.3646235Z   triton_mm_93 0.0287 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:05.3647478Z   triton_mm_97 0.0287 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:05.3648658Z   triton_mm_100 0.0287 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:05.3649649Z SingleProcess AUTOTUNE benchmarking takes 0.1593 seconds and 0.2030 seconds precompiling for 12 choices
2026-01-14T08:44:05.3650232Z [32mPASSED[0m
2026-01-14T08:44:05.3650773Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_5 Autotune Choices Stats:
2026-01-14T08:44:05.3652265Z {"num_choices": 12, "num_triton_choices": 10, "best_kernel": "triton_mm_106", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.026655999943614006, "best_triton_pos": 0}
2026-01-14T08:44:05.3653451Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:44:05.3653734Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:44:05.3654067Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:05.3654878Z   triton_mm_106 0.0267 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:05.3656067Z   triton_mm_105 0.0276 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:14.4662761Z   triton_mm_109 0.0277 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:14.4664863Z   triton_mm_101 0.0287 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:14.4666941Z   triton_mm_102 0.0287 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:14.4668927Z   triton_mm_103 0.0287 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:14.4670962Z   triton_mm_107 0.0287 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:14.4673015Z   triton_mm_108 0.0287 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:14.4675215Z   triton_mm_110 0.0287 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:14.4677287Z   triton_mm_104 0.0287 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:14.4678886Z SingleProcess AUTOTUNE benchmarking takes 0.1598 seconds and 0.1985 seconds precompiling for 12 choices
2026-01-14T08:44:14.4680623Z [32mPASSED[0m
2026-01-14T08:44:14.4681663Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4683291Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4685318Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4687247Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:44:14.4688777Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:44:14.4690383Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:44:14.4691941Z test/integration/test_integration.py::TestSubclass::test_autoquantizable_flatten_unflatten [32mPASSED[0m
2026-01-14T08:44:14.4693417Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_0_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4694845Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_1_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4696249Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_2_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4697648Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_3 [33mSKIPPED[0m
2026-01-14T08:44:14.4699050Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_4 [33mSKIPPED[0m
2026-01-14T08:44:14.4700407Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_5 [33mSKIPPED[0m
2026-01-14T08:44:14.4702025Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4703789Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4705474Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_2_cpu Autotune Choices Stats:
2026-01-14T08:44:14.4706918Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.029889999950682977}
2026-01-14T08:44:14.4707769Z AUTOTUNE addmm(16x16, 16x16, 16x16)
2026-01-14T08:44:14.4708248Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:44:14.4708808Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:14.4709401Z   addmm 0.0299 ms 100.0% 
2026-01-14T08:44:14.4709811Z   bias_addmm 0.0693 ms 43.1% 
2026-01-14T08:44:14.4710742Z SingleProcess AUTOTUNE benchmarking takes 0.2441 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:44:14.4711738Z [32mPASSED[0m
2026-01-14T08:44:14.4712710Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:44:14.4714345Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:44:14.4715965Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_5 Autotune Choices Stats:
2026-01-14T08:44:14.4718422Z {"num_choices": 7, "num_triton_choices": 5, "best_kernel": "triton_mm_113", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1", "best_time": 0.027648000046610832, "best_triton_pos": 0}
2026-01-14T08:44:14.4720408Z AUTOTUNE addmm(16x16, 16x16, 16x16)
2026-01-14T08:44:14.4720917Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:44:14.4721492Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:14.4722803Z   triton_mm_113 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:44:14.4724837Z   triton_mm_115 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:44:14.4727135Z   triton_mm_111 0.0287 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:44:14.4729157Z   triton_mm_112 0.0287 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:44:14.4731324Z   triton_mm_114 0.0287 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:44:14.4732642Z   addmm 0.0522 ms 52.9% 
2026-01-14T08:44:14.4733039Z   bias_addmm 0.0727 ms 38.0% 
2026-01-14T08:44:14.4733915Z SingleProcess AUTOTUNE benchmarking takes 0.0963 seconds and 0.1194 seconds precompiling for 7 choices
2026-01-14T08:44:14.4734969Z [32mPASSED[0m
2026-01-14T08:44:14.4736029Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4737781Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4739497Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:44:14.4741214Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:44:14.4742891Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:44:14.4744589Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_5 [32mPASSED[0m
2026-01-14T08:44:14.4746322Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_0_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4748214Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_1_cpu [33mSKIPPED[0m
2026-01-14T08:44:14.4749952Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_2_cpu Autotune Choices Stats:
2026-01-14T08:44:14.4751421Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.06469599998126796}
2026-01-14T08:44:14.4752283Z AUTOTUNE addmm(256x16, 256x16, 16x16)
2026-01-14T08:44:14.4752762Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:44:14.4753333Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:14.4753924Z   addmm 0.0647 ms 100.0% 
2026-01-14T08:44:14.4754334Z   bias_addmm 0.0906 ms 71.4% 
2026-01-14T08:44:14.4755273Z SingleProcess AUTOTUNE benchmarking takes 0.2439 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:44:14.4756289Z [32mPASSED[0m
2026-01-14T08:44:14.4757379Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_3 [33mSKIPPED[0m
2026-01-14T08:44:14.4759216Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_4 [33mSKIPPED[0m
2026-01-14T08:44:14.4760895Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_5 Autotune Choices Stats:
2026-01-14T08:44:14.4763605Z {"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_118", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:44:14.4765630Z AUTOTUNE addmm(256x16, 256x16, 16x16)
2026-01-14T08:44:14.4766093Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:44:14.4766621Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:14.4767999Z   triton_mm_118 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:44:14.4770328Z   triton_mm_120 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:29.3999332Z   triton_mm_121 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:29.4000917Z   triton_mm_122 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:29.4002126Z   triton_mm_126 0.0276 ms 96.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:29.4003343Z   triton_mm_124 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:29.4004560Z   triton_mm_125 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:44:29.4005748Z   triton_mm_116 0.0286 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:29.4006946Z   triton_mm_117 0.0287 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:44:29.4008128Z   triton_mm_119 0.0287 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:29.4009149Z SingleProcess AUTOTUNE benchmarking takes 0.1721 seconds and 0.1803 seconds precompiling for 13 choices
2026-01-14T08:44:29.4009714Z Autotune Choices Stats:
2026-01-14T08:44:29.4010872Z {"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_168", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:44:29.4012066Z AUTOTUNE addmm(256x8, 256x8, 8x8)
2026-01-14T08:44:29.4012356Z strides: [0, 1], [8, 1], [1, 8]
2026-01-14T08:44:29.4012686Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:44:29.4013519Z   triton_mm_168 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:44:29.4014752Z   triton_mm_167 0.0276 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:29.4015999Z   triton_mm_160 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:29.4017204Z   triton_mm_165 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:29.4018410Z   triton_mm_166 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:29.4019613Z   triton_mm_169 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:44:29.4020830Z   triton_mm_170 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:44:29.4022239Z   triton_mm_163 0.0286 ms 93.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:29.4023423Z   triton_mm_161 0.0287 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:44:29.4024702Z   triton_mm_162 0.0287 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:44:29.4025755Z SingleProcess AUTOTUNE benchmarking takes 0.1737 seconds and 0.1425 seconds precompiling for 13 choices
2026-01-14T08:44:29.4026524Z [32mPASSED[0m
2026-01-14T08:44:29.4027162Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_00_cpu [33mSKIPPED[0m
2026-01-14T08:44:29.4028131Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_01_cpu [33mSKIPPED[0m
2026-01-14T08:44:29.4029082Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_02_cpu [33mSKIPPED[0m
2026-01-14T08:44:29.4030011Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_03_cpu [33mSKIPPED[0m
2026-01-14T08:44:29.4030955Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_04_cpu [33mSKIPPED[0m
2026-01-14T08:44:29.4031887Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_05_cpu [33mSKIPPED[0m
2026-01-14T08:44:29.4032811Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_06 [33mSKIPPED[0m
2026-01-14T08:44:29.4033712Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_07 [33mSKIPPED[0m
2026-01-14T08:44:29.4034613Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_08 [33mSKIPPED[0m
2026-01-14T08:44:29.4035661Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_09 [33mSKIPPED[0m
2026-01-14T08:44:29.4036554Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_10 [33mSKIPPED[0m
2026-01-14T08:44:29.4037464Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_11 [33mSKIPPED[0m
2026-01-14T08:44:29.4038406Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_0_cpu [32mPASSED[0m
2026-01-14T08:44:29.4039366Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_1_cpu [32mPASSED[0m
2026-01-14T08:44:29.4040318Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:44:29.4041209Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_3 Autotune Choices Stats:
2026-01-14T08:44:29.4042723Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_204", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:44:29.4043899Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:44:29.4044152Z strides: [64, 1], [32, 1]
2026-01-14T08:44:29.4044436Z dtypes: torch.float32, torch.float32
2026-01-14T08:44:29.4045191Z   triton_mm_204 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:29.4046407Z   triton_mm_205 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:29.4047713Z   triton_mm_206 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:29.4048921Z   triton_mm_207 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:29.4050210Z   triton_mm_208 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:29.4051399Z   triton_mm_209 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:29.4052604Z   triton_mm_210 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:29.4053818Z   triton_mm_211 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:29.4055018Z   triton_mm_212 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:29.4056283Z   triton_mm_213 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:29.4057294Z SingleProcess AUTOTUNE benchmarking takes 0.1410 seconds and 0.2449 seconds precompiling for 11 choices
2026-01-14T08:44:29.4057841Z Autotune Choices Stats:
2026-01-14T08:44:56.3263866Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_214", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:44:56.3265461Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:44:56.3265786Z strides: [32, 1], [32, 1]
2026-01-14T08:44:56.3266124Z dtypes: torch.float32, torch.float32
2026-01-14T08:44:56.3267093Z   triton_mm_214 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:56.3268631Z   triton_mm_216 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:56.3270143Z   triton_mm_217 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:56.3271671Z   triton_mm_218 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:56.3273187Z   triton_mm_219 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:56.3274760Z   triton_mm_215 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:56.3275697Z   mm 0.0399 ms 66.7% 
2026-01-14T08:44:56.3276307Z SingleProcess AUTOTUNE benchmarking takes 0.0972 seconds and 0.0001 seconds precompiling for 7 choices
2026-01-14T08:44:56.3277229Z [32mPASSED[0m
2026-01-14T08:44:56.3277926Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_4 Autotune Choices Stats:
2026-01-14T08:44:56.3279794Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_222", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:44:56.3281534Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:44:56.3281846Z strides: [64, 1], [32, 1]
2026-01-14T08:44:56.3282161Z dtypes: torch.float16, torch.float16
2026-01-14T08:44:56.3283286Z   triton_mm_222 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:56.3284989Z   triton_mm_226 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:56.3286491Z   triton_mm_220 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:56.3287990Z   triton_mm_221 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:56.3289478Z   triton_mm_223 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:56.3290982Z   triton_mm_224 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:56.3292541Z   triton_mm_228 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:56.3293850Z   triton_mm_225 0.0287 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:56.3295057Z   triton_mm_229 0.0287 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:56.3296256Z   triton_mm_227 0.0297 ms 89.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:56.3297254Z SingleProcess AUTOTUNE benchmarking takes 0.1469 seconds and 0.1346 seconds precompiling for 11 choices
2026-01-14T08:44:56.3297811Z Autotune Choices Stats:
2026-01-14T08:44:56.3298942Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_230", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:44:56.3300131Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:44:56.3300375Z strides: [32, 1], [32, 1]
2026-01-14T08:44:56.3300633Z dtypes: torch.float16, torch.float16
2026-01-14T08:44:56.3301375Z   triton_mm_230 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:44:56.3302582Z   triton_mm_234 0.0276 ms 96.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:44:56.3303781Z   triton_mm_231 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:56.3304961Z   triton_mm_232 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:44:56.3306310Z   triton_mm_233 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:44:56.3307503Z   triton_mm_235 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:44:56.3308240Z   mm 0.0410 ms 65.0% 
2026-01-14T08:44:56.3308838Z SingleProcess AUTOTUNE benchmarking takes 0.0983 seconds and 0.0001 seconds precompiling for 7 choices
2026-01-14T08:44:56.3309447Z [32mPASSED[0m
2026-01-14T08:44:56.3310043Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_5 [32mPASSED[0m
2026-01-14T08:44:56.3310953Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_0_cpu Autotune Choices Stats:
2026-01-14T08:44:56.3311853Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_0", "best_time": 0.006279999979597051}
2026-01-14T08:44:56.3312472Z AUTOTUNE packed_linear(32x64, 1459233x1, 32x64)
2026-01-14T08:44:56.3312799Z strides: [64, 1], [1, 0], [64, 1]
2026-01-14T08:44:56.3313115Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:44:56.3313491Z   cpp_CppMicroGemmFP32Vec_0 0.0063 ms 100.0% 
2026-01-14T08:44:56.3313818Z   _mkl_linear 0.0277 ms 22.7% 
2026-01-14T08:44:56.3314374Z SingleProcess AUTOTUNE benchmarking takes 0.2527 seconds and 2.4439 seconds precompiling for 2 choices
2026-01-14T08:44:56.3314999Z Autotune Choices Stats:
2026-01-14T08:44:56.3315524Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_1", "best_time": 0.006250000069485395}
2026-01-14T08:44:56.3316135Z AUTOTUNE packed_linear(32x32, 1459233x1, 32x32)
2026-01-14T08:44:56.3316456Z strides: [32, 1], [1, 0], [32, 1]
2026-01-14T08:44:56.3316779Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:44:56.3317156Z   cpp_CppMicroGemmFP32Vec_1 0.0063 ms 100.0% 
2026-01-14T08:44:56.3317477Z   _mkl_linear 0.0273 ms 22.9% 
2026-01-14T08:44:56.3317975Z SingleProcess AUTOTUNE benchmarking takes 0.2517 seconds and 2.4302 seconds precompiling for 2 choices
2026-01-14T08:44:56.3318556Z [32mPASSED[0m
2026-01-14T08:44:56.3319100Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_1_cpu Autotune Choices Stats:
2026-01-14T08:44:56.3320005Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_2", "best_time": 0.006670000175290625}
2026-01-14T08:44:56.3320591Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:44:56.3320839Z strides: [64, 1], [1, 64]
2026-01-14T08:44:56.3321111Z dtypes: torch.float16, torch.float16
2026-01-14T08:44:56.3321438Z   cpp_CppMicroGemmFP32Vec_2 0.0067 ms 100.0% 
2026-01-14T08:44:56.3321746Z   mm 0.0319 ms 20.9% 
2026-01-14T08:44:56.3322239Z SingleProcess AUTOTUNE benchmarking takes 0.2470 seconds and 2.6425 seconds precompiling for 2 choices
2026-01-14T08:44:56.3322792Z Autotune Choices Stats:
2026-01-14T08:44:56.3323321Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_3", "best_time": 0.006649999932051287}
2026-01-14T08:44:56.3323894Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:44:56.3324148Z strides: [32, 1], [1, 32]
2026-01-14T08:44:56.3324442Z dtypes: torch.float16, torch.float16
2026-01-14T08:44:56.3324793Z   cpp_CppMicroGemmFP32Vec_3 0.0066 ms 100.0% 
2026-01-14T08:44:56.3325101Z   mm 0.0321 ms 20.7% 
2026-01-14T08:44:56.3325587Z SingleProcess AUTOTUNE benchmarking takes 0.2467 seconds and 2.6470 seconds precompiling for 2 choices
2026-01-14T08:44:56.3326167Z [32mPASSED[0m
2026-01-14T08:44:56.3326704Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_2_cpu Autotune Choices Stats:
2026-01-14T08:44:56.3327604Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_4", "best_time": 0.007030000006125192}
2026-01-14T08:44:56.3328220Z AUTOTUNE _weight_int8pack_mm(32x64, 32x64, 32)
2026-01-14T08:44:56.3328645Z strides: [64, 1], [64, 1], [1]
2026-01-14T08:44:56.3328954Z dtypes: torch.bfloat16, torch.int8, torch.bfloat16
2026-01-14T08:45:05.1308266Z   cpp_CppMicroGemmFP32Vec_4 0.0070 ms 100.0% 
2026-01-14T08:45:05.1308724Z   _weight_int8pack_mm 0.0179 ms 39.3% 
2026-01-14T08:45:05.1309292Z SingleProcess AUTOTUNE benchmarking takes 0.2525 seconds and 2.6016 seconds precompiling for 2 choices
2026-01-14T08:45:05.1309860Z Autotune Choices Stats:
2026-01-14T08:45:05.1310766Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_5", "best_time": 0.007100999937392771}
2026-01-14T08:45:05.1311397Z AUTOTUNE _weight_int8pack_mm(32x32, 32x32, 32)
2026-01-14T08:45:05.1311716Z strides: [32, 1], [32, 1], [1]
2026-01-14T08:45:05.1312034Z dtypes: torch.bfloat16, torch.int8, torch.bfloat16
2026-01-14T08:45:05.1312408Z   cpp_CppMicroGemmFP32Vec_5 0.0071 ms 100.0% 
2026-01-14T08:45:05.1312743Z   _weight_int8pack_mm 0.0178 ms 39.8% 
2026-01-14T08:45:05.1313297Z SingleProcess AUTOTUNE benchmarking takes 0.2529 seconds and 2.5969 seconds precompiling for 2 choices
2026-01-14T08:45:05.1314061Z [32mPASSED[0m
2026-01-14T08:45:05.1314724Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_3 Autotune Choices Stats:
2026-01-14T08:45:05.1316309Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_238", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:45:05.1317524Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:45:05.1317783Z strides: [64, 1], [1, 64]
2026-01-14T08:45:05.1318046Z dtypes: torch.float32, torch.float32
2026-01-14T08:45:05.1318808Z   triton_mm_238 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:05.1320030Z   triton_mm_242 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:05.1321249Z   triton_mm_239 0.0266 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:05.1322466Z   triton_mm_236 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:05.1323671Z   triton_mm_245 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:05.1324864Z   triton_mm_240 0.0276 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:05.1326065Z   triton_mm_237 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:05.1327252Z   triton_mm_241 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:05.1328466Z   triton_mm_243 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:05.1329673Z   triton_mm_244 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:05.1330678Z SingleProcess AUTOTUNE benchmarking takes 0.1401 seconds and 0.3966 seconds precompiling for 11 choices
2026-01-14T08:45:05.1331410Z Autotune Choices Stats:
2026-01-14T08:45:05.1332548Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_247", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.027648000046610832, "best_triton_pos": 0}
2026-01-14T08:45:05.1333739Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:45:05.1333999Z strides: [32, 1], [1, 32]
2026-01-14T08:45:05.1334266Z dtypes: torch.float32, torch.float32
2026-01-14T08:45:05.1335097Z   triton_mm_247 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:05.1336318Z   triton_mm_248 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:05.1337533Z   triton_mm_249 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:05.1338753Z   triton_mm_250 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:05.1339958Z   triton_mm_251 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:05.1341156Z   triton_mm_246 0.0277 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:05.1341910Z   mm 0.0399 ms 69.2% 
2026-01-14T08:45:05.1342386Z SingleProcess AUTOTUNE benchmarking takes 0.0944 seconds and 0.0001 seconds precompiling for 7 choices
2026-01-14T08:45:05.1342979Z [32mPASSED[0m
2026-01-14T08:45:05.1343527Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_4 Autotune Choices Stats:
2026-01-14T08:45:05.1345018Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_260", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:05.1346210Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:45:05.1346465Z strides: [64, 1], [1, 64]
2026-01-14T08:45:05.1346738Z dtypes: torch.float16, torch.float16
2026-01-14T08:45:05.1347486Z   triton_mm_260 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:05.1348683Z   triton_mm_255 0.0276 ms 96.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:05.1349874Z   triton_mm_252 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:05.1351050Z   triton_mm_253 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:05.1352265Z   triton_mm_254 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:05.1353461Z   triton_mm_256 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:05.1354720Z   triton_mm_257 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:05.1356004Z   triton_mm_258 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:05.1357200Z   triton_mm_259 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:05.1358464Z   triton_mm_261 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:05.1359469Z SingleProcess AUTOTUNE benchmarking takes 0.7226 seconds and 0.1032 seconds precompiling for 11 choices
2026-01-14T08:45:05.1360026Z Autotune Choices Stats:
2026-01-14T08:45:05.1361148Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_262", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.027648000046610832, "best_triton_pos": 0}
2026-01-14T08:45:05.1362340Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:45:05.1362591Z strides: [32, 1], [1, 32]
2026-01-14T08:45:05.1362863Z dtypes: torch.float16, torch.float16
2026-01-14T08:45:05.1363629Z   triton_mm_262 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:05.1364854Z   triton_mm_263 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:05.1366057Z   triton_mm_264 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:13.6735519Z   triton_mm_265 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:13.6736818Z   triton_mm_266 0.0287 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:13.6738057Z   triton_mm_267 0.0287 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:13.6738793Z   mm 0.0420 ms 65.9% 
2026-01-14T08:45:13.6739285Z SingleProcess AUTOTUNE benchmarking takes 0.0906 seconds and 0.0001 seconds precompiling for 7 choices
2026-01-14T08:45:13.6740063Z [32mPASSED[0m
2026-01-14T08:45:13.6748577Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_5 [32mPASSED[0m
2026-01-14T08:45:13.6749529Z test/integration/test_integration.py::TestDynamicQuant::test_dynamic_quant [32mPASSED[0m
2026-01-14T08:45:13.6750483Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_embedding_quant [32mPASSED[0m
2026-01-14T08:45:13.6751506Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_quant [32mPASSED[0m
2026-01-14T08:45:13.6752446Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant [32mPASSED[0m
2026-01-14T08:45:13.6753438Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:45:13.6754515Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:45:13.6755648Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:45:13.6756616Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_3 Autotune Choices Stats:
2026-01-14T08:45:13.6759684Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_269", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:13.6760878Z AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:45:13.6761108Z strides: [4, 1], [5, 1]
2026-01-14T08:45:13.6761532Z dtypes: torch.float32, torch.float32
2026-01-14T08:45:13.6762281Z   triton_mm_269 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:45:13.6763510Z   triton_mm_270 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:45:13.6764740Z   triton_mm_271 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:45:13.6765949Z   triton_mm_268 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:45:13.6767165Z   triton_mm_272 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:45:13.6767911Z   mm 0.0410 ms 65.0% 
2026-01-14T08:45:13.6768387Z SingleProcess AUTOTUNE benchmarking takes 0.0803 seconds and 0.1589 seconds precompiling for 6 choices
2026-01-14T08:45:13.6768941Z Autotune Choices Stats:
2026-01-14T08:45:13.6770131Z {"num_choices": 12, "num_triton_choices": 11, "best_kernel": "triton_mm_282", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8", "best_time": 0.02566399984061718, "best_triton_pos": 0}
2026-01-14T08:45:13.6771319Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:45:13.6771560Z strides: [4, 1], [5, 1]
2026-01-14T08:45:13.6771811Z dtypes: torch.float32, torch.float32
2026-01-14T08:45:13.6772579Z   triton_mm_282 0.0257 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:45:13.6773780Z   triton_mm_274 0.0266 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:45:13.6774986Z   triton_mm_275 0.0266 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:45:13.6776179Z   triton_mm_276 0.0266 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:13.6777360Z   triton_mm_278 0.0266 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:13.6778551Z   triton_mm_273 0.0276 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:13.6779736Z   triton_mm_277 0.0276 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:13.6780929Z   triton_mm_279 0.0276 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:13.6782228Z   triton_mm_280 0.0276 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:13.6783441Z   triton_mm_281 0.0276 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:45:13.6784699Z SingleProcess AUTOTUNE benchmarking takes 0.1550 seconds and 0.2707 seconds precompiling for 12 choices
2026-01-14T08:45:13.6785374Z Autotune Choices Stats:
2026-01-14T08:45:13.6786503Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_285", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:13.6787682Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:45:13.6787919Z strides: [4, 1], [5, 1]
2026-01-14T08:45:13.6788169Z dtypes: torch.float32, torch.float32
2026-01-14T08:45:13.6788922Z   triton_mm_285 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:45:13.6790126Z   triton_mm_284 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:45:13.6791329Z   triton_mm_286 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:45:13.6792525Z   triton_mm_287 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:45:13.6793716Z   triton_mm_288 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:45:13.6794461Z   mm 0.0399 ms 66.7% 
2026-01-14T08:45:13.6794983Z SingleProcess AUTOTUNE benchmarking takes 0.0781 seconds and 0.1800 seconds precompiling for 6 choices
2026-01-14T08:45:13.6795568Z [32mPASSED[0m
2026-01-14T08:45:13.6796142Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_4 Autotune Choices Stats:
2026-01-14T08:45:13.6797689Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_289", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1", "best_time": 0.027648000046610832, "best_triton_pos": 0}
2026-01-14T08:45:13.6798873Z AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:45:13.6799111Z strides: [4, 1], [5, 1]
2026-01-14T08:45:13.6799360Z dtypes: torch.float16, torch.float16
2026-01-14T08:45:13.6800130Z   triton_mm_289 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:45:13.6801339Z   triton_mm_290 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:45:13.6802558Z   triton_mm_291 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:45:27.0614208Z   triton_mm_292 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:45:27.0615648Z   triton_mm_293 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:45:27.0616776Z   mm 0.0461 ms 60.0% 
2026-01-14T08:45:27.0617266Z SingleProcess AUTOTUNE benchmarking takes 0.0792 seconds and 0.1730 seconds precompiling for 6 choices
2026-01-14T08:45:27.0617826Z Autotune Choices Stats:
2026-01-14T08:45:27.0619150Z {"num_choices": 12, "num_triton_choices": 11, "best_kernel": "triton_mm_302", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:27.0620377Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:45:27.0620617Z strides: [4, 1], [5, 1]
2026-01-14T08:45:27.0620872Z dtypes: torch.float16, torch.float16
2026-01-14T08:45:27.0621650Z   triton_mm_302 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:45:27.0622883Z   triton_mm_303 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:45:27.0624218Z   triton_mm_294 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:27.0625433Z   triton_mm_295 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:45:27.0626621Z   triton_mm_296 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:45:27.0627817Z   triton_mm_297 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:27.0629031Z   triton_mm_298 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:27.0630231Z   triton_mm_299 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:27.0631450Z   triton_mm_300 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:27.0632668Z   triton_mm_301 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:27.0633696Z SingleProcess AUTOTUNE benchmarking takes 0.1559 seconds and 0.1956 seconds precompiling for 12 choices
2026-01-14T08:45:27.0634283Z Autotune Choices Stats:
2026-01-14T08:45:27.0635504Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_309", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:27.0636683Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:45:27.0636926Z strides: [4, 1], [5, 1]
2026-01-14T08:45:27.0637182Z dtypes: torch.float16, torch.float16
2026-01-14T08:45:27.0637959Z   triton_mm_309 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:45:27.0639180Z   triton_mm_305 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:45:27.0640384Z   triton_mm_306 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:45:27.0641685Z   triton_mm_307 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:45:27.0642884Z   triton_mm_308 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:45:27.0643700Z   mm 0.0461 ms 57.8% 
2026-01-14T08:45:27.0644187Z SingleProcess AUTOTUNE benchmarking takes 0.0812 seconds and 0.1543 seconds precompiling for 6 choices
2026-01-14T08:45:27.0644955Z [32mPASSED[0m
2026-01-14T08:45:27.0645623Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_5 [32mPASSED[0m
2026-01-14T08:45:27.0646679Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:45:27.0647751Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:45:27.0648800Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:45:27.0649817Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_3 [32mPASSED[0m
2026-01-14T08:45:27.0650832Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_4 [32mPASSED[0m
2026-01-14T08:45:27.0651826Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_5 [32mPASSED[0m
2026-01-14T08:45:27.0652772Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:45:27.0653659Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:45:27.0654540Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_2_cpu [33mSKIPPED[0m
2026-01-14T08:45:27.0655347Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_3 Autotune Choices Stats:
2026-01-14T08:45:27.0656810Z {"num_choices": 5, "num_triton_choices": 4, "best_kernel": "triton_mm_357", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:27.0657988Z AUTOTUNE int_mm(32x32, 32x32)
2026-01-14T08:45:27.0658265Z strides: [32, 1], [1, 32]
2026-01-14T08:45:27.0658525Z dtypes: torch.int8, torch.int8
2026-01-14T08:45:27.0659255Z   triton_mm_357 0.0266 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:27.0660451Z   triton_mm_358 0.0267 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:27.0661620Z   triton_mm_359 0.0276 ms 96.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:27.0662804Z   triton_mm_360 0.0276 ms 96.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:27.0663535Z   _int_mm 0.0399 ms 66.7% 
2026-01-14T08:45:27.0664084Z SingleProcess AUTOTUNE benchmarking takes 0.0659 seconds and 0.1162 seconds precompiling for 5 choices
2026-01-14T08:45:27.0664648Z Autotune Choices Stats:
2026-01-14T08:45:27.0665774Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_355", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:27.0668163Z AUTOTUNE int_mm(32x64, 64x32)
2026-01-14T08:45:27.0668425Z strides: [64, 1], [1, 64]
2026-01-14T08:45:27.0668694Z dtypes: torch.int8, torch.int8
2026-01-14T08:45:27.0669418Z   triton_mm_355 0.0266 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:27.0670686Z   triton_mm_352 0.0276 ms 96.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:27.0671874Z   triton_mm_353 0.0276 ms 96.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:27.0673057Z   triton_mm_354 0.0276 ms 96.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:27.0674231Z   triton_mm_356 0.0276 ms 96.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:27.0675027Z   _int_mm 0.0399 ms 66.7% 
2026-01-14T08:45:45.1257667Z SingleProcess AUTOTUNE benchmarking takes 0.0768 seconds and 0.0001 seconds precompiling for 6 choices
2026-01-14T08:45:45.1258544Z [32mPASSED[0m
2026-01-14T08:45:45.1259126Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_4 [32mPASSED[0m
2026-01-14T08:45:45.1259971Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_5 [32mPASSED[0m
2026-01-14T08:45:45.1260874Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:45:45.1261787Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:45:45.1262675Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_2_cpu Autotune Choices Stats:
2026-01-14T08:45:45.1263458Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.0396209998143604}
2026-01-14T08:45:45.1263951Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:45:45.1264243Z strides: [0, 1], [64, 1], [1, 64]
2026-01-14T08:45:45.1264588Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:45:45.1264943Z   addmm 0.0396 ms 100.0% 
2026-01-14T08:45:45.1265192Z   bias_addmm 0.0651 ms 60.8% 
2026-01-14T08:45:45.1265705Z SingleProcess AUTOTUNE benchmarking takes 0.2444 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:45:45.1266265Z Autotune Choices Stats:
2026-01-14T08:45:45.1266699Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.03886100012095994}
2026-01-14T08:45:45.1267207Z AUTOTUNE addmm(32x32, 32x32, 32x32)
2026-01-14T08:45:45.1267488Z strides: [0, 1], [32, 1], [1, 32]
2026-01-14T08:45:45.1267836Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:45:45.1268187Z   addmm 0.0389 ms 100.0% 
2026-01-14T08:45:45.1268438Z   bias_addmm 0.0643 ms 60.4% 
2026-01-14T08:45:45.1268933Z SingleProcess AUTOTUNE benchmarking takes 0.2439 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:45:45.1269520Z [32mPASSED[0m
2026-01-14T08:45:45.1270150Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_3 [33mSKIPPED[0m
2026-01-14T08:45:45.1271054Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_4 [33mSKIPPED[0m
2026-01-14T08:45:45.1271894Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_5 Autotune Choices Stats:
2026-01-14T08:45:45.1273344Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_381", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:45.1274965Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:45:45.1275225Z strides: [64, 1], [1, 64]
2026-01-14T08:45:45.1275493Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:45:45.1276439Z   triton_mm_381 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:45.1277645Z   triton_mm_385 0.0276 ms 96.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:45.1278843Z   triton_mm_382 0.0276 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:45.1280052Z   triton_mm_379 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:45.1281249Z   triton_mm_380 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:45.1282450Z   triton_mm_383 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:45.1283650Z   triton_mm_384 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:45.1285155Z   triton_mm_386 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:45.1286351Z   triton_mm_387 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:45.1287549Z   triton_mm_388 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:45.1288541Z SingleProcess AUTOTUNE benchmarking takes 0.1497 seconds and 0.1181 seconds precompiling for 11 choices
2026-01-14T08:45:45.1289102Z Autotune Choices Stats:
2026-01-14T08:45:45.1290238Z {"num_choices": 8, "num_triton_choices": 6, "best_kernel": "triton_mm_391", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.027648000046610832, "best_triton_pos": 0}
2026-01-14T08:45:45.1291426Z AUTOTUNE addmm(32x32, 32x32, 32x32)
2026-01-14T08:45:45.1291726Z strides: [0, 1], [32, 1], [1, 32]
2026-01-14T08:45:45.1292059Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:45:45.1292881Z   triton_mm_391 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:45.1294100Z   triton_mm_392 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:45.1295303Z   triton_mm_394 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:45.1296526Z   triton_mm_390 0.0286 ms 96.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:45.1297717Z   triton_mm_389 0.0287 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:45.1299063Z   triton_mm_393 0.0287 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:45.1299865Z   addmm 0.0522 ms 52.9% 
2026-01-14T08:45:45.1300109Z   bias_addmm 0.0717 ms 38.6% 
2026-01-14T08:45:45.1300740Z SingleProcess AUTOTUNE benchmarking takes 0.1093 seconds and 0.0001 seconds precompiling for 8 choices
2026-01-14T08:45:45.1301315Z [32mPASSED[0m
2026-01-14T08:45:45.1301908Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_0_cpu [32mPASSED[0m
2026-01-14T08:45:45.1302827Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_1_cpu [32mPASSED[0m
2026-01-14T08:45:45.1303731Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_2_cpu [32mPASSED[0m
2026-01-14T08:45:45.1304590Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_3 Autotune Choices Stats:
2026-01-14T08:45:45.1306067Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_399", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:45.1307258Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:45:45.1307515Z strides: [64, 1], [32, 1]
2026-01-14T08:45:45.1307778Z dtypes: torch.float32, torch.float32
2026-01-14T08:45:45.1308530Z   triton_mm_399 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:45.1309747Z   triton_mm_395 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:45.1310954Z   triton_mm_396 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:45.1312152Z   triton_mm_397 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:45.1313352Z   triton_mm_398 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:45.1314551Z   triton_mm_400 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:45.1315812Z   triton_mm_401 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:45.1317006Z   triton_mm_402 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:53.4698446Z   triton_mm_403 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:53.4699743Z   triton_mm_404 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:53.4700768Z SingleProcess AUTOTUNE benchmarking takes 0.1493 seconds and 0.2794 seconds precompiling for 11 choices
2026-01-14T08:45:53.4701331Z Autotune Choices Stats:
2026-01-14T08:45:53.4702469Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_405", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:53.4703975Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:45:53.4704222Z strides: [32, 1], [32, 1]
2026-01-14T08:45:53.4704487Z dtypes: torch.float32, torch.float32
2026-01-14T08:45:53.4705483Z   triton_mm_405 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:53.4706691Z   triton_mm_408 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:53.4707885Z   triton_mm_409 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:53.4709060Z   triton_mm_410 0.0276 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:53.4710260Z   triton_mm_406 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:53.4711446Z   triton_mm_407 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:53.4712182Z   mm 0.0399 ms 66.7% 
2026-01-14T08:45:53.4712670Z SingleProcess AUTOTUNE benchmarking takes 0.0897 seconds and 0.0001 seconds precompiling for 7 choices
2026-01-14T08:45:53.4713432Z [32mPASSED[0m
2026-01-14T08:45:53.4713970Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_4 Autotune Choices Stats:
2026-01-14T08:45:53.4715554Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_418", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.024607999250292778, "best_triton_pos": 0}
2026-01-14T08:45:53.4716746Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:45:53.4716998Z strides: [64, 1], [32, 1]
2026-01-14T08:45:53.4717268Z dtypes: torch.float16, torch.float16
2026-01-14T08:45:53.4718034Z   triton_mm_418 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:53.4719246Z   triton_mm_415 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:53.4720450Z   triton_mm_416 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:53.4721638Z   triton_mm_417 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:53.4722831Z   triton_mm_419 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:53.4724041Z   triton_mm_420 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:53.4725252Z   triton_mm_411 0.0266 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:53.4726448Z   triton_mm_412 0.0276 ms 89.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:53.4727754Z   triton_mm_413 0.0276 ms 89.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:53.4729044Z   triton_mm_414 0.0276 ms 89.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:53.4730055Z SingleProcess AUTOTUNE benchmarking takes 0.1407 seconds and 0.1189 seconds precompiling for 11 choices
2026-01-14T08:45:53.4730608Z Autotune Choices Stats:
2026-01-14T08:45:53.4731761Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_421", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:45:53.4733004Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:45:53.4733260Z strides: [32, 1], [32, 1]
2026-01-14T08:45:53.4733530Z dtypes: torch.float16, torch.float16
2026-01-14T08:45:53.4734273Z   triton_mm_421 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:45:53.4735492Z   triton_mm_422 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:53.4736687Z   triton_mm_423 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:45:53.4737896Z   triton_mm_424 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:45:53.4739116Z   triton_mm_425 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:45:53.4740320Z   triton_mm_426 0.0287 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:45:53.4741067Z   mm 0.0410 ms 65.0% 
2026-01-14T08:45:53.4741561Z SingleProcess AUTOTUNE benchmarking takes 0.0896 seconds and 0.0001 seconds precompiling for 7 choices
2026-01-14T08:45:53.4742147Z [32mPASSED[0m
2026-01-14T08:45:53.4742768Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_5 [32mPASSED[0m
2026-01-14T08:45:53.4743579Z test/integration/test_integration.py::UtilsUnitTest::test_shape_logger [32mPASSED[0m
2026-01-14T08:45:53.4744397Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_00_cpu [33mSKIPPED[0m
2026-01-14T08:45:53.4745252Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_01_cpu [33mSKIPPED[0m
2026-01-14T08:45:53.4746094Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_02_cpu [33mSKIPPED[0m
2026-01-14T08:45:53.4746936Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_03_cpu [33mSKIPPED[0m
2026-01-14T08:45:53.4747775Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_04_cpu [33mSKIPPED[0m
2026-01-14T08:45:53.4748618Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_05_cpu [33mSKIPPED[0m
2026-01-14T08:45:53.4749454Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_06_cpu [33mSKIPPED[0m
2026-01-14T08:45:53.4750295Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_07_cpu [33mSKIPPED[0m
2026-01-14T08:45:53.4751138Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_08_cpu [33mSKIPPED[0m
2026-01-14T08:45:53.4752057Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_09 [33mSKIPPED[0m
2026-01-14T08:45:53.4752865Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_10 [33mSKIPPED[0m
2026-01-14T08:45:53.4753747Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_11 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:45:53.4754663Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:45:53.4755220Z Autotune Choices Stats:
2026-01-14T08:45:53.4756366Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_427", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:45:53.4757577Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:45:53.4757872Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:45:53.4758199Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:46:02.5603025Z   triton_mm_427 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:46:02.5604524Z   triton_mm_428 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:02.5605740Z   triton_mm_430 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:02.5606957Z   triton_mm_431 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:02.5608176Z   triton_mm_440 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:02.5609379Z   triton_mm_441 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:02.5610592Z   triton_mm_434 0.0276 ms 92.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:02.5611796Z   triton_mm_429 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:02.5612990Z   triton_mm_433 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:02.5614205Z   triton_mm_438 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:02.5615216Z SingleProcess AUTOTUNE benchmarking takes 0.9244 seconds and 3.5323 seconds precompiling for 20 choices
2026-01-14T08:46:02.5616027Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:02.5616594Z Autotune Choices Stats:
2026-01-14T08:46:02.5617742Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_445", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:46:02.5618957Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:46:02.5619217Z strides: [128, 1], [128, 1]
2026-01-14T08:46:02.5619825Z dtypes: torch.float32, torch.float32
2026-01-14T08:46:02.5620578Z   triton_mm_445 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:46:02.5621782Z   triton_mm_447 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:02.5623143Z   triton_mm_448 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:02.5624339Z   triton_mm_450 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:02.5625537Z   triton_mm_451 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:02.5626746Z   triton_mm_452 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:02.5627943Z   triton_mm_453 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:02.5629154Z   triton_mm_455 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:02.5630366Z   triton_mm_456 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:02.5631553Z   triton_mm_458 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:02.5632558Z SingleProcess AUTOTUNE benchmarking takes 0.2399 seconds and 2.0964 seconds precompiling for 19 choices
2026-01-14T08:46:02.5633464Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.014ms 
2026-01-14T08:46:02.5634472Z >>time: 0.017ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.012ms 
2026-01-14T08:46:02.5635244Z Autotune Choices Stats:
2026-01-14T08:46:02.5636371Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_469", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:46:02.5637518Z AUTOTUNE int_mm(32x128, 128x128)
2026-01-14T08:46:02.5637803Z strides: [128, 1], [1, 128]
2026-01-14T08:46:02.5638066Z dtypes: torch.int8, torch.int8
2026-01-14T08:46:02.5638792Z   triton_mm_469 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:02.5639965Z   triton_mm_463 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:02.5641118Z   triton_mm_471 0.0256 ms 95.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:02.5642279Z   triton_mm_465 0.0266 ms 92.4% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:02.5643444Z   triton_mm_466 0.0266 ms 92.4% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:02.5644721Z   triton_mm_464 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:02.5645903Z   triton_mm_467 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:02.5647145Z   triton_mm_468 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:02.5648325Z   triton_mm_470 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:46:02.5649512Z   triton_mm_472 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:02.5650514Z SingleProcess AUTOTUNE benchmarking takes 0.1416 seconds and 0.2165 seconds precompiling for 11 choices
2026-01-14T08:46:02.5651445Z >>time: 0.017ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.012ms
2026-01-14T08:46:02.5652371Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:46:02.5652836Z 
2026-01-14T08:46:02.5653161Z [32mPASSED[0m
2026-01-14T08:46:02.5653714Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_12 [33mSKIPPED[0m
2026-01-14T08:46:02.5654532Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_13 [33mSKIPPED[0m
2026-01-14T08:46:02.5655413Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_14 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:46:02.5656244Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:46:02.5656716Z Autotune Choices Stats:
2026-01-14T08:46:02.5657840Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_478", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:46:02.5659031Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:46:02.5659331Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:46:02.5659659Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:46:12.6639535Z   triton_mm_478 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:12.6640810Z   triton_mm_475 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:12.6642048Z   triton_mm_476 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:12.6643244Z   triton_mm_477 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:12.6644457Z   triton_mm_479 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:12.6645656Z   triton_mm_480 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:12.6646850Z   triton_mm_482 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:12.6648439Z   triton_mm_484 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:12.6649803Z   triton_mm_485 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:12.6651011Z   triton_mm_486 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:12.6652017Z SingleProcess AUTOTUNE benchmarking takes 0.2572 seconds and 0.3012 seconds precompiling for 20 choices
2026-01-14T08:46:12.6652805Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:12.6653368Z Autotune Choices Stats:
2026-01-14T08:46:12.6654500Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_502", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:46:12.6655708Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:46:12.6655976Z strides: [128, 1], [128, 1]
2026-01-14T08:46:12.6656253Z dtypes: torch.float16, torch.float16
2026-01-14T08:46:12.6657021Z   triton_mm_502 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:12.6658244Z   triton_mm_507 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:12.6659520Z   triton_mm_508 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:12.6660738Z   triton_mm_499 0.0236 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:12.6661952Z   triton_mm_491 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:46:12.6663152Z   triton_mm_492 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:12.6664375Z   triton_mm_493 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:12.6665577Z   triton_mm_494 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:12.6674408Z   triton_mm_495 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:12.6675688Z   triton_mm_496 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:12.6676680Z SingleProcess AUTOTUNE benchmarking takes 0.2358 seconds and 0.2658 seconds precompiling for 19 choices
2026-01-14T08:46:12.6677579Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.009ms 
2026-01-14T08:46:12.6678578Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.009ms 
2026-01-14T08:46:12.6679736Z >>time: 0.018ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.009ms
2026-01-14T08:46:12.6680574Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:46:12.6680938Z 
2026-01-14T08:46:12.6681256Z [32mPASSED[0m
2026-01-14T08:46:12.6681809Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_15 [33mSKIPPED[0m
2026-01-14T08:46:12.6682700Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_16 [33mSKIPPED[0m
2026-01-14T08:46:12.6683585Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_17 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:46:12.6684682Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:46:12.6685169Z Autotune Choices Stats:
2026-01-14T08:46:12.6686305Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_519", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:46:12.6687480Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:46:12.6687775Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:46:12.6688109Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:46:12.6688987Z   triton_mm_519 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:46:12.6690204Z   triton_mm_521 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:12.6691410Z   triton_mm_524 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:12.6692616Z   triton_mm_525 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:12.6693815Z   triton_mm_526 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:12.6695017Z   triton_mm_528 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:12.6696225Z   triton_mm_533 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:12.6697443Z   triton_mm_534 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:46:12.6698661Z   triton_mm_535 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:12.6699867Z   triton_mm_529 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:12.6700876Z SingleProcess AUTOTUNE benchmarking takes 0.2590 seconds and 0.2972 seconds precompiling for 20 choices
2026-01-14T08:46:12.6701680Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:12.6702599Z >>time: 0.023ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.009ms 
2026-01-14T08:46:12.6703598Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.009ms 
2026-01-14T08:46:12.6704803Z >>time: 0.017ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.009ms
2026-01-14T08:46:12.6705637Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:46:12.6706012Z 
2026-01-14T08:46:12.6706143Z [32mPASSED[0m
2026-01-14T08:46:21.3038863Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_0_cpu [33mSKIPPED[0m
2026-01-14T08:46:21.3039837Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_1_cpu [33mSKIPPED[0m
2026-01-14T08:46:21.3040738Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_2_cpu [33mSKIPPED[0m
2026-01-14T08:46:21.3041661Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_3 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:46:21.3042540Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:46:21.3043029Z Autotune Choices Stats:
2026-01-14T08:46:21.3044182Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_547", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:46:21.3045410Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:46:21.3045715Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:46:21.3046052Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:46:21.3046870Z   triton_mm_547 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:46:21.3048097Z   triton_mm_554 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:21.3049325Z   triton_mm_556 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:21.3050525Z   triton_mm_548 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:46:21.3051941Z   triton_mm_549 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:21.3053445Z   triton_mm_550 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:21.3054693Z   triton_mm_551 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:21.3055908Z   triton_mm_552 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:21.3057112Z   triton_mm_553 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:21.3058318Z   triton_mm_555 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:21.3059331Z SingleProcess AUTOTUNE benchmarking takes 0.2543 seconds and 1.4324 seconds precompiling for 20 choices
2026-01-14T08:46:21.3060142Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:21.3060869Z Autotune Choices Stats:
2026-01-14T08:46:21.3062278Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_578", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:46:21.3063635Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:46:21.3063914Z strides: [128, 1], [128, 1]
2026-01-14T08:46:21.3064322Z dtypes: torch.float32, torch.float32
2026-01-14T08:46:21.3065087Z   triton_mm_578 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:21.3066287Z   triton_mm_567 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:21.3067488Z   triton_mm_568 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:21.3068692Z   triton_mm_570 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:21.3069897Z   triton_mm_572 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:21.3071098Z   triton_mm_574 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:21.3072318Z   triton_mm_576 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:21.3073538Z   triton_mm_577 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:21.3074817Z   triton_mm_565 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:46:21.3076029Z   triton_mm_575 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:21.3077031Z SingleProcess AUTOTUNE benchmarking takes 0.2281 seconds and 0.8851 seconds precompiling for 19 choices
2026-01-14T08:46:21.3077939Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.011ms 
2026-01-14T08:46:21.3078960Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.011ms 
2026-01-14T08:46:21.3079630Z Autotune Choices Stats:
2026-01-14T08:46:21.3080782Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_588", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:46:21.3081976Z AUTOTUNE int_mm(16x128, 128x128)
2026-01-14T08:46:21.3082250Z strides: [128, 1], [1, 128]
2026-01-14T08:46:21.3082529Z dtypes: torch.int8, torch.int8
2026-01-14T08:46:21.3083260Z   triton_mm_588 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:21.3084704Z   triton_mm_587 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:21.3086029Z   triton_mm_583 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:21.3087197Z   triton_mm_584 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:21.3088508Z   triton_mm_585 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:21.3089700Z   triton_mm_586 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:21.3090879Z   triton_mm_590 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:46:21.3092132Z   triton_mm_592 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:21.3093331Z   triton_mm_589 0.0256 ms 91.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:21.3094512Z   triton_mm_591 0.0266 ms 88.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:21.3095500Z SingleProcess AUTOTUNE benchmarking takes 0.1305 seconds and 0.1661 seconds precompiling for 11 choices
2026-01-14T08:46:21.3096446Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.011ms
2026-01-14T08:46:21.3097382Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:46:21.3097851Z 
2026-01-14T08:46:21.3098001Z [32mPASSED[0m
2026-01-14T08:46:27.0214957Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_4 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:46:27.0216050Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:46:27.0216543Z Autotune Choices Stats:
2026-01-14T08:46:27.0217743Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_596", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:46:27.0218986Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:46:27.0219291Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:46:27.0219637Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:46:27.0220491Z   triton_mm_596 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:27.0221722Z   triton_mm_598 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:27.0222953Z   triton_mm_609 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:27.0224182Z   triton_mm_610 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:27.0225400Z   triton_mm_608 0.0256 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:46:27.0226965Z   triton_mm_593 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:46:27.0228181Z   triton_mm_594 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:46:27.0229563Z   triton_mm_595 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:27.0230773Z   triton_mm_597 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:27.0231978Z   triton_mm_599 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:27.0232986Z SingleProcess AUTOTUNE benchmarking takes 0.2591 seconds and 0.2866 seconds precompiling for 20 choices
2026-01-14T08:46:27.0233852Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:27.0234410Z Autotune Choices Stats:
2026-01-14T08:46:27.0235626Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_622", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:46:27.0236830Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:46:27.0237095Z strides: [128, 1], [128, 1]
2026-01-14T08:46:27.0237373Z dtypes: torch.float16, torch.float16
2026-01-14T08:46:27.0238133Z   triton_mm_622 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:27.0239370Z   triton_mm_625 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:27.0240599Z   triton_mm_626 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:46:27.0241820Z   triton_mm_628 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:27.0243052Z   triton_mm_627 0.0236 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:27.0244259Z   triton_mm_614 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:27.0245466Z   triton_mm_615 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:27.0246684Z   triton_mm_620 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:27.0247903Z   triton_mm_623 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:27.0249107Z   triton_mm_624 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:27.0250115Z SingleProcess AUTOTUNE benchmarking takes 0.2399 seconds and 0.2098 seconds precompiling for 19 choices
2026-01-14T08:46:27.0251120Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.016ms 
2026-01-14T08:46:27.0252130Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.015ms 
2026-01-14T08:46:27.0253171Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.015ms
2026-01-14T08:46:27.0254204Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:46:27.0254675Z 
2026-01-14T08:46:27.0254994Z [32mPASSED[0m
2026-01-14T08:46:27.0255618Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_5 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:46:27.0256477Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:46:27.0256969Z Autotune Choices Stats:
2026-01-14T08:46:27.0258124Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_653", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:46:27.0259330Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:46:27.0259632Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:46:27.0259975Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:46:27.0260817Z   triton_mm_653 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:27.0262042Z   triton_mm_647 0.0255 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:27.0263275Z   triton_mm_648 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:27.0264535Z   triton_mm_641 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:27.0265751Z   triton_mm_643 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:27.0266971Z   triton_mm_644 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:27.0268187Z   triton_mm_650 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:27.0269409Z   triton_mm_651 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:27.0270634Z   triton_mm_654 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:46:27.0271857Z   triton_mm_655 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:27.0272867Z SingleProcess AUTOTUNE benchmarking takes 0.2597 seconds and 0.2537 seconds precompiling for 20 choices
2026-01-14T08:46:37.8473221Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:37.8474341Z >>time: 0.023ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.016ms 
2026-01-14T08:46:37.8476499Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.016ms 
2026-01-14T08:46:37.8477807Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.015ms
2026-01-14T08:46:37.8479016Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:46:37.8479482Z 
2026-01-14T08:46:37.8479801Z [32mPASSED[0m
2026-01-14T08:46:37.8480606Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_0_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8481456Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_1_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8482286Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_2_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8483099Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_3 [33mSKIPPED[0m
2026-01-14T08:46:37.8483878Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_4 [33mSKIPPED[0m
2026-01-14T08:46:37.8485001Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_5 [33mSKIPPED[0m
2026-01-14T08:46:37.8485873Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_hp_float activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:46:37.8486737Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:46:37.8487503Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQFloat32LinearWeight'>, to_beat: infms 
2026-01-14T08:46:37.8488218Z best_cls=<class 'torchao.quantization.autoquant.AQFloat32LinearWeight'>
2026-01-14T08:46:37.8488579Z 
2026-01-14T08:46:37.8488740Z activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:46:37.8489260Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:46:37.8489980Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQBFloat16LinearWeight'>, to_beat: infms 
2026-01-14T08:46:37.8490697Z best_cls=<class 'torchao.quantization.autoquant.AQBFloat16LinearWeight'>
2026-01-14T08:46:37.8491070Z 
2026-01-14T08:46:37.8491228Z activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:46:37.8491740Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:46:37.8492463Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQFloat16LinearWeight'>, to_beat: infms 
2026-01-14T08:46:37.8493176Z best_cls=<class 'torchao.quantization.autoquant.AQFloat16LinearWeight'>
2026-01-14T08:46:37.8493534Z 
2026-01-14T08:46:37.8493688Z [32mPASSED[0m
2026-01-14T08:46:37.8494223Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_0_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8495046Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_1_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8495865Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_2_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8496671Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_3 [33mSKIPPED[0m
2026-01-14T08:46:37.8497453Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_4 [33mSKIPPED[0m
2026-01-14T08:46:37.8498243Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_5 [33mSKIPPED[0m
2026-01-14T08:46:37.8499052Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_00_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8499892Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_01_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8500724Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_02_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8501555Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_03_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8502383Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_04_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8503354Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_05_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8504184Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_06_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8505013Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_07_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8505831Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_08_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8506770Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_09 [33mSKIPPED[0m
2026-01-14T08:46:37.8507564Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_10 [33mSKIPPED[0m
2026-01-14T08:46:37.8508357Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_11 [32mPASSED[0m
2026-01-14T08:46:37.8509150Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_12 [33mSKIPPED[0m
2026-01-14T08:46:37.8509942Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_13 [33mSKIPPED[0m
2026-01-14T08:46:37.8510728Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_14 [32mPASSED[0m
2026-01-14T08:46:37.8511509Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_15 [33mSKIPPED[0m
2026-01-14T08:46:37.8512297Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_16 [33mSKIPPED[0m
2026-01-14T08:46:37.8513091Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_17 [32mPASSED[0m
2026-01-14T08:46:37.8513891Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_0_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8514712Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_1_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8515583Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_2_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8516388Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_3 [32mPASSED[0m
2026-01-14T08:46:37.8517181Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_4 [32mPASSED[0m
2026-01-14T08:46:37.8517987Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_5 [32mPASSED[0m
2026-01-14T08:46:37.8518775Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_0_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8519569Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_1_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8520361Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_2_cpu [33mSKIPPED[0m
2026-01-14T08:46:37.8521199Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_3 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:46:37.8522019Z weight_shape: torch.Size([4096, 4096]), dtype: torch.float32, bias_shape: torch.Size([4096])
2026-01-14T08:46:37.8522514Z Autotune Choices Stats:
2026-01-14T08:46:37.8523925Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "bias_addmm", "best_time": 0.14336000382900238, "best_triton_pos": 2, "best_triton_time": 0.187391996383667, "best_triton_kernel": "triton_mm_674", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
2026-01-14T08:46:37.8525435Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:46:37.8525750Z strides: [0, 1], [4096, 1], [1, 4096]
2026-01-14T08:46:37.8526084Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:46:37.8526439Z   bias_addmm 0.1434 ms 100.0% 
2026-01-14T08:46:37.8526700Z   addmm 0.1454 ms 98.6% 
2026-01-14T08:46:37.8527411Z   triton_mm_674 0.1874 ms 76.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:37.8528701Z   triton_mm_681 0.1915 ms 74.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:37.8529896Z   triton_mm_669 0.1925 ms 74.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:37.8531165Z   triton_mm_680 0.1925 ms 74.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:37.8532359Z   triton_mm_670 0.2028 ms 70.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:37.8533536Z   triton_mm_671 0.2028 ms 70.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:37.8534741Z   triton_mm_668 0.2294 ms 62.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:46:37.8535909Z   triton_mm_673 0.2601 ms 55.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:37.8536924Z SingleProcess AUTOTUNE benchmarking takes 0.4859 seconds and 1.0489 seconds precompiling for 20 choices
2026-01-14T08:46:37.8537728Z >>time: 0.145ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:37.8538634Z >>time: 0.038ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.145ms 
2026-01-14T08:46:37.8539645Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.038ms 
2026-01-14T08:46:37.8540312Z Autotune Choices Stats:
2026-01-14T08:46:51.3776974Z {"num_choices": 12, "num_triton_choices": 11, "best_kernel": "triton_mm_694", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8", "best_time": 0.050175998359918594, "best_triton_pos": 0}
2026-01-14T08:46:51.3778242Z AUTOTUNE int_mm(1x4096, 4096x4096)
2026-01-14T08:46:51.3778539Z strides: [4096, 1], [1, 4096]
2026-01-14T08:46:51.3778816Z dtypes: torch.int8, torch.int8
2026-01-14T08:46:51.3779602Z   triton_mm_694 0.0502 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:51.3780830Z   triton_mm_695 0.0502 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:51.3782015Z   triton_mm_693 0.0532 ms 94.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:51.3783206Z   triton_mm_690 0.0563 ms 89.1% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:51.3784552Z   triton_mm_691 0.0563 ms 89.1% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:51.3785727Z   triton_mm_689 0.0625 ms 80.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:51.3786895Z   triton_mm_687 0.0778 ms 64.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:51.3788068Z   triton_mm_686 0.0799 ms 62.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:51.3789558Z   triton_mm_688 0.1362 ms 36.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:51.3790905Z   triton_mm_685 0.1372 ms 36.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:51.3791896Z SingleProcess AUTOTUNE benchmarking takes 0.1757 seconds and 0.3378 seconds precompiling for 12 choices
2026-01-14T08:46:51.3792839Z >>time: 0.049ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.037ms
2026-01-14T08:46:51.3793769Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:46:51.3794228Z 
2026-01-14T08:46:51.3794555Z [32mPASSED[0m
2026-01-14T08:46:51.3795317Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_4 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:46:51.3796134Z weight_shape: torch.Size([4096, 4096]), dtype: torch.float16, bias_shape: torch.Size([4096])
2026-01-14T08:46:51.3796623Z Autotune Choices Stats:
2026-01-14T08:46:51.3797778Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_704", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.08089599758386612, "best_triton_pos": 0}
2026-01-14T08:46:51.3798979Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:46:51.3799295Z strides: [0, 1], [4096, 1], [1, 4096]
2026-01-14T08:46:51.3799618Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:46:51.3800435Z   triton_mm_704 0.0809 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:51.3801653Z   triton_mm_712 0.0829 ms 97.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:51.3802850Z   triton_mm_707 0.0850 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:51.3804063Z   triton_mm_703 0.0870 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:51.3805270Z   triton_mm_698 0.0881 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:51.3806470Z   triton_mm_700 0.0891 ms 90.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:51.3807236Z   addmm 0.0932 ms 86.8% 
2026-01-14T08:46:51.3807933Z   triton_mm_710 0.0932 ms 86.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:51.3808697Z   bias_addmm 0.0952 ms 84.9% 
2026-01-14T08:46:51.3809421Z   triton_mm_706 0.0973 ms 83.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:51.3810419Z SingleProcess AUTOTUNE benchmarking takes 0.3527 seconds and 0.4532 seconds precompiling for 20 choices
2026-01-14T08:46:51.3811230Z >>time: 0.082ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:51.3812175Z >>time: 0.038ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.082ms 
2026-01-14T08:46:51.3813285Z >>time: 0.038ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.038ms 
2026-01-14T08:46:51.3814338Z >>time: 0.050ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.038ms
2026-01-14T08:46:51.3815261Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:46:51.3815738Z 
2026-01-14T08:46:51.3815867Z [32mPASSED[0m
2026-01-14T08:46:51.3816584Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_5 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:46:51.3817428Z weight_shape: torch.Size([4096, 4096]), dtype: torch.bfloat16, bias_shape: torch.Size([4096])
2026-01-14T08:46:51.3817918Z Autotune Choices Stats:
2026-01-14T08:46:51.3819059Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_733", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.08089599758386612, "best_triton_pos": 0}
2026-01-14T08:46:51.3820268Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:46:51.3820576Z strides: [0, 1], [4096, 1], [1, 4096]
2026-01-14T08:46:51.3820952Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:46:51.3821836Z   triton_mm_733 0.0809 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:51.3823054Z   triton_mm_741 0.0829 ms 97.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:51.3824275Z   triton_mm_736 0.0850 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:51.3825504Z   triton_mm_727 0.0870 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:51.3826710Z   triton_mm_732 0.0870 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:51.3827939Z   triton_mm_729 0.0881 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:46:51.3829173Z   triton_mm_739 0.0922 ms 87.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:46:51.3829923Z   addmm 0.0942 ms 85.9% 
2026-01-14T08:46:51.3830199Z   bias_addmm 0.0963 ms 84.0% 
2026-01-14T08:46:51.3830931Z   triton_mm_735 0.0973 ms 83.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:51.3832016Z SingleProcess AUTOTUNE benchmarking takes 0.3520 seconds and 0.4422 seconds precompiling for 20 choices
2026-01-14T08:46:51.3832821Z >>time: 0.083ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:51.3833745Z >>time: 0.038ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.083ms 
2026-01-14T08:46:51.3834841Z >>time: 0.038ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.038ms 
2026-01-14T08:46:51.3835890Z >>time: 0.050ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.038ms
2026-01-14T08:46:55.4123428Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:46:55.4124509Z 
2026-01-14T08:46:55.4124830Z [32mPASSED[0m
2026-01-14T08:46:55.4125459Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_0 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:46:55.4126301Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:46:55.4126786Z Autotune Choices Stats:
2026-01-14T08:46:55.4128120Z {"num_choices": 22, "num_triton_choices": 20, "best_kernel": "triton_mm_760", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:46:55.4129334Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:46:55.4129635Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:46:55.4129971Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:46:55.4130776Z   triton_mm_760 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:55.4132001Z   triton_mm_764 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:55.4133218Z   triton_mm_767 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:55.4134400Z   triton_mm_768 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:55.4135589Z   triton_mm_759 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:55.4136792Z   triton_mm_762 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:55.4137978Z   triton_mm_758 0.0276 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:55.4139181Z   triton_mm_754 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:46:55.4140379Z   triton_mm_755 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:55.4141575Z   triton_mm_756 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:55.4142582Z SingleProcess AUTOTUNE benchmarking takes 0.2489 seconds and 0.8021 seconds precompiling for 22 choices
2026-01-14T08:46:55.4143390Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:55.4144529Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 53.31756591796875
2026-01-14T08:46:55.4146004Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 54.40925216674805
2026-01-14T08:46:55.4147470Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 48.288150787353516
2026-01-14T08:46:55.4148510Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:46:55.4148875Z 
2026-01-14T08:46:55.4149016Z [32mPASSED[0m
2026-01-14T08:46:55.4149713Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_1 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:46:55.4150548Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:46:55.4151025Z Autotune Choices Stats:
2026-01-14T08:46:55.4152747Z {"num_choices": 22, "num_triton_choices": 20, "best_kernel": "triton_mm_774", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:46:55.4153965Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:46:55.4154266Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:46:55.4154597Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:46:55.4155502Z   triton_mm_774 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:46:55.4156731Z   triton_mm_777 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:55.4157945Z   triton_mm_779 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:46:55.4159156Z   triton_mm_781 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:46:55.4160361Z   triton_mm_782 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:55.4161575Z   triton_mm_783 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:55.4162781Z   triton_mm_784 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:55.4164038Z   triton_mm_785 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:55.4165250Z   triton_mm_787 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:46:55.4166462Z   triton_mm_788 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:46:55.4167480Z SingleProcess AUTOTUNE benchmarking takes 0.2728 seconds and 0.5236 seconds precompiling for 22 choices
2026-01-14T08:46:55.4168290Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:46:55.4169404Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 53.3125
2026-01-14T08:46:55.4170807Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 54.0
2026-01-14T08:46:55.4172192Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 48.15625
2026-01-14T08:46:55.4173211Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:46:55.4173576Z 
2026-01-14T08:46:55.4173716Z [32mPASSED[0m
2026-01-14T08:46:55.4174320Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_2 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:46:55.4175279Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:46:55.4175771Z Autotune Choices Stats:
2026-01-14T08:46:55.4185986Z {"num_choices": 22, "num_triton_choices": 20, "best_kernel": "triton_mm_796", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:46:55.4187262Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:46:55.4187572Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:46:55.4187914Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:46:55.4188740Z   triton_mm_796 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:55.4189963Z   triton_mm_797 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:46:55.4191168Z   triton_mm_798 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:46:55.4192381Z   triton_mm_799 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:13.3180260Z   triton_mm_801 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:13.3181533Z   triton_mm_805 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:13.3182784Z   triton_mm_806 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:47:13.3184012Z   triton_mm_808 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:13.3185397Z   triton_mm_809 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:47:13.3186618Z   triton_mm_810 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:13.3187646Z SingleProcess AUTOTUNE benchmarking takes 0.2712 seconds and 0.5425 seconds precompiling for 22 choices
2026-01-14T08:47:13.3188455Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:47:13.3189533Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 49.0
2026-01-14T08:47:13.3190912Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 49.0
2026-01-14T08:47:13.3192300Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 46.25
2026-01-14T08:47:13.3193313Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:47:13.3193668Z 
2026-01-14T08:47:13.3194011Z [32mPASSED[0m
2026-01-14T08:47:13.3194537Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_00_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:47:13.3195564Z [33mSKIPPED[0m
2026-01-14T08:47:13.3196064Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_01_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:47:13.3196659Z [33mSKIPPED[0m
2026-01-14T08:47:13.3197146Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_02_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:47:13.3197736Z [33mSKIPPED[0m
2026-01-14T08:47:13.3198225Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_03_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:47:13.3199013Z [33mSKIPPED[0m
2026-01-14T08:47:13.3199511Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_04_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:47:13.3200096Z [33mSKIPPED[0m
2026-01-14T08:47:13.3200589Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_05_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:47:13.3201166Z [33mSKIPPED[0m
2026-01-14T08:47:13.3201660Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_06_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:47:13.3202248Z [33mSKIPPED[0m
2026-01-14T08:47:13.3202742Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_07_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:47:13.3203331Z [33mSKIPPED[0m
2026-01-14T08:47:13.3203817Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_08_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:47:13.3204407Z [33mSKIPPED[0m
2026-01-14T08:47:13.3204902Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_09_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:47:13.3205495Z [33mSKIPPED[0m
2026-01-14T08:47:13.3205981Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_10_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:47:13.3206572Z [33mSKIPPED[0m
2026-01-14T08:47:13.3207064Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_11_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:47:13.3207647Z [33mSKIPPED[0m
2026-01-14T08:47:13.3208145Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_12_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:47:13.3208724Z [33mSKIPPED[0m
2026-01-14T08:47:13.3209216Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_13_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:47:13.3209798Z [33mSKIPPED[0m
2026-01-14T08:47:13.3210287Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_14_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:47:13.3210883Z [33mSKIPPED[0m
2026-01-14T08:47:13.3211355Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_15 (m, k, n):  (16, 128, 128)
2026-01-14T08:47:13.3211928Z [32mPASSED[0m
2026-01-14T08:47:13.3212394Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_16 (m, k, n):  (64, 128, 128)
2026-01-14T08:47:13.3213020Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:47:13.3213544Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:47:13.3214026Z Autotune Choices Stats:
2026-01-14T08:47:13.3215176Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_815", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.026623999699950218, "best_triton_pos": 0}
2026-01-14T08:47:13.3216414Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:47:13.3216725Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:47:13.3217055Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:47:13.3217885Z   triton_mm_815 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:13.3219110Z   triton_mm_816 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:13.3220423Z   triton_mm_817 0.0266 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:13.3221643Z   triton_mm_814 0.0276 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:47:13.3222934Z   triton_mm_820 0.0287 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:13.3224146Z   triton_mm_827 0.0287 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:13.3225343Z   triton_mm_819 0.0328 ms 81.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:13.3226563Z   triton_mm_823 0.0328 ms 81.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:13.3227772Z   triton_mm_828 0.0358 ms 74.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:13.3228991Z   triton_mm_821 0.0369 ms 72.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:13.3230004Z SingleProcess AUTOTUNE benchmarking takes 0.3174 seconds and 10.5742 seconds precompiling for 20 choices
2026-01-14T08:47:13.3230810Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:47:13.3231380Z Autotune Choices Stats:
2026-01-14T08:47:13.3232527Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_832", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:47:13.3233724Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:47:13.3233986Z strides: [128, 1], [128, 1]
2026-01-14T08:47:13.3234265Z dtypes: torch.float32, torch.float32
2026-01-14T08:47:13.3235080Z   triton_mm_832 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:47:13.3236299Z   triton_mm_839 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:13.3237512Z   triton_mm_834 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:13.3238718Z   triton_mm_836 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:13.3239920Z   triton_mm_837 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:13.3241140Z   triton_mm_838 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:18.9916367Z   triton_mm_845 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:18.9917940Z   triton_mm_842 0.0266 ms 92.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:18.9919167Z   triton_mm_835 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:18.9920590Z   triton_mm_841 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:18.9921635Z SingleProcess AUTOTUNE benchmarking takes 0.2639 seconds and 5.3755 seconds precompiling for 19 choices
2026-01-14T08:47:18.9922553Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.013ms 
2026-01-14T08:47:18.9923217Z Autotune Choices Stats:
2026-01-14T08:47:18.9924349Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_851", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:47:18.9925569Z AUTOTUNE int_mm(64x128, 128x128)
2026-01-14T08:47:18.9925841Z strides: [128, 1], [1, 128]
2026-01-14T08:47:18.9926122Z dtypes: torch.int8, torch.int8
2026-01-14T08:47:18.9926868Z   triton_mm_851 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:18.9928068Z   triton_mm_858 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:18.9929261Z   triton_mm_856 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:18.9930506Z   triton_mm_857 0.0256 ms 95.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:47:18.9931673Z   triton_mm_850 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:18.9932856Z   triton_mm_852 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:18.9934040Z   triton_mm_853 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:18.9935222Z   triton_mm_855 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:18.9936425Z   triton_mm_859 0.0266 ms 92.3% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:18.9937608Z   triton_mm_854 0.0276 ms 88.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:18.9938610Z SingleProcess AUTOTUNE benchmarking takes 0.1453 seconds and 0.2663 seconds precompiling for 11 choices
2026-01-14T08:47:18.9939554Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.013ms
2026-01-14T08:47:18.9940419Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:47:18.9940815Z 
2026-01-14T08:47:18.9941133Z [32mPASSED[0m
2026-01-14T08:47:18.9941632Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_17 (m, k, n):  (16, 128, 256)
2026-01-14T08:47:18.9942392Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:47:18.9942921Z weight_shape: torch.Size([256, 128]), dtype: torch.float32, bias_shape: torch.Size([256])
2026-01-14T08:47:18.9943393Z Autotune Choices Stats:
2026-01-14T08:47:18.9944621Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_863", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:47:18.9945827Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:47:18.9946121Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:47:18.9946455Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:47:18.9947260Z   triton_mm_863 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:47:18.9948478Z   triton_mm_873 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:18.9949677Z   triton_mm_860 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:47:18.9950942Z   triton_mm_861 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:47:18.9952157Z   triton_mm_862 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:18.9953347Z   triton_mm_864 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:47:18.9954537Z   triton_mm_865 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:18.9955817Z   triton_mm_866 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:18.9957031Z   triton_mm_867 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:18.9958236Z   triton_mm_868 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:18.9959242Z SingleProcess AUTOTUNE benchmarking takes 0.2541 seconds and 1.5389 seconds precompiling for 20 choices
2026-01-14T08:47:18.9960051Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:47:18.9960606Z Autotune Choices Stats:
2026-01-14T08:47:18.9961759Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_895", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.023615999147295952, "best_triton_pos": 0}
2026-01-14T08:47:18.9962958Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:47:18.9963224Z strides: [128, 1], [256, 1]
2026-01-14T08:47:18.9963502Z dtypes: torch.float32, torch.float32
2026-01-14T08:47:18.9964277Z   triton_mm_895 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:18.9965488Z   triton_mm_878 0.0246 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:47:18.9966780Z   triton_mm_880 0.0246 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:18.9967976Z   triton_mm_881 0.0246 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:47:18.9969251Z   triton_mm_883 0.0246 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:18.9970437Z   triton_mm_884 0.0246 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:18.9971647Z   triton_mm_885 0.0246 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:18.9972862Z   triton_mm_888 0.0246 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:28.5387819Z   triton_mm_889 0.0246 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:28.5389129Z   triton_mm_890 0.0246 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:47:28.5390186Z SingleProcess AUTOTUNE benchmarking takes 0.2296 seconds and 0.8533 seconds precompiling for 19 choices
2026-01-14T08:47:28.5391105Z >>time: 0.017ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.009ms 
2026-01-14T08:47:28.5392137Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.009ms 
2026-01-14T08:47:28.5392803Z Autotune Choices Stats:
2026-01-14T08:47:28.5394198Z {"num_choices": 12, "num_triton_choices": 11, "best_kernel": "triton_mm_906", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:47:28.5395717Z AUTOTUNE int_mm(16x128, 128x256)
2026-01-14T08:47:28.5395989Z strides: [128, 1], [1, 128]
2026-01-14T08:47:28.5396254Z dtypes: torch.int8, torch.int8
2026-01-14T08:47:28.5396984Z   triton_mm_906 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:28.5398184Z   triton_mm_897 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:28.5399378Z   triton_mm_901 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:47:28.5400564Z   triton_mm_904 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:28.5401721Z   triton_mm_896 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:28.5402902Z   triton_mm_898 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:28.5404468Z   triton_mm_899 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:28.5405644Z   triton_mm_900 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:47:28.5406981Z   triton_mm_902 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:28.5408160Z   triton_mm_903 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:47:28.5409159Z SingleProcess AUTOTUNE benchmarking takes 0.1435 seconds and 0.2529 seconds precompiling for 12 choices
2026-01-14T08:47:28.5410100Z >>time: 0.017ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.009ms
2026-01-14T08:47:28.5410943Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:47:28.5411306Z 
2026-01-14T08:47:28.5411632Z [32mPASSED[0m
2026-01-14T08:47:28.5412131Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_18 (m, k, n):  (16, 256, 128)
2026-01-14T08:47:28.5412760Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:47:28.5413281Z weight_shape: torch.Size([128, 256]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:47:28.5413761Z Autotune Choices Stats:
2026-01-14T08:47:28.5414910Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_911", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:47:28.5416111Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:47:28.5416416Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:47:28.5416741Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:47:28.5417559Z   triton_mm_911 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:47:28.5418783Z   triton_mm_910 0.0256 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:47:28.5419972Z   triton_mm_908 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:47:28.5421177Z   triton_mm_920 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:28.5422369Z   triton_mm_909 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:28.5423566Z   triton_mm_914 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:28.5424759Z   triton_mm_921 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:47:28.5425933Z   triton_mm_907 0.0287 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:47:28.5427107Z   triton_mm_913 0.0297 ms 86.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:28.5428398Z   triton_mm_912 0.0338 ms 75.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:28.5429409Z SingleProcess AUTOTUNE benchmarking takes 0.2187 seconds and 1.2139 seconds precompiling for 20 choices
2026-01-14T08:47:28.5430205Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:47:28.5430765Z Autotune Choices Stats:
2026-01-14T08:47:28.5431979Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_926", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:47:28.5433178Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:47:28.5433458Z strides: [256, 1], [128, 1]
2026-01-14T08:47:28.5433769Z dtypes: torch.float32, torch.float32
2026-01-14T08:47:28.5434541Z   triton_mm_926 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:47:28.5435834Z   triton_mm_928 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:47:28.5437049Z   triton_mm_929 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:47:28.5438254Z   triton_mm_930 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:28.5439445Z   triton_mm_931 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:28.5440663Z   triton_mm_938 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:28.5441871Z   triton_mm_939 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:47:28.5443080Z   triton_mm_927 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:28.5444289Z   triton_mm_935 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:46.9322849Z   triton_mm_936 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:46.9323941Z SingleProcess AUTOTUNE benchmarking takes 0.2044 seconds and 0.9350 seconds precompiling for 19 choices
2026-01-14T08:47:46.9324870Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.011ms 
2026-01-14T08:47:46.9325883Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.011ms 
2026-01-14T08:47:46.9326564Z Autotune Choices Stats:
2026-01-14T08:47:46.9327711Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_949", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:47:46.9328920Z AUTOTUNE int_mm(16x256, 256x128)
2026-01-14T08:47:46.9329200Z strides: [256, 1], [1, 256]
2026-01-14T08:47:46.9329765Z dtypes: torch.int8, torch.int8
2026-01-14T08:47:46.9330500Z   triton_mm_949 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:46.9331713Z   triton_mm_950 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:47:46.9333115Z   triton_mm_943 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:46.9334310Z   triton_mm_946 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:46.9335502Z   triton_mm_948 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:47:46.9336685Z   triton_mm_951 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:46.9337903Z   triton_mm_952 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:46.9339102Z   triton_mm_947 0.0257 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:47:46.9340336Z   triton_mm_944 0.0266 ms 92.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:46.9341524Z   triton_mm_945 0.0266 ms 92.4% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:46.9342519Z SingleProcess AUTOTUNE benchmarking takes 0.1328 seconds and 0.2146 seconds precompiling for 11 choices
2026-01-14T08:47:46.9343462Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.011ms
2026-01-14T08:47:46.9344400Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:47:46.9344863Z 
2026-01-14T08:47:46.9345183Z [32mPASSED[0m
2026-01-14T08:47:46.9345693Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_19 (m, k, n):  (64, 256, 128)
2026-01-14T08:47:46.9346318Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:47:46.9346828Z weight_shape: torch.Size([128, 256]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:47:46.9347308Z Autotune Choices Stats:
2026-01-14T08:47:46.9348451Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_954", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.027648000046610832, "best_triton_pos": 0}
2026-01-14T08:47:46.9349669Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:47:46.9349965Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:47:46.9350283Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:47:46.9351102Z   triton_mm_954 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:46.9352316Z   triton_mm_953 0.0348 ms 79.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:47:46.9353523Z   triton_mm_955 0.0389 ms 71.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:46.9354901Z   triton_mm_956 0.0389 ms 71.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:46.9356101Z   triton_mm_966 0.0409 ms 67.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:46.9357389Z   triton_mm_959 0.0440 ms 62.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:46.9358605Z   triton_mm_962 0.0471 ms 58.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:46.9359807Z   triton_mm_958 0.0481 ms 57.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:46.9361020Z   triton_mm_964 0.0481 ms 57.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:46.9362217Z   triton_mm_967 0.0481 ms 57.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:46.9363211Z SingleProcess AUTOTUNE benchmarking takes 0.2238 seconds and 4.9640 seconds precompiling for 20 choices
2026-01-14T08:47:46.9364017Z >>time: 0.017ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:47:46.9364570Z Autotune Choices Stats:
2026-01-14T08:47:46.9365710Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_974", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:47:46.9366909Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:47:46.9367165Z strides: [256, 1], [128, 1]
2026-01-14T08:47:46.9367439Z dtypes: torch.float32, torch.float32
2026-01-14T08:47:46.9368203Z   triton_mm_974 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:46.9369409Z   triton_mm_973 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:46.9370618Z   triton_mm_978 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:46.9371812Z   triton_mm_984 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:46.9373005Z   triton_mm_971 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:47:46.9374206Z   triton_mm_972 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:46.9375386Z   triton_mm_985 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:46.9376585Z   triton_mm_977 0.0297 ms 82.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:46.9377879Z   triton_mm_976 0.0317 ms 77.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:46.9379073Z   triton_mm_981 0.0317 ms 77.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:46.9380118Z SingleProcess AUTOTUNE benchmarking takes 0.2110 seconds and 4.4677 seconds precompiling for 19 choices
2026-01-14T08:47:53.4875276Z >>time: 0.029ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.017ms 
2026-01-14T08:47:53.4876097Z Autotune Choices Stats:
2026-01-14T08:47:53.4877251Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_991", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:47:53.4878516Z AUTOTUNE int_mm(64x256, 256x128)
2026-01-14T08:47:53.4878792Z strides: [256, 1], [1, 256]
2026-01-14T08:47:53.4879064Z dtypes: torch.int8, torch.int8
2026-01-14T08:47:53.4879790Z   triton_mm_991 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:53.4880997Z   triton_mm_992 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:53.4882178Z   triton_mm_993 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:53.4883372Z   triton_mm_998 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:53.4884941Z   triton_mm_996 0.0246 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:47:53.4886127Z   triton_mm_990 0.0255 ms 96.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:53.4887285Z   triton_mm_989 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:53.4888447Z   triton_mm_994 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:53.4889621Z   triton_mm_995 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:53.4890786Z   triton_mm_997 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:47:53.4891774Z SingleProcess AUTOTUNE benchmarking takes 0.1433 seconds and 0.2739 seconds precompiling for 11 choices
2026-01-14T08:47:53.4892708Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.017ms
2026-01-14T08:47:53.4893750Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.067ms 
2026-01-14T08:47:53.4894850Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 3.40
2026-01-14T08:47:53.4895826Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:47:53.4896498Z 
2026-01-14T08:47:53.4896818Z [32mPASSED[0m
2026-01-14T08:47:53.4897319Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_20 (m, k, n):  (16, 128, 128)
2026-01-14T08:47:53.4897899Z [32mPASSED[0m
2026-01-14T08:47:53.4898368Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_21 (m, k, n):  (64, 128, 128)
2026-01-14T08:47:53.4898971Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:47:53.4899622Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:47:53.4900090Z Autotune Choices Stats:
2026-01-14T08:47:53.4901239Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_1023", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.024607999250292778, "best_triton_pos": 0}
2026-01-14T08:47:53.4902486Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:47:53.4902782Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:47:53.4903111Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:47:53.4903919Z   triton_mm_1023 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:53.4905133Z   triton_mm_1010 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:53.4906330Z   triton_mm_1020 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:53.4907522Z   triton_mm_1021 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:47:53.4908739Z   triton_mm_1024 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:47:53.4909945Z   triton_mm_1025 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:53.4911136Z   triton_mm_1009 0.0266 ms 92.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:47:53.4912337Z   triton_mm_1011 0.0266 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:53.4913525Z   triton_mm_1012 0.0266 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:53.4914803Z   triton_mm_1013 0.0266 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:53.4916240Z SingleProcess AUTOTUNE benchmarking takes 0.2598 seconds and 0.4020 seconds precompiling for 20 choices
2026-01-14T08:47:53.4917372Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:47:53.4918123Z Autotune Choices Stats:
2026-01-14T08:47:53.4919259Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_1027", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:47:53.4920440Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:47:53.4920700Z strides: [128, 1], [128, 1]
2026-01-14T08:47:53.4921194Z dtypes: torch.float16, torch.float16
2026-01-14T08:47:53.4922005Z   triton_mm_1027 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:47:53.4923213Z   triton_mm_1028 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:53.4924492Z   triton_mm_1031 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:47:53.4925693Z   triton_mm_1032 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:47:53.4926886Z   triton_mm_1037 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:53.4928078Z   triton_mm_1038 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:53.4929289Z   triton_mm_1039 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:47:53.4930489Z   triton_mm_1040 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:47:53.4931688Z   triton_mm_1041 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:47:53.4932890Z   triton_mm_1043 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:47:53.4933895Z SingleProcess AUTOTUNE benchmarking takes 0.2466 seconds and 0.4017 seconds precompiling for 19 choices
2026-01-14T08:48:00.4573665Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.015ms 
2026-01-14T08:48:00.4574841Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.010ms
2026-01-14T08:48:00.4575820Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:48:00.4576286Z 
2026-01-14T08:48:00.4576627Z [32mPASSED[0m
2026-01-14T08:48:00.4577138Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_22 (m, k, n):  (16, 128, 256)
2026-01-14T08:48:00.4577771Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:48:00.4578292Z weight_shape: torch.Size([256, 128]), dtype: torch.float16, bias_shape: torch.Size([256])
2026-01-14T08:48:00.4578785Z Autotune Choices Stats:
2026-01-14T08:48:00.4579953Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_1056", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:48:00.4581156Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:48:00.4581463Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:48:00.4581786Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:48:00.4582622Z   triton_mm_1056 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:48:00.4583880Z   triton_mm_1057 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:00.4585660Z   triton_mm_1059 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:48:00.4594800Z   triton_mm_1060 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:00.4596283Z   triton_mm_1061 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:00.4597499Z   triton_mm_1062 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:00.4598729Z   triton_mm_1064 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:00.4599964Z   triton_mm_1065 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:00.4601190Z   triton_mm_1067 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:48:00.4602425Z   triton_mm_1068 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:00.4603441Z SingleProcess AUTOTUNE benchmarking takes 0.2531 seconds and 0.3473 seconds precompiling for 20 choices
2026-01-14T08:48:00.4604240Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:48:00.4604806Z Autotune Choices Stats:
2026-01-14T08:48:00.4605962Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_1079", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:48:00.4607200Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:48:00.4607463Z strides: [128, 1], [256, 1]
2026-01-14T08:48:00.4607728Z dtypes: torch.float16, torch.float16
2026-01-14T08:48:00.4608499Z   triton_mm_1079 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:00.4609720Z   triton_mm_1073 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:48:00.4610929Z   triton_mm_1074 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:48:00.4612142Z   triton_mm_1075 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:00.4613352Z   triton_mm_1076 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:48:00.4614608Z   triton_mm_1077 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:48:00.4615824Z   triton_mm_1078 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:00.4617155Z   triton_mm_1080 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:00.4618366Z   triton_mm_1081 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:00.4619670Z   triton_mm_1082 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:00.4620671Z SingleProcess AUTOTUNE benchmarking takes 0.2399 seconds and 0.2683 seconds precompiling for 19 choices
2026-01-14T08:48:00.4621584Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.016ms 
2026-01-14T08:48:00.4622599Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.008ms 
2026-01-14T08:48:00.4623642Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.008ms
2026-01-14T08:48:00.4624550Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:48:00.4625010Z 
2026-01-14T08:48:00.4625193Z [32mPASSED[0m
2026-01-14T08:48:00.4625694Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_23 (m, k, n):  (16, 256, 128)
2026-01-14T08:48:00.4626315Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:48:00.4626830Z weight_shape: torch.Size([128, 256]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:48:00.4627310Z Autotune Choices Stats:
2026-01-14T08:48:00.4628458Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_1104", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:48:00.4629673Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:48:00.4629971Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:48:00.4630291Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:48:00.4631102Z   triton_mm_1104 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:00.4632333Z   triton_mm_1106 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:48:00.4633560Z   triton_mm_1109 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:00.4634837Z   triton_mm_1110 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:00.4636057Z   triton_mm_1111 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:00.4637289Z   triton_mm_1112 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:00.4638507Z   triton_mm_1115 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:00.4639719Z   triton_mm_1117 0.0266 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:48:08.5786346Z   triton_mm_1102 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:48:08.5788253Z   triton_mm_1103 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:48:08.5789277Z SingleProcess AUTOTUNE benchmarking takes 0.2404 seconds and 0.3518 seconds precompiling for 20 choices
2026-01-14T08:48:08.5790253Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:48:08.5790816Z Autotune Choices Stats:
2026-01-14T08:48:08.5791973Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_1127", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:48:08.5793154Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:48:08.5793423Z strides: [256, 1], [128, 1]
2026-01-14T08:48:08.5793692Z dtypes: torch.float16, torch.float16
2026-01-14T08:48:08.5794450Z   triton_mm_1127 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:08.5795764Z   triton_mm_1129 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:08.5796982Z   triton_mm_1130 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:08.5798207Z   triton_mm_1131 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:08.5799427Z   triton_mm_1133 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:08.5800629Z   triton_mm_1134 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:48:08.5801847Z   triton_mm_1120 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:48:08.5803052Z   triton_mm_1121 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:48:08.5804260Z   triton_mm_1122 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:08.5805470Z   triton_mm_1123 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:48:08.5806459Z SingleProcess AUTOTUNE benchmarking takes 0.2231 seconds and 0.2938 seconds precompiling for 19 choices
2026-01-14T08:48:08.5807374Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.016ms 
2026-01-14T08:48:08.5808394Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.016ms 
2026-01-14T08:48:08.5809430Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.016ms
2026-01-14T08:48:08.5810254Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:48:08.5810621Z 
2026-01-14T08:48:08.5810933Z [32mPASSED[0m
2026-01-14T08:48:08.5811534Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_24 (m, k, n):  (64, 256, 128)
2026-01-14T08:48:08.5812155Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:48:08.5812664Z weight_shape: torch.Size([128, 256]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:48:08.5813138Z Autotune Choices Stats:
2026-01-14T08:48:08.5814350Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_1152", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:48:08.5815553Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:48:08.5815847Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:48:08.5816172Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:48:08.5816984Z   triton_mm_1152 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:08.5818214Z   triton_mm_1158 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:08.5819416Z   triton_mm_1161 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:08.5820626Z   triton_mm_1154 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:08.5821824Z   triton_mm_1155 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:48:08.5823032Z   triton_mm_1162 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:08.5824245Z   triton_mm_1163 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:48:08.5825453Z   triton_mm_1164 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:48:08.5826670Z   triton_mm_1153 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:08.5827872Z   triton_mm_1148 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:48:08.5828869Z SingleProcess AUTOTUNE benchmarking takes 0.2295 seconds and 0.4776 seconds precompiling for 20 choices
2026-01-14T08:48:08.5829675Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:48:08.5830230Z Autotune Choices Stats:
2026-01-14T08:48:08.5831382Z {"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_mm_1177", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:48:08.5832576Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:48:08.5832829Z strides: [256, 1], [128, 1]
2026-01-14T08:48:08.5833100Z dtypes: torch.float16, torch.float16
2026-01-14T08:48:08.5833852Z   triton_mm_1177 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:08.5835211Z   triton_mm_1179 0.0245 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:08.5836422Z   triton_mm_1170 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:08.5837737Z   triton_mm_1171 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:08.5838946Z   triton_mm_1175 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:08.5840163Z   triton_mm_1176 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:08.5841371Z   triton_mm_1180 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:08.5842578Z   triton_mm_1166 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:48:17.8742655Z   triton_mm_1167 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:17.8744107Z   triton_mm_1168 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:48:17.8745141Z SingleProcess AUTOTUNE benchmarking takes 0.2110 seconds and 0.4500 seconds precompiling for 19 choices
2026-01-14T08:48:17.8746067Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.009ms 
2026-01-14T08:48:17.8747120Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.009ms
2026-01-14T08:48:17.8747971Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:48:17.8748337Z 
2026-01-14T08:48:17.8748661Z [32mPASSED[0m
2026-01-14T08:48:17.8749170Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_25 (m, k, n):  (16, 128, 128)
2026-01-14T08:48:17.8749746Z [32mPASSED[0m
2026-01-14T08:48:17.8750225Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_26 (m, k, n):  (64, 128, 128)
2026-01-14T08:48:17.8750844Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:48:17.8751367Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:48:17.8751857Z Autotune Choices Stats:
2026-01-14T08:48:17.8753012Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_1204", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:48:17.8754242Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:48:17.8754542Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:48:17.8754973Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:48:17.8755814Z   triton_mm_1204 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:17.8757051Z   triton_mm_1207 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:17.8758272Z   triton_mm_1205 0.0257 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:17.8759874Z   triton_mm_1197 0.0266 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:48:17.8761990Z   triton_mm_1195 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:17.8763200Z   triton_mm_1196 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:48:17.8764402Z   triton_mm_1198 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:17.8765607Z   triton_mm_1199 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:17.8766801Z   triton_mm_1200 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:17.8768007Z   triton_mm_1201 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:48:17.8768997Z SingleProcess AUTOTUNE benchmarking takes 0.2635 seconds and 0.4336 seconds precompiling for 20 choices
2026-01-14T08:48:17.8769815Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:48:17.8770724Z >>time: 0.023ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.009ms 
2026-01-14T08:48:17.8771784Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.009ms
2026-01-14T08:48:17.8772633Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:48:17.8772990Z 
2026-01-14T08:48:17.8773120Z [32mPASSED[0m
2026-01-14T08:48:17.8773606Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_27 (m, k, n):  (16, 128, 256)
2026-01-14T08:48:17.8774217Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:48:17.8774756Z weight_shape: torch.Size([256, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([256])
2026-01-14T08:48:17.8775246Z Autotune Choices Stats:
2026-01-14T08:48:17.8776388Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_1223", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:48:17.8777580Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:48:17.8777868Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:48:17.8778224Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:48:17.8779060Z   triton_mm_1223 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:48:17.8780292Z   triton_mm_1225 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:48:17.8781520Z   triton_mm_1229 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:17.8782735Z   triton_mm_1238 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:48:17.8784043Z   triton_mm_1222 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:48:17.8785425Z   triton_mm_1224 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:17.8786765Z   triton_mm_1226 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:48:17.8787983Z   triton_mm_1227 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:17.8789168Z   triton_mm_1228 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:17.8790434Z   triton_mm_1230 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:17.8791432Z SingleProcess AUTOTUNE benchmarking takes 0.2655 seconds and 0.2583 seconds precompiling for 20 choices
2026-01-14T08:48:17.8792245Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:48:17.8793149Z >>time: 0.024ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.015ms 
2026-01-14T08:48:17.8794168Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.015ms 
2026-01-14T08:48:17.8795260Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.015ms
2026-01-14T08:48:17.8796105Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:48:17.8796476Z 
2026-01-14T08:48:17.8796605Z [32mPASSED[0m
2026-01-14T08:48:17.8797092Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_28 (m, k, n):  (16, 256, 128)
2026-01-14T08:48:17.8797699Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:48:17.8798227Z weight_shape: torch.Size([128, 256]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:48:17.8798715Z Autotune Choices Stats:
2026-01-14T08:48:17.8799864Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_1255", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:48:17.8801065Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:48:17.8801363Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:48:17.8801711Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:48:17.8802531Z   triton_mm_1255 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:48:28.3390025Z   triton_mm_1260 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:28.3391669Z   triton_mm_1264 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:28.3393195Z   triton_mm_1265 0.0246 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:48:28.3394815Z   triton_mm_1256 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:28.3396695Z   triton_mm_1258 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:28.3398416Z   triton_mm_1259 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:48:28.3399958Z   triton_mm_1261 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:28.3401490Z   triton_mm_1267 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:48:28.3403054Z   triton_mm_1251 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:48:28.3404340Z SingleProcess AUTOTUNE benchmarking takes 0.2414 seconds and 0.2924 seconds precompiling for 20 choices
2026-01-14T08:48:28.3405348Z >>time: 0.015ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:48:28.3406467Z >>time: 0.034ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.015ms 
2026-01-14T08:48:28.3407728Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.015ms 
2026-01-14T08:48:28.3409022Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.015ms
2026-01-14T08:48:28.3410069Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:48:28.3410529Z 
2026-01-14T08:48:28.3410911Z [32mPASSED[0m
2026-01-14T08:48:28.3411537Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_29 (m, k, n):  (64, 256, 128)
2026-01-14T08:48:28.3412335Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:48:28.3412980Z weight_shape: torch.Size([128, 256]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:48:28.3413593Z Autotune Choices Stats:
2026-01-14T08:48:28.3415052Z {"num_choices": 20, "num_triton_choices": 18, "best_kernel": "triton_mm_1290", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:48:28.3416584Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:48:28.3416962Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:48:28.3417382Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:48:28.3418428Z   triton_mm_1290 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:28.3419974Z   triton_mm_1293 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:28.3421509Z   triton_mm_1284 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:28.3423029Z   triton_mm_1285 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:28.3424540Z   triton_mm_1286 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:48:28.3426170Z   triton_mm_1289 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:48:28.3427694Z   triton_mm_1292 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:48:28.3429292Z   triton_mm_1294 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:48:28.3430824Z   triton_mm_1295 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:48:28.3432350Z   triton_mm_1280 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:48:28.3433621Z SingleProcess AUTOTUNE benchmarking takes 0.2309 seconds and 0.5409 seconds precompiling for 20 choices
2026-01-14T08:48:28.3434619Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:48:28.3435805Z >>time: 0.034ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.012ms 
2026-01-14T08:48:28.3437087Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.012ms
2026-01-14T08:48:28.3438373Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.035ms 
2026-01-14T08:48:28.3439729Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 1.95
2026-01-14T08:48:28.3440960Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:48:28.3441528Z 
2026-01-14T08:48:28.3441691Z [32mPASSED[0m
2026-01-14T08:48:28.3442243Z test/integration/test_integration.py::TestAOTI::test_aoti_00 [33mSKIPPED[0m
2026-01-14T08:48:28.3443108Z test/integration/test_integration.py::TestAOTI::test_aoti_01 [33mSKIPPED[0m
2026-01-14T08:48:28.3443957Z test/integration/test_integration.py::TestAOTI::test_aoti_02 [33mSKIPPED[0m
2026-01-14T08:48:28.3444784Z test/integration/test_integration.py::TestAOTI::test_aoti_03 [33mSKIPPED[0m
2026-01-14T08:48:28.3445628Z test/integration/test_integration.py::TestAOTI::test_aoti_04 [33mSKIPPED[0m
2026-01-14T08:48:28.3446445Z test/integration/test_integration.py::TestAOTI::test_aoti_05 [33mSKIPPED[0m
2026-01-14T08:48:28.3447267Z test/integration/test_integration.py::TestAOTI::test_aoti_06 [33mSKIPPED[0m
2026-01-14T08:48:28.3448085Z test/integration/test_integration.py::TestAOTI::test_aoti_07 [33mSKIPPED[0m
2026-01-14T08:48:28.3448902Z test/integration/test_integration.py::TestAOTI::test_aoti_08 [33mSKIPPED[0m
2026-01-14T08:48:28.3449723Z test/integration/test_integration.py::TestAOTI::test_aoti_09 [33mSKIPPED[0m
2026-01-14T08:48:28.3450546Z test/integration/test_integration.py::TestAOTI::test_aoti_10 [33mSKIPPED[0m
2026-01-14T08:48:28.3451375Z test/integration/test_integration.py::TestAOTI::test_aoti_11 [33mSKIPPED[0m
2026-01-14T08:48:28.3452192Z test/integration/test_integration.py::TestAOTI::test_aoti_12 [33mSKIPPED[0m
2026-01-14T08:48:28.3453020Z test/integration/test_integration.py::TestAOTI::test_aoti_13 [33mSKIPPED[0m
2026-01-14T08:48:28.3453835Z test/integration/test_integration.py::TestAOTI::test_aoti_14 [33mSKIPPED[0m
2026-01-14T08:48:28.3454653Z test/integration/test_integration.py::TestAOTI::test_aoti_15 [33mSKIPPED[0m
2026-01-14T08:48:28.3455461Z test/integration/test_integration.py::TestAOTI::test_aoti_16 [33mSKIPPED[0m
2026-01-14T08:48:28.3456289Z test/integration/test_integration.py::TestAOTI::test_aoti_17 [33mSKIPPED[0m
2026-01-14T08:48:28.3457252Z test/integration/test_integration.py::TestExport::test_export_00 [32mPASSED[0m
2026-01-14T08:48:28.3458099Z test/integration/test_integration.py::TestExport::test_export_01 [32mPASSED[0m
2026-01-14T08:48:28.3458963Z test/integration/test_integration.py::TestExport::test_export_02 [32mPASSED[0m
2026-01-14T08:48:28.3459887Z test/integration/test_integration.py::TestExport::test_export_03 [32mPASSED[0m
2026-01-14T08:48:28.3460675Z test/integration/test_integration.py::TestExport::test_export_04 [32mPASSED[0m
2026-01-14T08:48:28.3461486Z test/integration/test_integration.py::TestExport::test_export_05 [32mPASSED[0m
2026-01-14T08:48:28.3462172Z test/integration/test_integration.py::TestExport::test_export_06 [32mPASSED[0m
2026-01-14T08:48:28.3462860Z test/integration/test_integration.py::TestExport::test_export_07 [32mPASSED[0m
2026-01-14T08:48:28.3463538Z test/integration/test_integration.py::TestExport::test_export_08 [32mPASSED[0m
2026-01-14T08:48:28.3464224Z test/integration/test_integration.py::TestExport::test_export_09 [32mPASSED[0m
2026-01-14T08:48:28.3464908Z test/integration/test_integration.py::TestExport::test_export_10 [32mPASSED[0m
2026-01-14T08:48:28.3465594Z test/integration/test_integration.py::TestExport::test_export_11 [32mPASSED[0m
2026-01-14T08:48:28.3466275Z test/integration/test_integration.py::TestExport::test_export_12 [32mPASSED[0m
2026-01-14T08:50:20.4562081Z test/integration/test_integration.py::TestExport::test_export_13 [32mPASSED[0m
2026-01-14T08:50:20.4562995Z test/integration/test_integration.py::TestExport::test_export_14 [32mPASSED[0m
2026-01-14T08:50:20.4563673Z test/integration/test_integration.py::TestExport::test_export_15 [32mPASSED[0m
2026-01-14T08:50:20.4564354Z test/integration/test_integration.py::TestExport::test_export_16 [32mPASSED[0m
2026-01-14T08:50:20.4565143Z test/integration/test_integration.py::TestExport::test_export_17 [32mPASSED[0m
2026-01-14T08:50:20.4566121Z test/integration/test_integration.py::TestExport::test_export_18 [32mPASSED[0m
2026-01-14T08:50:20.4567055Z test/integration/test_integration.py::TestExport::test_export_19 [32mPASSED[0m
2026-01-14T08:50:20.4567743Z test/integration/test_integration.py::TestExport::test_export_20 [32mPASSED[0m
2026-01-14T08:50:20.4568561Z test/integration/test_integration.py::TestExport::test_export_21 [32mPASSED[0m
2026-01-14T08:50:20.4569390Z test/integration/test_integration.py::TestExport::test_export_22 [32mPASSED[0m
2026-01-14T08:50:20.4570265Z test/integration/test_integration.py::TestExport::test_export_23 [32mPASSED[0m
2026-01-14T08:50:20.4571248Z test/integration/test_integration.py::TestExport::test_export_float8 [33mSKIPPED[0m
2026-01-14T08:50:20.4572022Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_00 [33mSKIPPED[0m
2026-01-14T08:50:20.4572791Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_01 [33mSKIPPED[0m
2026-01-14T08:50:20.4573546Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_02 [33mSKIPPED[0m
2026-01-14T08:50:20.4574319Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_03 [33mSKIPPED[0m
2026-01-14T08:50:20.4575077Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_04 [33mSKIPPED[0m
2026-01-14T08:50:20.4575842Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_05 [32mPASSED[0m
2026-01-14T08:50:20.4576608Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_06 [33mSKIPPED[0m
2026-01-14T08:50:20.4577372Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_07 [33mSKIPPED[0m
2026-01-14T08:50:20.4578166Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_08 [33mSKIPPED[0m
2026-01-14T08:50:20.4578931Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_09 [33mSKIPPED[0m
2026-01-14T08:50:20.4579739Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_10 [33mSKIPPED[0m
2026-01-14T08:50:20.4580917Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_11 [32mPASSED[0m
2026-01-14T08:50:20.4581671Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_12 [33mSKIPPED[0m
2026-01-14T08:50:20.4582438Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_13 [33mSKIPPED[0m
2026-01-14T08:50:20.4583201Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_14 [33mSKIPPED[0m
2026-01-14T08:50:20.4584339Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_15 [33mSKIPPED[0m
2026-01-14T08:50:20.4585135Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_16 [33mSKIPPED[0m
2026-01-14T08:50:20.4585890Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_17 [32mPASSED[0m
2026-01-14T08:50:20.4586695Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cpu [32mPASSED[0m
2026-01-14T08:50:20.4587543Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cuda [32mPASSED[0m
2026-01-14T08:50:20.4588552Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_hf_models_model_info0 [33mSKIPPED[0m
2026-01-14T08:50:20.4589685Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:50:20.4590801Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:50:20.4591890Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info1 [33mSKIPPED[0m
2026-01-14T08:50:20.4592963Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info2 [33mSKIPPED[0m
2026-01-14T08:50:20.4594020Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info3 [33mSKIPPED[0m
2026-01-14T08:50:20.4595151Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info4 [33mSKIPPED[0m
2026-01-14T08:50:20.4596009Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_0_cuda [32mPASSED[0m
2026-01-14T08:50:20.4596678Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_1_cuda [32mPASSED[0m
2026-01-14T08:50:20.4597380Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_0_cuda [33mSKIPPED[0m
2026-01-14T08:50:20.4598105Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_1_cuda [33mSKIPPED[0m
2026-01-14T08:50:20.4598821Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_0_cuda [32mPASSED[0m
2026-01-14T08:50:20.4599529Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu [32mPASSED[0m
2026-01-14T08:50:20.4600243Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_2_cuda [32mPASSED[0m
2026-01-14T08:50:20.4600951Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu [32mPASSED[0m
2026-01-14T08:50:20.4601673Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-2-512-128] Relative Error: 0.052789
2026-01-14T08:50:20.4602269Z [32mPASSED[0m
2026-01-14T08:50:20.4602753Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-3-2048-2048] Relative Error: 0.052619
2026-01-14T08:50:20.4603346Z [32mPASSED[0m
2026-01-14T08:50:20.4603822Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-4-3584-640] Relative Error: 0.052605
2026-01-14T08:50:20.4604400Z [32mPASSED[0m
2026-01-14T08:50:20.4604887Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-13-8704-8576] Relative Error: 0.052641
2026-01-14T08:50:20.4605462Z [32mPASSED[0m
2026-01-14T08:50:20.4605952Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-26-18944-1664] Relative Error: 0.052629
2026-01-14T08:50:20.4606531Z [32mPASSED[0m
2026-01-14T08:50:20.4607015Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-67-6656-1408] Relative Error: 0.052626
2026-01-14T08:50:20.4607736Z [32mPASSED[0m
2026-01-14T08:50:20.4608190Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-2-512-128] Relative Error: 0.076733
2026-01-14T08:50:20.4608739Z [32mPASSED[0m
2026-01-14T08:50:20.4609198Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-3-2048-2048] Relative Error: 0.073021
2026-01-14T08:50:20.4609810Z [32mPASSED[0m
2026-01-14T08:50:20.4610381Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-4-3584-640] Relative Error: 0.073371
2026-01-14T08:50:20.4610936Z [32mPASSED[0m
2026-01-14T08:50:20.4611395Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-13-8704-8576] Relative Error: 0.073475
2026-01-14T08:50:20.4611955Z [32mPASSED[0m
2026-01-14T08:50:20.4612432Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-26-18944-1664] Relative Error: 0.073329
2026-01-14T08:50:20.4612994Z [32mPASSED[0m
2026-01-14T08:50:20.4613463Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-67-6656-1408] Relative Error: 0.073540
2026-01-14T08:50:20.4614019Z [32mPASSED[0m
2026-01-14T08:50:20.4614712Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-2-512-128] [33mSKIPPED[0m
2026-01-14T08:50:20.4615832Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-2-5120-1280] [33mSKIPPED[0m
2026-01-14T08:50:20.4616968Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-3-2048-2048] [33mSKIPPED[0m
2026-01-14T08:50:20.4618088Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-4-3584-640] [33mSKIPPED[0m
2026-01-14T08:50:20.4619202Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-13-8704-8576] [33mSKIPPED[0m
2026-01-14T08:50:20.4620351Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-26-18944-1664] [33mSKIPPED[0m
2026-01-14T08:50:20.4621491Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-67-6656-1408] [33mSKIPPED[0m
2026-01-14T08:50:20.4622592Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-2-512-128] [33mSKIPPED[0m
2026-01-14T08:50:20.4631519Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-2-5120-1280] [33mSKIPPED[0m
2026-01-14T08:50:20.4632748Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-3-2048-2048] [33mSKIPPED[0m
2026-01-14T08:50:20.4633851Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-4-3584-640] [33mSKIPPED[0m
2026-01-14T08:50:20.4635021Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-13-8704-8576] [33mSKIPPED[0m
2026-01-14T08:50:20.4636145Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-26-18944-1664] [33mSKIPPED[0m
2026-01-14T08:50:20.4637261Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-67-6656-1408] [33mSKIPPED[0m
2026-01-14T08:50:20.4638331Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_lhs[128] [33mSKIPPED[0m
2026-01-14T08:50:20.4639371Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_lhs[256] [33mSKIPPED[0m
2026-01-14T08:50:21.0123410Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_rhs[128] [33mSKIPPED[0m
2026-01-14T08:50:21.0125569Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_rhs[256] [33mSKIPPED[0m
2026-01-14T08:50:21.0128197Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-1024-128] [33mSKIPPED[0m
2026-01-14T08:50:21.0130058Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-1024-256] [33mSKIPPED[0m
2026-01-14T08:50:21.0131397Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-16384-128] [33mSKIPPED[0m
2026-01-14T08:50:21.0132648Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-16384-256] [33mSKIPPED[0m
2026-01-14T08:50:21.0133824Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-1024-128] [33mSKIPPED[0m
2026-01-14T08:50:21.0135005Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-1024-256] [33mSKIPPED[0m
2026-01-14T08:50:21.0136166Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-16384-128] [33mSKIPPED[0m
2026-01-14T08:50:21.0137345Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-16384-256] [33mSKIPPED[0m
2026-01-14T08:50:21.0138524Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_transposed_rhs[128] [33mSKIPPED[0m
2026-01-14T08:50:21.0139720Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_transposed_rhs[256] [33mSKIPPED[0m
2026-01-14T08:50:21.0140867Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_fp8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:50:21.0141907Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_int8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:50:21.0142977Z test/prototype/module_swap_quantization/test_kmeans_codebook.py::TestKmeansCodebook::test_kmeans_codebook [33mSKIPPED[0m
2026-01-14T08:50:21.0144023Z test/prototype/module_swap_quantization/test_llm_ptq_data_getter.py::TestPTQDataGetter::test_data_getter [33mSKIPPED[0m
2026-01-14T08:50:21.0145038Z test/prototype/module_swap_quantization/test_module_swap.py::TestEmbeddingSwap::test_embedding_swap [32mPASSED[0m
2026-01-14T08:50:21.0146193Z test/prototype/module_swap_quantization/test_module_swap_quantization_utils.py::TestQuantizedModuleUtils::test_set_bit_widths_by_name [32mPASSED[0m
2026-01-14T08:50:21.0147376Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic [32mPASSED[0m
2026-01-14T08:50:21.0148499Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic_vectorized [32mPASSED[0m
2026-01-14T08:50:21.0149629Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear [32mPASSED[0m
2026-01-14T08:50:21.0150731Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_init [32mPASSED[0m
2026-01-14T08:50:21.0151908Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients [32mPASSED[0m
2026-01-14T08:50:21.0153220Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_activation_scale [32mPASSED[0m
2026-01-14T08:50:21.0154615Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_weight_scale [32mPASSED[0m
2026-01-14T08:50:21.0156052Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_all_options [32mPASSED[0m
2026-01-14T08:50:21.0157374Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_correct [32mPASSED[0m
2026-01-14T08:50:21.0158677Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedEmbedding::test_quantized_embedding [32mPASSED[0m
2026-01-14T08:50:21.0159726Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_qmin_qmax [32mPASSED[0m
2026-01-14T08:50:21.0160810Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max [32mPASSED[0m
2026-01-14T08:50:21.0161895Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max_vectorized [32mPASSED[0m
2026-01-14T08:50:21.0162996Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_asymmetric [32mPASSED[0m
2026-01-14T08:50:21.0164073Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max [32mPASSED[0m
2026-01-14T08:50:21.0165240Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max_tensorized [32mPASSED[0m
2026-01-14T08:50:21.0166372Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_symmetric [32mPASSED[0m
2026-01-14T08:50:21.0167417Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_param_size [32mPASSED[0m
2026-01-14T08:50:21.0168428Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward [32mPASSED[0m
2026-01-14T08:50:21.0169501Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_asymmetric_clipping [32mPASSED[0m
2026-01-14T08:50:21.0170673Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric [32mPASSED[0m
2026-01-14T08:50:21.0171796Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric_clipping [32mPASSED[0m
2026-01-14T08:50:21.0172899Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_codebook_quantizer [32mPASSED[0m
2026-01-14T08:50:21.0173963Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_vector_quantizer [32mPASSED[0m
2026-01-14T08:50:21.0175072Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max [32mPASSED[0m
2026-01-14T08:50:21.0176272Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max_grouped [32mPASSED[0m
2026-01-14T08:50:21.0177431Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse [32mPASSED[0m
2026-01-14T08:50:21.0178548Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse_grouped [32mPASSED[0m
2026-01-14T08:50:21.0179851Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss [32mPASSED[0m
2026-01-14T08:50:21.0181330Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss_progressive [32mPASSED[0m
2026-01-14T08:50:21.0182778Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting [32mPASSED[0m
2026-01-14T08:50:21.0184352Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting_no_input [32mPASSED[0m
2026-01-14T08:50:21.0185692Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales [32mPASSED[0m
2026-01-14T08:50:21.0187184Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales_dont_change_per_channel [32mPASSED[0m
2026-01-14T08:50:21.0188466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0189576Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0190805Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0191954Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0193070Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0194186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:21.0195366Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0196496Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:21.0941850Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0944123Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0946355Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0948598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0950294Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0951430Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0952577Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0953714Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0954914Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0956041Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0957164Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0958295Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0959416Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0960553Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:21.0961690Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0962824Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:21.0964124Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0965254Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0966394Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0967677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0968830Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0970011Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0971177Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0972332Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0973480Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0974611Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0975757Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0976901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0978027Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0979183Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:21.0980323Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0981455Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:21.0982593Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0983716Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0985090Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0986250Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0987395Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0988537Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0989703Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0990860Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0992006Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0993263Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0994403Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0995598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.0996859Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.0998000Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:21.0999126Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.1000321Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:21.1001466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.1002592Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.1003740Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.1004882Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.1006026Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.1007176Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.1008324Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:21.1009487Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:21.1010779Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1012189Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1013592Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1581668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1583158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1584752Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1586227Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1587683Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1589128Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1590743Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1592170Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1593708Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1595202Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1596643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1598116Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1599590Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1601081Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1602495Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1603912Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1605351Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1606797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1608276Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1609741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.1611216Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.1612650Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1614069Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1615500Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1616938Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1618394Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1619870Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1621425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.1622883Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.1624414Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1625823Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1627256Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1628672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1630174Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1631649Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1633123Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1634602Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1636106Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1637527Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1638964Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1640400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1641847Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1643316Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1644785Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1646262Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1647708Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1649136Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.1650570Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.1652143Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2296325Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2297980Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2299455Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.2300980Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.2302424Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2303845Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2305289Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2306722Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2308169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2309654Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2311125Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.2312598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.2314049Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2315518Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2316925Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2318354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2319791Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2321258Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2322732Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2324210Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2325776Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2327201Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2330400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2331854Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2333330Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2334800Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2336276Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2337750Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2339189Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2340624Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2342081Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2343511Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2344989Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2346471Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2347927Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.2349403Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.2350847Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2352265Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2353702Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2355196Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2356637Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2358207Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2359679Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.2361276Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.2362744Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2364163Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2365636Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2367096Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2368582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2946652Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2948166Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2949657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2951119Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2952569Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2954010Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2955498Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2956955Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2958432Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2959946Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2961444Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2962911Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2964341Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2965914Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2967356Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2968956Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2970430Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2971932Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.2973445Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.2974898Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2976363Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2977827Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2979276Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2980761Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2982242Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2983741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.2985425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.2986873Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2988296Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2989713Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2991123Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2992564Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2994026Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2995518Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.2997142Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.2998570Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3000068Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3001503Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3002905Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3004346Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3005801Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3007257Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3008732Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3010170Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3011590Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3013009Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3014438Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3015894Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3017346Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3630136Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.3631626Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.3633078Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3634495Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3635975Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3637398Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3638994Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3640463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3642042Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.3643517Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.3644946Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3646359Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3647772Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3649200Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3650708Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3652158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3653631Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3655100Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3656533Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3657940Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3659377Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3660805Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3662274Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3663754Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3665224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3666719Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3668165Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3669589Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3671105Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3672553Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3674187Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3675702Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3677174Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.3678654Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.3680146Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3681586Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3683024Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3684630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3686073Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3687565Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3689057Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.3690539Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.3691986Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3693397Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3694825Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3696240Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3697686Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.3699150Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.3700625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4301158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4304059Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4307179Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4310282Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4312013Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4313781Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4315469Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4316945Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4318413Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4319851Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4321281Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4322698Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4324123Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4325591Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4327073Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4328529Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.4329997Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.4331431Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4332862Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4334311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4335739Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4337330Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4338798Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4340332Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.4341797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.4343237Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4344651Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4346083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4347543Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4348996Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4350518Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4351999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4353481Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4354982Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4356408Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4357839Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4359270Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4360720Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4362177Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4363667Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4365161Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4366615Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4368162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4376832Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4378428Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4379880Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4381350Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4382836Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.4384566Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.4969778Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4972657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4975514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4978426Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4980605Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4982093Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4983588Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.4985252Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.4986689Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4988121Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4989546Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4990978Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4992436Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4993903Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4995606Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.4997080Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.4998630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5000053Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5001489Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5002906Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5004374Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5005849Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5007323Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5008796Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5010289Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5011731Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5013161Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5014583Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5016041Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5017518Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5018996Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.5020472Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.5021915Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5023316Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5024741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5026290Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5027753Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5029314Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5030799Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.5032264Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.5033712Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5035188Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5036613Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5038023Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5039463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5040998Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5042494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5043969Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5045440Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5629663Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5631118Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5632567Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5634005Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5635536Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5636999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5638495Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5640094Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5641520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5643080Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5644501Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5645974Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5647461Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5648946Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.5650494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.5651949Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5653396Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5654822Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5656288Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5657775Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5659269Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5660745Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.5662218Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.5663672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5665047Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5666439Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5667828Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5669229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5670789Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5672230Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5673764Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5675239Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5676629Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5678021Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5679436Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5680914Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5682361Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5683791Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5685416Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5686853Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5688256Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5689664Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5691066Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5692506Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5693971Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.5695429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.5696878Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.5698309Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.5699718Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6296335Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6297766Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6299347Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6300804Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6302275Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.6303732Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.6305171Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6306571Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6307995Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6309428Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6310938Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6312398Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6313855Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6315387Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6316818Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6318219Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6319646Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6321071Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6322507Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6323971Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6325423Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6326902Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6328475Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6329883Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6331397Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6332833Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6334282Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6335763Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6337236Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.6338706Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.6340164Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6341589Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6343007Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6344437Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6345879Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6347357Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6348814Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.6350275Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.6351720Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6353139Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6354561Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6356033Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6357479Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6359032Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6360504Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6362074Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6363503Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6364907Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6366312Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6963335Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6964820Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6966286Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6967750Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6969226Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6970718Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6972140Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6973577Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6974998Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6976443Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6978219Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6979987Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.6981759Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.6983508Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6985195Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6986803Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6988236Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6989818Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6991286Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6992760Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.6994244Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.6995738Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.6997162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.6998587Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7000073Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7001522Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7003009Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7004507Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7005978Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7007416Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7008843Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7010262Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7011683Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7013132Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7014599Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7016077Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7017650Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7019088Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7020589Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7022017Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7023457Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7024929Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7026406Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7027895Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.7029378Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.7030833Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7032290Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7033730Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7035228Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7591732Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7593538Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7595274Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.7596733Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.7598162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7599560Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7600996Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7602395Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7603999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7605446Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7607004Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7608454Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7609907Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7611301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7612682Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7614078Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7615492Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7616931Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7618383Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7619829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7621256Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7622653Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7624058Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7625463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7626902Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7628345Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7629796Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.7631248Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.7632664Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7634140Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7635593Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7637099Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7638526Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7640032Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7641504Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7642980Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7644399Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7645793Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7647200Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7648611Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7650040Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7651499Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7652960Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7654436Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7655870Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7657274Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7658667Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.7660079Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.7661520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8180090Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8181761Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8183226Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8184947Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8186374Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8187786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8189204Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8190655Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8192114Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8193590Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:21.8195116Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:21.8196552Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8197966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8199386Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8200818Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8202259Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8203718Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8205195Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8206675Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8208106Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8209492Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8210977Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8212577Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8214029Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8215481Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8217026Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8218488Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8219909Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8221322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8222714Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8224110Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8225552Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8226999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8228462Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8229920Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8231354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8232744Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8234149Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8235613Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8237035Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8238512Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8240025Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8241518Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8242959Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8244478Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8245904Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8247409Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8248841Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8250302Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8741901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8743386Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8744837Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8746230Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8747620Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8749024Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8750472Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8751932Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8753408Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8754932Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8756350Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8757749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8759154Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8760577Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8762003Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8763457Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8765152Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8766631Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8768185Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8769607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8771072Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8772518Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8773966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8775448Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8776907Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8778386Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8779834Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8781248Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8782681Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8784274Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8785717Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8787195Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8788672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8790156Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8791589Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8792963Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8794352Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8795913Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8797315Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8798864Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8800303Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8801754Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8803172Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8804538Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8805954Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8807355Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8808783Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.8810289Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.8811743Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9305231Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9308089Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9310392Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9311799Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9313206Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9314645Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9323759Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9325213Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9326667Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9328279Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9329693Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9331207Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9332625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9334072Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9335545Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9337007Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9338475Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9339909Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9341359Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9342752Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9344176Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9345614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9347061Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9348509Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9349966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9351407Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9352816Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9354233Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9355726Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9357149Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9358674Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9360125Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9362459Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9363895Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9365303Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9366717Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9368126Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9369568Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9371036Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9372499Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9373968Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9375400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9376810Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9378247Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9379668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9381146Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9382617Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9384073Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9385823Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9875320Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9876712Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9878138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9879727Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9881169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9882733Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9884361Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9885818Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9887250Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9888642Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9890031Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9891429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9892859Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9894308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9895752Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9897204Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9898642Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9900060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9901460Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9902882Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9904318Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9905770Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9907248Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9908711Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9910311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9911733Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9913306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9914711Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9916210Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9917668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9919133Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9920614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9922031Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9923447Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9924872Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9926284Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9927710Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9929165Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9930616Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9932093Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9933528Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9934925Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9936338Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9937733Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9939157Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9940715Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9942171Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9943733Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:21.9945176Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:21.9946589Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0431651Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0433122Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0434574Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0436122Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0437579Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0439049Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0440500Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0441913Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0443344Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0444783Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0446221Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0447692Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0449167Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0450694Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0452134Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0453545Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0455107Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0456530Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0458093Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0459552Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0461004Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0462469Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0463874Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0465266Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0466679Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0468090Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0469521Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0470968Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0472428Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0473916Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0475397Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0476818Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0478243Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0479652Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0481143Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0482607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0484277Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0485882Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0487317Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0488839Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0490251Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0491687Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0493142Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0494609Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0496065Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0497542Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0498985Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0500416Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0501839Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0985590Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0987068Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0988531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0990004Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0991480Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0992914Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0994339Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0995787Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.0997211Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.0998839Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1000304Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1001770Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1003352Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1004786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1006206Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1007641Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1009079Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1010553Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1012016Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1013487Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1014975Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1016447Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1017853Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1019280Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1020772Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1022220Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1023690Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1025174Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1026657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1028086Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1029545Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1030931Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1032316Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1033806Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1035298Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1036728Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1038174Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1039582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1040952Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1042346Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1043753Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1045163Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1046591Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1048037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1049488Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1050950Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1052338Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1053738Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1055141Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1550625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1552119Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1553577Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1555248Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1556666Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1558157Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1559536Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1560936Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1562372Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1563814Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1565271Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1566737Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1568146Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1569524Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1570922Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1572322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1573737Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1575176Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1576628Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1578072Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1579479Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1580889Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1582292Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1583699Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1585355Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1586809Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1588376Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1589837Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1591327Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1592726Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1594145Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1595589Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1597046Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1598497Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1599950Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1601426Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1602858Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1604252Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1605668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1607084Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1608525Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1609975Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1611441Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1612897Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1614328Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1615878Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1617286Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1618697Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.1620264Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.1621724Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2106917Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2108663Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2110127Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2111562Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2112977Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2114393Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2115924Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2117363Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2118839Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2120315Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2121747Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2123169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2124602Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2126034Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2127490Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2128955Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2130408Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2133030Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2134446Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2135955Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2137383Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2138791Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2140228Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2141691Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2143158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2144610Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2146042Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2147436Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2148851Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2150284Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2151720Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2153181Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2154648Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2156174Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2157604Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2159002Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2160417Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2161826Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2163361Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2164824Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2166365Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2167833Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2169263Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2170676Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2172085Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2173531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2174981Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2176428Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2177904Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2703304Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2705042Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2706460Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2707877Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2709312Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2710812Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2712266Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2713738Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2715295Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2716722Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2718286Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2719674Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2721184Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2722619Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2724061Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2725513Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2726983Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2728422Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2729824Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2731225Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2732635Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2734056Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2735500Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2736973Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2738437Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2739873Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2741269Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2742687Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2744129Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2745559Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2747027Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2748603Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:22.2750064Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:22.2751579Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2752983Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2754375Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2755855Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2757294Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2758762Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2760226Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2761687Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2763124Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2764531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2765930Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2767337Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2768761Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2770222Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.2771673Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.2773132Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3294584Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3296249Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3297677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3299277Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3300706Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3302293Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3303764Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3305236Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3306688Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3308103Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3309531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3310959Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3312423Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3313901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3315477Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:22.3316955Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:22.3327383Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3328821Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3330246Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3331667Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3333119Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3334583Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3336042Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3337543Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3339111Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3340522Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3342028Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3343452Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3344875Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3346334Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3347786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3349256Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3350700Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3352107Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3353523Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3355007Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3356454Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3357923Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3359400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3360877Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3362309Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3363721Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3365141Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3366557Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3368004Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3369545Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3371005Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3372563Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3374010Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3843196Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3844753Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3846189Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3847662Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3849162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3850644Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3852134Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3853586Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3855005Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3856437Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3857856Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3859329Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3860786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3862252Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3863743Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3865209Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3866615Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3868273Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3869720Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3871306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3872789Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3874244Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3875808Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3877266Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3878701Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3880161Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3881629Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3883112Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3884779Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3886258Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3887741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3889200Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3890642Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3892092Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3893554Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3895007Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3896495Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3897976Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3899584Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3901050Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3902585Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3904011Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3905435Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3906865Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3908317Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3909789Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3911258Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.3912676Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.3914091Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4395214Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4396852Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4398306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4399768Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4401257Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4402733Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4404157Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4405579Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4407004Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4408429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4410022Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4411461Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4413030Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4414521Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4415979Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4417378Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4418797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4420210Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4421662Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4423108Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4424582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4426037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4427473Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4428893Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4430313Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4431770Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4433206Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4434677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4436224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4437693Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4439144Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4440559Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4442063Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4443481Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4445009Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4446472Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4447956Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4449424Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4450847Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4452295Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4453723Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4455169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4456634Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4458101Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4459593Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4461082Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4462520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4463969Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4465397Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4944850Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4948108Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4950572Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4952060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4953690Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4955202Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4956712Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4958115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4959537Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4960985Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4962446Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4963891Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4965346Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4966782Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4968176Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4969575Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4970989Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4972410Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4973849Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4975324Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4976779Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4978202Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4979643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4981070Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4982491Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4984045Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4985749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4987349Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4988821Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4990268Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4991681Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4993102Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4994542Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4996056Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.4997496Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.4998979Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5000442Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5001886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5003302Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5004707Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5006134Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5007596Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5009040Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5010514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5011981Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5013411Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5014950Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5016358Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5017872Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5475044Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5476679Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5478135Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5479599Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5481040Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5482471Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5483892Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5485494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5486942Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5488425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5489891Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5491351Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5492808Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5494215Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5495629Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5497064Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5498507Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5499963Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5501599Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5503065Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5504619Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5506014Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5507420Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5508836Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5510269Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5511795Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5513254Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5514701Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5516217Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5517621Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5519012Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5520455Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5521903Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5523352Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5524814Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5526275Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5527722Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5529132Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5530544Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5532145Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5533598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5535141Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5536588Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5538063Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5539509Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5540924Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5542351Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.5543785Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.5545217Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6029962Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6031695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6033184Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6034637Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6036115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6037523Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6038947Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6040410Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6041877Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6043324Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6044807Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6046437Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6047850Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6049363Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6050784Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6052238Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6053718Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6055191Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6056667Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6058122Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6059549Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6060979Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6062410Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6063848Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6065337Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6066824Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6068309Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6069764Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6071191Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6072611Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6074058Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6075570Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6077124Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6078598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6080172Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6081602Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6083006Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6084561Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6085961Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6087400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6088838Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6090280Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6091737Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6093155Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6094564Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6095986Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6097385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6098789Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6100217Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6579322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6581825Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6584977Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6587774Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6590596Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6592002Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6594330Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6595861Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6597306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6598784Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6600194Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6601574Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6602966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6604367Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6605788Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6607229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6608689Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6610150Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6611568Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6612967Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6614361Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6615759Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6617189Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6618634Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6620066Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6621595Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6623020Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6624510Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6625901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6627306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6628733Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6630185Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6631640Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6633093Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6634517Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6635978Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6637378Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6638799Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6640224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6641660Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6643121Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6644595Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6646014Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6647429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6648855Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6650276Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6651707Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.6653259Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.6654714Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7132475Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7134151Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7135554Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7136956Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7138357Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7139780Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7141286Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7142749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7144204Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7145608Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7147005Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7148407Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7149804Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7151237Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7152708Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7154170Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7155726Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7157150Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7158549Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7160094Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7161516Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7163031Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7164500Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7165973Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7167433Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7175918Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7177447Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7178876Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7180301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7181740Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7183193Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7185402Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7186881Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7188323Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7189728Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7191125Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7192535Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7193976Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7195470Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7196934Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7198576Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7200001Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7201530Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7202966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7204375Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7205820Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7207291Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7208775Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7210280Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7725783Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7727289Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7728721Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7730172Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7731624Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7733086Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7734575Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7736048Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7737498Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7738918Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7740343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7741775Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7743380Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7744836Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7746412Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7747886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7749306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7750686Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7752071Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7753473Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7754981Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7756404Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7757850Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7759291Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7760724Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7762125Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7763516Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7764913Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7766340Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7767779Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7769245Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7770708Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7772108Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7773620Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7775037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7776527Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7777970Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7779435Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7780897Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:22.7782344Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:22.7783772Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7785379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7786786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7788212Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7789656Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7791115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7792554Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.7794022Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.7795509Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8309885Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8311356Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8312793Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8314239Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8315782Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8317394Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8318841Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8320470Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8321878Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8323274Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8324687Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8326120Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8327581Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8329035Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8330496Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8331935Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8333356Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8334773Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8336209Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8337657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8339108Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8340570Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:50:22.8342046Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:50:22.8343473Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8344884Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8346313Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8347821Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8349271Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8350850Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8352328Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8353791Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8355281Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8356682Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8358088Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8359495Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8360955Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8362414Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8363865Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8365317Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8366773Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8368162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8369586Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8371006Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8372444Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8373912Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8375366Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8376814Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8378377Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8379799Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8859130Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8860912Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8862377Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8864054Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8865530Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8866999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8868754Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8870422Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8871847Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8873532Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8875293Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8876786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8878260Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8879733Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8881179Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8882791Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8884406Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8885857Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8887312Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8888950Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8890849Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8892342Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8893917Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8895590Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8897030Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8898472Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8900176Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8901866Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8903423Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8904998Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8906460Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8907904Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8909556Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8911008Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8912474Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8914138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8915654Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8917263Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8918709Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8920284Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8921745Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8923315Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8924745Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8926306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8927976Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8929471Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8930915Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.8932299Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.8933720Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9399103Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9400574Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9402031Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9403474Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9404922Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9406335Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9407723Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9409127Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9410549Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9411986Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9413435Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9414860Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9416311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9417901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9419294Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9420863Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9422288Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9423749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9425193Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9426667Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9428140Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9429565Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9430984Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9432425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9433834Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9435369Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9436801Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9438244Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9439698Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9441120Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9442501Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9443934Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9445345Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9446801Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9448346Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9449806Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9451333Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9452769Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9454164Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9455582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9457001Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9458417Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9459878Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9461341Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9462805Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9464257Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9465656Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9467082Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9468524Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9469975Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9960950Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9962455Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9963960Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9965400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9966838Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9968404Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9969829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9971385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9972851Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9974328Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9975814Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9977230Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9978618Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9980035Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9981447Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9982881Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9984483Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9985938Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9987418Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9988828Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9990227Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9991647Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9993033Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9994467Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9995984Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:22.9997429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:22.9998893Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0000489Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0001875Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0003380Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0004797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0006228Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0007688Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0009155Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0010643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0012102Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0013487Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0014912Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0016322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0017787Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0019253Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0020729Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0022187Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0023618Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0025014Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0026427Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0027861Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0029308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0030844Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0510818Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0512450Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0513882Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0515371Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0516793Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0518212Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0519671Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0521142Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0522637Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0524109Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0525555Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0527006Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0528439Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0529871Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0531338Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0532838Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0534322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0535829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0537263Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0538695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0540262Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0541750Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0543310Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0544789Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0546249Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0547730Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0549192Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0550592Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0552020Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0553447Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0554955Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0556417Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0557885Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0559377Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0560867Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0562266Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0563692Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0565115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0566586Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0568051Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0569534Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0571100Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0572553Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0574099Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0575530Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0576971Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0578449Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.0579935Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.0581420Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1060038Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1061523Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1062966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1064395Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1065825Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1067318Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1068776Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1070270Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1071819Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1073252Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1074686Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1076177Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1077622Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1079229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1080695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1082286Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1083784Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1085427Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1086838Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1088278Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1089723Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1091182Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1092666Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1094157Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1095636Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1097079Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1098511Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1099961Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1101423Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1102889Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1104362Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1105875Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1107364Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1108852Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1110412Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1111865Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1113433Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1114956Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1116443Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1117934Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1119435Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1120876Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1122268Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1123662Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1125059Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1126492Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1127915Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1129386Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1130893Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1619567Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1621006Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1622403Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1623808Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1625224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1626668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1628107Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1629719Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1631134Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1640402Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1641905Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1643298Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1644724Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1646148Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1647561Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1649001Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1650390Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1651754Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1653143Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1654541Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1655929Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1657346Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1658775Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1660205Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1661597Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1662982Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1664373Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1665758Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1667270Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1668687Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1670193Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1671648Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1673062Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1674436Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1675901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1677291Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1678712Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1680145Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1681586Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1683006Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1684720Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1686136Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1687530Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1688919Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1690351Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1691796Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1693229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1694658Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.1696067Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.1697601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2171354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2172961Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2174410Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2175894Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2177374Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2178835Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2180258Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2181679Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2183082Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2184659Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2186090Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2187535Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2188999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2190453Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2191879Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2193297Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2194713Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2196221Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2197673Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2199120Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2200716Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2202166Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2203602Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2205129Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2206568Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2207999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2209463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2210941Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2212416Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2213880Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2215308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2216742Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2218168Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2219597Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2221063Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2222543Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2224025Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2225509Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2226965Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2228387Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2229823Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2231244Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2232815Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2234281Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2235893Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2237384Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2238830Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.2240253Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.2241749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4893086Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4894572Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4896028Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4897494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4898966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4900436Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4901896Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4903338Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4904780Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4906250Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4907737Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4909234Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4910721Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4912178Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4913790Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4915304Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4917896Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4919362Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4920846Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4922330Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:50:23.4923824Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:50:23.4925123Z test/prototype/mx_formats/test_inference_workflow.py::VLLMIntegrationTestCase::test_narrow_similar_to_vllm [32mPASSED[0m
2026-01-14T08:50:23.4926260Z test/prototype/mx_formats/test_inference_workflow.py::VLLMIntegrationTestCase::test_nvfp4_quantize_3d_param_similar_to_vllm [32mPASSED[0m
2026-01-14T08:50:23.4927432Z test/prototype/mx_formats/test_inference_workflow.py::VLLMIntegrationTestCase::test_slice_and_copy_similar_to_vllm [32mPASSED[0m
2026-01-14T08:50:23.4928335Z test/prototype/mx_formats/test_kernels.py::test_fp32 [33mSKIPPED[0m (TODO d...)
2026-01-14T08:50:23.4929042Z test/prototype/mx_formats/test_kernels.py::test_bf16 [33mSKIPPED[0m (TODO d...)
2026-01-14T08:50:23.4929697Z test/prototype/mx_formats/test_kernels.py::test_fp16 [32mPASSED[0m
2026-01-14T08:50:23.4930322Z test/prototype/mx_formats/test_kernels.py::test_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:50:23.4931019Z test/prototype/mx_formats/test_kernels.py::test_float8_e5m2 [32mPASSED[0m
2026-01-14T08:50:23.4931685Z test/prototype/mx_formats/test_kernels.py::test_float4_e2m1_table [32mPASSED[0m
2026-01-14T08:50:23.4932374Z test/prototype/mx_formats/test_kernels.py::test_float6_e3m2_table [32mPASSED[0m
2026-01-14T08:50:23.4933041Z test/prototype/mx_formats/test_kernels.py::test_float6_e2m3_table [32mPASSED[0m
2026-01-14T08:50:23.4933687Z test/prototype/mx_formats/test_kernels.py::test_fp4_0_0 [32mPASSED[0m
2026-01-14T08:50:23.4934288Z test/prototype/mx_formats/test_kernels.py::test_fp4_0_5 [32mPASSED[0m
2026-01-14T08:50:23.4934886Z test/prototype/mx_formats/test_kernels.py::test_fp4_1_0 [32mPASSED[0m
2026-01-14T08:50:23.4935490Z test/prototype/mx_formats/test_kernels.py::test_fp4_1_5 [32mPASSED[0m
2026-01-14T08:50:23.4936080Z test/prototype/mx_formats/test_kernels.py::test_fp4_2_0 [32mPASSED[0m
2026-01-14T08:50:23.4936676Z test/prototype/mx_formats/test_kernels.py::test_fp4_3_0 [32mPASSED[0m
2026-01-14T08:50:23.4937267Z test/prototype/mx_formats/test_kernels.py::test_fp4_4_0 [32mPASSED[0m
2026-01-14T08:50:23.4937879Z test/prototype/mx_formats/test_kernels.py::test_fp4_6_0 [32mPASSED[0m
2026-01-14T08:50:23.4938519Z test/prototype/mx_formats/test_kernels.py::test_fp4_pack_unpack [32mPASSED[0m
2026-01-14T08:50:23.4939212Z test/prototype/mx_formats/test_kernels.py::test_fp6_values[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:23.4939933Z test/prototype/mx_formats/test_kernels.py::test_fp6_values[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:23.4940690Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[29.0-31-cpu] [32mPASSED[0m
2026-01-14T08:50:23.4941572Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[29.0-31-cuda] [32mPASSED[0m
2026-01-14T08:50:23.4942367Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[26.0-30-cpu] [32mPASSED[0m
2026-01-14T08:50:23.4943148Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[26.0-30-cuda] [32mPASSED[0m
2026-01-14T08:50:23.4943930Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.1251-2-cpu] [32mPASSED[0m
2026-01-14T08:50:23.4944789Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.1251-2-cuda] [32mPASSED[0m
2026-01-14T08:50:23.4945583Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.0314-1-cpu] [32mPASSED[0m
2026-01-14T08:50:23.4946370Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.0314-1-cuda] [32mPASSED[0m
2026-01-14T08:50:23.4947147Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.03-0-cpu] [32mPASSED[0m
2026-01-14T08:50:23.4947938Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.03-0-cuda] [32mPASSED[0m
2026-01-14T08:50:23.4948859Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-128-128] [33mSKIPPED[0m
2026-01-14T08:50:23.4949920Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-128-256] [33mSKIPPED[0m
2026-01-14T08:50:23.4950983Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-256-128] [33mSKIPPED[0m
2026-01-14T08:50:23.4952029Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-256-256] [33mSKIPPED[0m
2026-01-14T08:50:23.4953085Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-128-128] [33mSKIPPED[0m
2026-01-14T08:50:23.4954132Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-128-256] [33mSKIPPED[0m
2026-01-14T08:50:23.4955267Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-256-128] [33mSKIPPED[0m
2026-01-14T08:50:23.4956314Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-256-256] [33mSKIPPED[0m
2026-01-14T08:50:23.4957367Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-128-128] [33mSKIPPED[0m
2026-01-14T08:50:23.4958428Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-128-256] [33mSKIPPED[0m
2026-01-14T08:50:23.4959474Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-256-128] [33mSKIPPED[0m
2026-01-14T08:50:23.4960529Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-256-256] [33mSKIPPED[0m
2026-01-14T08:50:23.4961582Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-128-128] [33mSKIPPED[0m
2026-01-14T08:50:23.4962633Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-128-256] [33mSKIPPED[0m
2026-01-14T08:50:23.4963700Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-256-128] [33mSKIPPED[0m
2026-01-14T08:50:24.5228443Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-256-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5229540Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_zeros[ScaleCalculationMode.FLOOR] [33mSKIPPED[0m
2026-01-14T08:50:24.5230570Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_zeros[ScaleCalculationMode.RCEIL] [33mSKIPPED[0m
2026-01-14T08:50:24.5231553Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-128-128] [33mSKIPPED[0m
2026-01-14T08:50:24.5232478Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-128-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5233713Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-256-128] [33mSKIPPED[0m
2026-01-14T08:50:24.5234637Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-256-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5235662Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-128-128] [33mSKIPPED[0m
2026-01-14T08:50:24.5236791Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-128-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5237709Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-256-128] [33mSKIPPED[0m
2026-01-14T08:50:24.5238639Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-256-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5239454Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape0] [32mPASSED[0m
2026-01-14T08:50:24.5240170Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape1] [32mPASSED[0m
2026-01-14T08:50:24.5240852Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape2] [32mPASSED[0m
2026-01-14T08:50:24.5241523Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape3] [32mPASSED[0m
2026-01-14T08:50:24.5242205Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape4] [32mPASSED[0m
2026-01-14T08:50:24.5242883Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape5] [32mPASSED[0m
2026-01-14T08:50:24.5243590Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape6] [32mPASSED[0m
2026-01-14T08:50:24.5244273Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape7] [32mPASSED[0m
2026-01-14T08:50:24.5245209Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-32-32] [33mSKIPPED[0m
2026-01-14T08:50:24.5246367Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-32-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5247524Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-256-32] [33mSKIPPED[0m
2026-01-14T08:50:24.5248672Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-256-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5249825Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-32-32] [33mSKIPPED[0m
2026-01-14T08:50:24.5250962Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-32-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5252104Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-256-32] [33mSKIPPED[0m
2026-01-14T08:50:24.5253260Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-256-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5254399Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-32-32] [33mSKIPPED[0m
2026-01-14T08:50:24.5255539Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-32-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5256676Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-256-32] [33mSKIPPED[0m
2026-01-14T08:50:24.5257835Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-256-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5258973Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-32-32] [33mSKIPPED[0m
2026-01-14T08:50:24.5260107Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-32-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5261342Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-256-32] [33mSKIPPED[0m
2026-01-14T08:50:24.5262492Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-256-256] [33mSKIPPED[0m
2026-01-14T08:50:24.5263434Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim0_not_supported [33mSKIPPED[0m
2026-01-14T08:50:24.5264747Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.5266332Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.5267920Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.5269518Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.5271129Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.5272734Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.5274319Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.5275980Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.5277587Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.5279178Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.5280752Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.5282327Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.5283904Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.5285778Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.5287370Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.5288960Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.5290560Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.5292150Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.5293905Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.5295486Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.5297188Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.5298782Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.6183286Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.6185048Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.6186652Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.6188257Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.6189870Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.6191467Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.6193060Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.6194662Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.6196363Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.6197973Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.6199575Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.6201185Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.6202801Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.6204422Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.6206041Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.6207672Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.6209476Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.6211082Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.6212804Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.6214459Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.6216057Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.6217667Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.6219289Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.6220893Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.6222513Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.6224133Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.6225746Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.6227370Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.6229001Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.6230613Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.6232234Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.6233847Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.6235529Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.6237148Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.6238755Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.6240390Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.6242094Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.6243705Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.6245412Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.6247005Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.6248584Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.6250186Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.6251783Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.6253376Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.6254999Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.6256606Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.8570773Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.8572426Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.8574047Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.8575638Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.8577241Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.8578861Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.8580446Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.8582063Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.8583668Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.8585508Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.8587274Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.8588862Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.8590569Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.8592216Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.8593800Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.8595479Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.8597079Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.8598675Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.8600287Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.8601901Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.8603511Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.8605131Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.8606752Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.8608345Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.8609940Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.8611588Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.8613160Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.8614762Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.8616360Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.8617943Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.8619635Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.8621276Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.8622949Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.8624544Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.8626118Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.8627706Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.8629295Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.8630884Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.8632471Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.8634056Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.8635695Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.8637281Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.8638868Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.8640446Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.8642038Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.8643624Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.9385260Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.9386888Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:24.9388533Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:24.9390110Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:24.9391930Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:24.9393528Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:24.9395325Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.9396957Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.9398565Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.9400168Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.9401776Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.9403399Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.9404996Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.9406617Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.9408236Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.9409838Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.9411454Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.9413071Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.9414668Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.9416278Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.9417884Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.9419497Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.9421140Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.9422741Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.9424483Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.9426098Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.9427776Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.9429382Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.9430993Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.9432598Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.9434210Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.9435892Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.9437496Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.9439103Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.9440734Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.9442348Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.9452138Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.9453733Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.9455304Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.9456866Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.9458458Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:24.9460037Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:24.9461599Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:24.9463169Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:24.9464886Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:24.9466458Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2129365Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2131004Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2132568Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2134159Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2135728Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2137316Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2138894Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2140472Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2142092Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2143671Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2145252Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2146813Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2148380Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2149959Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2151520Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2153103Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2154683Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2156338Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2158083Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2159657Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2161372Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.2162948Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.2164516Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.2166096Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.2167669Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.2169242Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.2170827Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.2172413Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.2173986Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.2175562Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.2177143Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.2178711Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.2180284Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.2181872Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.2183437Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.2185279Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.2186862Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.2188439Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.2190153Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.2191746Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.2193432Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.2195094Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.2196694Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.2198262Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.2199838Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.2201424Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.2830491Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.2832527Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.2834169Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.2835862Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.2837507Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2839163Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2840795Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2842443Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2844089Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2845725Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2847379Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2849014Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2850846Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2852509Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2854280Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2855932Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2857594Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2859236Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2860876Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2862583Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2864222Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2865869Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2867519Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2869147Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2870784Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2872415Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2874040Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2875734Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2877368Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2878999Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2880635Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2882267Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2883996Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2885812Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2887548Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2889169Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2890782Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2892447Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2894066Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2895689Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2897307Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.2898933Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.2900557Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.2902170Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.2903812Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.2905439Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.5520258Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.5522017Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.5523622Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.5525214Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.5526810Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.5528420Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.5530177Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.5531776Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.5533483Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.5535061Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.5536650Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.5538247Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.5539827Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.5541475Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.5543083Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.5544667Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.5546275Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.5547875Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.5549463Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.5551074Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.5552741Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.5554334Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.5556025Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.5557635Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.5559239Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.5560848Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.5562534Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.5564146Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.5565829Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.5567419Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.5569012Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.5570623Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.5572264Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.5573871Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.5575473Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.5577068Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.5578678Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.5580281Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.5581940Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.5583536Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.5585421Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.5587016Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.5588624Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.5590229Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.5591843Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.5593455Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:50:25.6013053Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:50:25.6015111Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.6016952Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6018714Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6020343Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6021997Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6023633Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6025366Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6027097Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6028749Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6030419Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6032101Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6033842Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6035556Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6037273Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6038905Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6040520Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6042274Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6043894Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6045664Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6047412Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6049046Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6050898Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6052528Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6054265Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6055879Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6057470Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6059070Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6060794Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6062423Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6064160Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6065766Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6067367Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6069074Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6070674Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6072380Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6074013Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6075671Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6077257Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6078981Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6080777Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6082405Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6084247Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6085853Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6087591Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6089174Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6517909Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6519756Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6521403Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6523108Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6524722Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6526320Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6527909Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6529493Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6531191Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6532819Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6534471Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6536080Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6537672Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6539385Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:50:25.6541141Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:50:25.6542899Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:25.6544405Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn0-MXLinearRecipeName.MXFP8_CUBLAS] [33mSKIPPED[0m
2026-01-14T08:50:25.6545603Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn0-MXLinearRecipeName.MXFP4_CUTLASS] [33mSKIPPED[0m
2026-01-14T08:50:25.6546817Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn1-MXLinearRecipeName.MXFP8_CUBLAS] [33mSKIPPED[0m
2026-01-14T08:50:25.6548104Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn1-MXLinearRecipeName.MXFP4_CUTLASS] [33mSKIPPED[0m
2026-01-14T08:50:25.6549280Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn2-MXLinearRecipeName.MXFP8_CUBLAS] [33mSKIPPED[0m
2026-01-14T08:50:25.6550570Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn2-MXLinearRecipeName.MXFP4_CUTLASS] [33mSKIPPED[0m
2026-01-14T08:50:25.6551530Z test/prototype/mx_formats/test_mx_linear.py::test_activation_checkpointing [32mPASSED[0m
2026-01-14T08:50:25.6552777Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6554385Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6556181Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6557798Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6559497Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6561099Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6562670Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6564289Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6565950Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6567677Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6569301Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6570894Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6572499Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6574369Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6576073Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6577800Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6579385Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6580975Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6582703Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6584442Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6586160Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6587745Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6589300Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.6590869Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.6592571Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7095607Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7097407Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7099005Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7100922Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7103559Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7106184Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7108783Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7111204Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7113077Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7114664Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7116460Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7118073Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7119652Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7121256Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7122866Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7124442Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7126025Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7127591Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7129162Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7130743Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7132306Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7133869Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:25.7135424Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:25.7136488Z test/prototype/mx_formats/test_mx_linear.py::test_filter_fn [32mPASSED[0m
2026-01-14T08:50:25.7137172Z test/prototype/mx_formats/test_mx_linear.py::test_training_print_str [32mPASSED[0m
2026-01-14T08:50:25.7137949Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-128x128x128] [33mSKIPPED[0m
2026-01-14T08:50:25.7138773Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-256x256x256] [33mSKIPPED[0m
2026-01-14T08:50:25.7139605Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-384x384x384] [33mSKIPPED[0m
2026-01-14T08:50:25.7140431Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-512x512x512] [33mSKIPPED[0m
2026-01-14T08:50:25.7141249Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-768x768x768] [33mSKIPPED[0m
2026-01-14T08:50:25.7142102Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-1024x1024x1024] [33mSKIPPED[0m
2026-01-14T08:50:25.7142950Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-8192x8192x8192] [33mSKIPPED[0m
2026-01-14T08:50:25.7143883Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-128x256x384] [33mSKIPPED[0m
2026-01-14T08:50:25.7144695Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-256x384x512] [33mSKIPPED[0m
2026-01-14T08:50:25.7145522Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-129x256x384] [33mSKIPPED[0m
2026-01-14T08:50:25.7146338Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-133x512x528] [33mSKIPPED[0m
2026-01-14T08:50:25.7147248Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-128x128x128] [33mSKIPPED[0m
2026-01-14T08:50:25.7148078Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-256x256x256] [33mSKIPPED[0m
2026-01-14T08:50:25.7148895Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-384x384x384] [33mSKIPPED[0m
2026-01-14T08:50:25.7149725Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-512x512x512] [33mSKIPPED[0m
2026-01-14T08:50:25.7150555Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-768x768x768] [33mSKIPPED[0m
2026-01-14T08:50:25.7151404Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-1024x1024x1024] [33mSKIPPED[0m
2026-01-14T08:50:25.7152263Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-8192x8192x8192] [33mSKIPPED[0m
2026-01-14T08:50:25.7153100Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-128x256x384] [33mSKIPPED[0m
2026-01-14T08:50:25.7153930Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-256x384x512] [33mSKIPPED[0m
2026-01-14T08:50:25.7154746Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-129x256x384] [33mSKIPPED[0m
2026-01-14T08:50:25.7155635Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-133x512x528] [33mSKIPPED[0m
2026-01-14T08:50:25.7156445Z test/prototype/mx_formats/test_mx_serialization.py::test_serialization[mxfp8] [33mSKIPPED[0m
2026-01-14T08:50:25.7157245Z test/prototype/mx_formats/test_mx_serialization.py::test_serialization[nvfp4] [33mSKIPPED[0m
2026-01-14T08:50:25.7158012Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:25.7158756Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:25.7159489Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:25.7160207Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:25.7160935Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:25.7161909Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:50:25.7162989Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:50:25.7164074Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:50:25.7165126Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:50:25.7166191Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:50:25.7167269Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:50:25.7168330Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:50:25.7169394Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:50:25.7170543Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:50:37.5079647Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:50:37.5080754Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:50:37.5082222Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:50:37.5083275Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:50:37.5084581Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:50:37.5085652Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:50:37.5086674Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:50:37.5087709Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:50:37.5088787Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:50:37.5089857Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:50:37.5090910Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:50:37.5091804Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5092533Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5093263Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5093964Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5094675Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5095435Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5096193Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5096915Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5097615Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5098340Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5099034Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_rceil [32mPASSED[0m
2026-01-14T08:50:37.5099754Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5100525Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5101280Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5102031Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5102799Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5103566Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5104349Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5105134Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5105917Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5106864Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5107594Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5108292Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5108975Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5109775Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5110454Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5111179Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5111954Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5112714Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-fp6_e2m3] [33mSKIPPED[0m
2026-01-14T08:50:37.5113456Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-fp6_e3m2] [33mSKIPPED[0m
2026-01-14T08:50:37.5114210Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:50:37.5123366Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5124157Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5124895Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5125637Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5126368Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5127125Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5127890Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5128629Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5129367Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5130106Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5130850Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5131574Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5132279Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5132976Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5133684Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5134385Z test/prototype/mx_formats/test_mx_tensor.py::test_view[elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:37.5135061Z test/prototype/mx_formats/test_mx_tensor.py::test_view[elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:37.5135732Z test/prototype/mx_formats/test_mx_tensor.py::test_view[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5136392Z test/prototype/mx_formats/test_mx_tensor.py::test_view[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5137058Z test/prototype/mx_formats/test_mx_tensor.py::test_view[elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5137697Z test/prototype/mx_formats/test_mx_tensor.py::test_clone [32mPASSED[0m
2026-01-14T08:50:37.5138547Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:37.5139596Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:37.5140780Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5141771Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5142783Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5143909Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:37.5145084Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:37.5146358Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5147454Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5148480Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5149504Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:37.5150537Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:37.5151534Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:37.5152517Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:37.5153521Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:37.5154560Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:37.5155939Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:40.4670716Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:50:40.4672558Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:50:40.4674334Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-elem_dtype4] [32mPASSED[0m
2026-01-14T08:50:40.4676174Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_inductor_single_kernel [33mSKIPPED[0m
2026-01-14T08:50:40.4677723Z test/prototype/mx_formats/test_mx_tensor.py::test_index_select [32mPASSED[0m
2026-01-14T08:50:40.4679125Z test/prototype/mx_formats/test_mx_tensor.py::test_cast_to_float8_e4m3fn_saturation_behavior [33mSKIPPED[0m
2026-01-14T08:50:40.4680733Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape0] [32mPASSED[0m
2026-01-14T08:50:40.4682381Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape1] [32mPASSED[0m
2026-01-14T08:50:40.4684031Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape2] [32mPASSED[0m
2026-01-14T08:50:40.4686199Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape3] [32mPASSED[0m
2026-01-14T08:50:40.4687775Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape4] [32mPASSED[0m
2026-01-14T08:50:40.4689382Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape5] [32mPASSED[0m
2026-01-14T08:50:40.4690973Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape0] [32mPASSED[0m
2026-01-14T08:50:40.4693112Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape1] [32mPASSED[0m
2026-01-14T08:50:40.4694695Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape2] [32mPASSED[0m
2026-01-14T08:50:40.4696347Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape3] [32mPASSED[0m
2026-01-14T08:50:40.4698208Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape4] [32mPASSED[0m
2026-01-14T08:50:40.4699847Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape5] [32mPASSED[0m
2026-01-14T08:50:40.4701406Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape0-False] [32mPASSED[0m
2026-01-14T08:50:40.4702910Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape0-True] [32mPASSED[0m
2026-01-14T08:50:40.4704431Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape1-False] [32mPASSED[0m
2026-01-14T08:50:40.4705955Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape1-True] [33mSKIPPED[0m
2026-01-14T08:50:40.4707469Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:40.4708951Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:40.4710367Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:40.4711801Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:40.4713200Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:50:40.4714552Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:50:40.4716051Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:50:40.4717466Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:50:40.4718978Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype0-shape0-False] [32mPASSED[0m
2026-01-14T08:50:40.4720596Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype1-shape1-False] [32mPASSED[0m
2026-01-14T08:50:40.4722202Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype2-shape2-False] [32mPASSED[0m
2026-01-14T08:50:40.4723820Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype3-shape3-True] [32mPASSED[0m
2026-01-14T08:50:40.4725415Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype4-shape4-False] [32mPASSED[0m
2026-01-14T08:50:40.4727150Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape0-False] [32mPASSED[0m
2026-01-14T08:50:40.4728850Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape0-True] [32mPASSED[0m
2026-01-14T08:50:40.4730536Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape1-False] [32mPASSED[0m
2026-01-14T08:50:40.4732244Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape1-True] [32mPASSED[0m
2026-01-14T08:50:40.4733941Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape2-False] [32mPASSED[0m
2026-01-14T08:50:40.4735678Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape2-True] [32mPASSED[0m
2026-01-14T08:50:40.4737415Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape3-False] [32mPASSED[0m
2026-01-14T08:50:40.4739364Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape3-True] [32mPASSED[0m
2026-01-14T08:50:40.4741062Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape4-False] [32mPASSED[0m
2026-01-14T08:50:40.4742732Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape4-True] [32mPASSED[0m
2026-01-14T08:50:40.4744592Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_rows[0:128]] [32mPASSED[0m
2026-01-14T08:50:40.4746296Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_rows[128:256]] [32mPASSED[0m
2026-01-14T08:50:40.4747996Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:64]] [32mPASSED[0m
2026-01-14T08:50:40.4749662Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[64:128]] [32mPASSED[0m
2026-01-14T08:50:40.4751448Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:128]_full_width] [32mPASSED[0m
2026-01-14T08:50:40.4753324Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:2048]_tp_first_half] [32mPASSED[0m
2026-01-14T08:50:40.4755302Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[2048:4096]_tp_second_half] [32mPASSED[0m
2026-01-14T08:50:40.4757240Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:1024]_quarter] [32mPASSED[0m
2026-01-14T08:50:40.4759053Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[1024:2048]_quarter] [32mPASSED[0m
2026-01-14T08:50:40.4760878Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_row_end] [32mPASSED[0m
2026-01-14T08:50:40.4762724Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_row_start] [32mPASSED[0m
2026-01-14T08:50:40.4764537Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_col_32] [32mPASSED[0m
2026-01-14T08:50:40.4766360Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_col_start] [32mPASSED[0m
2026-01-14T08:50:40.4768178Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_col_end] [32mPASSED[0m
2026-01-14T08:50:40.4769943Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[odd_start] [32mPASSED[0m
2026-01-14T08:50:40.4771586Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[odd_end] [32mPASSED[0m
2026-01-14T08:50:40.4773158Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_view_semantics [32mPASSED[0m
2026-01-14T08:50:40.4774673Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_serialization [32mPASSED[0m
2026-01-14T08:50:40.4776195Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_get_scales_method [32mPASSED[0m
2026-01-14T08:50:40.4777957Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.4779836Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.4781748Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.4783568Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.4785758Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.4787886Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.4992969Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.4995026Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.4997191Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.4999138Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5001056Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5002873Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5004760Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5006679Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5008630Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5010547Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5012422Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5014334Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5016270Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5018161Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5020090Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5021978Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5023861Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5025795Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5027727Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5029651Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5031561Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5033452Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5035478Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5037388Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5039244Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5041404Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5043300Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5045322Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5047689Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5049674Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5051572Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5053499Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5055394Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5057748Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5059652Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5061534Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5063461Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5065377Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5067318Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5069277Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5071196Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5073015Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5074987Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5077280Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5079443Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5081385Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5083338Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5085642Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5087972Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5089893Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5092040Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5094001Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5095939Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5098106Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5100074Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5101970Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5103890Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5105955Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5108338Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5110272Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5112221Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5114170Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5319185Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5321157Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5323087Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5325006Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5327247Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5329244Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5331195Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5333105Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5335065Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5337041Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5338953Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5340901Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5342789Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5344935Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5347216Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5349332Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5351454Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5353387Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5355368Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5357724Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5359670Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5361595Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5363528Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5365446Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5367399Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5369344Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5371278Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5373075Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5374969Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5377273Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5379382Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5381281Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5383213Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5385456Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5387794Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5389668Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5391527Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5393445Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5395428Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5397558Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5399479Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5401405Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5403547Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5405503Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5407477Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5409419Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5411355Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5413285Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5415211Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5417190Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5419129Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5421065Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5423026Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5424949Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5426939Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5428868Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5430758Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5432720Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5434653Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5436661Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5438576Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5633549Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5635582Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5637504Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5639624Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5641507Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5643435Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5647751Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5649739Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5651641Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5653514Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5655446Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5657376Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5659302Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5661234Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5663126Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5665057Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5666892Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5668785Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5670669Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5672604Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5674508Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5676491Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5678442Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5680350Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5682272Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5684426Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5686372Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5688306Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5690239Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5692412Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5694343Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5696497Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5698427Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5700392Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5702303Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5704200Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5706161Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5708070Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5709983Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5711936Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5713841Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5715877Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5717824Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5719725Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5721665Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5723592Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5725528Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5727494Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5729434Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5731398Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5733395Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5735288Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5737109Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5739009Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5741163Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5743102Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5745053Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5747187Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5749145Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5751093Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5753077Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:50:40.5920053Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:50:40.5922037Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:50:40.5924011Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:50:40.5925955Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:50:40.5927878Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:50:40.5929840Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:50:40.5931913Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5934079Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5936342Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5938603Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5940796Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5942955Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5945217Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5947435Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5949619Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5951785Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5953998Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5956542Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5958722Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5960879Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5963167Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5965207Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5967436Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5969630Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5971833Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5974066Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5976326Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5978555Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5980786Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5983063Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5985528Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5987727Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5990120Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5992415Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5994631Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.5997014Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.5999260Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6001587Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6003837Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6006040Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6008494Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6010765Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6013004Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6015425Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6017675Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6019931Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6022211Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6024405Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6026612Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6028845Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6031111Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6033270Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6035567Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6037835Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6040031Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6203689Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6205989Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6208251Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6210485Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6212708Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6214993Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6217252Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6219513Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6222011Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6224210Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6226663Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6228905Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6231117Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6233340Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6235690Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6237923Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6240103Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6242281Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6244502Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6246706Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6248848Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6250962Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6253179Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6255370Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6257595Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6259802Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6262047Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6264282Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6266506Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6268738Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6270998Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6285889Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6288171Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6290626Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6292879Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6295082Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6297297Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6299524Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6301793Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6304059Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6306242Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6308482Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6310738Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6312989Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6315298Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6317569Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6319733Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6321865Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6324060Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6326249Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6328445Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6330679Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6332841Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6335060Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6491641Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6493908Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6496274Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6498520Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6500744Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6502954Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6505191Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6507420Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6509674Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6511892Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6514047Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6516367Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6518601Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6520817Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6522997Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6525264Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6527523Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6529756Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6531909Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6534163Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6536469Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6538697Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6540897Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6543298Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6545551Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6547991Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6550197Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6552401Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6554675Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6557341Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6559756Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6562025Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6564311Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6566849Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6569239Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6571449Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6573709Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6575975Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6578214Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6580444Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6582687Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6585183Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6587830Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6590184Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6592460Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6594726Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6597754Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6600020Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6602504Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6604773Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6606994Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6609242Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6611499Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6613651Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6780052Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6782347Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6784927Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6787182Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6789372Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6791550Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6793757Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6796047Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6798205Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6800421Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6802696Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6804932Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6807092Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6809285Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6811529Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6814013Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6816167Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6818539Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6820781Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6822997Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6825147Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6827344Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6829588Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6831796Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6833949Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6836245Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6838422Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6840576Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6842761Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6844928Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6847154Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6849366Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6851538Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6853443Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6855256Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6857177Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6859159Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6861154Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6863252Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6865382Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6867752Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6869976Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6872232Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6874388Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6876492Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6878551Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6880685Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6882817Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6885446Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6887794Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6890055Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6892397Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.6894520Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.6896711Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7491417Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7492811Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7494103Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7495437Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7496821Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7498124Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7499395Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7500937Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7502250Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7503696Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7504980Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7506290Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7507650Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7508671Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_to_copy [32mPASSED[0m
2026-01-14T08:50:40.7509546Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7510555Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7511578Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7512586Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7513586Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7514598Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7515685Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7516723Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7517708Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7518704Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7519688Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7520684Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7521674Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7522647Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7523631Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7524618Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7525597Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7526599Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7527593Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7528685Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7529669Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7530662Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7531766Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7532756Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7533759Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7534749Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7535751Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7536763Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7537755Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7538755Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7539731Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7540730Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7541728Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7542723Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7543728Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7544722Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7545727Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-False-False] [32mPASSED[0m
2026-01-14T08:50:40.7546765Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-False-True] [32mPASSED[0m
2026-01-14T08:50:40.7547754Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-True-False] [33mSKIPPED[0m
2026-01-14T08:50:40.7548753Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-True-True] [33mSKIPPED[0m
2026-01-14T08:50:40.7549648Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims0] [32mPASSED[0m
2026-01-14T08:50:40.7550444Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims1] [32mPASSED[0m
2026-01-14T08:50:40.7551230Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims2] [32mPASSED[0m
2026-01-14T08:50:40.7552005Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims3] [32mPASSED[0m
2026-01-14T08:50:40.7552782Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims0] [32mPASSED[0m
2026-01-14T08:50:40.7553555Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims1] [32mPASSED[0m
2026-01-14T08:50:40.7554332Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims2] [32mPASSED[0m
2026-01-14T08:50:40.7555296Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims3] [32mPASSED[0m
2026-01-14T08:50:40.7556281Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:40.7557436Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:40.7558657Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:50:40.7559802Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7301215Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7302436Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7303624Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7304765Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7305930Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7307150Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7308371Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7309605Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:50:45.7310842Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7312051Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7313265Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7314477Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7315760Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7316971Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:50:45.7318131Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_metadata_torchao [33mSKIPPED[0m
2026-01-14T08:50:45.7319198Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata0 [33mSKIPPED[0m
2026-01-14T08:50:45.7320301Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata1 [33mSKIPPED[0m
2026-01-14T08:50:45.7321400Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata2 [33mSKIPPED[0m
2026-01-14T08:50:45.7322496Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata3 [33mSKIPPED[0m
2026-01-14T08:50:45.7323586Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata4 [33mSKIPPED[0m
2026-01-14T08:50:45.7324682Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata5 [33mSKIPPED[0m
2026-01-14T08:50:45.7326247Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata6 [33mSKIPPED[0m
2026-01-14T08:50:45.7327346Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata7 [33mSKIPPED[0m
2026-01-14T08:50:45.7328627Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata8 [33mSKIPPED[0m
2026-01-14T08:50:45.7329742Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata9 [33mSKIPPED[0m
2026-01-14T08:50:45.7330588Z test/prototype/test_awq.py::TestAWQ::test_awq_config [32mPASSED[0m
2026-01-14T08:50:45.7331313Z test/prototype/test_awq.py::TestAWQ::test_awq_functionality_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:50:45.7332103Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:50:45.7332907Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_vllm_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:50:45.7333795Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook [33mSKIPPED[0m
2026-01-14T08:50:45.7334832Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook_row_grouping [33mSKIPPED[0m
2026-01-14T08:50:45.7335918Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [33mSKIPPED[0m
2026-01-14T08:50:45.7336982Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [33mSKIPPED[0m
2026-01-14T08:50:45.7338130Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float_row_grouping [33mSKIPPED[0m
2026-01-14T08:50:45.7339119Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_export [33mSKIPPED[0m
2026-01-14T08:50:45.7339977Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_quantize_api [33mSKIPPED[0m
2026-01-14T08:50:45.7340895Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook [32mPASSED[0m
2026-01-14T08:50:45.7341886Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:50:45.7342954Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [32mPASSED[0m
2026-01-14T08:50:45.7343892Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:50:45.7344698Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_accuracy [33mSKIPPED[0m
2026-01-14T08:50:45.7345513Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T08:50:45.7346977Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7348983Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7350934Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7352859Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7354951Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7356900Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7358924Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7360868Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7362812Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7364811Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7366887Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7368934Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7370995Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7496476Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7498610Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7500636Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7502683Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7504700Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7506753Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7508807Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7510971Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7512996Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7515185Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7517197Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7519282Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7521318Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7523336Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7525681Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7528283Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7530858Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7533410Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7535972Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7538577Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7541132Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7543770Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7546443Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7549010Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7551554Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7554095Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7556698Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7559242Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7561786Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7564320Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7670952Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7673485Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7676141Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7678770Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7681578Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7684479Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7687135Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7689846Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7692486Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7695130Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7697763Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7700393Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7703030Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7705660Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7708291Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7710912Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7713617Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7716393Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7719006Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7721610Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7724249Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7726882Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7729560Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7732173Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7734785Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7737393Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7739978Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7846399Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7849490Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7852478Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7855101Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7857816Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7860770Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7863356Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7865966Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7868578Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7871197Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7873818Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7876477Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7879516Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7882198Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7885112Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7887877Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7890726Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7893289Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7895864Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7898406Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7900973Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7903555Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7906105Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7909003Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.7911764Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.7914304Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.7916894Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8023511Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8026042Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8028645Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8031298Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8033934Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8037020Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8040286Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8043507Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8046736Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8049965Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8053184Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8056385Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8059146Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8061856Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8072662Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8075316Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8077932Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8080520Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8083100Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8086013Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8088621Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8091226Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8093835Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8096421Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8099183Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8101861Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8104417Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8196517Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8199176Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8201791Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8204414Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8207030Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8209677Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8212261Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8214853Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8217430Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8220001Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8222830Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8225415Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8228016Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8230547Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8233102Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8235709Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8238221Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8240754Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8243288Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8245798Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8248307Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8250811Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8253408Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8255990Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8258541Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8261057Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8263587Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8369764Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8372298Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8374905Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8377568Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8380272Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8382928Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8385755Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8388451Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8391245Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8394025Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8396699Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8399344Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8401959Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8404584Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8407207Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8409833Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8412455Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8415093Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8417735Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8420379Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8423110Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8425826Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8428453Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8431082Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8433708Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8436368Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8438987Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8540951Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8546084Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8549619Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8552253Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8554928Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8558606Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8561417Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8564020Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8566645Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8569315Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8571941Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8574520Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8577096Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8579714Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8582281Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8584983Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8587553Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8590109Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8592792Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8595497Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8598063Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8600630Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8603176Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8605725Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8608330Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8610884Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8613425Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8708983Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8711535Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8714145Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8717029Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8719824Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8722489Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8725123Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8727771Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8730384Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8733010Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8735648Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8738269Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8740900Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8743549Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8746180Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8748795Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8751505Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8754207Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8756863Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8759455Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8762036Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8764670Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8767318Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8769997Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8772627Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8775243Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8777868Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8880167Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8882954Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8885836Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8888443Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8891065Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8893680Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8896290Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8898947Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8901556Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8904161Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8906780Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8909388Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8911971Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8914663Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8917924Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8921049Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8924152Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8926728Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8929354Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8931913Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8934479Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8937040Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8939595Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8942155Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.8944710Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.8947241Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.8949883Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9048879Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9051423Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9054030Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9056661Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9059322Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9061969Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9064622Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9067269Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9069967Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9072610Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9075292Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9078008Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9080726Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9083358Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9086202Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9088848Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9091466Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9094087Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9096722Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9099338Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9101983Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9104646Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9107277Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9109917Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9112682Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9115469Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9118150Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9217482Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9220134Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9222754Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9225406Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9228102Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9230729Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9233336Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9236006Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9238633Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9241398Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9244104Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9246684Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9249270Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9251843Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9254404Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9256980Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9259544Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9262105Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9264653Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9267223Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9269784Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9272352Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9275151Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9277715Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9280322Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9282865Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9285635Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9385818Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9389639Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9392248Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9394940Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9398212Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9401436Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9404658Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9407443Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9410200Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9412825Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9415456Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9418072Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9420694Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9423324Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9425951Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9428559Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9431170Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9433794Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9436470Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9439174Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9441886Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9444525Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9447143Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9449767Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9452381Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9454992Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9457610Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9550309Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9552903Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9555585Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9558201Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9560808Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9563572Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9566307Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9568976Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9571577Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9574176Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9576783Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9579367Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9581929Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9584711Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9587286Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9589859Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9592398Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9595142Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9597815Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9600329Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9602864Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9605392Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9607938Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9610473Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9613026Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9615547Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9618133Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9720496Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9723061Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9725666Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9728450Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9731188Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9733825Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9736458Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9739147Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9741774Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9744424Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9747063Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9749693Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9752312Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9754985Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9757591Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9760389Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9763075Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9765694Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9768313Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9770935Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9773545Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9776178Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9778867Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9781486Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9784262Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9786890Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9789513Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9889182Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9891970Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9894603Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9897234Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9899869Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9902489Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9905096Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9907703Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9910363Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9912962Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9915792Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9918387Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9920950Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9923633Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9926273Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9928825Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9931383Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9933940Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9936490Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9939089Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9941644Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9944184Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9946723Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9949273Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:45.9951813Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:45.9954430Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:45.9957073Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0059880Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0062439Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0065032Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0067674Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0070315Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0072962Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0075644Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0078327Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0080962Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0083594Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0086419Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0089198Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0091935Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0094556Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0097177Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0099800Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0102416Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0105033Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0107647Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0110249Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0112879Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0115552Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0118168Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0120913Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0123615Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0126221Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0128902Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0248758Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0251388Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0254011Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0256629Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0259249Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0261868Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0264480Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0267083Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0269688Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:50:46.0272532Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:50:46.0275180Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0277531Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0279686Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0281870Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0284220Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0286432Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0288692Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0290866Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0292996Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0295187Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0297407Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0299607Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0301942Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0311248Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0313525Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0315981Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0318161Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0320355Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0322538Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0324673Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0456784Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0460364Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0464767Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0468476Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0470675Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0472840Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0475039Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0477346Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0479711Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0481916Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0484301Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0486466Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0488576Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0490740Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0492954Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0495156Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0497341Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0499504Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0501650Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0503822Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0506030Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0508356Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0510647Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0512813Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0515011Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0517191Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0519401Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0521603Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0523823Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:50:46.0525282Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_shared_embedding [33mSKIPPED[0m
2026-01-14T08:50:46.0526486Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0527961Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0529423Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0778728Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.0781723Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.0785210Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0788029Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0789543Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0791889Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.0793370Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.0795010Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0796487Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0797980Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0799471Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.0800956Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.0802437Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0803916Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0805379Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0806851Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.0808317Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.0809778Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0811250Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0812721Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0814185Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.0815670Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.0817158Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0818664Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0820128Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0821698Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.0823164Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.0824706Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0826167Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0827622Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0829101Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.0830552Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.0832012Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0833469Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0834968Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0836430Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.0837899Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.0839376Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0840833Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0842300Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0843749Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.0845207Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.0846676Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.0848147Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.0849602Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.0851152Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1101460Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1103108Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1104596Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1106047Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1107538Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1109005Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1110461Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1111924Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1113377Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1114891Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1116349Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1117806Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1119251Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1120706Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1122165Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1123621Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1125081Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1126526Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1127981Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1129594Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1131045Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1132581Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1134039Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1135488Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1136970Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1138482Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1139928Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1141372Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1142814Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1144257Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1145701Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1147152Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1148584Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1150032Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1151476Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1152921Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1154365Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1155853Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1157302Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1158874Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1160304Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1161866Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1163337Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1164778Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1166223Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1167659Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1421236Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1422707Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1424145Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1425601Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1427040Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1428559Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1430020Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1431488Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1432947Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1434399Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1435910Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1437374Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1438830Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1440454Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1441941Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1443506Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1444997Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1446459Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1447920Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1449395Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1450862Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1452316Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1453777Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1455257Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1456716Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1458177Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1459636Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1461097Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1462586Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1464039Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1465504Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1466974Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1468423Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1470053Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1471515Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1473043Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1474507Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1476269Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1478060Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1479844Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1481631Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1483089Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1484703Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1486177Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1487633Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1489135Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1741415Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1742910Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1744371Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1745818Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1747272Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1748735Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1750181Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1751789Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1753235Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1754796Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1756334Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1757809Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1759262Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1760714Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1762186Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1763637Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1765096Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1766561Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1768014Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1769483Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1770934Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1772384Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1773842Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1775291Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1776758Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1778238Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1779686Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1781259Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1782722Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1784542Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1786031Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1787489Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1788944Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1790428Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1791887Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1793331Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1794771Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1796285Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1797738Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1799226Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1800677Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.1802121Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.1803574Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.1805012Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.1806467Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.1807908Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2078255Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2079886Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2081325Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2082873Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2084525Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2085967Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2087411Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2088852Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2090299Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2091755Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2093184Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2094628Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2096067Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2097456Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2098802Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2100134Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2101461Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2102795Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2104139Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2105497Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2106822Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2108287Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2109627Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2110950Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2112369Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2113712Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2115099Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2116439Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2117754Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2119133Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2120446Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2121762Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2123077Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2124391Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2125720Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2127035Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:50:46.2128347Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:50:46.2129732Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2131242Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2132711Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2134163Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2135605Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2137078Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2138649Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2140092Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2141630Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2143118Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2144562Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2393643Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2395150Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2396625Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2398142Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2399591Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2401049Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2402505Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2403953Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2405393Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2406849Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2408322Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2409771Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2411216Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2412668Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2414115Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2415756Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2417307Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2418781Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2420218Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2421659Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2423100Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2424553Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2425989Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2427419Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2428857Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2430299Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2431730Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2433169Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2434603Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2436088Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2437527Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2439008Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2440462Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2441901Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2443328Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2444883Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2446317Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2447829Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2449302Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2450739Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2452176Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2453623Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2455067Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2456512Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2457989Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2459448Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2713426Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2716442Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2718533Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2719977Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2721431Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2722897Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2724340Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2725814Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2727265Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2729204Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2730989Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2732877Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2734674Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2745156Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2746638Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2748136Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2749585Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2751021Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2752452Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2753880Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2755366Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2756802Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2758226Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2759646Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2761072Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2762512Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2763938Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2765363Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2766791Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2768376Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2769829Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2771350Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2772801Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2774243Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2775704Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2777155Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2778657Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2780086Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2781518Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2782977Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2784666Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.2786130Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.2787568Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.2789012Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.2790480Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.2791944Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3033509Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3035030Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3036527Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3038166Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3039644Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3041236Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3042707Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3044185Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3045673Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3047142Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3048636Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3050107Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3051566Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3053052Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3054535Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3056001Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3057475Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3058947Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3060423Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3061907Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3063379Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3064839Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3066306Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3067847Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3069352Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3070892Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3072340Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3073796Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3075309Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3076777Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3078239Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3079699Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3081143Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3082606Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3084067Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3085737Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3087192Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3088642Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3090096Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3091541Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3092997Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3094438Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3095902Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3097499Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3099001Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3100583Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3353191Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3356198Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3358452Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3359912Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3361365Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3362825Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3364302Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3365791Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3367254Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3368715Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3370181Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3371647Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3373114Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3374583Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3376061Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3377524Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3378996Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3380617Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3382074Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3383653Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3385346Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3386818Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3388344Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3389796Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3391271Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3392744Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3394207Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3395708Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3397161Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3398623Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3400061Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3401524Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3402992Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3404440Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3405894Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3407330Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3408794Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3410421Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3411862Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3413411Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3414893Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3416335Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3417810Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3419291Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3420736Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3422184Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3669245Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3670714Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3672163Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3673633Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3675128Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3676596Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3678087Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3679558Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3681044Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3682519Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3684003Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3685884Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3687357Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3689005Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3690496Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3691971Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3693442Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3694908Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3696389Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3697860Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3699386Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3700855Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3702326Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3703801Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3705257Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3706729Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3708215Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3709690Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3711165Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3712633Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3714092Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3715752Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3717224Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3718756Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3720225Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3721695Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3723158Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3724631Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3726106Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3727558Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3729063Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3730515Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3731988Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3733453Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3734913Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3736367Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3989212Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3990715Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3992184Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.3993634Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.3995143Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.3996762Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.3998213Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.3999785Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4001249Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4002728Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4004198Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4005662Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4007136Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4008606Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4010073Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4011564Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4013026Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4014497Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4015980Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4017436Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4018967Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4020427Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4021891Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4023346Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4024815Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4026367Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4027832Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4029377Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4030836Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4032299Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4033769Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4035279Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4036760Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4038225Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4039680Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4041141Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4042597Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4044058Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4045512Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4046960Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4048471Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4049928Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4051372Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4052824Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4054278Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4055820Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4305135Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4307943Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4309416Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4310857Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4312317Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4313762Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4315281Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4316728Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4318168Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4319618Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4321077Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4322517Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4323964Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4325433Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4326907Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4328444Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4329924Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4331386Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4332859Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4334499Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4335957Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4337513Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4338997Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4340458Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4341927Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4343381Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4344842Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4346310Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4347765Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4349233Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4350694Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4352154Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4353616Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4355137Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4356597Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4358058Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4359525Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4360979Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4362433Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4363994Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4365436Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4366963Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4368470Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4369913Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4371363Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4372808Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4623253Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4626841Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4629218Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4631002Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4632799Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4634586Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4636152Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4637603Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4639064Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4640521Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4641986Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4643448Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4644901Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4646515Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4647998Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4649596Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4651066Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4652531Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4654004Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4655473Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4656935Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4658405Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4659869Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4661328Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4662801Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4664272Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4665733Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4667194Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4668656Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4670109Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4671583Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4673046Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4674494Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4676108Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4677577Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4679213Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4680683Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4682140Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4683608Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4685318Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4686778Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.4688248Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.4689703Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.4691154Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.4692625Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.4694068Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.5008509Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.5009981Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.5011431Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.5012870Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.5014326Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.5015787Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.5017227Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.5018839Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.5020289Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.5021835Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.5023299Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.5024744Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.5026185Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.5027640Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.5029148Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.5030585Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.5032032Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:50:46.5033481Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:50:46.5034972Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:50:46.5036432Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:50:46.5037875Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:50:46.5039063Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_bfloat16 [33mSKIPPED[0m
2026-01-14T08:50:46.5040017Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float16 [33mSKIPPED[0m
2026-01-14T08:50:46.5040962Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float32 [33mSKIPPED[0m
2026-01-14T08:50:46.5041856Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_choose_qparams_gguf [32mPASSED[0m
2026-01-14T08:50:46.5042774Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_gguf_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:50:46.5043641Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:50:46.5044681Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_00 [33mSKIPPED[0m
2026-01-14T08:50:46.5046204Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_01 [33mSKIPPED[0m
2026-01-14T08:50:46.5047809Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_02 [33mSKIPPED[0m
2026-01-14T08:50:46.5049498Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_03 [33mSKIPPED[0m
2026-01-14T08:50:46.5051062Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_04 [33mSKIPPED[0m
2026-01-14T08:50:46.5052718Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_05 [33mSKIPPED[0m
2026-01-14T08:50:46.5054287Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_06 [33mSKIPPED[0m
2026-01-14T08:50:46.5055858Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_07 [33mSKIPPED[0m
2026-01-14T08:50:46.5057431Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_08 [33mSKIPPED[0m
2026-01-14T08:50:46.5059055Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_09 [33mSKIPPED[0m
2026-01-14T08:50:46.5060628Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_10 [33mSKIPPED[0m
2026-01-14T08:50:46.5062208Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_11 [33mSKIPPED[0m
2026-01-14T08:50:46.5063776Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_12 [33mSKIPPED[0m
2026-01-14T08:50:46.5065348Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_13 [33mSKIPPED[0m
2026-01-14T08:50:46.5066917Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_14 [33mSKIPPED[0m
2026-01-14T08:50:46.5068489Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_15 [33mSKIPPED[0m
2026-01-14T08:50:46.5070034Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_00 [33mSKIPPED[0m
2026-01-14T08:50:46.5071543Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_01 [33mSKIPPED[0m
2026-01-14T08:50:46.5073061Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_02 [33mSKIPPED[0m
2026-01-14T08:50:46.5074587Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_03 [33mSKIPPED[0m
2026-01-14T08:50:46.5076197Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_04 [33mSKIPPED[0m
2026-01-14T08:50:46.5077716Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_05 [33mSKIPPED[0m
2026-01-14T08:50:46.5079224Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_06 [33mSKIPPED[0m
2026-01-14T08:50:46.5080748Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_07 [33mSKIPPED[0m
2026-01-14T08:50:46.5082270Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_08 [33mSKIPPED[0m
2026-01-14T08:50:46.5083774Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_09 [33mSKIPPED[0m
2026-01-14T08:50:46.5085538Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_10 [33mSKIPPED[0m
2026-01-14T08:50:56.0577837Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_11 [33mSKIPPED[0m
2026-01-14T08:50:56.0579443Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_12 [33mSKIPPED[0m
2026-01-14T08:50:56.0581612Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_13 [33mSKIPPED[0m
2026-01-14T08:50:56.0583132Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_14 [33mSKIPPED[0m
2026-01-14T08:50:56.0584853Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_15 [33mSKIPPED[0m
2026-01-14T08:50:56.0586286Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0587604Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0589015Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0590477Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0591944Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0593402Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0594915Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0596386Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0597843Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0599282Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0600736Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0602177Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0603622Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0605065Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0606509Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0607964Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0609402Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0610844Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0612300Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0613733Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0615426Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0616893Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0618467Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0619932Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0621370Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0622823Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0624289Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0625726Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0627179Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0628610Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0630030Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0631469Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0632920Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0634368Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0635889Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0637340Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0638788Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0640244Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0641702Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0643176Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0644629Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0646095Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0647566Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0649026Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0650490Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0652045Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0653500Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0655037Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0656490Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0657941Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0659402Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0660875Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0662378Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:50:56.0663825Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:50:56.0665278Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:51:02.5879552Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:51:02.5881035Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_False [32mPASSED[0m
2026-01-14T08:51:02.5882394Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_True [32mPASSED[0m
2026-01-14T08:51:02.5883690Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_False [32mPASSED[0m
2026-01-14T08:51:02.5885220Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_True [32mPASSED[0m
2026-01-14T08:51:02.5886538Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_False [32mPASSED[0m
2026-01-14T08:51:02.5887798Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_True [32mPASSED[0m
2026-01-14T08:51:02.5889063Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5890245Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5891420Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5892593Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5893753Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5894930Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5896105Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5897260Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5898425Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5900113Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5901275Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5902450Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5903613Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5904966Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5906137Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5907382Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5908553Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5909728Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5910896Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5912066Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5913235Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5914399Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5915658Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5916861Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5918043Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5919202Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5920372Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5921538Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5922707Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5923872Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5925033Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5926202Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5927311Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5928378Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5929450Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5930509Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5931571Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5932624Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5933693Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5934864Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5935918Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5936978Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5938028Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5939181Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5940249Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5941301Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5942369Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5943427Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5944485Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5945540Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5946597Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5947666Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5948716Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5949781Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5950848Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5951908Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5952969Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5954021Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5955165Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5956226Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5957293Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5958341Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5959404Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:51:02.5960460Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:51:02.5961563Z test/prototype/test_mixed_precision.py::TestWeightOnlyQuantNaive::test_quantization_intNwo [32mPASSED[0m
2026-01-14T08:51:02.5962615Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace [32mPASSED[0m
2026-01-14T08:51:02.5963595Z test/prototype/test_parametrization.py::TestFakeSparsity::test_masking_logic [32mPASSED[0m
2026-01-14T08:51:02.5964627Z test/prototype/test_parametrization.py::TestFakeSparsity::test_state_dict_preserved [32mPASSED[0m
2026-01-14T08:51:02.5965695Z test/prototype/test_parametrization.py::TestFakeSparsity::test_weights_parametrized [32mPASSED[0m
2026-01-14T08:51:03.1689872Z test/prototype/test_paretoq.py::TestParetoQ::test_quantize_functions [32mPASSED[0m
2026-01-14T08:51:03.1690888Z test/prototype/test_paretoq.py::TestParetoQ::test_quantized_linear [32mPASSED[0m
2026-01-14T08:51:03.1692250Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1693566Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1694927Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1696147Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1697375Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1698600Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1699812Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1701015Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1702238Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1703459Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1704677Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1705901Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1707111Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1708330Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1709537Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1710747Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1711965Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1713185Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1714403Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1715704Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1716921Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1718135Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1719336Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1720649Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1721863Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1723201Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1724418Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1725633Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1726843Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1728057Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1729257Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:51:03.1730470Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:51:03.1731483Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_e2e [33mSKIPPED[0m
2026-01-14T08:51:03.1732374Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_256 [33mSKIPPED[0m
2026-01-14T08:51:03.1733320Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_32 [33mSKIPPED[0m
2026-01-14T08:51:03.1734271Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_32 [32mPASSED[0m
2026-01-14T08:51:03.1735212Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_512 [32mPASSED[0m
2026-01-14T08:51:03.1736171Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_32 [32mPASSED[0m
2026-01-14T08:51:03.1737108Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_512 [32mPASSED[0m
2026-01-14T08:51:03.1738047Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_32 [32mPASSED[0m
2026-01-14T08:51:03.1739000Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_512 [32mPASSED[0m
2026-01-14T08:51:03.1739943Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_32 [32mPASSED[0m
2026-01-14T08:51:03.1740904Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_512 [32mPASSED[0m
2026-01-14T08:51:03.1741811Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_2 [32mPASSED[0m
2026-01-14T08:51:03.1742693Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_3 [32mPASSED[0m
2026-01-14T08:51:03.1743558Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_4 [32mPASSED[0m
2026-01-14T08:51:03.1744421Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_8 [32mPASSED[0m
2026-01-14T08:51:03.1745307Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only [32mPASSED[0m
2026-01-14T08:51:03.1746232Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_e2e [32mPASSED[0m
2026-01-14T08:51:03.1747220Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_parq_equivalent [32mPASSED[0m
2026-01-14T08:51:03.1748361Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_tied_embed_linear [32mPASSED[0m
2026-01-14T08:51:03.1749574Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:51:03.1750909Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:51:03.1752314Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:51:03.1753651Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:51:03.1755036Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:51:03.1756358Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:51:03.1757687Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:51:05.3764711Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:51:05.3766128Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:51:05.3767471Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:51:05.3768811Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:51:05.3770165Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:51:05.3771503Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:51:05.3772866Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:51:05.3774254Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:51:05.3775576Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:51:05.3776914Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:51:05.3778244Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:51:05.3779579Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:51:05.3780924Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:51:05.3782251Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:51:05.3783588Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:51:05.3785582Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:51:05.3786916Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:51:05.3788225Z test/prototype/test_parq.py::TestTorchAoConfigIntegration::test_tied_weights_quantization [32mPASSED[0m
2026-01-14T08:51:05.3789322Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity0 [33mSKIPPED[0m
2026-01-14T08:51:05.3790504Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity1 [33mSKIPPED[0m
2026-01-14T08:51:05.3791849Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:51:05.3793292Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:51:05.3794837Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:51:05.3796261Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:51:05.3797678Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:51:05.3799095Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:51:05.3800518Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:51:05.3801919Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:51:05.3803338Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:51:05.3804754Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:51:05.3806159Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:51:05.3807572Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:51:05.3809001Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:51:05.3810402Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:51:05.3811810Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:51:05.3813203Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:51:05.3814529Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity0 [33mSKIPPED[0m
2026-01-14T08:51:05.3815917Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity1 [33mSKIPPED[0m
2026-01-14T08:51:05.3817041Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_False [33mSKIPPED[0m
2026-01-14T08:51:05.3818063Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_True [33mSKIPPED[0m
2026-01-14T08:51:05.3819328Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_False [32mPASSED[0m
2026-01-14T08:51:05.3820656Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_True [32mPASSED[0m
2026-01-14T08:51:05.3821984Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_False [32mPASSED[0m
2026-01-14T08:51:05.3823313Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_True [32mPASSED[0m
2026-01-14T08:51:05.3824684Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_False [32mPASSED[0m
2026-01-14T08:51:05.3826030Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_True [32mPASSED[0m
2026-01-14T08:51:05.3827349Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_False [32mPASSED[0m
2026-01-14T08:51:05.3828676Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_True [32mPASSED[0m
2026-01-14T08:51:05.3829999Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_False [32mPASSED[0m
2026-01-14T08:51:05.3831309Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_True [32mPASSED[0m
2026-01-14T08:51:05.3832624Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_False [32mPASSED[0m
2026-01-14T08:51:05.3833946Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_True [32mPASSED[0m
2026-01-14T08:51:05.3835307Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_False [32mPASSED[0m
2026-01-14T08:53:04.6683004Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_True [32mPASSED[0m
2026-01-14T08:53:04.6684627Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_False [32mPASSED[0m
2026-01-14T08:53:04.6685948Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_True [32mPASSED[0m
2026-01-14T08:53:04.6687154Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_stochastic_rounding_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6688212Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_stochastic_rounding_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6689372Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6690645Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6692316Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6693575Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6695008Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6696288Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6697542Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6698798Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6700062Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6701318Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6702582Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6703846Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6705100Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6706408Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6707714Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6709009Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6710322Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6711619Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6712901Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6714192Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6715587Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6716896Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6718201Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6719493Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6720708Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_False_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6722004Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_False_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6723230Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_True_device_cpu [32mPASSED[0m
2026-01-14T08:53:04.6724501Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_True_device_cuda [32mPASSED[0m
2026-01-14T08:53:04.6725838Z test/prototype/test_quantized_training.py::TestFSDP2::test_fsdp2_correctness I0114 08:52:08.129000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 0 with pid 11132
2026-01-14T08:53:04.6727058Z I0114 08:52:08.130000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 1 with pid 11133
2026-01-14T08:53:04.6727675Z dist init r=0, world=2
2026-01-14T08:53:04.6727942Z dist init r=1, world=2
2026-01-14T08:53:04.6728904Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:53:04.6729925Z   return func(*args, **kwargs)
2026-01-14T08:53:04.6730896Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:53:04.6731899Z   return func(*args, **kwargs)
2026-01-14T08:53:04.6732861Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:53:04.6733871Z   return func(*args, **kwargs)
2026-01-14T08:53:04.6734846Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:53:04.6735854Z   return func(*args, **kwargs)
2026-01-14T08:53:04.6744221Z [32mPASSED[0m
2026-01-14T08:53:04.6745156Z test/prototype/test_quantized_training.py::TestFSDP2::test_precompute_bitnet_scale I0114 08:52:59.206000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 0 with pid 11388
2026-01-14T08:53:04.6746433Z I0114 08:52:59.207000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 1 with pid 11389
2026-01-14T08:53:04.6747043Z dist init r=1, world=2
2026-01-14T08:53:04.6747279Z dist init r=0, world=2
2026-01-14T08:53:04.6747585Z [32mPASSED[0m
2026-01-14T08:53:04.6748078Z test/prototype/test_scheduler.py::TestScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:53:04.6748792Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler [32mPASSED[0m
2026-01-14T08:53:04.6749524Z test/prototype/test_scheduler.py::TestScheduler::test_order_of_steps [32mPASSED[0m
2026-01-14T08:53:04.6750190Z test/prototype/test_scheduler.py::TestScheduler::test_step [32mPASSED[0m
2026-01-14T08:53:04.6750889Z test/prototype/test_scheduler.py::TestCubicScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:53:04.6751597Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step [32mPASSED[0m
2026-01-14T08:53:04.6752391Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_observer_insertion_base_config0 [32mPASSED[0m
2026-01-14T08:53:04.6753348Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_prepare_for_loading_base_config0 [32mPASSED[0m
2026-01-14T08:53:04.6754391Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_5_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:53:04.6755654Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_5_base_config0_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:53:04.6756961Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_75_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:53:04.6758143Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_75_base_config0_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:53:04.6759093Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:53:04.6759909Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_convert [32mPASSED[0m
2026-01-14T08:53:08.0386785Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:53:08.0387636Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params1 [32mPASSED[0m
2026-01-14T08:53:08.0388525Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params2 [32mPASSED[0m
2026-01-14T08:53:08.0389404Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params3 [32mPASSED[0m
2026-01-14T08:53:08.0390239Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_prepare_config [32mPASSED[0m
2026-01-14T08:53:08.0391023Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_state_dict [32mPASSED[0m
2026-01-14T08:53:08.0391741Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_step [32mPASSED[0m
2026-01-14T08:53:08.0392546Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:53:08.0393378Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:53:08.0394182Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:53:08.0395082Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:53:08.0395885Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step [32mPASSED[0m
2026-01-14T08:53:08.0396668Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step_2_of_4 [32mPASSED[0m
2026-01-14T08:53:08.0397502Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:53:08.0398351Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:53:08.0399193Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:53:08.0400042Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:53:08.0400879Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_step [32mPASSED[0m
2026-01-14T08:53:08.0401708Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module [32mPASSED[0m
2026-01-14T08:53:08.0402596Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_fail [32mPASSED[0m
2026-01-14T08:53:08.0403551Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_for_tensors [32mPASSED[0m
2026-01-14T08:53:08.0404524Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn [32mPASSED[0m
2026-01-14T08:53:08.0405539Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn_fail [32mPASSED[0m
2026-01-14T08:53:08.0406495Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn [32mPASSED[0m
2026-01-14T08:53:08.0407371Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_fail [32mPASSED[0m
2026-01-14T08:53:08.0408285Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_root [32mPASSED[0m
2026-01-14T08:53:08.0409248Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_lstm_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:53:08.0410507Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:53:08.0411492Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_complex_conv2d [32mPASSED[0m
2026-01-14T08:53:08.0412468Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:53:08.0413585Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_conv2d [32mPASSED[0m
2026-01-14T08:53:08.0414561Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_linear [32mPASSED[0m
2026-01-14T08:53:08.0415629Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_activation_conv2d [32mPASSED[0m
2026-01-14T08:53:08.0416723Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_bias_conv2d [32mPASSED[0m
2026-01-14T08:53:08.0417776Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_conv2d [32mPASSED[0m
2026-01-14T08:53:08.0418837Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_padding_conv2d [32mPASSED[0m
2026-01-14T08:53:08.0419927Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_pool_conv2d [32mPASSED[0m
2026-01-14T08:53:08.0421009Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_activation_linear [32mPASSED[0m
2026-01-14T08:53:08.0422093Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_bias_linear [32mPASSED[0m
2026-01-14T08:53:08.0423138Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_linear [32mPASSED[0m
2026-01-14T08:53:08.0424262Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:53:08.0425482Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_single_layer [32mPASSED[0m
2026-01-14T08:53:08.0426631Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:53:08.0427745Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_single_layer [32mPASSED[0m
2026-01-14T08:53:08.0428764Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_conv2d [32mPASSED[0m
2026-01-14T08:53:08.0429710Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_linear [32mPASSED[0m
2026-01-14T08:53:08.0430622Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_compute_distance [32mPASSED[0m
2026-01-14T08:53:08.0431452Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_update_mask [32mPASSED[0m
2026-01-14T08:53:08.0432374Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0433365Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0434354Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0435406Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0436385Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0437384Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0438367Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0439457Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0440451Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0441422Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0442478Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0443453Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0444421Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0445390Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0446361Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0447332Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0448312Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0449286Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0450264Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0451230Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0452202Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0453184Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0454152Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0455125Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:08.0456098Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:08.0457084Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8694364Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8695473Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8696501Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8697476Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8698459Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8699441Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8700447Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8701430Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8702402Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8703678Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8704650Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8705634Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8706731Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8707721Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8708710Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8709688Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8710674Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8711661Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8712637Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8713621Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8714592Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:53:10.8715633Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:53:10.8716501Z test/prototype/test_tensor_conversion.py::test_int4_tensor_conversion [33mSKIPPED[0m
2026-01-14T08:53:10.8717421Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_attention_block [33mSKIPPED[0m
2026-01-14T08:53:10.8718447Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d [33mSKIPPED[0m
2026-01-14T08:53:10.8719447Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:53:10.8720491Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:53:10.8721568Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:53:10.8722658Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_filter_linear_recipe [33mSKIPPED[0m
2026-01-14T08:53:10.8723684Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear [33mSKIPPED[0m
2026-01-14T08:53:10.8724677Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary [33mSKIPPED[0m
2026-01-14T08:53:10.8725746Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic [33mSKIPPED[0m
2026-01-14T08:53:10.8726857Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic_qat [33mSKIPPED[0m
2026-01-14T08:53:10.8727958Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_qat [33mSKIPPED[0m
2026-01-14T08:53:10.8728986Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d [33mSKIPPED[0m
2026-01-14T08:53:10.8730019Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:53:10.8731082Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:53:10.8733165Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:53:10.8734344Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case1 [33mSKIPPED[0m
2026-01-14T08:53:10.8735578Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case2 [33mSKIPPED[0m
2026-01-14T08:53:10.8736978Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:53:10.8738196Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig [33mSKIPPED[0m
2026-01-14T08:53:10.8739389Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_for_dynamic_quant [33mSKIPPED[0m
2026-01-14T08:53:10.8740652Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_with_underscores [33mSKIPPED[0m
2026-01-14T08:53:10.8741870Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:53:10.8742960Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_avgpool_use_different_qconfig [32mPASSED[0m
2026-01-14T08:53:10.8743935Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_add_quant_duplicate_dq [32mPASSED[0m
2026-01-14T08:53:10.8744890Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_need_for_duplicate_dq [32mPASSED[0m
2026-01-14T08:53:10.8745828Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_simple_duplicate_dq [32mPASSED[0m
2026-01-14T08:53:10.8746682Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu [32mPASSED[0m
2026-01-14T08:53:10.8747824Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244] Failed to reduce inequalities
2026-01-14T08:53:10.8749032Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244] Traceback (most recent call last):
2026-01-14T08:53:10.8750308Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/experimental/symbolic_shapes.py", line 3240, in solve
2026-01-14T08:53:10.8751619Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     self._dynamic_results.add(self._dcp.doprint(arg))
2026-01-14T08:53:10.8752875Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/printer.py", line 293, in doprint
2026-01-14T08:53:10.8754081Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self._str(self._print(expr))
2026-01-14T08:53:10.8755367Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/printer.py", line 332, in _print
2026-01-14T08:53:10.8756563Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return printmethod(expr, **kwargs)
2026-01-14T08:53:10.8757802Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/utils/_sympy/printers.py", line 29, in _print_Relational
2026-01-14T08:53:10.8759191Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self.stringify(expr.args, f" {expr.rel_op} ", precedence(expr))
2026-01-14T08:53:10.8760608Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 42, in stringify
2026-01-14T08:53:10.8761895Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return sep.join([self.parenthesize(item, level) for item in args])
2026-01-14T08:53:11.0406783Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 42, in <listcomp>
2026-01-14T08:53:11.0408100Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return sep.join([self.parenthesize(item, level) for item in args])
2026-01-14T08:53:11.0409409Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 39, in parenthesize
2026-01-14T08:53:11.0410587Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self._print(item)
2026-01-14T08:53:11.0411747Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/printer.py", line 332, in _print
2026-01-14T08:53:11.0412942Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return printmethod(expr, **kwargs)
2026-01-14T08:53:11.0414149Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/utils/_sympy/printers.py", line 20, in _print_Mul
2026-01-14T08:53:11.0415435Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self.stringify(expr.args, "*", precedence(expr))
2026-01-14T08:53:11.0416693Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 42, in stringify
2026-01-14T08:53:11.0417970Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return sep.join([self.parenthesize(item, level) for item in args])
2026-01-14T08:53:11.0419259Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 42, in <listcomp>
2026-01-14T08:53:11.0420561Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return sep.join([self.parenthesize(item, level) for item in args])
2026-01-14T08:53:11.0421847Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 39, in parenthesize
2026-01-14T08:53:11.0423005Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self._print(item)
2026-01-14T08:53:11.0424165Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/printer.py", line 332, in _print
2026-01-14T08:53:11.0425389Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return printmethod(expr, **kwargs)
2026-01-14T08:53:11.0426615Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/utils/_sympy/printers.py", line 75, in _print_Pow
2026-01-14T08:53:11.0427806Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     raise AssertionError(exp)
2026-01-14T08:53:11.0428633Z W0114 08:53:10.866000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244] AssertionError: 1/2
2026-01-14T08:53:11.0429230Z [32mPASSED[0m
2026-01-14T08:53:11.0430263Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244] Failed to reduce inequalities
2026-01-14T08:53:11.0431567Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244] Traceback (most recent call last):
2026-01-14T08:53:11.0432912Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/experimental/symbolic_shapes.py", line 3240, in solve
2026-01-14T08:53:11.0434216Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     self._dynamic_results.add(self._dcp.doprint(arg))
2026-01-14T08:53:11.0435545Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/printer.py", line 293, in doprint
2026-01-14T08:53:11.0436742Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self._str(self._print(expr))
2026-01-14T08:53:11.0437935Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/printer.py", line 332, in _print
2026-01-14T08:53:11.0439123Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return printmethod(expr, **kwargs)
2026-01-14T08:53:11.0440376Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/utils/_sympy/printers.py", line 29, in _print_Relational
2026-01-14T08:53:11.0441764Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self.stringify(expr.args, f" {expr.rel_op} ", precedence(expr))
2026-01-14T08:53:11.0443108Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 42, in stringify
2026-01-14T08:53:11.0444391Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return sep.join([self.parenthesize(item, level) for item in args])
2026-01-14T08:53:11.0445701Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 42, in <listcomp>
2026-01-14T08:53:11.0446997Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return sep.join([self.parenthesize(item, level) for item in args])
2026-01-14T08:53:11.0448312Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 39, in parenthesize
2026-01-14T08:53:11.0449465Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self._print(item)
2026-01-14T08:53:11.0450608Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/printer.py", line 332, in _print
2026-01-14T08:53:11.0451796Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return printmethod(expr, **kwargs)
2026-01-14T08:53:11.0453030Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/utils/_sympy/printers.py", line 20, in _print_Mul
2026-01-14T08:53:11.0454321Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self.stringify(expr.args, "*", precedence(expr))
2026-01-14T08:53:11.0455588Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 42, in stringify
2026-01-14T08:53:11.0456965Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return sep.join([self.parenthesize(item, level) for item in args])
2026-01-14T08:53:11.0458260Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 42, in <listcomp>
2026-01-14T08:53:11.0459629Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return sep.join([self.parenthesize(item, level) for item in args])
2026-01-14T08:53:11.0460924Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/str.py", line 39, in parenthesize
2026-01-14T08:53:11.0462071Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return self._print(item)
2026-01-14T08:53:11.0463236Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/sympy/printing/printer.py", line 332, in _print
2026-01-14T08:53:11.0464433Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     return printmethod(expr, **kwargs)
2026-01-14T08:53:11.0465650Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]   File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/utils/_sympy/printers.py", line 75, in _print_Pow
2026-01-14T08:53:11.0466858Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244]     raise AssertionError(exp)
2026-01-14T08:54:19.5587482Z W0114 08:53:11.039000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3244] AssertionError: 1/2
2026-01-14T08:54:19.5589983Z [32mPASSED[0m
2026-01-14T08:54:19.5590726Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_calculate_qparams [32mPASSED[0m
2026-01-14T08:54:19.5591884Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_disable_range_learning [32mPASSED[0m
2026-01-14T08:54:19.5592932Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_observer [32mPASSED[0m
2026-01-14T08:54:19.5593984Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_range_learning [32mPASSED[0m
2026-01-14T08:54:19.5595116Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_error_conditions [32mPASSED[0m
2026-01-14T08:54:19.5596232Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_and_observer_control [32mPASSED[0m
2026-01-14T08:54:19.5597372Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_control [32mPASSED[0m
2026-01-14T08:54:19.5598494Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_fake_quant_disabled [32mPASSED[0m
2026-01-14T08:54:19.5599617Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_learning_enabled [32mPASSED[0m
2026-01-14T08:54:19.5600714Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_observer_enabled [32mPASSED[0m
2026-01-14T08:54:19.5601789Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_gradient_scaling [32mPASSED[0m
2026-01-14T08:54:19.5602894Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_channel [32mPASSED[0m
2026-01-14T08:54:19.5604027Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_tensor [32mPASSED[0m
2026-01-14T08:54:19.5605165Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_backward_per_tensor [32mPASSED[0m
2026-01-14T08:54:19.5606590Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_forward_per_tensor [32mPASSED[0m
2026-01-14T08:54:19.5607715Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_per_channel_quantization [32mPASSED[0m
2026-01-14T08:54:19.5608791Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_state_persistence [32mPASSED[0m
2026-01-14T08:54:19.5610017Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_symmetric_quantization [32mPASSED[0m
2026-01-14T08:54:19.5611186Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_device_compatibility [32mPASSED[0m
2026-01-14T08:54:19.5612438Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_integration_with_linear_layer [32mPASSED[0m
2026-01-14T08:54:19.5613719Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_multiple_fake_quant_modules [32mPASSED[0m
2026-01-14T08:54:19.5615035Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_optimizer_updates_scale_and_zero_point [32mPASSED[0m
2026-01-14T08:54:19.5616333Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_training_mode_switching [32mPASSED[0m
2026-01-14T08:54:19.5617596Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_numerical_consistency_per_tensor [32mPASSED[0m
2026-01-14T08:54:19.5618814Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_serialization [32mPASSED[0m
2026-01-14T08:54:19.5619880Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq [33mSKIPPED[0m
2026-01-14T08:54:19.5620913Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq_no_static_q [32mPASSED[0m
2026-01-14T08:54:19.5621946Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_two_dq [32mPASSED[0m
2026-01-14T08:54:19.5623008Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_with_no_quant_inbetween [32mPASSED[0m
2026-01-14T08:54:19.5624039Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting [32mPASSED[0m
2026-01-14T08:54:19.5625080Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting_through_unknown_ops [32mPASSED[0m
2026-01-14T08:54:19.5626136Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_simple_metadata_porting [32mPASSED[0m
2026-01-14T08:54:19.5627149Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_added_node_gets_unique_id [32mPASSED[0m
2026-01-14T08:54:19.5628193Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_control_flow [33mSKIPPED[0m
2026-01-14T08:54:19.5629167Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_copy_preserve_handle [32mPASSED[0m
2026-01-14T08:54:19.5630183Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_deepcopy_preserve_handle [32mPASSED[0m
2026-01-14T08:54:19.5631274Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_prepare_for_propagation_comparison [32mPASSED[0m
2026-01-14T08:54:19.5632356Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_re_export_preserve_handle [32mPASSED[0m
2026-01-14T08:54:19.5633472Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_map_handle_to_new_nodes [32mPASSED[0m
2026-01-14T08:54:19.5634620Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_same_handle_id [32mPASSED[0m
2026-01-14T08:54:19.5635764Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_simple [32mPASSED[0m
2026-01-14T08:54:19.5636699Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval [32mPASSED[0m
2026-01-14T08:54:19.5637798Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval_idempotent [32mPASSED[0m
2026-01-14T08:54:19.5638857Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing [32mPASSED[0m
2026-01-14T08:54:19.5639864Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing_with_shared_input_edge [32mPASSED[0m
2026-01-14T08:54:19.5640835Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_chunked_bn_fusion [32mPASSED[0m
2026-01-14T08:54:19.5641760Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_linear_conv [32mPASSED[0m
2026-01-14T08:54:19.5642729Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_throw [32mPASSED[0m
2026-01-14T08:54:19.5643752Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_transform_for_annotation [32mPASSED[0m
2026-01-14T08:54:19.5644748Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_folding_pass [32mPASSED[0m
2026-01-14T08:54:19.5645699Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_prop_preserve_metadata [32mPASSED[0m
2026-01-14T08:54:19.5646600Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv3d_bn_relu [32mPASSED[0m
2026-01-14T08:54:19.5647465Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_padding_bn_relu [32mPASSED[0m
2026-01-14T08:54:19.5648368Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose3d_bn_relu [32mPASSED[0m
2026-01-14T08:54:19.5649286Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:54:19.5650153Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec [32mPASSED[0m
2026-01-14T08:54:19.5651033Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec_per_channel [32mPASSED[0m
2026-01-14T08:54:19.5651941Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_disallow_eval_train [32mPASSED[0m
2026-01-14T08:54:19.5652834Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_dont_fold_other_constant [32mPASSED[0m
2026-01-14T08:54:19.5653805Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_conv_linear_quantization [32mPASSED[0m
2026-01-14T08:54:19.5654756Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_quantizer [32mPASSED[0m
2026-01-14T08:54:19.5655710Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_observer_dedup [32mPASSED[0m
2026-01-14T08:54:19.5656694Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_ptq [32mPASSED[0m
2026-01-14T08:54:19.5657611Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_qat [32mPASSED[0m
2026-01-14T08:54:19.5658544Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_all_ops_before_quantize [32mPASSED[0m
2026-01-14T08:54:19.5659439Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize [32mPASSED[0m
2026-01-14T08:55:02.4413123Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize_per_channel [32mPASSED[0m
2026-01-14T08:55:02.4414418Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_groupwise_per_channel_quant [32mPASSED[0m
2026-01-14T08:55:02.4415624Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_input_edge_sanity_check [32mPASSED[0m
2026-01-14T08:55:02.4419043Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_max_pool2d_quantizer [32mPASSED[0m
2026-01-14T08:55:02.4420165Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported [32mPASSED[0m
2026-01-14T08:55:02.4421350Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_bn_device_cpu [32mPASSED[0m
2026-01-14T08:55:02.4422838Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_bn_device_cuda [32mPASSED[0m
2026-01-14T08:55:02.4424091Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout [32mPASSED[0m
2026-01-14T08:55:02.4425334Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout_inplace [32mPASSED[0m
2026-01-14T08:55:02.4426630Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_multi_users_without_output_observer [32mPASSED[0m
2026-01-14T08:55:02.4427815Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_observer_callback [32mPASSED[0m
2026-01-14T08:55:02.4428977Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_prepare_obs_or_fq_callback [32mPASSED[0m
2026-01-14T08:55:02.4430170Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_preserve_nn_module_stack [32mPASSED[0m
2026-01-14T08:55:02.4431504Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:55:02.4432861Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e5m2 [32mPASSED[0m
2026-01-14T08:55:02.4434147Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_int16 [32mPASSED[0m
2026-01-14T08:55:02.4435555Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:55:02.4436893Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e5m2 [32mPASSED[0m
2026-01-14T08:55:02.4438164Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_int16 [32mPASSED[0m
2026-01-14T08:55:02.4439278Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantize_in_place_ops input_act1 is a node
2026-01-14T08:55:02.4440032Z [32mPASSED[0m
2026-01-14T08:55:02.4440678Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant [32mPASSED[0m
2026-01-14T08:55:02.4442352Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_save_load W0114 08:55:01.535000 1007 site-packages/torch/export/pt2_archive/_package.py:693] Expect archive file to be a file ending in .pt2, or is a buffer. Instead got {/tmp/tmpr84emwyt}
2026-01-14T08:55:02.4444441Z W0114 08:55:01.547000 1007 site-packages/torch/export/pt2_archive/_package.py:1098] Unable to load package. f must be a buffer or a file ending in .pt2. Instead got {/tmp/tmpr84emwyt}
2026-01-14T08:55:02.4445483Z [32mPASSED[0m
2026-01-14T08:55:02.4446134Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec [32mPASSED[0m
2026-01-14T08:55:02.4447242Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity [32mPASSED[0m
2026-01-14T08:55:02.4448471Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity_case_2 [32mPASSED[0m
2026-01-14T08:55:02.4449623Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_simple_quantizer [32mPASSED[0m
2026-01-14T08:55:02.4450642Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_speed [32mPASSED[0m
2026-01-14T08:55:02.4451732Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_transform_for_annotation [32mPASSED[0m
2026-01-14T08:55:02.4452949Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_wo_annotate_conv_output_quantizer [32mPASSED[0m
2026-01-14T08:55:02.4454380Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_channel_group_quantization prepared model: GraphModule(
2026-01-14T08:55:02.4455296Z   (linear): Module()
2026-01-14T08:55:02.4455713Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:55:02.4456307Z   (activation_post_process_0): AffineQuantizedMinMaxObserver()
2026-01-14T08:55:02.4456760Z )
2026-01-14T08:55:02.4456969Z 
2026-01-14T08:55:02.4456975Z 
2026-01-14T08:55:02.4456991Z 
2026-01-14T08:55:02.4457103Z def forward(self, x):
2026-01-14T08:55:02.4457467Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:02.4457929Z     linear_weight = self.linear.weight
2026-01-14T08:55:02.4458565Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:55:02.4459234Z     linear_bias = self.linear.bias
2026-01-14T08:55:02.4459747Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:02.4460976Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:55:02.4462136Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:55:02.4462556Z     
2026-01-14T08:55:02.4462920Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:02.4463422Z quantized model GraphModule(
2026-01-14T08:55:02.4463755Z   (linear): Module()
2026-01-14T08:55:02.4464012Z )
2026-01-14T08:55:02.4464145Z 
2026-01-14T08:55:02.4464150Z 
2026-01-14T08:55:02.4464155Z 
2026-01-14T08:55:02.4464267Z def forward(self, x):
2026-01-14T08:55:02.4474095Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:02.4474554Z     _scale0 = self._scale0
2026-01-14T08:55:02.4474946Z     _zero_point0 = self._zero_point0
2026-01-14T08:55:02.4475363Z     quantize_affine = self._frozen_param0
2026-01-14T08:55:02.4476459Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:55:02.4477405Z     linear_bias = self.linear.bias
2026-01-14T08:55:02.4477686Z     _scale1 = self._scale1
2026-01-14T08:55:02.4477952Z     _zero_point1 = self._zero_point1
2026-01-14T08:55:02.4478547Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255);  x = None
2026-01-14T08:55:02.4479786Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine_1 = _scale1 = _zero_point1 = None
2026-01-14T08:55:02.4481187Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:55:02.4482021Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:55:02.4482377Z     
2026-01-14T08:55:02.4482679Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:02.4483143Z [32mPASSED[0m
2026-01-14T08:55:02.4483930Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_affine_act_per_channel_weights [32mPASSED[0m
2026-01-14T08:55:02.4485413Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_per_tok_act_per_group_weights prepared model: GraphModule(
2026-01-14T08:55:02.4486193Z   (linear): Module()
2026-01-14T08:55:02.4486532Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:55:02.4487056Z   (activation_post_process_0): AffineQuantizedPlaceholderObserver()
2026-01-14T08:55:02.4487460Z )
2026-01-14T08:55:02.4487564Z 
2026-01-14T08:55:02.4487750Z 
2026-01-14T08:55:02.4487754Z 
2026-01-14T08:55:02.4487847Z def forward(self, x):
2026-01-14T08:55:02.4488161Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:02.4488534Z     linear_weight = self.linear.weight
2026-01-14T08:55:02.4489059Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:55:02.4489597Z     linear_bias = self.linear.bias
2026-01-14T08:55:02.4490016Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:02.4491133Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:55:02.4492125Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:55:02.4492484Z     
2026-01-14T08:55:02.4492789Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:02.4493216Z quantized model GraphModule(
2026-01-14T08:55:02.4493479Z   (linear): Module()
2026-01-14T08:55:02.4493701Z )
2026-01-14T08:55:02.4493805Z 
2026-01-14T08:55:02.4493809Z 
2026-01-14T08:55:02.4493813Z 
2026-01-14T08:55:02.4493909Z def forward(self, x):
2026-01-14T08:55:02.4494210Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:02.4494573Z     _scale0 = self._scale0
2026-01-14T08:55:02.4494834Z     _zero_point0 = self._zero_point0
2026-01-14T08:55:02.4495149Z     quantize_affine = self._frozen_param0
2026-01-14T08:55:02.4496091Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.int8, -127, 127, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:55:02.4497034Z     linear_bias = self.linear.bias
2026-01-14T08:55:02.4497662Z     choose_qparams_affine = torch.ops.torchao.choose_qparams_affine(x, 'SYMMETRIC', (1, 128), torch.int8, -128, 127, None, None, None)
2026-01-14T08:55:02.4498326Z     getitem = choose_qparams_affine[0]
2026-01-14T08:55:02.4498728Z     getitem_1 = choose_qparams_affine[1];  choose_qparams_affine = None
2026-01-14T08:55:02.4499427Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), getitem, getitem_1, torch.int8, -128, 127);  x = None
2026-01-14T08:55:02.4500658Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), getitem, getitem_1, torch.int8, -128, 127, output_dtype = torch.float32);  quantize_affine_1 = getitem = getitem_1 = None
2026-01-14T08:55:02.4502045Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:56:15.1345099Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:56:15.1347715Z     
2026-01-14T08:56:15.1348400Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:15.1349163Z [32mPASSED[0m
2026-01-14T08:56:15.1350067Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_fold_bn_erases_bn_node [33mSKIPPED[0m
2026-01-14T08:56:15.1351506Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_bias_derived_qspec [33mSKIPPED[0m
2026-01-14T08:56:15.1352893Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion [33mSKIPPED[0m
2026-01-14T08:56:15.1354263Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:56:15.1355811Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_literal_args [33mSKIPPED[0m
2026-01-14T08:56:15.1357260Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:56:15.1358741Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_per_channel_weight_bias [33mSKIPPED[0m
2026-01-14T08:56:15.1360556Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion [33mSKIPPED[0m
2026-01-14T08:56:15.1361942Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:56:15.1363626Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:56:15.1365017Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_no_bias [33mSKIPPED[0m
2026-01-14T08:56:15.1366061Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn [33mSKIPPED[0m
2026-01-14T08:56:15.1367169Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn_relu [33mSKIPPED[0m
2026-01-14T08:56:15.1368264Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_inplace_add_relu [33mSKIPPED[0m
2026-01-14T08:56:15.1369393Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_per_channel_weight_custom_dtype [33mSKIPPED[0m
2026-01-14T08:56:15.1370573Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_preserve_source_fn_stack [33mSKIPPED[0m
2026-01-14T08:56:15.1371688Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_update_shared_qspec [33mSKIPPED[0m
2026-01-14T08:56:15.1372758Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T08:56:15.1373835Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T08:56:15.1374822Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T08:56:15.1375465Z   (conv): Module()
2026-01-14T08:56:15.1375688Z   (bn): Module()
2026-01-14T08:56:15.1376025Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:15.1377127Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:15.1378437Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:15.1379005Z   )
2026-01-14T08:56:15.1379204Z   (_guards_fn): GuardsFn()
2026-01-14T08:56:15.1379567Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:15.1380721Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0017, 0.0019, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:15.1382231Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2148, -0.0992, -0.2048]), max_val=tensor([0.0771, 0.2459, 0.3011]))
2026-01-14T08:56:15.1382961Z   )
2026-01-14T08:56:15.1383262Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:15.1384664Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:15.1386002Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4139440059661865)
2026-01-14T08:56:15.1386568Z   )
2026-01-14T08:56:15.1386762Z )
2026-01-14T08:56:15.1386867Z 
2026-01-14T08:56:15.1386872Z 
2026-01-14T08:56:15.1387018Z 
2026-01-14T08:56:15.1387114Z def forward(self, x):
2026-01-14T08:56:15.1387437Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:15.1387821Z     conv_weight = self.conv.weight
2026-01-14T08:56:15.1388116Z     conv_bias = self.conv.bias
2026-01-14T08:56:15.1388405Z     bn_weight = self.bn.weight
2026-01-14T08:56:15.1388674Z     bn_bias = self.bn.bias
2026-01-14T08:56:15.1389000Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:15.1389372Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:56:15.1389820Z     bn_running_var = self.bn.running_var
2026-01-14T08:56:15.1390233Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:56:15.1390702Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:56:15.1391287Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:15.1391887Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:56:15.1392335Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:56:15.1392787Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:56:15.1393273Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:56:15.1393827Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:56:15.1394461Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:56:15.1395206Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:56:15.1396366Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:56:15.1397376Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:56:15.1397970Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:56:15.1398623Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:56:15.1399245Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:56:15.1400278Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:56:15.1401393Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:56:15.1402056Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:15.1402492Z     
2026-01-14T08:56:15.1402811Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:15.1403213Z model fx: GraphModule(
2026-01-14T08:56:15.1403567Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:15.1404662Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:15.1405938Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:15.1406505Z   )
2026-01-14T08:56:15.1406703Z   (conv): ConvBn1d(
2026-01-14T08:56:15.1406950Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:56:15.1407405Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:56:15.1407941Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:15.1409073Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0017, 0.0019, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:15.1410685Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2148, -0.0992, -0.2048]), max_val=tensor([0.0771, 0.2459, 0.3011]))
2026-01-14T08:56:15.1411411Z     )
2026-01-14T08:56:15.1411593Z   )
2026-01-14T08:56:15.1411899Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:15.1413067Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:15.1414355Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4139440059661865)
2026-01-14T08:56:15.1414933Z   )
2026-01-14T08:56:15.1415115Z )
2026-01-14T08:56:15.1415221Z 
2026-01-14T08:56:15.1415226Z 
2026-01-14T08:56:15.1415230Z 
2026-01-14T08:56:15.1415329Z def forward(self, x):
2026-01-14T08:56:15.1415767Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:15.1416372Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:15.1416984Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:15.1417463Z     return activation_post_process_1
2026-01-14T08:56:15.1417754Z     
2026-01-14T08:56:15.1418059Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:15.1418478Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:15.1418735Z          [0., 0., 0.],
2026-01-14T08:56:44.8966259Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:44.8966722Z converted model pt2e: GraphModule(
2026-01-14T08:56:44.8967268Z   (conv): Module()
2026-01-14T08:56:44.8970234Z   (bn): Module()
2026-01-14T08:56:44.8970571Z   (_guards_fn): GuardsFn()
2026-01-14T08:56:44.8970900Z )
2026-01-14T08:56:44.8971055Z 
2026-01-14T08:56:44.8971060Z 
2026-01-14T08:56:44.8971065Z 
2026-01-14T08:56:44.8971197Z def forward(self, x):
2026-01-14T08:56:44.8971566Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:44.8972022Z     conv_bias = self.conv.bias
2026-01-14T08:56:44.8972418Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:44.8973341Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:56:44.8975037Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:44.8976292Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:56:44.8976994Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:44.8977633Z     _scale_0 = self._scale_0
2026-01-14T08:56:44.8977957Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:56:44.8978352Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:56:44.8979576Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:56:44.8981484Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:56:44.8983168Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011089790612459183, 0, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:56:44.8985289Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011089790612459183, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:44.8986964Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:56:44.8987513Z     
2026-01-14T08:56:44.8987881Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:44.8988385Z onverted model fx: GraphModule(
2026-01-14T08:56:44.8988862Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:56:44.8989353Z )
2026-01-14T08:56:44.8989481Z 
2026-01-14T08:56:44.8989486Z 
2026-01-14T08:56:44.8989491Z 
2026-01-14T08:56:44.8989777Z def forward(self, x):
2026-01-14T08:56:44.8990610Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:44.8992432Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:44.8993579Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:44.8994530Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011089790612459183, 0, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:44.8996062Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011089790612459183, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:44.8997060Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:44.8997355Z     
2026-01-14T08:56:44.8997652Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:44.8998052Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:44.8998301Z          [0., 0., 0.],
2026-01-14T08:56:44.8998525Z          [0., 0., 0.]]])
2026-01-14T08:56:44.8998763Z model pt2e: GraphModule(
2026-01-14T08:56:44.8999007Z   (conv): Module()
2026-01-14T08:56:44.8999222Z   (bn): Module()
2026-01-14T08:56:44.8999541Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:44.9000613Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:44.9001877Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:44.9002440Z   )
2026-01-14T08:56:44.9002643Z   (_guards_fn): GuardsFn()
2026-01-14T08:56:44.9003004Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:44.9004085Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:44.9005352Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.214811772108078, max_val=0.30109599232673645)
2026-01-14T08:56:44.9005929Z   )
2026-01-14T08:56:44.9006221Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:44.9007312Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:44.9008583Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4138529300689697)
2026-01-14T08:56:44.9009130Z   )
2026-01-14T08:56:44.9009316Z )
2026-01-14T08:56:44.9009418Z 
2026-01-14T08:56:44.9009422Z 
2026-01-14T08:56:44.9009426Z 
2026-01-14T08:56:44.9009524Z def forward(self, x):
2026-01-14T08:56:44.9009834Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:44.9010209Z     conv_weight = self.conv.weight
2026-01-14T08:56:44.9010500Z     conv_bias = self.conv.bias
2026-01-14T08:56:44.9010879Z     bn_weight = self.bn.weight
2026-01-14T08:56:44.9011143Z     bn_bias = self.bn.bias
2026-01-14T08:56:44.9011460Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:44.9011829Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:56:44.9012156Z     bn_running_var = self.bn.running_var
2026-01-14T08:56:44.9012556Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:56:44.9013014Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:56:44.9013663Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:44.9014258Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:56:44.9014688Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:56:44.9015137Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:56:44.9015619Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:56:44.9016164Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:56:44.9016790Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:56:44.9017466Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:56:44.9018563Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:56:44.9019564Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:56:44.9020154Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:56:44.9020782Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:56:44.9021396Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:56:44.9022416Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:56:44.9023496Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:56:44.9024149Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:44.9024557Z     
2026-01-14T08:56:44.9024861Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:44.9025283Z model fx: GraphModule(
2026-01-14T08:56:44.9025642Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:44.9026713Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:44.9027981Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:44.9028543Z   )
2026-01-14T08:56:44.9028730Z   (conv): ConvBn1d(
2026-01-14T08:56:44.9028970Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:56:44.9029405Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:56:44.9029931Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:44.9030967Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:44.9032253Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.214811772108078, max_val=0.30109599232673645)
2026-01-14T08:56:44.9032826Z     )
2026-01-14T08:56:44.9033015Z   )
2026-01-14T08:56:44.9033316Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:44.9034474Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:44.9035789Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4138529300689697)
2026-01-14T08:56:44.9036356Z   )
2026-01-14T08:56:44.9036531Z )
2026-01-14T08:56:44.9036637Z 
2026-01-14T08:56:44.9036720Z 
2026-01-14T08:56:44.9036725Z 
2026-01-14T08:56:44.9036821Z def forward(self, x):
2026-01-14T08:56:44.9037198Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:44.9037789Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:57:27.8961055Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:57:27.8961563Z     return activation_post_process_1
2026-01-14T08:57:27.8961852Z     
2026-01-14T08:57:27.8962170Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:27.8962569Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:57:27.8962828Z          [0., 0., 0.],
2026-01-14T08:57:27.8963083Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:57:27.8963412Z converted model pt2e: GraphModule(
2026-01-14T08:57:27.8963684Z   (conv): Module()
2026-01-14T08:57:27.8963915Z   (bn): Module()
2026-01-14T08:57:27.8964145Z   (_guards_fn): GuardsFn()
2026-01-14T08:57:27.8964387Z )
2026-01-14T08:57:27.8964489Z 
2026-01-14T08:57:27.8964494Z 
2026-01-14T08:57:27.8964497Z 
2026-01-14T08:57:27.8964591Z def forward(self, x):
2026-01-14T08:57:27.8964899Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:27.8965260Z     conv_bias = self.conv.bias
2026-01-14T08:57:27.8965581Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:57:27.8966359Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:57:27.8967719Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:27.8968724Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:57:27.8969312Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:57:27.8969866Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:57:27.8970737Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002370834583416581, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:57:27.8972150Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:57:27.8973486Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.01108943298459053, 0, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:57:27.8974908Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01108943298459053, 0, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:57:27.8976024Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:57:27.8976460Z     
2026-01-14T08:57:27.8976768Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:27.8977183Z onverted model fx: GraphModule(
2026-01-14T08:57:27.8977585Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:57:27.8978001Z )
2026-01-14T08:57:27.8978109Z 
2026-01-14T08:57:27.8978363Z 
2026-01-14T08:57:27.8978368Z 
2026-01-14T08:57:27.8978463Z def forward(self, x):
2026-01-14T08:57:27.8979142Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:57:27.8980483Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:27.8981755Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:57:27.8982695Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01108943298459053, 0, -128, 127, torch.int8);  conv = None
2026-01-14T08:57:27.8984268Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01108943298459053, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:27.8985248Z     return dequantize_per_tensor_default_1
2026-01-14T08:57:27.8985538Z     
2026-01-14T08:57:27.8985846Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:27.8986252Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:57:27.8986498Z          [0., 0., 0.],
2026-01-14T08:57:27.8986728Z          [0., 0., 0.]]])
2026-01-14T08:57:27.8987167Z [32mPASSED[0m
2026-01-14T08:57:27.8987794Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_cuda model pt2e: GraphModule(
2026-01-14T08:57:27.8988450Z   (conv): Module()
2026-01-14T08:57:27.8988669Z   (bn): Module()
2026-01-14T08:57:27.8988993Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:27.8990343Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:27.8991833Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:57:27.8992392Z   )
2026-01-14T08:57:27.8992591Z   (_guards_fn): GuardsFn()
2026-01-14T08:57:27.8992951Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:27.8994319Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:57:27.8996209Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:57:27.8997025Z   )
2026-01-14T08:57:27.8997322Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:27.8998613Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:27.9000093Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3958139419555664, max_val=1.4123148918151855)
2026-01-14T08:57:27.9000659Z   )
2026-01-14T08:57:27.9000834Z )
2026-01-14T08:57:27.9000944Z 
2026-01-14T08:57:27.9000948Z 
2026-01-14T08:57:27.9000952Z 
2026-01-14T08:57:27.9001040Z def forward(self, x):
2026-01-14T08:57:27.9001357Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:27.9001722Z     conv_weight = self.conv.weight
2026-01-14T08:57:27.9002014Z     conv_bias = self.conv.bias
2026-01-14T08:57:27.9002451Z     bn_weight = self.bn.weight
2026-01-14T08:57:27.9002720Z     bn_bias = self.bn.bias
2026-01-14T08:57:27.9003028Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:57:27.9003397Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:57:27.9003718Z     bn_running_var = self.bn.running_var
2026-01-14T08:57:27.9004112Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:57:27.9004582Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:57:27.9005282Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:57:27.9005890Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:57:27.9006316Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:57:27.9016699Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:57:27.9017406Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:57:27.9018039Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:57:27.9018962Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:57:27.9020204Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:57:27.9021403Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:57:27.9022401Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:57:27.9022980Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:57:27.9023608Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:57:27.9024207Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:57:27.9025234Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:57:27.9026329Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:57:27.9026964Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:57:27.9027380Z     
2026-01-14T08:57:27.9027677Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:27.9028080Z model fx: GraphModule(
2026-01-14T08:57:27.9028423Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:27.9029703Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:27.9031197Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:57:27.9031749Z   )
2026-01-14T08:57:27.9031941Z   (conv): ConvBn1d(
2026-01-14T08:57:27.9032172Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:57:27.9032620Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:57:27.9033134Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:27.9034478Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:57:58.5456953Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:57:58.5459269Z     )
2026-01-14T08:57:58.5459519Z   )
2026-01-14T08:57:58.5459911Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:58.5461531Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:58.5463040Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3958139419555664, max_val=1.4123148918151855)
2026-01-14T08:57:58.5463611Z   )
2026-01-14T08:57:58.5463801Z )
2026-01-14T08:57:58.5463912Z 
2026-01-14T08:57:58.5463916Z 
2026-01-14T08:57:58.5463920Z 
2026-01-14T08:57:58.5464012Z def forward(self, x):
2026-01-14T08:57:58.5464399Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:57:58.5464999Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:57:58.5465606Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:57:58.5466067Z     return activation_post_process_1
2026-01-14T08:57:58.5466349Z     
2026-01-14T08:57:58.5466650Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:58.5467060Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:57:58.5467311Z          [0., 0., 0.],
2026-01-14T08:57:58.5467616Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:57:58.5467994Z converted model pt2e: GraphModule(
2026-01-14T08:57:58.5468267Z   (conv): Module()
2026-01-14T08:57:58.5468510Z   (bn): Module()
2026-01-14T08:57:58.5468736Z   (_guards_fn): GuardsFn()
2026-01-14T08:57:58.5468981Z )
2026-01-14T08:57:58.5469085Z 
2026-01-14T08:57:58.5469090Z 
2026-01-14T08:57:58.5469094Z 
2026-01-14T08:57:58.5469190Z def forward(self, x):
2026-01-14T08:57:58.5469504Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:58.5469871Z     conv_bias = self.conv.bias
2026-01-14T08:57:58.5470195Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:57:58.5470939Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8)
2026-01-14T08:57:58.5472289Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:58.5473295Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:57:58.5473867Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:57:58.5474384Z     _scale_0 = self._scale_0
2026-01-14T08:57:58.5474664Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:57:58.5475098Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:57:58.5476096Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:57:58.5477612Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:57:58.5478987Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011012271046638489, -1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:57:58.5480437Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011012271046638489, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:58.5481562Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:57:58.5482093Z     
2026-01-14T08:57:58.5482396Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:58.5482799Z onverted model fx: GraphModule(
2026-01-14T08:57:58.5483206Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:57:58.5483603Z )
2026-01-14T08:57:58.5483715Z 
2026-01-14T08:57:58.5483719Z 
2026-01-14T08:57:58.5483723Z 
2026-01-14T08:57:58.5483812Z def forward(self, x):
2026-01-14T08:57:58.5484833Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:57:58.5486207Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:58.5487313Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:57:58.5488274Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011012271046638489, -1, -128, 127, torch.int8);  conv = None
2026-01-14T08:57:58.5489677Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011012271046638489, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:58.5490655Z     return dequantize_per_tensor_default_1
2026-01-14T08:57:58.5490947Z     
2026-01-14T08:57:58.5491248Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:58.5491655Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:57:58.5491902Z          [0., 0., 0.],
2026-01-14T08:57:58.5492147Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:57:58.5492440Z model pt2e: GraphModule(
2026-01-14T08:57:58.5492695Z   (conv): Module()
2026-01-14T08:57:58.5492911Z   (bn): Module()
2026-01-14T08:57:58.5493240Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:58.5494512Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:58.5495999Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:57:58.5496565Z   )
2026-01-14T08:57:58.5496763Z   (_guards_fn): GuardsFn()
2026-01-14T08:57:58.5497124Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:58.5498406Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:57:58.5499915Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:57:58.5500487Z   )
2026-01-14T08:57:58.5500783Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:58.5502086Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:58.5503565Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3977917432785034, max_val=1.4123148918151855)
2026-01-14T08:57:58.5504126Z   )
2026-01-14T08:57:58.5504308Z )
2026-01-14T08:57:58.5504411Z 
2026-01-14T08:57:58.5504415Z 
2026-01-14T08:57:58.5504419Z 
2026-01-14T08:57:58.5504509Z def forward(self, x):
2026-01-14T08:57:58.5504964Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:58.5505331Z     conv_weight = self.conv.weight
2026-01-14T08:57:58.5505632Z     conv_bias = self.conv.bias
2026-01-14T08:57:58.5505911Z     bn_weight = self.bn.weight
2026-01-14T08:57:58.5506175Z     bn_bias = self.bn.bias
2026-01-14T08:57:58.5506488Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:57:58.5506855Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:57:58.5507178Z     bn_running_var = self.bn.running_var
2026-01-14T08:57:58.5507652Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:57:58.5508111Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:57:58.5508678Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:57:58.5509331Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:57:58.5509763Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:57:58.5510217Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:57:58.5510700Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:57:58.5511241Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:57:58.5511867Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:57:58.5512546Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:57:58.5513652Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:57:58.5514649Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:57:58.5515277Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:57:58.5515918Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:57:58.5516519Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:57:58.5517545Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:57:58.5518638Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:57:58.5519284Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:57:58.5519700Z     
2026-01-14T08:57:58.5519996Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:58.5520396Z model fx: GraphModule(
2026-01-14T08:57:58.5520751Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:40.2005345Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:40.2007301Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:58:40.2008064Z   )
2026-01-14T08:58:40.2008302Z   (conv): ConvBn1d(
2026-01-14T08:58:40.2008585Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:58:40.2009146Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:58:40.2009784Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:40.2011373Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:58:40.2013573Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:58:40.2014298Z     )
2026-01-14T08:58:40.2014512Z   )
2026-01-14T08:58:40.2014869Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:40.2016666Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:40.2018516Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3977917432785034, max_val=1.4123148918151855)
2026-01-14T08:58:40.2019217Z   )
2026-01-14T08:58:40.2019432Z )
2026-01-14T08:58:40.2019555Z 
2026-01-14T08:58:40.2019566Z 
2026-01-14T08:58:40.2019571Z 
2026-01-14T08:58:40.2019686Z def forward(self, x):
2026-01-14T08:58:40.2020134Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:58:40.2020846Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:58:40.2021586Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:58:40.2022153Z     return activation_post_process_1
2026-01-14T08:58:40.2022489Z     
2026-01-14T08:58:40.2022850Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:40.2023337Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:58:40.2023632Z          [0., 0., 0.],
2026-01-14T08:58:40.2023982Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:58:40.2024427Z converted model pt2e: GraphModule(
2026-01-14T08:58:40.2024783Z   (conv): Module()
2026-01-14T08:58:40.2025036Z   (bn): Module()
2026-01-14T08:58:40.2025309Z   (_guards_fn): GuardsFn()
2026-01-14T08:58:40.2025594Z )
2026-01-14T08:58:40.2025739Z 
2026-01-14T08:58:40.2025744Z 
2026-01-14T08:58:40.2025749Z 
2026-01-14T08:58:40.2025855Z def forward(self, x):
2026-01-14T08:58:40.2026231Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:40.2026666Z     conv_bias = self.conv.bias
2026-01-14T08:58:40.2027059Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:58:40.2027969Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8)
2026-01-14T08:58:40.2029653Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:40.2030906Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:58:40.2031605Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:58:40.2032309Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:58:40.2033416Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:58:40.2035267Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:58:40.2036951Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011020027101039886, -1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:58:40.2038772Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011020027101039886, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:40.2040179Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:58:40.2040834Z     
2026-01-14T08:58:40.2041200Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:40.2041700Z onverted model fx: GraphModule(
2026-01-14T08:58:40.2042175Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:58:40.2042718Z )
2026-01-14T08:58:40.2042850Z 
2026-01-14T08:58:40.2042855Z 
2026-01-14T08:58:40.2042860Z 
2026-01-14T08:58:40.2042971Z def forward(self, x):
2026-01-14T08:58:40.2043854Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:58:40.2045237Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:40.2046361Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:58:40.2047317Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011020027101039886, -1, -128, 127, torch.int8);  conv = None
2026-01-14T08:58:40.2048741Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011020027101039886, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:40.2049733Z     return dequantize_per_tensor_default_1
2026-01-14T08:58:40.2050033Z     
2026-01-14T08:58:40.2050333Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:40.2050737Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:58:40.2050981Z          [0., 0., 0.],
2026-01-14T08:58:40.2051224Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:58:40.2051715Z [32mPASSED[0m
2026-01-14T08:58:40.2052387Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T08:58:40.2053101Z   (conv): Module()
2026-01-14T08:58:40.2053311Z   (bn): Module()
2026-01-14T08:58:40.2053636Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:40.2054715Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:40.2055989Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:58:40.2056546Z   )
2026-01-14T08:58:40.2056748Z   (_guards_fn): GuardsFn()
2026-01-14T08:58:40.2057107Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:40.2058257Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:58:40.2059763Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:58:40.2060476Z   )
2026-01-14T08:58:40.2060775Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:40.2061865Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:40.2063336Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9784814715385437, max_val=2.047511577606201)
2026-01-14T08:58:40.2064035Z   )
2026-01-14T08:58:40.2064252Z )
2026-01-14T08:58:40.2064387Z 
2026-01-14T08:58:40.2064392Z 
2026-01-14T08:58:40.2064396Z 
2026-01-14T08:58:40.2064510Z def forward(self, x):
2026-01-14T08:58:40.2064972Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:40.2065338Z     conv_weight = self.conv.weight
2026-01-14T08:58:40.2065635Z     conv_bias = self.conv.bias
2026-01-14T08:58:40.2065903Z     bn_weight = self.bn.weight
2026-01-14T08:58:40.2066174Z     bn_bias = self.bn.bias
2026-01-14T08:58:40.2066482Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:58:40.2066860Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:58:40.2067180Z     bn_running_var = self.bn.running_var
2026-01-14T08:58:40.2067670Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:58:40.2068132Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:58:40.2068702Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:58:40.2069301Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:58:40.2069729Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:58:40.2070191Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:58:40.2070669Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:58:40.2071222Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:58:40.2071853Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:58:40.2072641Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:58:40.2074051Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:58:40.2075189Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:58:40.2075780Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:58:40.2076421Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:58:40.2077029Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:59:11.3769282Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:59:11.3770728Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:59:11.3771550Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:59:11.3772083Z     
2026-01-14T08:59:11.3772454Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:11.3772943Z model fx: GraphModule(
2026-01-14T08:59:11.3773356Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:11.3774685Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:11.3776286Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:59:11.3776991Z   )
2026-01-14T08:59:11.3777214Z   (conv): ConvBn1d(
2026-01-14T08:59:11.3777541Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:59:11.3778128Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:59:11.3778767Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:11.3780138Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:59:11.3783756Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:59:11.3784882Z     )
2026-01-14T08:59:11.3785099Z   )
2026-01-14T08:59:11.3785462Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:11.3786999Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:11.3788595Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9784814715385437, max_val=2.047511577606201)
2026-01-14T08:59:11.3789294Z   )
2026-01-14T08:59:11.3789515Z )
2026-01-14T08:59:11.3789641Z 
2026-01-14T08:59:11.3789646Z 
2026-01-14T08:59:11.3789660Z 
2026-01-14T08:59:11.3789768Z def forward(self, x):
2026-01-14T08:59:11.3790223Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:11.3790963Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:59:11.3791708Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:59:11.3792277Z     return activation_post_process_1
2026-01-14T08:59:11.3792615Z     
2026-01-14T08:59:11.3792968Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:11.3793462Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:59:11.3793809Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:59:11.3794186Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:59:11.3794606Z converted model pt2e: GraphModule(
2026-01-14T08:59:11.3795038Z   (conv): Module()
2026-01-14T08:59:11.3795296Z   (bn): Module()
2026-01-14T08:59:11.3795565Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:11.3795856Z )
2026-01-14T08:59:11.3795979Z 
2026-01-14T08:59:11.3795984Z 
2026-01-14T08:59:11.3795989Z 
2026-01-14T08:59:11.3796109Z def forward(self, x):
2026-01-14T08:59:11.3796480Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:11.3796918Z     conv_bias = self.conv.bias
2026-01-14T08:59:11.3797307Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:11.3798227Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8)
2026-01-14T08:59:11.3799940Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:11.3801214Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:11.3801912Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:11.3802587Z     _scale_0 = self._scale_0
2026-01-14T08:59:11.3802934Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:59:11.3803334Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:59:11.3804583Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:59:11.3806535Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:59:11.3808280Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011866639368236065, -46, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:59:11.3810138Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011866639368236065, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:59:11.3811774Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:59:11.3812237Z     
2026-01-14T08:59:11.3812540Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:11.3812955Z onverted model fx: GraphModule(
2026-01-14T08:59:11.3813396Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:59:11.3813851Z )
2026-01-14T08:59:11.3813954Z 
2026-01-14T08:59:11.3813959Z 
2026-01-14T08:59:11.3813962Z 
2026-01-14T08:59:11.3814156Z def forward(self, x):
2026-01-14T08:59:11.3814839Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:59:11.3816231Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:11.3817373Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:59:11.3818329Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011866639368236065, -46, -128, 127, torch.int8);  conv = None
2026-01-14T08:59:11.3819771Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011866639368236065, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:59:11.3820769Z     return dequantize_per_tensor_default_1
2026-01-14T08:59:11.3821065Z     
2026-01-14T08:59:11.3821369Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:11.3821776Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:59:11.3822064Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:59:11.3822319Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:59:11.3822600Z model pt2e: GraphModule(
2026-01-14T08:59:11.3822847Z   (conv): Module()
2026-01-14T08:59:11.3823063Z   (bn): Module()
2026-01-14T08:59:11.3823380Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:11.3824463Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:11.3825743Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:59:11.3826302Z   )
2026-01-14T08:59:11.3826501Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:11.3826853Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:11.3827945Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:59:11.3829242Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.23078496754169464)
2026-01-14T08:59:11.3829810Z   )
2026-01-14T08:59:11.3830109Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:11.3831184Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-44], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:11.3832470Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9980934262275696, max_val=2.047511577606201)
2026-01-14T08:59:11.3833075Z   )
2026-01-14T08:59:11.3833251Z )
2026-01-14T08:59:11.3833353Z 
2026-01-14T08:59:11.3833357Z 
2026-01-14T08:59:11.3833361Z 
2026-01-14T08:59:11.3833458Z def forward(self, x):
2026-01-14T08:59:11.3833764Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:11.3834140Z     conv_weight = self.conv.weight
2026-01-14T08:59:11.3834528Z     conv_bias = self.conv.bias
2026-01-14T08:59:11.3834854Z     bn_weight = self.bn.weight
2026-01-14T08:59:11.3835124Z     bn_bias = self.bn.bias
2026-01-14T08:59:11.3835440Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:11.3835816Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:59:11.3836135Z     bn_running_var = self.bn.running_var
2026-01-14T08:59:11.3836541Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:59:11.3837070Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:11.3837653Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:11.3838248Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:59:11.3838686Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:59:11.3839142Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:59:11.3839630Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:59:11.3840182Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:59:11.3840821Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:59:11.3841518Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:59:53.7719759Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:59:53.7721067Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:59:53.7721791Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:59:53.7722579Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:59:53.7723353Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:59:53.7724624Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:59:53.7725985Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:59:53.7726789Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:59:53.7727330Z     
2026-01-14T08:59:53.7727700Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:53.7728180Z model fx: GraphModule(
2026-01-14T08:59:53.7728600Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.7729927Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:53.7731528Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:59:53.7732227Z   )
2026-01-14T08:59:53.7732451Z   (conv): ConvBn1d(
2026-01-14T08:59:53.7732776Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:59:53.7733356Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:59:53.7733997Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.7735294Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:59:53.7736904Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.23078496754169464)
2026-01-14T08:59:53.7737922Z     )
2026-01-14T08:59:53.7738140Z   )
2026-01-14T08:59:53.7738499Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.7739835Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-44], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:53.7741411Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9980934262275696, max_val=2.047511577606201)
2026-01-14T08:59:53.7742290Z   )
2026-01-14T08:59:53.7742512Z )
2026-01-14T08:59:53.7742636Z 
2026-01-14T08:59:53.7742649Z 
2026-01-14T08:59:53.7742653Z 
2026-01-14T08:59:53.7742770Z def forward(self, x):
2026-01-14T08:59:53.7743253Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:53.7743964Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:59:53.7744705Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:59:53.7745281Z     return activation_post_process_1
2026-01-14T08:59:53.7745625Z     
2026-01-14T08:59:53.7745979Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:53.7746475Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:59:53.7746825Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:59:53.7747195Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:59:53.7747623Z converted model pt2e: GraphModule(
2026-01-14T08:59:53.7747960Z   (conv): Module()
2026-01-14T08:59:53.7748222Z   (bn): Module()
2026-01-14T08:59:53.7748484Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:53.7748775Z )
2026-01-14T08:59:53.7748899Z 
2026-01-14T08:59:53.7748904Z 
2026-01-14T08:59:53.7748909Z 
2026-01-14T08:59:53.7749023Z def forward(self, x):
2026-01-14T08:59:53.7749386Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:53.7749834Z     conv_bias = self.conv.bias
2026-01-14T08:59:53.7750222Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:53.7751139Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8)
2026-01-14T08:59:53.7752813Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:53.7754087Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:53.7754899Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:53.7755597Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:59:53.7756806Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0024561204481869936, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:59:53.7758240Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:59:53.7759616Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011943548917770386, -44, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:59:53.7761057Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011943548917770386, -44, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:59:53.7762182Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:59:53.7762634Z     
2026-01-14T08:59:53.7762943Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:53.7763345Z onverted model fx: GraphModule(
2026-01-14T08:59:53.7763796Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:59:53.7764356Z )
2026-01-14T08:59:53.7764474Z 
2026-01-14T08:59:53.7764478Z 
2026-01-14T08:59:53.7764482Z 
2026-01-14T08:59:53.7764575Z def forward(self, x):
2026-01-14T08:59:53.7765245Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:59:53.7766702Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:53.7767835Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:59:53.7768777Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011943548917770386, -44, -128, 127, torch.int8);  conv = None
2026-01-14T08:59:53.7770214Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011943548917770386, -44, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:59:53.7771219Z     return dequantize_per_tensor_default_1
2026-01-14T08:59:53.7771513Z     
2026-01-14T08:59:53.7771818Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:53.7772219Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:59:53.7772509Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:59:53.7772774Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:59:53.7773266Z [32mPASSED[0m
2026-01-14T08:59:53.7773925Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:59:53.7774608Z   (conv): Module()
2026-01-14T08:59:53.7774828Z   (bn): Module()
2026-01-14T08:59:53.7775152Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.7776233Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:53.7777497Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:59:53.7778072Z   )
2026-01-14T08:59:53.7778284Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:53.7778640Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.7779791Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:59:53.7781264Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618]), max_val=tensor([0.1970, 0.2308, 0.2775]))
2026-01-14T08:59:53.7781992Z   )
2026-01-14T08:59:53.7782293Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.7783358Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:53.7784946Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:59:53.7785510Z   )
2026-01-14T08:59:53.7785696Z )
2026-01-14T08:59:53.7785800Z 
2026-01-14T08:59:53.7785804Z 
2026-01-14T08:59:53.7785808Z 
2026-01-14T08:59:53.7785904Z def forward(self, x):
2026-01-14T08:59:53.7786210Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:53.7786585Z     conv_weight = self.conv.weight
2026-01-14T08:59:53.7786877Z     bn_weight = self.bn.weight
2026-01-14T08:59:53.7787204Z     bn_bias = self.bn.bias
2026-01-14T08:59:53.7787699Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:53.7788076Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:59:53.7788393Z     bn_running_var = self.bn.running_var
2026-01-14T08:59:53.7788798Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:59:53.7789254Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:53.7789822Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:53.7790539Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:59:53.7790968Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:25.7717650Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:25.7718286Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:00:25.7718954Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:25.7719752Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:25.7720922Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:00:25.7722065Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:00:25.7722783Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:00:25.7724089Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:25.7725450Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:25.7726267Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:25.7726793Z     
2026-01-14T09:00:25.7727166Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:25.7727674Z model fx: GraphModule(
2026-01-14T09:00:25.7728115Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:25.7729443Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:25.7731048Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T09:00:25.7731762Z   )
2026-01-14T09:00:25.7731989Z   (conv): ConvBn1d(
2026-01-14T09:00:25.7732306Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:00:25.7732907Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:25.7733537Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:25.7734928Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:25.7736785Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618]), max_val=tensor([0.1970, 0.2308, 0.2775]))
2026-01-14T09:00:25.7737681Z     )
2026-01-14T09:00:25.7737912Z   )
2026-01-14T09:00:25.7738265Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:25.7739598Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:25.7741159Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T09:00:25.7742199Z   )
2026-01-14T09:00:25.7742420Z )
2026-01-14T09:00:25.7742552Z 
2026-01-14T09:00:25.7742556Z 
2026-01-14T09:00:25.7742561Z 
2026-01-14T09:00:25.7742671Z def forward(self, x):
2026-01-14T09:00:25.7743128Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:25.7743838Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:00:25.7744739Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:00:25.7745310Z     return activation_post_process_1
2026-01-14T09:00:25.7745652Z     
2026-01-14T09:00:25.7746011Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:25.7746500Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:00:25.7746800Z          [0., 0., 0.],
2026-01-14T09:00:25.7747059Z          [0., 0., 0.]],
2026-01-14T09:00:25.7747239Z 
2026-01-14T09:00:25.7747349Z         [[0., 0., 0.],
2026-01-14T09:00:25.7747653Z          [0., 0., 0.],
2026-01-14T09:00:25.7747909Z          [0., 0., 0.]],
2026-01-14T09:00:25.7748081Z 
2026-01-14T09:00:25.7748181Z         [[0., 0., 0.],
2026-01-14T09:00:25.7748436Z          [0., 0., 0.],
2026-01-14T09:00:25.7748735Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:00:25.7749124Z converted model pt2e: GraphModule(
2026-01-14T09:00:25.7749465Z   (conv): Module()
2026-01-14T09:00:25.7749719Z   (bn): Module()
2026-01-14T09:00:25.7749985Z   (_guards_fn): GuardsFn()
2026-01-14T09:00:25.7750262Z )
2026-01-14T09:00:25.7750400Z 
2026-01-14T09:00:25.7750405Z 
2026-01-14T09:00:25.7750410Z 
2026-01-14T09:00:25.7750518Z def forward(self, x):
2026-01-14T09:00:25.7750887Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:25.7751381Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:25.7752296Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8)
2026-01-14T09:00:25.7753987Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:25.7755371Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:00:25.7756064Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:25.7756705Z     _scale_0 = self._scale_0
2026-01-14T09:00:25.7757062Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:00:25.7757475Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:00:25.7758677Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:00:25.7759658Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:00:25.7760600Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:00:25.7762002Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.014605328440666199, 8, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T09:00:25.7763438Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:25.7764558Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:00:25.7765007Z     
2026-01-14T09:00:25.7765306Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:25.7765709Z onverted model fx: GraphModule(
2026-01-14T09:00:25.7766108Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:00:25.7766616Z )
2026-01-14T09:00:25.7766725Z 
2026-01-14T09:00:25.7766729Z 
2026-01-14T09:00:25.7766733Z 
2026-01-14T09:00:25.7766823Z def forward(self, x):
2026-01-14T09:00:25.7767504Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T09:00:25.7768955Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:25.7770080Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:25.7771025Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014605328440666199, 8, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:25.7772433Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:25.7773422Z     return dequantize_per_tensor_default_1
2026-01-14T09:00:25.7773721Z     
2026-01-14T09:00:25.7774012Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:25.7774413Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:00:25.7774656Z          [0., 0., 0.],
2026-01-14T09:00:25.7774881Z          [0., 0., 0.]],
2026-01-14T09:00:25.7775029Z 
2026-01-14T09:00:25.7775107Z         [[0., 0., 0.],
2026-01-14T09:00:25.7775323Z          [0., 0., 0.],
2026-01-14T09:00:25.7775535Z          [0., 0., 0.]],
2026-01-14T09:00:25.7775682Z 
2026-01-14T09:00:25.7775761Z         [[0., 0., 0.],
2026-01-14T09:00:25.7775978Z          [0., 0., 0.],
2026-01-14T09:00:25.7776191Z          [0., 0., 0.]]])
2026-01-14T09:00:25.7776443Z model pt2e: GraphModule(
2026-01-14T09:00:25.7776682Z   (conv): Module()
2026-01-14T09:00:25.7776939Z   (bn): Module()
2026-01-14T09:00:25.7777336Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:25.7778659Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:25.7780022Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T09:00:25.7780593Z   )
2026-01-14T09:00:25.7780794Z   (_guards_fn): GuardsFn()
2026-01-14T09:00:25.7781146Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:25.7782215Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:00:25.7783489Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T09:00:25.7784059Z   )
2026-01-14T09:00:25.7784694Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:25.7785758Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:25.7787031Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T09:00:25.7787585Z   )
2026-01-14T09:00:25.7787776Z )
2026-01-14T09:00:25.7787878Z 
2026-01-14T09:00:25.7787882Z 
2026-01-14T09:00:25.7787886Z 
2026-01-14T09:00:25.7787983Z def forward(self, x):
2026-01-14T09:00:25.7788314Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:25.7788718Z     conv_weight = self.conv.weight
2026-01-14T09:00:25.7789171Z     bn_weight = self.bn.weight
2026-01-14T09:00:25.7789440Z     bn_bias = self.bn.bias
2026-01-14T09:00:25.7789751Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:25.7790125Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:00:25.7790449Z     bn_running_var = self.bn.running_var
2026-01-14T09:00:25.7790847Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:00:58.2842338Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:00:58.2845060Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:58.2845839Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:00:58.2846358Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:58.2846895Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:58.2847475Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:00:58.2848158Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:58.2848917Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:58.2850080Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:00:58.2851214Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:00:58.2851945Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:00:58.2853241Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:58.2854588Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:58.2855403Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:58.2855920Z     
2026-01-14T09:00:58.2856288Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:58.2856765Z model fx: GraphModule(
2026-01-14T09:00:58.2857181Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:58.2858581Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:58.2860158Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T09:00:58.2860872Z   )
2026-01-14T09:00:58.2861096Z   (conv): ConvBn1d(
2026-01-14T09:00:58.2861416Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:00:58.2861990Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:58.2862636Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:58.2863676Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:00:58.2864957Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T09:00:58.2865531Z     )
2026-01-14T09:00:58.2865720Z   )
2026-01-14T09:00:58.2866014Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:58.2867066Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:58.2868326Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T09:00:58.2869082Z   )
2026-01-14T09:00:58.2869261Z )
2026-01-14T09:00:58.2869369Z 
2026-01-14T09:00:58.2869374Z 
2026-01-14T09:00:58.2869378Z 
2026-01-14T09:00:58.2869467Z def forward(self, x):
2026-01-14T09:00:58.2869843Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:58.2870423Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:00:58.2871112Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:00:58.2871575Z     return activation_post_process_1
2026-01-14T09:00:58.2871858Z     
2026-01-14T09:00:58.2872155Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:58.2872552Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:00:58.2872805Z          [0., 0., 0.],
2026-01-14T09:00:58.2873021Z          [0., 0., 0.]],
2026-01-14T09:00:58.2873164Z 
2026-01-14T09:00:58.2873249Z         [[0., 0., 0.],
2026-01-14T09:00:58.2873466Z          [0., 0., 0.],
2026-01-14T09:00:58.2873688Z          [0., 0., 0.]],
2026-01-14T09:00:58.2873830Z 
2026-01-14T09:00:58.2873909Z         [[0., 0., 0.],
2026-01-14T09:00:58.2874125Z          [0., 0., 0.],
2026-01-14T09:00:58.2874374Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:00:58.2874705Z converted model pt2e: GraphModule(
2026-01-14T09:00:58.2875083Z   (conv): Module()
2026-01-14T09:00:58.2875289Z   (bn): Module()
2026-01-14T09:00:58.2875516Z   (_guards_fn): GuardsFn()
2026-01-14T09:00:58.2875757Z )
2026-01-14T09:00:58.2875861Z 
2026-01-14T09:00:58.2875878Z 
2026-01-14T09:00:58.2875882Z 
2026-01-14T09:00:58.2875973Z def forward(self, x):
2026-01-14T09:00:58.2876270Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:58.2876689Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:58.2877440Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8)
2026-01-14T09:00:58.2878801Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:58.2879823Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:00:58.2880398Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:58.2880964Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:00:58.2881848Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:00:58.2882734Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:00:58.2883670Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:00:58.2885460Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.014605328440666199, 8, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T09:00:58.2886920Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:00:58.2888076Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:00:58.2888533Z     
2026-01-14T09:00:58.2888836Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:58.2889245Z onverted model fx: GraphModule(
2026-01-14T09:00:58.2889644Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:00:58.2890044Z )
2026-01-14T09:00:58.2890149Z 
2026-01-14T09:00:58.2890320Z 
2026-01-14T09:00:58.2890324Z 
2026-01-14T09:00:58.2890417Z def forward(self, x):
2026-01-14T09:00:58.2891082Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T09:00:58.2892427Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:58.2893661Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:58.2894611Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014605328440666199, 8, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:58.2896015Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:58.2897006Z     return dequantize_per_tensor_default_1
2026-01-14T09:00:58.2897294Z     
2026-01-14T09:00:58.2897591Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:58.2897993Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:00:58.2898265Z          [0., 0., 0.],
2026-01-14T09:00:58.2898512Z          [0., 0., 0.]],
2026-01-14T09:00:58.2898657Z 
2026-01-14T09:00:58.2898735Z         [[0., 0., 0.],
2026-01-14T09:00:58.2898958Z          [0., 0., 0.],
2026-01-14T09:00:58.2899176Z          [0., 0., 0.]],
2026-01-14T09:00:58.2899325Z 
2026-01-14T09:00:58.2899403Z         [[0., 0., 0.],
2026-01-14T09:00:58.2899618Z          [0., 0., 0.],
2026-01-14T09:00:58.2899838Z          [0., 0., 0.]]])
2026-01-14T09:00:58.2900080Z model pt2e: GraphModule(
2026-01-14T09:00:58.2900315Z   (conv1): Module()
2026-01-14T09:00:58.2900532Z   (bn1): Module()
2026-01-14T09:00:58.2900742Z   (conv2): Module()
2026-01-14T09:00:58.2900956Z   (bn2): Module()
2026-01-14T09:00:58.2901279Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:58.2902341Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:58.2903607Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T09:00:58.2904171Z   )
2026-01-14T09:00:58.2904378Z   (_guards_fn): GuardsFn()
2026-01-14T09:00:58.2904728Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:58.2905872Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:58.2907383Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2878, -0.2584, -0.3162]), max_val=tensor([0.2745, 0.3315, 0.3105]))
2026-01-14T09:00:58.2908130Z   )
2026-01-14T09:00:58.2908428Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:58.2909562Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:58.2911049Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3233, -0.3086, -0.2979]), max_val=tensor([0.3026, 0.1712, 0.2405]))
2026-01-14T09:00:58.2911761Z   )
2026-01-14T09:00:58.2912054Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:25.3521496Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:25.3524068Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.805302619934082, max_val=2.310788631439209)
2026-01-14T09:01:25.3524621Z   )
2026-01-14T09:01:25.3525045Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:25.3526678Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:25.3528199Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1982380151748657, max_val=1.4133442640304565)
2026-01-14T09:01:25.3528774Z   )
2026-01-14T09:01:25.3528967Z )
2026-01-14T09:01:25.3529082Z 
2026-01-14T09:01:25.3529087Z 
2026-01-14T09:01:25.3529090Z 
2026-01-14T09:01:25.3529185Z def forward(self, x):
2026-01-14T09:01:25.3529505Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:25.3529886Z     conv1_weight = self.conv1.weight
2026-01-14T09:01:25.3530199Z     bn1_weight = self.bn1.weight
2026-01-14T09:01:25.3530480Z     bn1_bias = self.bn1.bias
2026-01-14T09:01:25.3530766Z     conv2_weight = self.conv2.weight
2026-01-14T09:01:25.3531063Z     conv2_bias = self.conv2.bias
2026-01-14T09:01:25.3531353Z     bn2_weight = self.bn2.weight
2026-01-14T09:01:25.3531629Z     bn2_bias = self.bn2.bias
2026-01-14T09:01:25.3531965Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:01:25.3532359Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:01:25.3532691Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:01:25.3533065Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:01:25.3533442Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:01:25.3533777Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:01:25.3534171Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:01:25.3534640Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:25.3535206Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:01:25.3535979Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:01:25.3536608Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:01:25.3537076Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:25.3537561Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:01:25.3538046Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:01:25.3538608Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:01:25.3539242Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:01:25.3539921Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:01:25.3540555Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:01:25.3541005Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:01:25.3541489Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:01:25.3541999Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T09:01:25.3542594Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:01:25.3543257Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:01:25.3544212Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:01:25.3545149Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T09:01:25.3545850Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T09:01:25.3546927Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, False);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:01:25.3548064Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:01:25.3549206Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:01:25.3550211Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:01:25.3550805Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T09:01:25.3551446Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T09:01:25.3552079Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:01:25.3553132Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, False);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:01:25.3554257Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:01:25.3555000Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:01:25.3555477Z     
2026-01-14T09:01:25.3555806Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:25.3556247Z model fx: GraphModule(
2026-01-14T09:01:25.3556626Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:25.3557956Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:25.3559494Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T09:01:25.3560163Z   )
2026-01-14T09:01:25.3560359Z   (conv1): ConvBn1d(
2026-01-14T09:01:25.3560644Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:01:25.3561170Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:25.3561779Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:25.3563109Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:25.3564924Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3233, -0.3086, -0.2979]), max_val=tensor([0.3026, 0.1712, 0.2405]))
2026-01-14T09:01:25.3565784Z     )
2026-01-14T09:01:25.3565965Z   )
2026-01-14T09:01:25.3566270Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:25.3567411Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:25.3568690Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.805302619934082, max_val=2.310788631439209)
2026-01-14T09:01:25.3569244Z   )
2026-01-14T09:01:25.3569436Z   (conv2): ConvBn1d(
2026-01-14T09:01:25.3569686Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T09:01:25.3570128Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:25.3570661Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:25.3571870Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:25.3573377Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2878, -0.2584, -0.3162]), max_val=tensor([0.2745, 0.3315, 0.3105]))
2026-01-14T09:01:25.3574099Z     )
2026-01-14T09:01:25.3574278Z   )
2026-01-14T09:01:25.3574657Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:25.3575725Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:25.3576987Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1982380151748657, max_val=1.4133442640304565)
2026-01-14T09:01:25.3577561Z   )
2026-01-14T09:01:25.3577741Z )
2026-01-14T09:01:25.3577851Z 
2026-01-14T09:01:25.3577856Z 
2026-01-14T09:01:25.3577860Z 
2026-01-14T09:01:25.3577948Z def forward(self, x):
2026-01-14T09:01:25.3578326Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:25.3578929Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:25.3579548Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:01:25.3580160Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:01:25.3580776Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:01:25.3581250Z     return activation_post_process_2
2026-01-14T09:01:25.3581533Z     
2026-01-14T09:01:25.3581834Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:25.3582227Z diff: tensor([[[0.],
2026-01-14T09:01:25.3582462Z          [0.],
2026-01-14T09:01:25.3582672Z          [0.]],
2026-01-14T09:01:25.3582799Z 
2026-01-14T09:01:25.3582883Z         [[0.],
2026-01-14T09:01:25.3583079Z          [0.],
2026-01-14T09:01:25.3583284Z          [0.]],
2026-01-14T09:01:25.3583410Z 
2026-01-14T09:01:25.3583487Z         [[0.],
2026-01-14T09:01:25.3583691Z          [0.],
2026-01-14T09:01:25.3583913Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:01:25.3584499Z converted model pt2e: GraphModule(
2026-01-14T09:01:25.3584805Z   (conv1): Module()
2026-01-14T09:01:25.3585034Z   (bn1): Module()
2026-01-14T09:01:25.3585250Z   (conv2): Module()
2026-01-14T09:01:25.3585484Z   (bn2): Module()
2026-01-14T09:01:25.3585725Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:25.3586033Z )
2026-01-14T09:01:25.3586161Z 
2026-01-14T09:01:25.3586166Z 
2026-01-14T09:01:25.3586171Z 
2026-01-14T09:01:25.3586292Z def forward(self, x):
2026-01-14T09:01:25.3586700Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:25.3587215Z     conv2_bias = self.conv2.bias
2026-01-14T09:01:25.3587664Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:01:25.3588236Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:01:25.3589166Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8)
2026-01-14T09:01:31.0679935Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:31.0681242Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:31.0681966Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:01:31.0682925Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:01:31.0683875Z     _scale_0 = self._scale_0
2026-01-14T09:01:31.0684411Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:01:31.0684767Z     _scale_1 = self._scale_1
2026-01-14T09:01:31.0685093Z     _zero_point_1 = self._zero_point_1
2026-01-14T09:01:31.0685487Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T09:01:31.0686947Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T09:01:31.0688245Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:01:31.0689484Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T09:01:31.0691284Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.016141533851623535, -16, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T09:01:31.0693160Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016141533851623535, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:31.0694400Z     quantize_per_channel = self._frozen_param1
2026-01-14T09:01:31.0695643Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:01:31.0697578Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T09:01:31.0699287Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.010241499170660973, -11, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T09:01:31.0701116Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010241499170660973, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:01:31.0702522Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:01:31.0703069Z     
2026-01-14T09:01:31.0703438Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:31.0703937Z onverted model fx: GraphModule(
2026-01-14T09:01:31.0704438Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:01:31.0705103Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:01:31.0705595Z )
2026-01-14T09:01:31.0705721Z 
2026-01-14T09:01:31.0705726Z 
2026-01-14T09:01:31.0705731Z 
2026-01-14T09:01:31.0705853Z def forward(self, x):
2026-01-14T09:01:31.0706686Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T09:01:31.0708392Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:31.0709597Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:31.0710563Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.016141533851623535, -16, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:01:31.0712005Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016141533851623535, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:31.0713164Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:01:31.0714302Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.010241499170660973, -11, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:01:31.0715816Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010241499170660973, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:01:31.0716862Z     return dequantize_per_tensor_default_2
2026-01-14T09:01:31.0717162Z     
2026-01-14T09:01:31.0717467Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:31.0717855Z diff: tensor([[[0.],
2026-01-14T09:01:31.0718088Z          [0.],
2026-01-14T09:01:31.0718288Z          [0.]],
2026-01-14T09:01:31.0718412Z 
2026-01-14T09:01:31.0718497Z         [[0.],
2026-01-14T09:01:31.0718693Z          [0.],
2026-01-14T09:01:31.0718927Z          [0.]],
2026-01-14T09:01:31.0719076Z 
2026-01-14T09:01:31.0719157Z         [[0.],
2026-01-14T09:01:31.0719367Z          [0.],
2026-01-14T09:01:31.0719557Z          [0.]]])
2026-01-14T09:01:31.0719780Z model pt2e: GraphModule(
2026-01-14T09:01:31.0720024Z   (conv1): Module()
2026-01-14T09:01:31.0720242Z   (bn1): Module()
2026-01-14T09:01:31.0720451Z   (conv2): Module()
2026-01-14T09:01:31.0720665Z   (bn2): Module()
2026-01-14T09:01:31.0720986Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:31.0722057Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:31.0723331Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T09:01:31.0723897Z   )
2026-01-14T09:01:31.0724101Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:31.0724444Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:31.0725533Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:31.0726810Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3161814510822296, max_val=0.33154603838920593)
2026-01-14T09:01:31.0727375Z   )
2026-01-14T09:01:31.0727679Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:31.0728781Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:31.0730060Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232710361480713, max_val=0.30256387591362)
2026-01-14T09:01:31.0730619Z   )
2026-01-14T09:01:31.0730915Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:31.0731966Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:31.0733210Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.807204008102417, max_val=2.3096539974212646)
2026-01-14T09:01:31.0733769Z   )
2026-01-14T09:01:31.0734065Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:31.0735134Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:31.0736386Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2001533508300781, max_val=1.4126498699188232)
2026-01-14T09:01:31.0737030Z   )
2026-01-14T09:01:31.0737221Z )
2026-01-14T09:01:31.0737327Z 
2026-01-14T09:01:31.0737331Z 
2026-01-14T09:01:31.0737335Z 
2026-01-14T09:01:31.0737425Z def forward(self, x):
2026-01-14T09:01:31.0737747Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:31.0738119Z     conv1_weight = self.conv1.weight
2026-01-14T09:01:31.0738425Z     bn1_weight = self.bn1.weight
2026-01-14T09:01:31.0738710Z     bn1_bias = self.bn1.bias
2026-01-14T09:01:31.0738977Z     conv2_weight = self.conv2.weight
2026-01-14T09:01:31.0739360Z     conv2_bias = self.conv2.bias
2026-01-14T09:01:31.0739639Z     bn2_weight = self.bn2.weight
2026-01-14T09:01:31.0739915Z     bn2_bias = self.bn2.bias
2026-01-14T09:01:31.0740239Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:01:31.0740620Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:01:31.0740942Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:01:31.0741308Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:01:31.0741695Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:01:31.0742014Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:01:31.0742416Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:01:31.0742864Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:31.0743442Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:01:31.0744208Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:01:31.0744824Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:01:31.0745259Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:31.0745710Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:01:31.0746195Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:01:31.0746754Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:01:31.0747393Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:01:31.0748069Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:01:31.0748691Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:01:31.0749189Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:01:55.1056746Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:01:55.1057338Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T09:01:55.1057931Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:01:55.1058596Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:01:55.1059553Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:01:55.1060496Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T09:01:55.1061110Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T09:01:55.1062194Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, False);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:01:55.1063461Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:01:55.1064601Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:01:55.1065591Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:01:55.1066485Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T09:01:55.1067123Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T09:01:55.1067744Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:01:55.1069103Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, False);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:01:55.1070330Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:01:55.1070983Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:01:55.1071407Z     
2026-01-14T09:01:55.1071716Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:55.1072129Z model fx: GraphModule(
2026-01-14T09:01:55.1072477Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:55.1073598Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:55.1074991Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T09:01:55.1075580Z   )
2026-01-14T09:01:55.1075773Z   (conv1): ConvBn1d(
2026-01-14T09:01:55.1076039Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:01:55.1076562Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:55.1077079Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:55.1078140Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:55.1079410Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232710361480713, max_val=0.30256387591362)
2026-01-14T09:01:55.1079973Z     )
2026-01-14T09:01:55.1080160Z   )
2026-01-14T09:01:55.1080454Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:55.1081534Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:55.1082811Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.807204008102417, max_val=2.3096539974212646)
2026-01-14T09:01:55.1083379Z   )
2026-01-14T09:01:55.1083574Z   (conv2): ConvBn1d(
2026-01-14T09:01:55.1083811Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T09:01:55.1084597Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:55.1085116Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:55.1086170Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:55.1087540Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3161814510822296, max_val=0.33154603838920593)
2026-01-14T09:01:55.1088113Z     )
2026-01-14T09:01:55.1088299Z   )
2026-01-14T09:01:55.1088599Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:55.1089678Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:55.1091116Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2001533508300781, max_val=1.4126498699188232)
2026-01-14T09:01:55.1091681Z   )
2026-01-14T09:01:55.1091866Z )
2026-01-14T09:01:55.1091971Z 
2026-01-14T09:01:55.1091975Z 
2026-01-14T09:01:55.1091979Z 
2026-01-14T09:01:55.1092069Z def forward(self, x):
2026-01-14T09:01:55.1092453Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:55.1093158Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:55.1093778Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:01:55.1094394Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:01:55.1095001Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:01:55.1095477Z     return activation_post_process_2
2026-01-14T09:01:55.1095749Z     
2026-01-14T09:01:55.1096058Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:55.1096446Z diff: tensor([[[0.],
2026-01-14T09:01:55.1096668Z          [0.],
2026-01-14T09:01:55.1096872Z          [0.]],
2026-01-14T09:01:55.1096995Z 
2026-01-14T09:01:55.1097075Z         [[0.],
2026-01-14T09:01:55.1097271Z          [0.],
2026-01-14T09:01:55.1097461Z          [0.]],
2026-01-14T09:01:55.1097588Z 
2026-01-14T09:01:55.1097664Z         [[0.],
2026-01-14T09:01:55.1097856Z          [0.],
2026-01-14T09:01:55.1098086Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:01:55.1098392Z converted model pt2e: GraphModule(
2026-01-14T09:01:55.1098670Z   (conv1): Module()
2026-01-14T09:01:55.1098891Z   (bn1): Module()
2026-01-14T09:01:55.1099099Z   (conv2): Module()
2026-01-14T09:01:55.1099315Z   (bn2): Module()
2026-01-14T09:01:55.1099534Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:55.1099774Z )
2026-01-14T09:01:55.1099878Z 
2026-01-14T09:01:55.1099882Z 
2026-01-14T09:01:55.1099891Z 
2026-01-14T09:01:55.1099980Z def forward(self, x):
2026-01-14T09:01:55.1100289Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:55.1100652Z     conv2_bias = self.conv2.bias
2026-01-14T09:01:55.1100989Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:01:55.1101416Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:01:55.1102162Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8)
2026-01-14T09:01:55.1103523Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:55.1104542Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:55.1105134Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:01:55.1105910Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:01:55.1106485Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T09:01:55.1107394Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.0025454412680119276, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T09:01:55.1108320Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:01:55.1109290Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T09:01:55.1110730Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.016144542023539543, -16, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T09:01:55.1112197Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.016144542023539543, -16, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:01:55.1113268Z     quantize_per_tensor = self._frozen_param1
2026-01-14T09:01:55.1114158Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0026105986908078194, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:01:55.1115739Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T09:01:55.1117176Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.01024628710001707, -11, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T09:01:55.1118624Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.01024628710001707, -11, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T09:01:55.1119735Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T09:01:55.1120181Z     
2026-01-14T09:01:55.1120489Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:55.1120908Z onverted model fx: GraphModule(
2026-01-14T09:01:55.1121313Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:01:55.1121867Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:03:09.9489352Z )
2026-01-14T09:03:09.9491920Z 
2026-01-14T09:03:09.9492187Z 
2026-01-14T09:03:09.9492197Z 
2026-01-14T09:03:09.9492443Z def forward(self, x):
2026-01-14T09:03:09.9493223Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T09:03:09.9494716Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:09.9496315Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:03:09.9497504Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.016144542023539543, -16, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:03:09.9499183Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016144542023539543, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:09.9500492Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:03:09.9501581Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.01024628710001707, -11, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:03:09.9503173Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01024628710001707, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:03:09.9504247Z     return dequantize_per_tensor_default_2
2026-01-14T09:03:09.9504539Z     
2026-01-14T09:03:09.9513527Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:09.9513970Z diff: tensor([[[0.],
2026-01-14T09:03:09.9514234Z          [0.],
2026-01-14T09:03:09.9514486Z          [0.]],
2026-01-14T09:03:09.9514610Z 
2026-01-14T09:03:09.9514689Z         [[0.],
2026-01-14T09:03:09.9515008Z          [0.],
2026-01-14T09:03:09.9515269Z          [0.]],
2026-01-14T09:03:09.9515400Z 
2026-01-14T09:03:09.9515475Z         [[0.],
2026-01-14T09:03:09.9515663Z          [0.],
2026-01-14T09:03:09.9515863Z          [0.]]])
2026-01-14T09:03:09.9516335Z [32mPASSED[0m
2026-01-14T09:03:09.9517543Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T09:03:09.9518749Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T09:03:09.9519456Z   (conv): Module()
2026-01-14T09:03:09.9519695Z   (bn): Module()
2026-01-14T09:03:09.9520014Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:09.9521447Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:09.9522980Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:03:09.9523541Z   )
2026-01-14T09:03:09.9523812Z   (_guards_fn): GuardsFn()
2026-01-14T09:03:09.9524180Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:09.9525458Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:03:09.9527076Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2845, -0.3289, -0.3229]), max_val=tensor([0.2989, 0.2870, 0.2939]))
2026-01-14T09:03:09.9527826Z   )
2026-01-14T09:03:09.9528172Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:09.9529327Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:09.9530685Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T09:03:09.9531267Z   )
2026-01-14T09:03:09.9531442Z )
2026-01-14T09:03:09.9531547Z 
2026-01-14T09:03:09.9531559Z 
2026-01-14T09:03:09.9531564Z 
2026-01-14T09:03:09.9531654Z def forward(self, x):
2026-01-14T09:03:09.9531981Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:09.9532405Z     conv_weight = self.conv.weight
2026-01-14T09:03:09.9532704Z     conv_bias = self.conv.bias
2026-01-14T09:03:09.9532971Z     bn_weight = self.bn.weight
2026-01-14T09:03:09.9533245Z     bn_bias = self.bn.bias
2026-01-14T09:03:09.9533551Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:03:09.9533921Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:03:09.9534252Z     bn_running_var = self.bn.running_var
2026-01-14T09:03:09.9534702Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:03:09.9535151Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:03:09.9535724Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:03:09.9536353Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:03:09.9536768Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:03:09.9537215Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:03:09.9537693Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:03:09.9538315Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:03:09.9538946Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:03:09.9539615Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:03:09.9540721Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:03:09.9541837Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:03:09.9542411Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:03:09.9543045Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T09:03:09.9543649Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:03:09.9544755Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:03:09.9545852Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:03:09.9546417Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:03:09.9547017Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:03:09.9547431Z     
2026-01-14T09:03:09.9547736Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:09.9548130Z model fx: GraphModule(
2026-01-14T09:03:09.9548483Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:09.9549552Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:09.9550817Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:03:09.9551372Z   )
2026-01-14T09:03:09.9551563Z   (conv): ConvBnReLU1d(
2026-01-14T09:03:09.9551826Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T09:03:09.9552259Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:09.9552789Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:09.9553901Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:03:09.9555474Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2845, -0.3289, -0.3229]), max_val=tensor([0.2989, 0.2870, 0.2939]))
2026-01-14T09:03:09.9556199Z     )
2026-01-14T09:03:09.9556381Z   )
2026-01-14T09:03:09.9556677Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:09.9557753Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:09.9559037Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T09:03:09.9559553Z   )
2026-01-14T09:03:09.9559729Z )
2026-01-14T09:03:09.9559838Z 
2026-01-14T09:03:09.9559843Z 
2026-01-14T09:03:09.9559847Z 
2026-01-14T09:03:09.9559937Z def forward(self, x):
2026-01-14T09:03:09.9560322Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:09.9560904Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:03:09.9561509Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:03:09.9561975Z     return activation_post_process_1
2026-01-14T09:03:09.9562258Z     
2026-01-14T09:03:09.9562557Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:09.9562962Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:03:09.9563207Z          [0., 0., 0.],
2026-01-14T09:03:09.9563469Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:03:09.9563802Z converted model pt2e: GraphModule(
2026-01-14T09:03:09.9564181Z   (conv): Module()
2026-01-14T09:03:09.9564404Z   (bn): Module()
2026-01-14T09:03:09.9564624Z   (_guards_fn): GuardsFn()
2026-01-14T09:03:09.9564868Z )
2026-01-14T09:03:09.9564969Z 
2026-01-14T09:03:09.9564973Z 
2026-01-14T09:03:09.9564977Z 
2026-01-14T09:03:09.9565064Z def forward(self, x):
2026-01-14T09:03:09.9565376Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:09.9565736Z     conv_bias = self.conv.bias
2026-01-14T09:03:09.9566061Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:03:09.9566896Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:03:09.9568244Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:09.9569262Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:03:09.9569843Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:03:43.9240812Z     _scale_0 = self._scale_0
2026-01-14T09:03:43.9241250Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:03:43.9241725Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:03:43.9243353Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:03:43.9245680Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:03:43.9247080Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T09:03:43.9248323Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005544713232666254, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:03:43.9250539Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:43.9251656Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:03:43.9252144Z     
2026-01-14T09:03:43.9252464Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:43.9252965Z onverted model fx: GraphModule(
2026-01-14T09:03:43.9253254Z   (conv): ConvReLU1d(
2026-01-14T09:03:43.9253610Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:03:43.9253998Z     (1): ReLU()
2026-01-14T09:03:43.9254203Z   )
2026-01-14T09:03:43.9254384Z )
2026-01-14T09:03:43.9254498Z 
2026-01-14T09:03:43.9254502Z 
2026-01-14T09:03:43.9254506Z 
2026-01-14T09:03:43.9254600Z def forward(self, x):
2026-01-14T09:03:43.9255265Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:03:43.9256647Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:43.9257772Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:03:43.9258706Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005544713232666254, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:03:43.9260117Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:43.9261506Z     return dequantize_per_tensor_default_1
2026-01-14T09:03:43.9261790Z     
2026-01-14T09:03:43.9262096Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:43.9262493Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:03:43.9262767Z          [0., 0., 0.],
2026-01-14T09:03:43.9262989Z          [0., 0., 0.]]])
2026-01-14T09:03:43.9263226Z model pt2e: GraphModule(
2026-01-14T09:03:43.9263466Z   (conv): Module()
2026-01-14T09:03:43.9263672Z   (bn): Module()
2026-01-14T09:03:43.9264190Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:43.9265261Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:43.9266529Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:03:43.9267100Z   )
2026-01-14T09:03:43.9267295Z   (_guards_fn): GuardsFn()
2026-01-14T09:03:43.9267654Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:43.9268724Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:43.9270007Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3289433717727661, max_val=0.29890719056129456)
2026-01-14T09:03:43.9270565Z   )
2026-01-14T09:03:43.9270856Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:43.9271951Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:43.9273170Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T09:03:43.9273682Z   )
2026-01-14T09:03:43.9273863Z )
2026-01-14T09:03:43.9273965Z 
2026-01-14T09:03:43.9273970Z 
2026-01-14T09:03:43.9273974Z 
2026-01-14T09:03:43.9274061Z def forward(self, x):
2026-01-14T09:03:43.9274374Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:43.9274880Z     conv_weight = self.conv.weight
2026-01-14T09:03:43.9275176Z     conv_bias = self.conv.bias
2026-01-14T09:03:43.9275446Z     bn_weight = self.bn.weight
2026-01-14T09:03:43.9275724Z     bn_bias = self.bn.bias
2026-01-14T09:03:43.9276034Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:03:43.9276398Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:03:43.9276723Z     bn_running_var = self.bn.running_var
2026-01-14T09:03:43.9277120Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:03:43.9277571Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:03:43.9278143Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:03:43.9278737Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:03:43.9279157Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:03:43.9279612Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:03:43.9280083Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:03:43.9280632Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:03:43.9281257Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:03:43.9281933Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:03:43.9283076Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:03:43.9284372Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:03:43.9285111Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:03:43.9285740Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T09:03:43.9286342Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:03:43.9287500Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:03:43.9288499Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:03:43.9289076Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:03:43.9289666Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:03:43.9290082Z     
2026-01-14T09:03:43.9290380Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:43.9290764Z model fx: GraphModule(
2026-01-14T09:03:43.9291107Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:43.9292177Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:43.9293437Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:03:43.9293982Z   )
2026-01-14T09:03:43.9294179Z   (conv): ConvBnReLU1d(
2026-01-14T09:03:43.9294428Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T09:03:43.9294864Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:43.9295395Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:43.9296423Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:43.9297711Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3289433717727661, max_val=0.29890719056129456)
2026-01-14T09:03:43.9298280Z     )
2026-01-14T09:03:43.9298462Z   )
2026-01-14T09:03:43.9298754Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:43.9299835Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:43.9301045Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T09:03:43.9301548Z   )
2026-01-14T09:03:43.9301727Z )
2026-01-14T09:03:43.9301851Z 
2026-01-14T09:03:43.9301856Z 
2026-01-14T09:03:43.9301860Z 
2026-01-14T09:03:43.9301965Z def forward(self, x):
2026-01-14T09:03:43.9302351Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:43.9302935Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:03:43.9303526Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:03:43.9303994Z     return activation_post_process_1
2026-01-14T09:03:43.9304262Z     
2026-01-14T09:03:43.9304556Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:43.9304948Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:03:43.9305198Z          [0., 0., 0.],
2026-01-14T09:03:43.9305448Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:03:43.9305771Z converted model pt2e: GraphModule(
2026-01-14T09:03:43.9306046Z   (conv): Module()
2026-01-14T09:03:43.9306386Z   (bn): Module()
2026-01-14T09:03:43.9306603Z   (_guards_fn): GuardsFn()
2026-01-14T09:03:43.9306831Z )
2026-01-14T09:03:43.9306937Z 
2026-01-14T09:03:43.9306941Z 
2026-01-14T09:03:43.9306945Z 
2026-01-14T09:03:43.9307032Z def forward(self, x):
2026-01-14T09:03:43.9307330Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:43.9307693Z     conv_bias = self.conv.bias
2026-01-14T09:03:43.9308014Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:03:43.9308820Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:04:01.2104098Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:01.2105205Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:04:01.2105822Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:01.2106377Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:04:01.2107247Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002590105403214693, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:04:01.2108716Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:04:01.2109666Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T09:04:01.2110533Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005544713232666254, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:04:01.2111986Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:04:01.2113131Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:04:01.2113578Z     
2026-01-14T09:04:01.2113893Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:01.2114313Z onverted model fx: GraphModule(
2026-01-14T09:04:01.2114589Z   (conv): ConvReLU1d(
2026-01-14T09:04:01.2115026Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:04:01.2115418Z     (1): ReLU()
2026-01-14T09:04:01.2115626Z   )
2026-01-14T09:04:01.2115817Z )
2026-01-14T09:04:01.2115920Z 
2026-01-14T09:04:01.2115925Z 
2026-01-14T09:04:01.2115929Z 
2026-01-14T09:04:01.2116019Z def forward(self, x):
2026-01-14T09:04:01.2116695Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:04:01.2118107Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:01.2119236Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:01.2120207Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005544713232666254, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:01.2121623Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:01.2122634Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:01.2122938Z     
2026-01-14T09:04:01.2123236Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:01.2124982Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:04:01.2125233Z          [0., 0., 0.],
2026-01-14T09:04:01.2125463Z          [0., 0., 0.]]])
2026-01-14T09:04:01.2125920Z [32mPASSED[0m
2026-01-14T09:04:01.2126559Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_cuda model pt2e: GraphModule(
2026-01-14T09:04:01.2127236Z   (conv): Module()
2026-01-14T09:04:01.2127458Z   (bn): Module()
2026-01-14T09:04:01.2127939Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:01.2129244Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:01.2130772Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:04:01.2131336Z   )
2026-01-14T09:04:01.2131533Z   (_guards_fn): GuardsFn()
2026-01-14T09:04:01.2131895Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:01.2133253Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:01.2135062Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T09:04:01.2135889Z   )
2026-01-14T09:04:01.2136181Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:01.2137479Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:01.2138909Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T09:04:01.2139422Z   )
2026-01-14T09:04:01.2139609Z )
2026-01-14T09:04:01.2139713Z 
2026-01-14T09:04:01.2139718Z 
2026-01-14T09:04:01.2139721Z 
2026-01-14T09:04:01.2139810Z def forward(self, x):
2026-01-14T09:04:01.2140130Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:01.2140497Z     conv_weight = self.conv.weight
2026-01-14T09:04:01.2140794Z     conv_bias = self.conv.bias
2026-01-14T09:04:01.2141063Z     bn_weight = self.bn.weight
2026-01-14T09:04:01.2141329Z     bn_bias = self.bn.bias
2026-01-14T09:04:01.2141641Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:01.2142006Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:01.2142333Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:01.2142729Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:04:01.2143183Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:04:01.2143752Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:01.2144351Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:01.2144781Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:01.2145236Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:01.2145716Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:04:01.2146259Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:01.2146888Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:01.2147567Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:01.2148778Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:01.2149772Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:04:01.2150356Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:04:01.2151116Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T09:04:01.2151728Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:01.2152757Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:01.2153778Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:01.2154352Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:01.2154995Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:01.2155410Z     
2026-01-14T09:04:01.2155720Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:01.2156110Z model fx: GraphModule(
2026-01-14T09:04:01.2156471Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:01.2157774Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:01.2159254Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:04:01.2159826Z   )
2026-01-14T09:04:01.2160022Z   (conv): ConvBnReLU1d(
2026-01-14T09:04:01.2160284Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T09:04:01.2160733Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:01.2161250Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:01.2162598Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:01.2164588Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T09:04:01.2165408Z     )
2026-01-14T09:04:01.2165599Z   )
2026-01-14T09:04:01.2165894Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:01.2167204Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:35.7951487Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T09:04:35.7954077Z   )
2026-01-14T09:04:35.7954349Z )
2026-01-14T09:04:35.7954456Z 
2026-01-14T09:04:35.7954460Z 
2026-01-14T09:04:35.7954464Z 
2026-01-14T09:04:35.7954554Z def forward(self, x):
2026-01-14T09:04:35.7955063Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:35.7955696Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:04:35.7956657Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:04:35.7957130Z     return activation_post_process_1
2026-01-14T09:04:35.7957406Z     
2026-01-14T09:04:35.7957718Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:35.7958126Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:04:35.7958375Z          [0., 0., 0.],
2026-01-14T09:04:35.7958670Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:04:35.7959041Z converted model pt2e: GraphModule(
2026-01-14T09:04:35.7960429Z   (conv): Module()
2026-01-14T09:04:35.7960654Z   (bn): Module()
2026-01-14T09:04:35.7960882Z   (_guards_fn): GuardsFn()
2026-01-14T09:04:35.7961124Z )
2026-01-14T09:04:35.7961236Z 
2026-01-14T09:04:35.7961240Z 
2026-01-14T09:04:35.7961245Z 
2026-01-14T09:04:35.7961337Z def forward(self, x):
2026-01-14T09:04:35.7961659Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:35.7962021Z     conv_bias = self.conv.bias
2026-01-14T09:04:35.7962359Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:35.7963103Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8)
2026-01-14T09:04:35.7964442Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:35.7965481Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:04:35.7966063Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:35.7966592Z     _scale_0 = self._scale_0
2026-01-14T09:04:35.7966866Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:04:35.7967196Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:04:35.7968188Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:04:35.7969783Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:04:35.7970748Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T09:04:35.7971605Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005538490135222673, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:04:35.7973036Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:35.7974151Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:04:35.7974591Z     
2026-01-14T09:04:35.7974901Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:35.7975302Z onverted model fx: GraphModule(
2026-01-14T09:04:35.7975579Z   (conv): ConvReLU1d(
2026-01-14T09:04:35.7975946Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:04:35.7984807Z     (1): ReLU()
2026-01-14T09:04:35.7985119Z   )
2026-01-14T09:04:35.7985324Z )
2026-01-14T09:04:35.7985431Z 
2026-01-14T09:04:35.7985445Z 
2026-01-14T09:04:35.7985449Z 
2026-01-14T09:04:35.7985551Z def forward(self, x):
2026-01-14T09:04:35.7986238Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:04:35.7987602Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:35.7988907Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:35.7989846Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005538490135222673, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:35.7991297Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:35.7992400Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:35.7992695Z     
2026-01-14T09:04:35.7993004Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:35.7993400Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:04:35.7993656Z          [0., 0., 0.],
2026-01-14T09:04:35.7993894Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T09:04:35.7994199Z model pt2e: GraphModule(
2026-01-14T09:04:35.7994450Z   (conv): Module()
2026-01-14T09:04:35.7994672Z   (bn): Module()
2026-01-14T09:04:35.7995059Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:35.7996357Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:35.7997857Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:04:35.7998415Z   )
2026-01-14T09:04:35.7998626Z   (_guards_fn): GuardsFn()
2026-01-14T09:04:35.7999012Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:35.8000310Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:35.8001822Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T09:04:35.8002390Z   )
2026-01-14T09:04:35.8002689Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:35.8003996Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:35.8005429Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T09:04:35.8005950Z   )
2026-01-14T09:04:35.8006126Z )
2026-01-14T09:04:35.8006236Z 
2026-01-14T09:04:35.8006240Z 
2026-01-14T09:04:35.8006244Z 
2026-01-14T09:04:35.8006339Z def forward(self, x):
2026-01-14T09:04:35.8006652Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:35.8007016Z     conv_weight = self.conv.weight
2026-01-14T09:04:35.8007311Z     conv_bias = self.conv.bias
2026-01-14T09:04:35.8007577Z     bn_weight = self.bn.weight
2026-01-14T09:04:35.8007847Z     bn_bias = self.bn.bias
2026-01-14T09:04:35.8008159Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:35.8008571Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:35.8008898Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:35.8009302Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:04:35.8009760Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:04:35.8010319Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:35.8010914Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:35.8011423Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:35.8011877Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:35.8012352Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:04:35.8012901Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:35.8013539Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:35.8014290Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:35.8015397Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:35.8016384Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:04:35.8016978Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:04:35.8017614Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T09:04:35.8018222Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:35.8019272Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:35.8020298Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:35.8020881Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:35.8021479Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:35.8021891Z     
2026-01-14T09:04:35.8022193Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:35.8022579Z model fx: GraphModule(
2026-01-14T09:04:35.8022936Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:35.8024233Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:35.8025723Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:04:35.8026297Z   )
2026-01-14T09:04:35.8026495Z   (conv): ConvBnReLU1d(
2026-01-14T09:04:35.8026757Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T09:04:35.8027196Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:35.8027736Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:17.8634287Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:17.8636403Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T09:05:17.8637179Z     )
2026-01-14T09:05:17.8637406Z   )
2026-01-14T09:05:17.8637773Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:17.8639433Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:17.8641252Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T09:05:17.8641898Z   )
2026-01-14T09:05:17.8642458Z )
2026-01-14T09:05:17.8642595Z 
2026-01-14T09:05:17.8642600Z 
2026-01-14T09:05:17.8642605Z 
2026-01-14T09:05:17.8642714Z def forward(self, x):
2026-01-14T09:05:17.8643172Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:17.8643900Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:17.8644647Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:17.8645414Z     return activation_post_process_1
2026-01-14T09:05:17.8645761Z     
2026-01-14T09:05:17.8646122Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:17.8646620Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:05:17.8646917Z          [0., 0., 0.],
2026-01-14T09:05:17.8647271Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:05:17.8647714Z converted model pt2e: GraphModule(
2026-01-14T09:05:17.8648053Z   (conv): Module()
2026-01-14T09:05:17.8648325Z   (bn): Module()
2026-01-14T09:05:17.8648586Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:17.8648875Z )
2026-01-14T09:05:17.8648998Z 
2026-01-14T09:05:17.8649003Z 
2026-01-14T09:05:17.8649008Z 
2026-01-14T09:05:17.8649119Z def forward(self, x):
2026-01-14T09:05:17.8649493Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:17.8649931Z     conv_bias = self.conv.bias
2026-01-14T09:05:17.8650322Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:17.8651259Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8)
2026-01-14T09:05:17.8652958Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:17.8654239Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:17.8655000Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:17.8655727Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:05:17.8656612Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:05:17.8658018Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:05:17.8658985Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T09:05:17.8659852Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005538490135222673, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:17.8661299Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:05:17.8662446Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:05:17.8662890Z     
2026-01-14T09:05:17.8663199Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:17.8663608Z onverted model fx: GraphModule(
2026-01-14T09:05:17.8663887Z   (conv): ConvReLU1d(
2026-01-14T09:05:17.8664244Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:05:17.8664635Z     (1): ReLU()
2026-01-14T09:05:17.8664842Z   )
2026-01-14T09:05:17.8665023Z )
2026-01-14T09:05:17.8665125Z 
2026-01-14T09:05:17.8665129Z 
2026-01-14T09:05:17.8665133Z 
2026-01-14T09:05:17.8665232Z def forward(self, x):
2026-01-14T09:05:17.8665905Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:05:17.8667379Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:17.8668520Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:17.8669482Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005538490135222673, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:17.8671007Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:17.8672001Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:17.8672293Z     
2026-01-14T09:05:17.8672592Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:17.8672988Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:05:17.8673240Z          [0., 0., 0.],
2026-01-14T09:05:17.8673476Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T09:05:17.8673974Z [32mPASSED[0m
2026-01-14T09:05:17.8674642Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T09:05:17.8675408Z   (conv): Module()
2026-01-14T09:05:17.8675628Z   (bn): Module()
2026-01-14T09:05:17.8675953Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:17.8677027Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:17.8678289Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:05:17.8678855Z   )
2026-01-14T09:05:17.8679058Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:17.8679415Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:17.8680551Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:17.8682030Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3276, -0.3045, -0.2418]), max_val=tensor([0.2760, 0.3298, 0.3101]))
2026-01-14T09:05:17.8682777Z   )
2026-01-14T09:05:17.8683096Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:17.8684474Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:17.8685703Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3778926134109497)
2026-01-14T09:05:17.8686216Z   )
2026-01-14T09:05:17.8686396Z )
2026-01-14T09:05:17.8686498Z 
2026-01-14T09:05:17.8686502Z 
2026-01-14T09:05:17.8686506Z 
2026-01-14T09:05:17.8686596Z def forward(self, x):
2026-01-14T09:05:17.8686911Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:17.8687285Z     conv_weight = self.conv.weight
2026-01-14T09:05:17.8687571Z     bn_weight = self.bn.weight
2026-01-14T09:05:17.8687852Z     bn_bias = self.bn.bias
2026-01-14T09:05:17.8688158Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:17.8688534Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:05:17.8688859Z     bn_running_var = self.bn.running_var
2026-01-14T09:05:17.8689268Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:05:17.8689723Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:17.8690450Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:17.8691045Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:05:17.8691471Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:05:17.8691926Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:05:17.8692414Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:05:17.8693178Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:05:17.8693812Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:05:17.8694754Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:17.8695685Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:05:17.8696278Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:05:17.8697339Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:05:17.8698349Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:05:17.8699075Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:17.8699677Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:17.8700087Z     
2026-01-14T09:05:17.8700412Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:17.8700802Z model fx: GraphModule(
2026-01-14T09:05:17.8701151Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:17.8702235Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:53.1572770Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:05:53.1575244Z   )
2026-01-14T09:05:53.1575892Z   (conv): ConvBnReLU1d(
2026-01-14T09:05:53.1576347Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:05:53.1576972Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:05:53.1577633Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:53.1579042Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:53.1580978Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3276, -0.3045, -0.2418]), max_val=tensor([0.2760, 0.3298, 0.3101]))
2026-01-14T09:05:53.1581888Z     )
2026-01-14T09:05:53.1582112Z   )
2026-01-14T09:05:53.1582463Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:53.1583821Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:53.1585582Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3778926134109497)
2026-01-14T09:05:53.1586221Z   )
2026-01-14T09:05:53.1586445Z )
2026-01-14T09:05:53.1586569Z 
2026-01-14T09:05:53.1586575Z 
2026-01-14T09:05:53.1586579Z 
2026-01-14T09:05:53.1586688Z def forward(self, x):
2026-01-14T09:05:53.1587148Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:53.1588189Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:53.1588926Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:53.1589499Z     return activation_post_process_1
2026-01-14T09:05:53.1589830Z     
2026-01-14T09:05:53.1590201Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:53.1590684Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:05:53.1590992Z          [0., 0., 0.],
2026-01-14T09:05:53.1591492Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:53.1591898Z converted model pt2e: GraphModule(
2026-01-14T09:05:53.1592231Z   (conv): Module()
2026-01-14T09:05:53.1592495Z   (bn): Module()
2026-01-14T09:05:53.1592756Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:53.1593048Z )
2026-01-14T09:05:53.1593171Z 
2026-01-14T09:05:53.1593176Z 
2026-01-14T09:05:53.1593181Z 
2026-01-14T09:05:53.1593298Z def forward(self, x):
2026-01-14T09:05:53.1593659Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:53.1594172Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:53.1595171Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:05:53.1596858Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:53.1598129Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:53.1598823Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:53.1599464Z     _scale_0 = self._scale_0
2026-01-14T09:05:53.1599787Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:05:53.1600185Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:05:53.1601407Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:05:53.1602749Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:05:53.1603755Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:05:53.1604824Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T09:05:53.1605686Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0054035005159676075, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:53.1607142Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0054035005159676075, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:53.1608291Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:05:53.1608737Z     
2026-01-14T09:05:53.1609039Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:53.1609459Z onverted model fx: GraphModule(
2026-01-14T09:05:53.1609736Z   (conv): ConvReLU1d(
2026-01-14T09:05:53.1610095Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:05:53.1610493Z     (1): ReLU()
2026-01-14T09:05:53.1610693Z   )
2026-01-14T09:05:53.1610881Z )
2026-01-14T09:05:53.1610985Z 
2026-01-14T09:05:53.1610990Z 
2026-01-14T09:05:53.1610994Z 
2026-01-14T09:05:53.1611084Z def forward(self, x):
2026-01-14T09:05:53.1611762Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:05:53.1613130Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:53.1614364Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:53.1615330Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0054035005159676075, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:53.1616825Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0054035005159676075, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:53.1617837Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:53.1618132Z     
2026-01-14T09:05:53.1618432Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:53.1618836Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:05:53.1619080Z          [0., 0., 0.],
2026-01-14T09:05:53.1619310Z          [0., 0., 0.]]])
2026-01-14T09:05:53.1619554Z model pt2e: GraphModule(
2026-01-14T09:05:53.1619795Z   (conv): Module()
2026-01-14T09:05:53.1620007Z   (bn): Module()
2026-01-14T09:05:53.1620330Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:53.1621406Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:53.1622662Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:05:53.1623225Z   )
2026-01-14T09:05:53.1623421Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:53.1623782Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:53.1624855Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:53.1626139Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T09:05:53.1626709Z   )
2026-01-14T09:05:53.1627001Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:53.1628082Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:53.1629289Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3749419450759888)
2026-01-14T09:05:53.1629794Z   )
2026-01-14T09:05:53.1629975Z )
2026-01-14T09:05:53.1630078Z 
2026-01-14T09:05:53.1630082Z 
2026-01-14T09:05:53.1630086Z 
2026-01-14T09:05:53.1630178Z def forward(self, x):
2026-01-14T09:05:53.1630510Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:53.1630887Z     conv_weight = self.conv.weight
2026-01-14T09:05:53.1631176Z     bn_weight = self.bn.weight
2026-01-14T09:05:53.1631446Z     bn_bias = self.bn.bias
2026-01-14T09:05:53.1631756Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:53.1632131Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:05:53.1632451Z     bn_running_var = self.bn.running_var
2026-01-14T09:05:53.1632859Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:05:53.1633313Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:53.1633892Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:53.1634554Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:05:53.1635030Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:05:53.1635484Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:05:53.1636052Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:05:53.1636608Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:05:53.1637225Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:05:53.1638171Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:53.1639184Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:05:53.1639773Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:05:53.1640826Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:05:53.1641835Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:05:53.1642416Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:53.1643012Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:53.1643426Z     
2026-01-14T09:05:53.1643739Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:53.1644136Z model fx: GraphModule(
2026-01-14T09:05:53.1644521Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:21.3072631Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:21.3074769Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:06:21.3075633Z   )
2026-01-14T09:06:21.3075909Z   (conv): ConvBnReLU1d(
2026-01-14T09:06:21.3076269Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:06:21.3076865Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:06:21.3077528Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:21.3078878Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:21.3080504Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T09:06:21.3081225Z     )
2026-01-14T09:06:21.3081440Z   )
2026-01-14T09:06:21.3081793Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:21.3083150Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:21.3084919Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3749419450759888)
2026-01-14T09:06:21.3085567Z   )
2026-01-14T09:06:21.3085783Z )
2026-01-14T09:06:21.3085917Z 
2026-01-14T09:06:21.3085922Z 
2026-01-14T09:06:21.3085927Z 
2026-01-14T09:06:21.3086039Z def forward(self, x):
2026-01-14T09:06:21.3086504Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:21.3087218Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:21.3087963Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:21.3088533Z     return activation_post_process_1
2026-01-14T09:06:21.3088869Z     
2026-01-14T09:06:21.3089223Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:21.3090012Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:06:21.3090309Z          [0., 0., 0.],
2026-01-14T09:06:21.3090613Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:21.3091009Z converted model pt2e: GraphModule(
2026-01-14T09:06:21.3091341Z   (conv): Module()
2026-01-14T09:06:21.3091598Z   (bn): Module()
2026-01-14T09:06:21.3091858Z   (_guards_fn): GuardsFn()
2026-01-14T09:06:21.3092147Z )
2026-01-14T09:06:21.3092271Z 
2026-01-14T09:06:21.3092276Z 
2026-01-14T09:06:21.3092281Z 
2026-01-14T09:06:21.3092389Z def forward(self, x):
2026-01-14T09:06:21.3092954Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:21.3093462Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:06:21.3094470Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:06:21.3095939Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:21.3096976Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:06:21.3097556Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:06:21.3098122Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:06:21.3099011Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002597068203613162, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:06:21.3099914Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:06:21.3100829Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:06:21.3101856Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T09:06:21.3102737Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0053919292986392975, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:06:21.3104210Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0053919292986392975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:06:21.3105376Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:06:21.3105817Z     
2026-01-14T09:06:21.3106120Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:21.3106530Z onverted model fx: GraphModule(
2026-01-14T09:06:21.3114833Z   (conv): ConvReLU1d(
2026-01-14T09:06:21.3115239Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:06:21.3115640Z     (1): ReLU()
2026-01-14T09:06:21.3115855Z   )
2026-01-14T09:06:21.3116040Z )
2026-01-14T09:06:21.3116162Z 
2026-01-14T09:06:21.3116167Z 
2026-01-14T09:06:21.3116171Z 
2026-01-14T09:06:21.3116264Z def forward(self, x):
2026-01-14T09:06:21.3116960Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:06:21.3118363Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:21.3119506Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:21.3120489Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0053919292986392975, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:21.3121968Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0053919292986392975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:21.3123117Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:21.3123416Z     
2026-01-14T09:06:21.3123740Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:21.3124143Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:06:21.3124411Z          [0., 0., 0.],
2026-01-14T09:06:21.3124645Z          [0., 0., 0.]]])
2026-01-14T09:06:21.3125098Z [32mPASSED[0m
2026-01-14T09:06:21.3125801Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T09:06:21.3126462Z   (conv): Module()
2026-01-14T09:06:21.3126803Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:21.3127976Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:21.3129497Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T09:06:21.3130229Z   )
2026-01-14T09:06:21.3130535Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:21.3131626Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:21.3132903Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:06:21.3133499Z   )
2026-01-14T09:06:21.3133732Z   (_guards_fn): GuardsFn()
2026-01-14T09:06:21.3134094Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:21.3135195Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0038]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:21.3136428Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9578298330307007)
2026-01-14T09:06:21.3136952Z   )
2026-01-14T09:06:21.3137139Z )
2026-01-14T09:06:21.3137246Z 
2026-01-14T09:06:21.3137250Z 
2026-01-14T09:06:21.3137254Z 
2026-01-14T09:06:21.3137346Z def forward(self, x):
2026-01-14T09:06:21.3137674Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:21.3138051Z     conv_weight = self.conv.weight
2026-01-14T09:06:21.3138562Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:21.3139185Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:06:21.3139651Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:06:21.3140489Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:06:21.3141347Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T09:06:21.3141892Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:06:21.3142492Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:06:21.3142916Z     
2026-01-14T09:06:21.3143222Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:21.3143626Z model fx: GraphModule(
2026-01-14T09:06:21.3144006Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:21.3145106Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:21.3146480Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:06:21.3147037Z   )
2026-01-14T09:06:21.3147231Z   (conv): ConvReLU1d(
2026-01-14T09:06:21.3147503Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:06:21.3147897Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:21.3149111Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:21.3150621Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T09:06:21.3151342Z     )
2026-01-14T09:06:25.2940225Z   )
2026-01-14T09:06:25.2940680Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:25.2942083Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0038]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:25.2943698Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9578298330307007)
2026-01-14T09:06:25.2944337Z   )
2026-01-14T09:06:25.2944592Z )
2026-01-14T09:06:25.2944742Z 
2026-01-14T09:06:25.2944747Z 
2026-01-14T09:06:25.2944761Z 
2026-01-14T09:06:25.2944878Z def forward(self, x):
2026-01-14T09:06:25.2945341Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:25.2946059Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:25.2946807Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:25.2947393Z     return activation_post_process_1
2026-01-14T09:06:25.2947732Z     
2026-01-14T09:06:25.2948101Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:25.2948586Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:06:25.2948896Z          [0., 0., 0.],
2026-01-14T09:06:25.2949200Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:25.2949601Z converted model pt2e: GraphModule(
2026-01-14T09:06:25.2949937Z   (conv): Module()
2026-01-14T09:06:25.2950213Z   (_guards_fn): GuardsFn()
2026-01-14T09:06:25.2950493Z )
2026-01-14T09:06:25.2950625Z 
2026-01-14T09:06:25.2950635Z 
2026-01-14T09:06:25.2950640Z 
2026-01-14T09:06:25.2950749Z def forward(self, x):
2026-01-14T09:06:25.2951119Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:25.2951550Z     _scale_0 = self._scale_0
2026-01-14T09:06:25.2951880Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:06:25.2952293Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:06:25.2953697Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:06:25.2955659Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:06:25.2957341Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:25.2958609Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:06:25.2959717Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:06:25.2960854Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T09:06:25.2962273Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0037561955396085978, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:06:25.2964092Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0037561955396085978, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:25.2965567Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:06:25.2966285Z     
2026-01-14T09:06:25.2966650Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:25.2967156Z onverted model fx: GraphModule(
2026-01-14T09:06:25.2967481Z   (conv): ConvReLU1d(
2026-01-14T09:06:25.2967962Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T09:06:25.2968500Z     (1): ReLU()
2026-01-14T09:06:25.2968747Z   )
2026-01-14T09:06:25.2968968Z )
2026-01-14T09:06:25.2969106Z 
2026-01-14T09:06:25.2969111Z 
2026-01-14T09:06:25.2969116Z 
2026-01-14T09:06:25.2969225Z def forward(self, x):
2026-01-14T09:06:25.2970063Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:06:25.2971788Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:25.2973206Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:25.2974459Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0037561955396085978, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:25.2976279Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0037561955396085978, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:25.2977541Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:25.2977891Z     
2026-01-14T09:06:25.2978257Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:25.2978747Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:06:25.2979044Z          [0., 0., 0.],
2026-01-14T09:06:25.2979342Z          [0., 0., 0.]]])
2026-01-14T09:06:25.2979633Z model pt2e: GraphModule(
2026-01-14T09:06:25.2979932Z   (conv): Module()
2026-01-14T09:06:25.2980336Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:25.2981673Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:25.2983283Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3119288384914398, max_val=0.23078612983226776)
2026-01-14T09:06:25.2983993Z   )
2026-01-14T09:06:25.2984630Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:25.2985981Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:25.2987545Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:06:25.2988248Z   )
2026-01-14T09:06:25.2988488Z   (_guards_fn): GuardsFn()
2026-01-14T09:06:25.2988917Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:25.2990242Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0037]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:25.2992075Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9556508660316467)
2026-01-14T09:06:25.2992717Z   )
2026-01-14T09:06:25.2992927Z )
2026-01-14T09:06:25.2993050Z 
2026-01-14T09:06:25.2993063Z 
2026-01-14T09:06:25.2993068Z 
2026-01-14T09:06:25.2993177Z def forward(self, x):
2026-01-14T09:06:25.2993540Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:25.2993989Z     conv_weight = self.conv.weight
2026-01-14T09:06:25.2994845Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:25.2995628Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:06:25.2996179Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:06:25.2997182Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:06:25.2998329Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T09:06:25.2998947Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:06:25.2999557Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:06:25.2999978Z     
2026-01-14T09:06:25.3000274Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:25.3000672Z model fx: GraphModule(
2026-01-14T09:06:25.3001026Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:25.3002116Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:25.3003389Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:06:25.3003958Z   )
2026-01-14T09:06:25.3004158Z   (conv): ConvReLU1d(
2026-01-14T09:06:25.3004435Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:06:25.3004832Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:25.3005887Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:25.3007190Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3119288384914398, max_val=0.23078612983226776)
2026-01-14T09:06:25.3007769Z     )
2026-01-14T09:06:25.3007948Z   )
2026-01-14T09:06:25.3008255Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:25.3009338Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0037]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:25.3010569Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9556508660316467)
2026-01-14T09:06:25.3011090Z   )
2026-01-14T09:06:25.3011269Z )
2026-01-14T09:06:25.3011374Z 
2026-01-14T09:06:25.3011378Z 
2026-01-14T09:06:25.3011382Z 
2026-01-14T09:06:25.3011481Z def forward(self, x):
2026-01-14T09:06:25.3011856Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:25.3012447Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:25.3013054Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:25.3013526Z     return activation_post_process_1
2026-01-14T09:06:25.3013817Z     
2026-01-14T09:06:25.3014115Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:25.3014516Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:06:25.3014763Z          [0., 0., 0.],
2026-01-14T09:06:25.3015031Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:25.3015457Z converted model pt2e: GraphModule(
2026-01-14T09:06:25.3015739Z   (conv): Module()
2026-01-14T09:06:25.3015971Z   (_guards_fn): GuardsFn()
2026-01-14T09:06:25.3016215Z )
2026-01-14T09:06:25.3016319Z 
2026-01-14T09:06:25.3016323Z 
2026-01-14T09:06:25.3016327Z 
2026-01-14T09:06:25.3016425Z def forward(self, x):
2026-01-14T09:06:25.3016727Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:25.3017148Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:06:33.6519511Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0024561325553804636, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:33.6521301Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:06:33.6523011Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:33.6524308Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:06:33.6525424Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:06:33.6526591Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T09:06:33.6527680Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003747650422155857, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:06:33.6529488Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003747650422155857, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:06:33.6530905Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:06:33.6531452Z     
2026-01-14T09:06:33.6531820Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:33.6532315Z onverted model fx: GraphModule(
2026-01-14T09:06:33.6532645Z   (conv): ConvReLU1d(
2026-01-14T09:06:33.6533121Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T09:06:33.6533651Z     (1): ReLU()
2026-01-14T09:06:33.6533900Z   )
2026-01-14T09:06:33.6534120Z )
2026-01-14T09:06:33.6534245Z 
2026-01-14T09:06:33.6534250Z 
2026-01-14T09:06:33.6534263Z 
2026-01-14T09:06:33.6534379Z def forward(self, x):
2026-01-14T09:06:33.6535200Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:06:33.6536919Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:33.6538379Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:33.6539553Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003747650422155857, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:33.6541361Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003747650422155857, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:33.6542604Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:33.6542950Z     
2026-01-14T09:06:33.6543311Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:33.6543794Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:06:33.6544094Z          [0., 0., 0.],
2026-01-14T09:06:33.6544359Z          [0., 0., 0.]]])
2026-01-14T09:06:33.6544844Z model pt2e: GraphModule(
2026-01-14T09:06:33.6545135Z   (conv): Module()
2026-01-14T09:06:33.6545524Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:33.6546946Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0025, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:33.6548891Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2203, -0.3233, -0.3086]), max_val=tensor([0.2796, 0.3026, 0.2405]))
2026-01-14T09:06:33.6549785Z   )
2026-01-14T09:06:33.6550131Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:33.6551449Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:33.6553016Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:06:33.6553704Z   )
2026-01-14T09:06:33.6553948Z   (_guards_fn): GuardsFn()
2026-01-14T09:06:33.6554372Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:33.6555833Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-25], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:33.6557402Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8935509324073792, max_val=1.3209781646728516)
2026-01-14T09:06:33.6558103Z   )
2026-01-14T09:06:33.6558321Z )
2026-01-14T09:06:33.6558443Z 
2026-01-14T09:06:33.6558448Z 
2026-01-14T09:06:33.6558452Z 
2026-01-14T09:06:33.6558560Z def forward(self, x):
2026-01-14T09:06:33.6558928Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:33.6559376Z     conv_weight = self.conv.weight
2026-01-14T09:06:33.6559981Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:33.6560729Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:06:33.6561273Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:06:33.6562288Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:06:33.6563424Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T09:06:33.6564176Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:06:33.6564694Z     
2026-01-14T09:06:33.6565051Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:33.6565535Z model fx: GraphModule(
2026-01-14T09:06:33.6565948Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:33.6567276Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:33.6568835Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:06:33.6569530Z   )
2026-01-14T09:06:33.6569764Z   (conv): Conv1d(
2026-01-14T09:06:33.6570064Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:06:33.6570536Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:33.6571912Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0025, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:33.6573877Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2203, -0.3233, -0.3086]), max_val=tensor([0.2796, 0.3026, 0.2405]))
2026-01-14T09:06:33.6574813Z     )
2026-01-14T09:06:33.6575038Z   )
2026-01-14T09:06:33.6575409Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:33.6576624Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-25], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:33.6577953Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8935509324073792, max_val=1.3209781646728516)
2026-01-14T09:06:33.6578516Z   )
2026-01-14T09:06:33.6578700Z )
2026-01-14T09:06:33.6578803Z 
2026-01-14T09:06:33.6578806Z 
2026-01-14T09:06:33.6578810Z 
2026-01-14T09:06:33.6578904Z def forward(self, x):
2026-01-14T09:06:33.6579281Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:33.6579878Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:33.6580473Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:33.6580942Z     return activation_post_process_1
2026-01-14T09:06:33.6581216Z     
2026-01-14T09:06:33.6581518Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:33.6581913Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:06:33.6582165Z          [0., 0., 0.],
2026-01-14T09:06:33.6582424Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:33.6582750Z converted model pt2e: GraphModule(
2026-01-14T09:06:33.6583040Z   (conv): Module()
2026-01-14T09:06:33.6583262Z   (_guards_fn): GuardsFn()
2026-01-14T09:06:33.6583501Z )
2026-01-14T09:06:33.6583603Z 
2026-01-14T09:06:33.6583607Z 
2026-01-14T09:06:33.6583611Z 
2026-01-14T09:06:33.6583707Z def forward(self, x):
2026-01-14T09:06:33.6584013Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:33.6584614Z     _scale_0 = self._scale_0
2026-01-14T09:06:33.6584880Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:06:33.6585226Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:06:33.6586346Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:06:33.6587833Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:06:33.6589145Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:33.6590132Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:06:33.6591032Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:06:33.6592370Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.008684427477419376, -25, -128, 127, torch.int8);  conv1d = None
2026-01-14T09:06:37.1957536Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008684427477419376, -25, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:37.1959060Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:06:37.1959606Z     
2026-01-14T09:06:37.1959971Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:37.1960476Z onverted model fx: GraphModule(
2026-01-14T09:06:37.1961217Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T09:06:37.1961768Z )
2026-01-14T09:06:37.1961892Z 
2026-01-14T09:06:37.1961897Z 
2026-01-14T09:06:37.1961902Z 
2026-01-14T09:06:37.1962010Z def forward(self, x):
2026-01-14T09:06:37.1962846Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:06:37.1964707Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:37.1966108Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:37.1967294Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008684427477419376, -25, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:37.1969099Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008684427477419376, -25, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:37.1970329Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:37.1970685Z     
2026-01-14T09:06:37.1971042Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:37.1971530Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:06:37.1971830Z          [0., 0., 0.],
2026-01-14T09:06:37.1972115Z          [0., 0., 0.]]])
2026-01-14T09:06:37.1972402Z model pt2e: GraphModule(
2026-01-14T09:06:37.1972700Z   (conv): Module()
2026-01-14T09:06:37.1973090Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:37.1974423Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:37.1976025Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232726454734802, max_val=0.30256539583206177)
2026-01-14T09:06:37.1976728Z   )
2026-01-14T09:06:37.1977082Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:37.1978399Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:37.1979955Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:06:37.1980648Z   )
2026-01-14T09:06:37.1980881Z   (_guards_fn): GuardsFn()
2026-01-14T09:06:37.1981308Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:37.1982626Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-26], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:37.1984406Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.887858510017395, max_val=1.3209781646728516)
2026-01-14T09:06:37.1985107Z   )
2026-01-14T09:06:37.1985314Z )
2026-01-14T09:06:37.1985443Z 
2026-01-14T09:06:37.1985449Z 
2026-01-14T09:06:37.1985453Z 
2026-01-14T09:06:37.1985559Z def forward(self, x):
2026-01-14T09:06:37.1985920Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:37.1986371Z     conv_weight = self.conv.weight
2026-01-14T09:06:37.1986970Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:37.1987719Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:06:37.1988264Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:06:37.1989265Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:06:37.1990588Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T09:06:37.1991332Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:06:37.1991858Z     
2026-01-14T09:06:37.1992221Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:37.1992700Z model fx: GraphModule(
2026-01-14T09:06:37.1993231Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:37.1994549Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:37.1996200Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:06:37.1996909Z   )
2026-01-14T09:06:37.1997127Z   (conv): Conv1d(
2026-01-14T09:06:37.1997431Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T09:06:37.1997893Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:37.1999245Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:37.2000844Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232726454734802, max_val=0.30256539583206177)
2026-01-14T09:06:37.2001553Z     )
2026-01-14T09:06:37.2001778Z   )
2026-01-14T09:06:37.2002125Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:37.2003449Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-26], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:37.2005016Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.887858510017395, max_val=1.3209781646728516)
2026-01-14T09:06:37.2005711Z   )
2026-01-14T09:06:37.2005921Z )
2026-01-14T09:06:37.2006049Z 
2026-01-14T09:06:37.2006053Z 
2026-01-14T09:06:37.2006058Z 
2026-01-14T09:06:37.2006163Z def forward(self, x):
2026-01-14T09:06:37.2006614Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:37.2007328Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:06:37.2008062Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:37.2008625Z     return activation_post_process_1
2026-01-14T09:06:37.2008957Z     
2026-01-14T09:06:37.2009317Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:37.2009796Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:06:37.2010094Z          [0., 0., 0.],
2026-01-14T09:06:37.2010397Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:37.2010791Z converted model pt2e: GraphModule(
2026-01-14T09:06:37.2011124Z   (conv): Module()
2026-01-14T09:06:37.2011353Z   (_guards_fn): GuardsFn()
2026-01-14T09:06:37.2011582Z )
2026-01-14T09:06:37.2011695Z 
2026-01-14T09:06:37.2011699Z 
2026-01-14T09:06:37.2011703Z 
2026-01-14T09:06:37.2011790Z def forward(self, x):
2026-01-14T09:06:37.2012100Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:37.2012510Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:06:37.2013507Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.002545453840866685, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:37.2014848Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:06:37.2016288Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:37.2017312Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:06:37.2018209Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:06:37.2019657Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.008662103675305843, -26, -128, 127, torch.int8);  conv1d = None
2026-01-14T09:06:37.2021093Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.008662103675305843, -26, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:06:37.2022210Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:06:37.2022655Z     
2026-01-14T09:06:37.2022954Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:37.2023364Z onverted model fx: GraphModule(
2026-01-14T09:06:37.2023795Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T09:06:37.2024239Z )
2026-01-14T09:06:37.2024342Z 
2026-01-14T09:06:37.2024346Z 
2026-01-14T09:06:37.2024349Z 
2026-01-14T09:06:37.2024446Z def forward(self, x):
2026-01-14T09:06:37.2025119Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:06:37.2026496Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:37.2027623Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:37.2036571Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008662103675305843, -26, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:37.2038062Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008662103675305843, -26, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:37.2039064Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:37.2039357Z     
2026-01-14T09:06:37.2039671Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:37.2040073Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:08:55.5762170Z          [0., 0., 0.],
2026-01-14T09:08:55.5764832Z          [0., 0., 0.]]])
2026-01-14T09:08:55.5765593Z [32mPASSED[0m
2026-01-14T09:08:55.5766326Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T09:08:55.5767448Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T09:08:55.5768461Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T09:08:55.5769156Z   (conv): Module()
2026-01-14T09:08:55.5769489Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:55.5770614Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:08:55.5772023Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2457]), max_val=tensor([-0.2457]))
2026-01-14T09:08:55.5772651Z   )
2026-01-14T09:08:55.5772966Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:55.5774483Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:55.5775748Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T09:08:55.5776315Z   )
2026-01-14T09:08:55.5776519Z   (_guards_fn): GuardsFn()
2026-01-14T09:08:55.5777082Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:55.5778145Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:55.5779405Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T09:08:55.5779981Z   )
2026-01-14T09:08:55.5780284Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:55.5781368Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:55.5782589Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T09:08:55.5783124Z   )
2026-01-14T09:08:55.5783349Z )
2026-01-14T09:08:55.5783458Z 
2026-01-14T09:08:55.5783462Z 
2026-01-14T09:08:55.5783466Z 
2026-01-14T09:08:55.5783559Z def forward(self, x):
2026-01-14T09:08:55.5783876Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:55.5784439Z     conv_weight = self.conv.weight
2026-01-14T09:08:55.5784944Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:08:55.5785460Z     conv_bias = self.conv.bias
2026-01-14T09:08:55.5785827Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:08:55.5786289Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:08:55.5787080Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:08:55.5787990Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T09:08:55.5788897Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:08:55.5789709Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:08:55.5790227Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:08:55.5790826Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:08:55.5791248Z     
2026-01-14T09:08:55.5791549Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:55.5791942Z model fx: GraphModule(
2026-01-14T09:08:55.5792286Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:55.5793351Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:55.5794628Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T09:08:55.5795254Z   )
2026-01-14T09:08:55.5795450Z   (conv): Conv1d(
2026-01-14T09:08:55.5795683Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T09:08:55.5796054Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:55.5797118Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:08:55.5798615Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2457]), max_val=tensor([-0.2457]))
2026-01-14T09:08:55.5799250Z     )
2026-01-14T09:08:55.5799432Z   )
2026-01-14T09:08:55.5799737Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:55.5800920Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:55.5802213Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T09:08:55.5802789Z   )
2026-01-14T09:08:55.5802992Z   (relu): ReLU(inplace=True)
2026-01-14T09:08:55.5803364Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:55.5804471Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:55.5805706Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T09:08:55.5806229Z   )
2026-01-14T09:08:55.5806405Z )
2026-01-14T09:08:55.5806509Z 
2026-01-14T09:08:55.5806519Z 
2026-01-14T09:08:55.5806530Z 
2026-01-14T09:08:55.5806623Z def forward(self, x):
2026-01-14T09:08:55.5807001Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:55.5807482Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:08:55.5807966Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:08:55.5808750Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:08:55.5809396Z     relu = self.relu(add);  add = None
2026-01-14T09:08:55.5809841Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:08:55.5810315Z     return activation_post_process_2
2026-01-14T09:08:55.5810591Z     
2026-01-14T09:08:55.5810900Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:55.5811343Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:08:55.5811716Z converted model pt2e: GraphModule(
2026-01-14T09:08:55.5812006Z   (conv): Module()
2026-01-14T09:08:55.5812242Z   (_guards_fn): GuardsFn()
2026-01-14T09:08:55.5812487Z )
2026-01-14T09:08:55.5812593Z 
2026-01-14T09:08:55.5812597Z 
2026-01-14T09:08:55.5812601Z 
2026-01-14T09:08:55.5812696Z def forward(self, x):
2026-01-14T09:08:55.5813012Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:55.5813420Z     _scale_0 = self._scale_0
2026-01-14T09:08:55.5813706Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:08:55.5814053Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:08:55.5815203Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:08:55.5816304Z     conv_bias = self.conv.bias
2026-01-14T09:08:55.5816980Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T09:08:55.5818205Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T09:08:55.5819705Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:55.5820828Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:08:55.5821836Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T09:08:55.5823352Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv1d = None
2026-01-14T09:08:55.5824814Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:55.5826334Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T09:08:55.5827245Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:08:55.5828089Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:08:55.5829557Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:55.5830681Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:08:55.5831134Z     
2026-01-14T09:08:59.2233073Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:59.2233621Z onverted model fx: GraphModule(
2026-01-14T09:08:59.2234206Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T09:08:59.2234690Z   (relu): ReLU(inplace=True)
2026-01-14T09:08:59.2235054Z )
2026-01-14T09:08:59.2235175Z 
2026-01-14T09:08:59.2235180Z 
2026-01-14T09:08:59.2235184Z 
2026-01-14T09:08:59.2235292Z def forward(self, x):
2026-01-14T09:08:59.2235981Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T09:08:59.2237694Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:59.2239023Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:08:59.2239832Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv = None
2026-01-14T09:08:59.2241274Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:59.2242654Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:08:59.2243365Z     relu = self.relu(add);  add = None
2026-01-14T09:08:59.2244131Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:08:59.2245620Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:59.2246599Z     return dequantize_per_tensor_default_2
2026-01-14T09:08:59.2246899Z     
2026-01-14T09:08:59.2247201Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:59.2247855Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T09:08:59.2248124Z model pt2e: GraphModule(
2026-01-14T09:08:59.2248378Z   (conv): Module()
2026-01-14T09:08:59.2248705Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:59.2249775Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:08:59.2251224Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24565386772155762, max_val=-0.24565386772155762)
2026-01-14T09:08:59.2251795Z   )
2026-01-14T09:08:59.2252094Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:59.2253172Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:59.2254424Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T09:08:59.2255006Z   )
2026-01-14T09:08:59.2255239Z   (_guards_fn): GuardsFn()
2026-01-14T09:08:59.2255597Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:59.2256672Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:59.2257929Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T09:08:59.2258495Z   )
2026-01-14T09:08:59.2258784Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:59.2259869Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:59.2261077Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T09:08:59.2261585Z   )
2026-01-14T09:08:59.2261771Z )
2026-01-14T09:08:59.2261875Z 
2026-01-14T09:08:59.2261879Z 
2026-01-14T09:08:59.2261883Z 
2026-01-14T09:08:59.2261972Z def forward(self, x):
2026-01-14T09:08:59.2262289Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:59.2262664Z     conv_weight = self.conv.weight
2026-01-14T09:08:59.2263168Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:08:59.2263678Z     conv_bias = self.conv.bias
2026-01-14T09:08:59.2264046Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:08:59.2264505Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:08:59.2265293Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:08:59.2266207Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T09:08:59.2267104Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:08:59.2267911Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:08:59.2268442Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:08:59.2269038Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:08:59.2269460Z     
2026-01-14T09:08:59.2269754Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:59.2270160Z model fx: GraphModule(
2026-01-14T09:08:59.2270497Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:59.2271686Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:59.2272949Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T09:08:59.2273511Z   )
2026-01-14T09:08:59.2273709Z   (conv): Conv1d(
2026-01-14T09:08:59.2274014Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T09:08:59.2274380Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:59.2275565Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:08:59.2276854Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24565386772155762, max_val=-0.24565386772155762)
2026-01-14T09:08:59.2277441Z     )
2026-01-14T09:08:59.2277625Z   )
2026-01-14T09:08:59.2277928Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:59.2278982Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:59.2280265Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T09:08:59.2280832Z   )
2026-01-14T09:08:59.2281041Z   (relu): ReLU(inplace=True)
2026-01-14T09:08:59.2281415Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:59.2282475Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:59.2283702Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T09:08:59.2284455Z   )
2026-01-14T09:08:59.2284636Z )
2026-01-14T09:08:59.2284756Z 
2026-01-14T09:08:59.2284761Z 
2026-01-14T09:08:59.2284765Z 
2026-01-14T09:08:59.2284855Z def forward(self, x):
2026-01-14T09:08:59.2285263Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:59.2285762Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:08:59.2286244Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:08:59.2287019Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:08:59.2287647Z     relu = self.relu(add);  add = None
2026-01-14T09:08:59.2288099Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:08:59.2288569Z     return activation_post_process_2
2026-01-14T09:08:59.2288859Z     
2026-01-14T09:08:59.2289148Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:59.2289598Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:08:59.2289953Z converted model pt2e: GraphModule(
2026-01-14T09:08:59.2290225Z   (conv): Module()
2026-01-14T09:08:59.2290458Z   (_guards_fn): GuardsFn()
2026-01-14T09:08:59.2290691Z )
2026-01-14T09:08:59.2290802Z 
2026-01-14T09:08:59.2290806Z 
2026-01-14T09:08:59.2290810Z 
2026-01-14T09:08:59.2290904Z def forward(self, x):
2026-01-14T09:08:59.2291210Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:59.2291622Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:08:59.2292632Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0019342823652550578, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:59.2293737Z     conv_bias = self.conv.bias
2026-01-14T09:08:59.2294405Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T09:08:59.2295675Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T09:08:59.2297288Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:59.2298317Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:10:11.5073618Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T09:10:11.5075561Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv1d = None
2026-01-14T09:10:11.5077412Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:10:11.5079348Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T09:10:11.5080453Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:10:11.5081503Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:10:11.5083327Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:10:11.5084972Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:10:11.5085566Z     
2026-01-14T09:10:11.5085955Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:10:11.5086469Z onverted model fx: GraphModule(
2026-01-14T09:10:11.5086879Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T09:10:11.5087310Z   (relu): ReLU(inplace=True)
2026-01-14T09:10:11.5087561Z )
2026-01-14T09:10:11.5087664Z 
2026-01-14T09:10:11.5087668Z 
2026-01-14T09:10:11.5087678Z 
2026-01-14T09:10:11.5087768Z def forward(self, x):
2026-01-14T09:10:11.5088432Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T09:10:11.5089813Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:10:11.5090813Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:10:11.5091612Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv = None
2026-01-14T09:10:11.5093051Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:10:11.5094413Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:10:11.5095125Z     relu = self.relu(add);  add = None
2026-01-14T09:10:11.5095883Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:10:11.5097629Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:10:11.5098667Z     return dequantize_per_tensor_default_2
2026-01-14T09:10:11.5098960Z     
2026-01-14T09:10:11.5099498Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:10:11.5099905Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T09:10:11.5100381Z [32mPASSED[0m
2026-01-14T09:10:11.5101133Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T09:10:11.5102271Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T09:10:11.5103289Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T09:10:11.5103951Z   (conv): Module()
2026-01-14T09:10:11.5104167Z   (bn): Module()
2026-01-14T09:10:11.5104499Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:11.5105579Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:10:11.5106895Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:10:11.5107464Z   )
2026-01-14T09:10:11.5107663Z   (_guards_fn): GuardsFn()
2026-01-14T09:10:11.5108028Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:11.5109204Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:10:11.5110708Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3156, -0.1982, -0.3261]), max_val=tensor([0.2827, 0.2978, 0.2359]))
2026-01-14T09:10:11.5111411Z   )
2026-01-14T09:10:11.5111705Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:11.5112784Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:10:11.5114036Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T09:10:11.5114590Z   )
2026-01-14T09:10:11.5114938Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:11.5115991Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:10:11.5117243Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T09:10:11.5117800Z   )
2026-01-14T09:10:11.5117979Z )
2026-01-14T09:10:11.5118083Z 
2026-01-14T09:10:11.5118087Z 
2026-01-14T09:10:11.5118096Z 
2026-01-14T09:10:11.5118190Z def forward(self, x):
2026-01-14T09:10:11.5118498Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:10:11.5118864Z     conv_weight = self.conv.weight
2026-01-14T09:10:11.5119153Z     conv_bias = self.conv.bias
2026-01-14T09:10:11.5119429Z     bn_weight = self.bn.weight
2026-01-14T09:10:11.5119692Z     bn_bias = self.bn.bias
2026-01-14T09:10:11.5120011Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:10:11.5120480Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:10:11.5120801Z     bn_running_var = self.bn.running_var
2026-01-14T09:10:11.5121205Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:10:11.5121657Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:10:11.5122231Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:10:11.5122903Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:10:11.5123338Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:10:11.5123792Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:10:11.5124270Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:10:11.5124819Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:10:11.5125441Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:10:11.5126124Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:10:11.5127224Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:10:11.5128220Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:10:11.5128875Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:10:11.5129510Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T09:10:11.5130126Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:10:11.5131146Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:10:11.5132254Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:10:11.5133089Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:10:11.5133881Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:10:11.5134517Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:10:11.5134932Z     
2026-01-14T09:10:11.5135238Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:10:11.5135634Z model fx: GraphModule(
2026-01-14T09:10:11.5135979Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:11.5137059Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:10:11.5138321Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:10:11.5138942Z   )
2026-01-14T09:10:11.5139147Z   (conv): ConvBn1d(
2026-01-14T09:10:11.5139384Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T09:10:11.5139828Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:10:44.1173169Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:44.1176490Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:10:44.1186342Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3156, -0.1982, -0.3261]), max_val=tensor([0.2827, 0.2978, 0.2359]))
2026-01-14T09:10:44.1187506Z     )
2026-01-14T09:10:44.1187724Z   )
2026-01-14T09:10:44.1188086Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:44.1189476Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:10:44.1191199Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T09:10:44.1191909Z   )
2026-01-14T09:10:44.1192183Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:10:44.1192698Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:44.1194028Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:10:44.1195680Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T09:10:44.1196377Z   )
2026-01-14T09:10:44.1196594Z )
2026-01-14T09:10:44.1196725Z 
2026-01-14T09:10:44.1196730Z 
2026-01-14T09:10:44.1196735Z 
2026-01-14T09:10:44.1196843Z def forward(self, x):
2026-01-14T09:10:44.1197292Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:10:44.1198016Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:10:44.1198756Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:10:44.1199584Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:10:44.1200412Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:10:44.1201023Z     return activation_post_process_2
2026-01-14T09:10:44.1201367Z     
2026-01-14T09:10:44.1201723Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:10:44.1202212Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:10:44.1202517Z          [0., 0., 0.],
2026-01-14T09:10:44.1202814Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:10:44.1203213Z converted model pt2e: GraphModule(
2026-01-14T09:10:44.1203543Z   (conv): Module()
2026-01-14T09:10:44.1203810Z   (bn): Module()
2026-01-14T09:10:44.1204069Z   (_guards_fn): GuardsFn()
2026-01-14T09:10:44.1204359Z )
2026-01-14T09:10:44.1204483Z 
2026-01-14T09:10:44.1204488Z 
2026-01-14T09:10:44.1204493Z 
2026-01-14T09:10:44.1204602Z def forward(self, x):
2026-01-14T09:10:44.1204970Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:10:44.1205408Z     conv_bias = self.conv.bias
2026-01-14T09:10:44.1205790Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:10:44.1206702Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:10:44.1208384Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:10:44.1209641Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:10:44.1210413Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:10:44.1211089Z     _scale_0 = self._scale_0
2026-01-14T09:10:44.1211401Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:10:44.1211722Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:10:44.1212718Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:10:44.1214329Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:10:44.1215661Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010604282841086388, -5, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T09:10:44.1217205Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:10:44.1218500Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T09:10:44.1219687Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010604282841086388, -5, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:10:44.1221121Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:10:44.1222233Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:10:44.1222675Z     
2026-01-14T09:10:44.1222976Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:10:44.1223371Z onverted model fx: GraphModule(
2026-01-14T09:10:44.1223777Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:10:44.1224226Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:10:44.1224539Z )
2026-01-14T09:10:44.1224641Z 
2026-01-14T09:10:44.1224646Z 
2026-01-14T09:10:44.1224650Z 
2026-01-14T09:10:44.1224737Z def forward(self, x):
2026-01-14T09:10:44.1225409Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:10:44.1226787Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:10:44.1227896Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:10:44.1228858Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010604282841086388, -5, -128, 127, torch.int8);  conv = None
2026-01-14T09:10:44.1230302Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:10:44.1231468Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:10:44.1232507Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010604282841086388, -5, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:10:44.1233932Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:10:44.1234962Z     return dequantize_per_tensor_default_2
2026-01-14T09:10:44.1235255Z     
2026-01-14T09:10:44.1235552Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:10:44.1235951Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:10:44.1236195Z          [0., 0., 0.],
2026-01-14T09:10:44.1236422Z          [0., 0., 0.]]])
2026-01-14T09:10:44.1236661Z model pt2e: GraphModule(
2026-01-14T09:10:44.1236905Z   (conv): Module()
2026-01-14T09:10:44.1237113Z   (bn): Module()
2026-01-14T09:10:44.1237437Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:44.1238579Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:10:44.1239880Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:10:44.1240448Z   )
2026-01-14T09:10:44.1240641Z   (_guards_fn): GuardsFn()
2026-01-14T09:10:44.1241075Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:44.1242159Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:10:44.1243421Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3261372148990631, max_val=0.297783762216568)
2026-01-14T09:10:44.1243989Z   )
2026-01-14T09:10:44.1244279Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:44.1245330Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:10:44.1246562Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T09:10:44.1247119Z   )
2026-01-14T09:10:44.1247419Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:10:44.1248461Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:10:44.1249742Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T09:10:44.1250302Z   )
2026-01-14T09:10:44.1250475Z )
2026-01-14T09:10:44.1250575Z 
2026-01-14T09:10:44.1250580Z 
2026-01-14T09:10:44.1250591Z 
2026-01-14T09:10:44.1250682Z def forward(self, x):
2026-01-14T09:10:44.1250978Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:10:44.1251348Z     conv_weight = self.conv.weight
2026-01-14T09:10:44.1251631Z     conv_bias = self.conv.bias
2026-01-14T09:10:44.1251900Z     bn_weight = self.bn.weight
2026-01-14T09:10:44.1252165Z     bn_bias = self.bn.bias
2026-01-14T09:10:44.1252479Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:11:10.4258040Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:11:10.4260984Z     bn_running_var = self.bn.running_var
2026-01-14T09:11:10.4261645Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:11:10.4262277Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:11:10.4262956Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:11:10.4263741Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:11:10.4264197Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:11:10.4264654Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:11:10.4265146Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T09:11:10.4265709Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:11:10.4266364Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:11:10.4267075Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:11:10.4268319Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:11:10.4269648Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T09:11:10.4270267Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T09:11:10.4270941Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T09:11:10.4271570Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:11:10.4272768Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:11:10.4273917Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:11:10.4275102Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:11:10.4275903Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:11:10.4276547Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:11:10.4276978Z     
2026-01-14T09:11:10.4277289Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:11:10.4277695Z model fx: GraphModule(
2026-01-14T09:11:10.4278046Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:11:10.4279160Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:11:10.4280515Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T09:11:10.4281084Z   )
2026-01-14T09:11:10.4281286Z   (conv): ConvBn1d(
2026-01-14T09:11:10.4281527Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T09:11:10.4281983Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:11:10.4282520Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:11:10.4283593Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
﻿2026-01-14T09:11:10.4288543Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3261372148990631, max_val=0.297783762216568)
2026-01-14T09:11:10.4289112Z     )
2026-01-14T09:11:10.4289304Z   )
2026-01-14T09:11:10.4289606Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:11:10.4290733Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:11:10.4292034Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T09:11:10.4292607Z   )
2026-01-14T09:11:10.4292853Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:11:10.4293288Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:11:10.4294384Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:11:10.4295694Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T09:11:10.4296271Z   )
2026-01-14T09:11:10.4296454Z )
2026-01-14T09:11:10.4296564Z 
2026-01-14T09:11:10.4296569Z 
2026-01-14T09:11:10.4296573Z 
2026-01-14T09:11:10.4296664Z def forward(self, x):
2026-01-14T09:11:10.4297052Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:11:10.4297799Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:11:10.4298447Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:11:10.4299097Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:11:10.4299789Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:11:10.4300427Z     return activation_post_process_2
2026-01-14T09:11:10.4300710Z     
2026-01-14T09:11:10.4301021Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:11:10.4301432Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:11:10.4301695Z          [0., 0., 0.],
2026-01-14T09:11:10.4301950Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T09:11:10.4302289Z converted model pt2e: GraphModule(
2026-01-14T09:11:10.4302566Z   (conv): Module()
2026-01-14T09:11:10.4302795Z   (bn): Module()
2026-01-14T09:11:10.4303017Z   (_guards_fn): GuardsFn()
2026-01-14T09:11:10.4303261Z )
2026-01-14T09:11:10.4303368Z 
2026-01-14T09:11:10.4303372Z 
2026-01-14T09:11:10.4303377Z 
2026-01-14T09:11:10.4303482Z def forward(self, x):
2026-01-14T09:11:10.4303792Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:11:10.4304163Z     conv_bias = self.conv.bias
2026-01-14T09:11:10.4304487Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:11:10.4305254Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T09:11:10.4306641Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:11:10.4307674Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:11:10.4308271Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:11:10.4308837Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:11:10.4309737Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002568009542301297, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:11:10.4311203Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:11:10.4312680Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010644976049661636, -4, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T09:11:10.4314181Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:11:10.4315604Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T09:11:10.4316769Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010644976049661636, -4, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:11:10.4318321Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:11:10.4319486Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:11:10.4319930Z     
2026-01-14T09:11:10.4320251Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:11:10.4320670Z onverted model fx: GraphModule(
2026-01-14T09:11:10.4321082Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:11:10.4321601Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:11:10.4321918Z )
2026-01-14T09:11:10.4322022Z 
2026-01-14T09:11:10.4322027Z 
2026-01-14T09:11:10.4322031Z 
2026-01-14T09:11:10.4322121Z def forward(self, x):
2026-01-14T09:11:10.4322818Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:11:10.4324313Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:11:10.4325480Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:11:10.4326455Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010644976049661636, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:11:10.4327960Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:11:10.4329176Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:11:10.4330245Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010644976049661636, -4, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:13:10.7229203Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:13:10.7231180Z     return dequantize_per_tensor_default_2
2026-01-14T09:13:10.7231577Z     
2026-01-14T09:13:10.7231951Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:13:10.7232456Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:13:10.7232762Z          [0., 0., 0.],
2026-01-14T09:13:10.7233026Z          [0., 0., 0.]]])
2026-01-14T09:13:10.7233546Z [32mPASSED[0m
2026-01-14T09:13:10.7234396Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T09:13:10.7235874Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T09:13:10.7237531Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T09:13:10.7238327Z   (conv): Module()
2026-01-14T09:13:10.7238626Z   (bn): Module()
2026-01-14T09:13:10.7239008Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:10.7240334Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:13:10.7241919Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:13:10.7242615Z   )
2026-01-14T09:13:10.7242849Z   (_guards_fn): GuardsFn()
2026-01-14T09:13:10.7243274Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:10.7244686Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:13:10.7246554Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1894, -0.1850, -0.1857]), max_val=tensor([0.1520, 0.1622, 0.1895]))
2026-01-14T09:13:10.7247447Z   )
2026-01-14T09:13:10.7247795Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:10.7249246Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:13:10.7250807Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9920659065246582, max_val=2.112386465072632)
2026-01-14T09:13:10.7251494Z   )
2026-01-14T09:13:10.7251719Z )
2026-01-14T09:13:10.7251846Z 
2026-01-14T09:13:10.7251851Z 
2026-01-14T09:13:10.7251856Z 
2026-01-14T09:13:10.7252150Z def forward(self, x):
2026-01-14T09:13:10.7252528Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:13:10.7252969Z     conv_weight = self.conv.weight
2026-01-14T09:13:10.7253321Z     conv_bias = self.conv.bias
2026-01-14T09:13:10.7253651Z     bn_weight = self.bn.weight
2026-01-14T09:13:10.7253968Z     bn_bias = self.bn.bias
2026-01-14T09:13:10.7254341Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:13:10.7254784Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:13:10.7255170Z     bn_running_var = self.bn.running_var
2026-01-14T09:13:10.7255648Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:13:10.7256200Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:13:10.7256919Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:13:10.7257663Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:13:10.7258181Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:13:10.7258714Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:13:10.7259304Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:13:10.7259973Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:13:10.7260731Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:13:10.7261563Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:13:10.7262936Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:13:10.7264172Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:13:10.7264961Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:13:10.7265750Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:13:10.7266502Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:13:10.7267814Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:13:10.7269159Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:13:10.7269957Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:13:10.7270476Z     
2026-01-14T09:13:10.7270830Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:13:10.7271317Z model fx: GraphModule(
2026-01-14T09:13:10.7271740Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:10.7273060Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:13:10.7274621Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:13:10.7275397Z   )
2026-01-14T09:13:10.7275688Z   (conv): ConvBn2d(
2026-01-14T09:13:10.7275973Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:13:10.7276517Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:13:10.7277146Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:10.7278600Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:13:10.7280464Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1894, -0.1850, -0.1857]), max_val=tensor([0.1520, 0.1622, 0.1895]))
2026-01-14T09:13:10.7291381Z     )
2026-01-14T09:13:10.7291597Z   )
2026-01-14T09:13:10.7291901Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:10.7292995Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:13:10.7294259Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9920659065246582, max_val=2.112386465072632)
2026-01-14T09:13:10.7294823Z   )
2026-01-14T09:13:10.7294997Z )
2026-01-14T09:13:10.7295111Z 
2026-01-14T09:13:10.7295115Z 
2026-01-14T09:13:10.7295121Z 
2026-01-14T09:13:10.7295211Z def forward(self, x):
2026-01-14T09:13:10.7295602Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:13:10.7296186Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:13:10.7296783Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:13:10.7297297Z     return activation_post_process_1
2026-01-14T09:13:10.7297578Z     
2026-01-14T09:13:10.7297871Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:13:10.7298279Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:13:10.7298535Z           [0., 0., 0.],
2026-01-14T09:13:10.7298754Z           [0., 0., 0.]],
2026-01-14T09:13:10.7298904Z 
2026-01-14T09:13:10.7298991Z          [[0., 0., 0.],
2026-01-14T09:13:10.7299205Z           [0., 0., 0.],
2026-01-14T09:13:10.7299428Z           [0., 0., 0.]],
2026-01-14T09:13:10.7299575Z 
2026-01-14T09:13:10.7299651Z          [[0., 0., 0.],
2026-01-14T09:13:10.7300002Z           [0., 0., 0.],
2026-01-14T09:13:10.7300258Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:13:10.7300595Z converted model pt2e: GraphModule(
2026-01-14T09:13:10.7300871Z   (conv): Module()
2026-01-14T09:13:10.7301087Z   (bn): Module()
2026-01-14T09:13:10.7301308Z   (_guards_fn): GuardsFn()
2026-01-14T09:13:10.7301534Z )
2026-01-14T09:13:10.7301636Z 
2026-01-14T09:13:10.7301640Z 
2026-01-14T09:13:10.7301644Z 
2026-01-14T09:13:10.7301745Z def forward(self, x):
2026-01-14T09:13:10.7302047Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:13:10.7302409Z     conv_bias = self.conv.bias
2026-01-14T09:13:10.7303065Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:13:10.7304397Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:13:10.7305422Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:13:10.7305772Z     _scale_0 = self._scale_0
2026-01-14T09:13:10.7306048Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:13:10.7306359Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:13:10.7307386Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:13:10.7309003Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:13:10.7310342Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01609589159488678, -4, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:13:10.7311886Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01609589159488678, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:13:10.7313006Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:13:10.7313439Z     
2026-01-14T09:13:10.7313749Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:13:10.7314147Z onverted model fx: GraphModule(
2026-01-14T09:13:44.3063950Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:13:44.3066582Z )
2026-01-14T09:13:44.3067010Z 
2026-01-14T09:13:44.3067194Z 
2026-01-14T09:13:44.3067204Z 
2026-01-14T09:13:44.3067337Z def forward(self, x):
2026-01-14T09:13:44.3068190Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:13:44.3069802Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:13:44.3071414Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:13:44.3072638Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01609589159488678, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:13:44.3074081Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01609589159488678, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:13:44.3075154Z     return dequantize_per_tensor_default_1
2026-01-14T09:13:44.3075453Z     
2026-01-14T09:13:44.3075764Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:13:44.3076166Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:13:44.3076602Z           [0., 0., 0.],
2026-01-14T09:13:44.3076832Z           [0., 0., 0.]],
2026-01-14T09:13:44.3076991Z 
2026-01-14T09:13:44.3077072Z          [[0., 0., 0.],
2026-01-14T09:13:44.3077300Z           [0., 0., 0.],
2026-01-14T09:13:44.3077521Z           [0., 0., 0.]],
2026-01-14T09:13:44.3077668Z 
2026-01-14T09:13:44.3077759Z          [[0., 0., 0.],
2026-01-14T09:13:44.3077976Z           [0., 0., 0.],
2026-01-14T09:13:44.3078211Z           [0., 0., 0.]]]])
2026-01-14T09:13:44.3078462Z model pt2e: GraphModule(
2026-01-14T09:13:44.3078716Z   (conv): Module()
2026-01-14T09:13:44.3078933Z   (bn): Module()
2026-01-14T09:13:44.3079268Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:44.3080363Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:13:44.3081647Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:13:44.3082224Z   )
2026-01-14T09:13:44.3082426Z   (_guards_fn): GuardsFn()
2026-01-14T09:13:44.3082792Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:44.3083889Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:13:44.3085530Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18937721848487854, max_val=0.18946029245853424)
2026-01-14T09:13:44.3086114Z   )
2026-01-14T09:13:44.3086412Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:44.3087638Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:13:44.3088915Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9922423362731934, max_val=2.1162424087524414)
2026-01-14T09:13:44.3089480Z   )
2026-01-14T09:13:44.3089666Z )
2026-01-14T09:13:44.3089771Z 
2026-01-14T09:13:44.3089775Z 
2026-01-14T09:13:44.3089779Z 
2026-01-14T09:13:44.3089873Z def forward(self, x):
2026-01-14T09:13:44.3090190Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:13:44.3090573Z     conv_weight = self.conv.weight
2026-01-14T09:13:44.3090875Z     conv_bias = self.conv.bias
2026-01-14T09:13:44.3091156Z     bn_weight = self.bn.weight
2026-01-14T09:13:44.3091423Z     bn_bias = self.bn.bias
2026-01-14T09:13:44.3091740Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:13:44.3092110Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:13:44.3092439Z     bn_running_var = self.bn.running_var
2026-01-14T09:13:44.3092847Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:13:44.3093318Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:13:44.3093897Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:13:44.3094493Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:13:44.3094928Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:13:44.3095377Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:13:44.3095871Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:13:44.3096426Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:13:44.3097055Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:13:44.3097805Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:13:44.3098993Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:13:44.3100001Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:13:44.3100596Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:13:44.3101254Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:13:44.3101887Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:13:44.3102886Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:13:44.3103985Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:13:44.3104641Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:13:44.3105063Z     
2026-01-14T09:13:44.3105368Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:13:44.3105758Z model fx: GraphModule(
2026-01-14T09:13:44.3106110Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:44.3107168Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:13:44.3108548Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:13:44.3109104Z   )
2026-01-14T09:13:44.3109299Z   (conv): ConvBn2d(
2026-01-14T09:13:44.3109556Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:13:44.3110008Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:13:44.3110620Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:44.3111676Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:13:44.3112971Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18937721848487854, max_val=0.18946029245853424)
2026-01-14T09:13:44.3113557Z     )
2026-01-14T09:13:44.3113738Z   )
2026-01-14T09:13:44.3114045Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:13:44.3115181Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:13:44.3116436Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9922423362731934, max_val=2.1162424087524414)
2026-01-14T09:13:44.3117002Z   )
2026-01-14T09:13:44.3117189Z )
2026-01-14T09:13:44.3117295Z 
2026-01-14T09:13:44.3117299Z 
2026-01-14T09:13:44.3117303Z 
2026-01-14T09:13:44.3117407Z def forward(self, x):
2026-01-14T09:13:44.3117792Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:13:44.3118386Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:13:44.3118991Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:13:44.3119472Z     return activation_post_process_1
2026-01-14T09:13:44.3119754Z     
2026-01-14T09:13:44.3120071Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:13:44.3120476Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:13:44.3120727Z           [0., 0., 0.],
2026-01-14T09:13:44.3120958Z           [0., 0., 0.]],
2026-01-14T09:13:44.3121163Z 
2026-01-14T09:13:44.3121244Z          [[0., 0., 0.],
2026-01-14T09:13:44.3121479Z           [0., 0., 0.],
2026-01-14T09:13:44.3121699Z           [0., 0., 0.]],
2026-01-14T09:13:44.3121854Z 
2026-01-14T09:13:44.3121935Z          [[0., 0., 0.],
2026-01-14T09:13:44.3122158Z           [0., 0., 0.],
2026-01-14T09:13:44.3122422Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:13:44.3122764Z converted model pt2e: GraphModule(
2026-01-14T09:13:44.3123039Z   (conv): Module()
2026-01-14T09:13:44.3123260Z   (bn): Module()
2026-01-14T09:13:44.3123483Z   (_guards_fn): GuardsFn()
2026-01-14T09:13:44.3123732Z )
2026-01-14T09:13:44.3123837Z 
2026-01-14T09:13:44.3123841Z 
2026-01-14T09:13:44.3123845Z 
2026-01-14T09:13:44.3123935Z def forward(self, x):
2026-01-14T09:13:44.3124262Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:13:44.3124625Z     conv_bias = self.conv.bias
2026-01-14T09:13:44.3125283Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:13:44.3126660Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:13:44.3127725Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:13:44.3128114Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:13:44.3128987Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014918133383616805, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:13:44.3130459Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:13:44.3131882Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01611170545220375, -4, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:14:37.9488554Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01611170545220375, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:14:37.9489740Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:14:37.9490191Z     
2026-01-14T09:14:37.9490510Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:14:37.9490934Z onverted model fx: GraphModule(
2026-01-14T09:14:37.9491357Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:14:37.9491770Z )
2026-01-14T09:14:37.9491881Z 
2026-01-14T09:14:37.9491886Z 
2026-01-14T09:14:37.9491889Z 
2026-01-14T09:14:37.9491978Z def forward(self, x):
2026-01-14T09:14:37.9492663Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:14:37.9494067Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:14:37.9495205Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:14:37.9496135Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01611170545220375, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:14:37.9497532Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01611170545220375, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:14:37.9498534Z     return dequantize_per_tensor_default_1
2026-01-14T09:14:37.9498828Z     
2026-01-14T09:14:37.9499127Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:14:37.9499793Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:14:37.9500041Z           [0., 0., 0.],
2026-01-14T09:14:37.9500265Z           [0., 0., 0.]],
2026-01-14T09:14:37.9500414Z 
2026-01-14T09:14:37.9500492Z          [[0., 0., 0.],
2026-01-14T09:14:37.9500714Z           [0., 0., 0.],
2026-01-14T09:14:37.9500934Z           [0., 0., 0.]],
2026-01-14T09:14:37.9501085Z 
2026-01-14T09:14:37.9501163Z          [[0., 0., 0.],
2026-01-14T09:14:37.9501383Z           [0., 0., 0.],
2026-01-14T09:14:37.9501605Z           [0., 0., 0.]]]])
2026-01-14T09:14:37.9502069Z [32mPASSED[0m
2026-01-14T09:14:37.9502696Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_cuda model pt2e: GraphModule(
2026-01-14T09:14:37.9503365Z   (conv): Module()
2026-01-14T09:14:37.9503574Z   (bn): Module()
2026-01-14T09:14:37.9503899Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:37.9505260Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:14:37.9506751Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:14:37.9507306Z   )
2026-01-14T09:14:37.9507495Z   (_guards_fn): GuardsFn()
2026-01-14T09:14:37.9507949Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:37.9509324Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:14:37.9511292Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:14:37.9512121Z   )
2026-01-14T09:14:37.9512411Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:37.9513702Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0165], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:14:37.9515326Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1394810676574707, max_val=2.0564441680908203)
2026-01-14T09:14:37.9515885Z   )
2026-01-14T09:14:37.9516062Z )
2026-01-14T09:14:37.9516164Z 
2026-01-14T09:14:37.9516168Z 
2026-01-14T09:14:37.9516172Z 
2026-01-14T09:14:37.9516259Z def forward(self, x):
2026-01-14T09:14:37.9516562Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:14:37.9516941Z     conv_weight = self.conv.weight
2026-01-14T09:14:37.9517231Z     conv_bias = self.conv.bias
2026-01-14T09:14:37.9517502Z     bn_weight = self.bn.weight
2026-01-14T09:14:37.9517767Z     bn_bias = self.bn.bias
2026-01-14T09:14:37.9518077Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:14:37.9518438Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:14:37.9518758Z     bn_running_var = self.bn.running_var
2026-01-14T09:14:37.9519152Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:14:37.9519603Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:14:37.9520174Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:14:37.9520761Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:14:37.9521187Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:14:37.9521693Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:14:37.9522179Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:14:37.9522725Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:14:37.9523343Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:14:37.9524015Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:14:37.9525158Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:14:37.9526150Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:14:37.9526739Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:14:37.9527386Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:14:37.9528013Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:14:37.9529032Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:14:37.9530121Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:14:37.9530817Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:14:37.9531228Z     
2026-01-14T09:14:37.9531537Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:14:37.9531918Z model fx: GraphModule(
2026-01-14T09:14:37.9532259Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:37.9533637Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:14:37.9535181Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:14:37.9535738Z   )
2026-01-14T09:14:37.9535919Z   (conv): ConvBn2d(
2026-01-14T09:14:37.9536158Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:14:37.9536602Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:14:37.9537116Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:37.9538430Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:14:37.9540261Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:14:37.9541087Z     )
2026-01-14T09:14:37.9541263Z   )
2026-01-14T09:14:37.9541559Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:37.9542843Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0165], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:14:37.9544327Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1394810676574707, max_val=2.0564441680908203)
2026-01-14T09:14:37.9544891Z   )
2026-01-14T09:14:37.9545065Z )
2026-01-14T09:14:37.9545248Z 
2026-01-14T09:14:37.9545253Z 
2026-01-14T09:14:37.9545258Z 
2026-01-14T09:14:37.9545373Z def forward(self, x):
2026-01-14T09:14:37.9545744Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:14:37.9546329Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:14:37.9546925Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:14:37.9547383Z     return activation_post_process_1
2026-01-14T09:14:37.9547658Z     
2026-01-14T09:14:37.9547949Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:14:37.9548341Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:14:37.9548589Z           [0., 0., 0.],
2026-01-14T09:14:37.9548814Z           [0., 0., 0.]],
2026-01-14T09:14:37.9548962Z 
2026-01-14T09:14:37.9549039Z          [[0., 0., 0.],
2026-01-14T09:14:37.9549259Z           [0., 0., 0.],
2026-01-14T09:14:37.9549483Z           [0., 0., 0.]],
2026-01-14T09:14:37.9549631Z 
2026-01-14T09:14:37.9549708Z          [[0., 0., 0.],
2026-01-14T09:14:37.9549930Z           [0., 0., 0.],
2026-01-14T09:14:37.9550220Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:14:37.9550590Z converted model pt2e: GraphModule(
2026-01-14T09:14:37.9550854Z   (conv): Module()
2026-01-14T09:14:37.9551067Z   (bn): Module()
2026-01-14T09:14:37.9551280Z   (_guards_fn): GuardsFn()
2026-01-14T09:14:37.9551513Z )
2026-01-14T09:14:37.9551614Z 
2026-01-14T09:14:37.9551618Z 
2026-01-14T09:14:37.9551672Z 
2026-01-14T09:14:37.9551771Z def forward(self, x):
2026-01-14T09:14:37.9552073Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:14:37.9552436Z     conv_bias = self.conv.bias
2026-01-14T09:14:44.3953176Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:14:44.3956887Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:14:44.3958111Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:14:44.3958471Z     _scale_0 = self._scale_0
2026-01-14T09:14:44.3958761Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:14:44.3959100Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:14:44.3960090Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:14:44.3961636Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:14:44.3962984Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.016454609110951424, 2, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:14:44.3964425Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016454609110951424, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:14:44.3965549Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:14:44.3965985Z     
2026-01-14T09:14:44.3966302Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:14:44.3966709Z onverted model fx: GraphModule(
2026-01-14T09:14:44.3967128Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:14:44.3967550Z )
2026-01-14T09:14:44.3967655Z 
2026-01-14T09:14:44.3967660Z 
2026-01-14T09:14:44.3967663Z 
2026-01-14T09:14:44.3967754Z def forward(self, x):
2026-01-14T09:14:44.3968421Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:14:44.3969879Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:14:44.3971006Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:14:44.3971961Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016454609110951424, 2, -128, 127, torch.int8);  conv = None
2026-01-14T09:14:44.3973376Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016454609110951424, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:14:44.3974365Z     return dequantize_per_tensor_default_1
2026-01-14T09:14:44.3974659Z     
2026-01-14T09:14:44.3974958Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:14:44.3975363Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:14:44.3975619Z           [0., 0., 0.],
2026-01-14T09:14:44.3975845Z           [0., 0., 0.]],
2026-01-14T09:14:44.3975995Z 
2026-01-14T09:14:44.3976074Z          [[0., 0., 0.],
2026-01-14T09:14:44.3976298Z           [0., 0., 0.],
2026-01-14T09:14:44.3976515Z           [0., 0., 0.]],
2026-01-14T09:14:44.3976669Z 
2026-01-14T09:14:44.3976750Z          [[0., 0., 0.],
2026-01-14T09:14:44.3976968Z           [0., 0., 0.],
2026-01-14T09:14:44.3977363Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:14:44.3977662Z model pt2e: GraphModule(
2026-01-14T09:14:44.3977903Z   (conv): Module()
2026-01-14T09:14:44.3978119Z   (bn): Module()
2026-01-14T09:14:44.3978434Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:44.3979831Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:14:44.3981402Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:14:44.3981956Z   )
2026-01-14T09:14:44.3982157Z   (_guards_fn): GuardsFn()
2026-01-14T09:14:44.3982513Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:44.3983816Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:14:44.3985515Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:14:44.3986077Z   )
2026-01-14T09:14:44.3986380Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:44.3987653Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0164], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:14:44.3989415Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.137371778488159, max_val=2.0522286891937256)
2026-01-14T09:14:44.3990069Z   )
2026-01-14T09:14:44.3990250Z )
2026-01-14T09:14:44.3990362Z 
2026-01-14T09:14:44.3990366Z 
2026-01-14T09:14:44.3990370Z 
2026-01-14T09:14:44.3990460Z def forward(self, x):
2026-01-14T09:14:44.3990786Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:14:44.3991193Z     conv_weight = self.conv.weight
2026-01-14T09:14:44.3991484Z     conv_bias = self.conv.bias
2026-01-14T09:14:44.3991753Z     bn_weight = self.bn.weight
2026-01-14T09:14:44.3992109Z     bn_bias = self.bn.bias
2026-01-14T09:14:44.3992424Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:14:44.3992800Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:14:44.3993118Z     bn_running_var = self.bn.running_var
2026-01-14T09:14:44.3993524Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:14:44.3993976Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:14:44.3994554Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:14:44.3995203Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:14:44.3995630Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:14:44.3996083Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:14:44.3996564Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:14:44.3997122Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:14:44.3997779Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:14:44.3998460Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:14:44.3999564Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:14:44.4000647Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:14:44.4001255Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:14:44.4001906Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:14:44.4002527Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:14:44.4003665Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:14:44.4004770Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:14:44.4005425Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:14:44.4014466Z     
2026-01-14T09:14:44.4014772Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:14:44.4015260Z model fx: GraphModule(
2026-01-14T09:14:44.4015612Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:44.4016916Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:14:44.4018426Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:14:44.4019029Z   )
2026-01-14T09:14:44.4019214Z   (conv): ConvBn2d(
2026-01-14T09:14:44.4019458Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:14:44.4019896Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:14:44.4020410Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:44.4021678Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:14:44.4023225Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:14:44.4023976Z     )
2026-01-14T09:14:44.4024155Z   )
2026-01-14T09:14:44.4024474Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:14:44.4026008Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0164], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:14:44.4027780Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.137371778488159, max_val=2.0522286891937256)
2026-01-14T09:14:44.4028433Z   )
2026-01-14T09:14:44.4028614Z )
2026-01-14T09:14:44.4028717Z 
2026-01-14T09:14:44.4028721Z 
2026-01-14T09:14:44.4028734Z 
2026-01-14T09:14:44.4028823Z def forward(self, x):
2026-01-14T09:15:31.6148891Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:15:31.6149675Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:15:31.6150463Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:15:31.6151043Z     return activation_post_process_1
2026-01-14T09:15:31.6151376Z     
2026-01-14T09:15:31.6151758Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:15:31.6152248Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:15:31.6152569Z           [0., 0., 0.],
2026-01-14T09:15:31.6152845Z           [0., 0., 0.]],
2026-01-14T09:15:31.6153039Z 
2026-01-14T09:15:31.6153484Z          [[0., 0., 0.],
2026-01-14T09:15:31.6153750Z           [0., 0., 0.],
2026-01-14T09:15:31.6154025Z           [0., 0., 0.]],
2026-01-14T09:15:31.6154206Z 
2026-01-14T09:15:31.6154312Z          [[0., 0., 0.],
2026-01-14T09:15:31.6154575Z           [0., 0., 0.],
2026-01-14T09:15:31.6155039Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:15:31.6155492Z converted model pt2e: GraphModule(
2026-01-14T09:15:31.6155833Z   (conv): Module()
2026-01-14T09:15:31.6156095Z   (bn): Module()
2026-01-14T09:15:31.6156544Z   (_guards_fn): GuardsFn()
2026-01-14T09:15:31.6156838Z )
2026-01-14T09:15:31.6156975Z 
2026-01-14T09:15:31.6156981Z 
2026-01-14T09:15:31.6156985Z 
2026-01-14T09:15:31.6157106Z def forward(self, x):
2026-01-14T09:15:31.6157652Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:15:31.6158098Z     conv_bias = self.conv.bias
2026-01-14T09:15:31.6158938Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:15:31.6160633Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:15:31.6161904Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:15:31.6162384Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:15:31.6163483Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:15:31.6165248Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:15:31.6166912Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.016429806128144264, 2, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:15:31.6168736Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.016429806128144264, 2, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:15:31.6170138Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:15:31.6170684Z     
2026-01-14T09:15:31.6171183Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:15:31.6171683Z onverted model fx: GraphModule(
2026-01-14T09:15:31.6172215Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:15:31.6172639Z )
2026-01-14T09:15:31.6172744Z 
2026-01-14T09:15:31.6172748Z 
2026-01-14T09:15:31.6172752Z 
2026-01-14T09:15:31.6172844Z def forward(self, x):
2026-01-14T09:15:31.6173526Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:15:31.6174891Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:15:31.6176027Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:15:31.6176984Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016429806128144264, 2, -128, 127, torch.int8);  conv = None
2026-01-14T09:15:31.6178392Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016429806128144264, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:15:31.6179381Z     return dequantize_per_tensor_default_1
2026-01-14T09:15:31.6179678Z     
2026-01-14T09:15:31.6179980Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:15:31.6180442Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:15:31.6180692Z           [0., 0., 0.],
2026-01-14T09:15:31.6180919Z           [0., 0., 0.]],
2026-01-14T09:15:31.6181070Z 
2026-01-14T09:15:31.6181150Z          [[0., 0., 0.],
2026-01-14T09:15:31.6181377Z           [0., 0., 0.],
2026-01-14T09:15:31.6181591Z           [0., 0., 0.]],
2026-01-14T09:15:31.6181743Z 
2026-01-14T09:15:31.6181822Z          [[0., 0., 0.],
2026-01-14T09:15:31.6182042Z           [0., 0., 0.],
2026-01-14T09:15:31.6182370Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:15:31.6182900Z [32mPASSED[0m
2026-01-14T09:15:31.6183560Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T09:15:31.6184454Z   (conv): Module()
2026-01-14T09:15:31.6184672Z   (bn): Module()
2026-01-14T09:15:31.6185010Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:15:31.6186093Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:15:31.6187388Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:15:31.6187962Z   )
2026-01-14T09:15:31.6188165Z   (_guards_fn): GuardsFn()
2026-01-14T09:15:31.6188541Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:15:31.6189679Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:15:31.6191174Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1774, -0.1913]), max_val=tensor([0.1806, 0.1870, 0.1478]))
2026-01-14T09:15:31.6191896Z   )
2026-01-14T09:15:31.6192190Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:15:31.6193265Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0279]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:15:31.6194524Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.481316328048706, max_val=3.622279405593872)
2026-01-14T09:15:31.6195227Z   )
2026-01-14T09:15:31.6195412Z )
2026-01-14T09:15:31.6195517Z 
2026-01-14T09:15:31.6195521Z 
2026-01-14T09:15:31.6195525Z 
2026-01-14T09:15:31.6195615Z def forward(self, x):
2026-01-14T09:15:31.6195929Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:15:31.6196296Z     conv_weight = self.conv.weight
2026-01-14T09:15:31.6196592Z     conv_bias = self.conv.bias
2026-01-14T09:15:31.6196869Z     bn_weight = self.bn.weight
2026-01-14T09:15:31.6197137Z     bn_bias = self.bn.bias
2026-01-14T09:15:31.6197448Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:15:31.6197808Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:15:31.6198130Z     bn_running_var = self.bn.running_var
2026-01-14T09:15:31.6198528Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:15:31.6198977Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:15:31.6199555Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:15:31.6200154Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:15:31.6200585Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:15:31.6201034Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:15:31.6201523Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:15:31.6202077Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:15:31.6202787Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:15:31.6203469Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:15:31.6204604Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:15:31.6205729Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:15:31.6206322Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:15:31.6206973Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:15:31.6207602Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:15:31.6208629Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:15:31.6209725Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:15:31.6210379Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:15:31.6210801Z     
2026-01-14T09:15:31.6211112Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:15:31.6211516Z model fx: GraphModule(
2026-01-14T09:15:31.6211870Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:15:31.6212951Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:15:31.6214228Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:15:31.6214775Z   )
2026-01-14T09:15:31.6214975Z   (conv): ConvBn2d(
2026-01-14T09:15:31.6215270Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T09:15:31.6215769Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:15:31.6216289Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:15:31.6217471Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:16:13.5757833Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1774, -0.1913]), max_val=tensor([0.1806, 0.1870, 0.1478]))
2026-01-14T09:16:13.5760107Z     )
2026-01-14T09:16:13.5760454Z   )
2026-01-14T09:16:13.5760850Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:16:13.5762203Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0279]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:16:13.5763794Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.481316328048706, max_val=3.622279405593872)
2026-01-14T09:16:13.5764494Z   )
2026-01-14T09:16:13.5764734Z )
2026-01-14T09:16:13.5764860Z 
2026-01-14T09:16:13.5764865Z 
2026-01-14T09:16:13.5764870Z 
2026-01-14T09:16:13.5764980Z def forward(self, x):
2026-01-14T09:16:13.5765436Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:16:13.5766147Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:16:13.5766885Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:16:13.5767672Z     return activation_post_process_1
2026-01-14T09:16:13.5768002Z     
2026-01-14T09:16:13.5768364Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:16:13.5768853Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5769204Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5769521Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5769837Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5770151Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5770640Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:16:13.5770861Z 
2026-01-14T09:16:13.5770973Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5771303Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5771611Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5771927Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5772253Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5772563Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:16:13.5772789Z 
2026-01-14T09:16:13.5772897Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5773206Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5773520Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5773829Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5774147Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5774520Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:16:13.5774957Z converted model pt2e: GraphModule(
2026-01-14T09:16:13.5775305Z   (conv): Module()
2026-01-14T09:16:13.5775558Z   (bn): Module()
2026-01-14T09:16:13.5775851Z   (_guards_fn): GuardsFn()
2026-01-14T09:16:13.5776162Z )
2026-01-14T09:16:13.5776284Z 
2026-01-14T09:16:13.5776289Z 
2026-01-14T09:16:13.5776300Z 
2026-01-14T09:16:13.5776411Z def forward(self, x):
2026-01-14T09:16:13.5776775Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:16:13.5777225Z     conv_bias = self.conv.bias
2026-01-14T09:16:13.5778056Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8)
2026-01-14T09:16:13.5779760Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:16:13.5781028Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:16:13.5781600Z     _scale_0 = self._scale_0
2026-01-14T09:16:13.5781933Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:16:13.5782316Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:16:13.5783550Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:16:13.5785731Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:16:13.5787459Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.027857238426804543, -3, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:16:13.5789289Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.027857238426804543, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:16:13.5790702Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:16:13.5791247Z     
2026-01-14T09:16:13.5791614Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:16:13.5792106Z onverted model fx: GraphModule(
2026-01-14T09:16:13.5792667Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T09:16:13.5793326Z )
2026-01-14T09:16:13.5793457Z 
2026-01-14T09:16:13.5793462Z 
2026-01-14T09:16:13.5793467Z 
2026-01-14T09:16:13.5793575Z def forward(self, x):
2026-01-14T09:16:13.5794414Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:16:13.5796369Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:16:13.5797787Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:16:13.5799083Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.027857238426804543, -3, -128, 127, torch.int8);  conv = None
2026-01-14T09:16:13.5800558Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.027857238426804543, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:16:13.5801550Z     return dequantize_per_tensor_default_1
2026-01-14T09:16:13.5801850Z     
2026-01-14T09:16:13.5802152Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:16:13.5802566Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5802851Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5803120Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5803384Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5803647Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5803914Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:16:13.5804093Z 
2026-01-14T09:16:13.5804179Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5804448Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5804705Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5804968Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5805231Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5805495Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:16:13.5805678Z 
2026-01-14T09:16:13.5805764Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5806075Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5806339Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5806594Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5806862Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:16:13.5807202Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T09:16:13.5807499Z model pt2e: GraphModule(
2026-01-14T09:16:13.5807749Z   (conv): Module()
2026-01-14T09:16:13.5807979Z   (bn): Module()
2026-01-14T09:16:13.5808300Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:16:13.5809392Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:16:13.5810663Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:16:13.5811223Z   )
2026-01-14T09:16:13.5811431Z   (_guards_fn): GuardsFn()
2026-01-14T09:16:13.5811783Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:16:13.5812879Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:16:13.5814162Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T09:16:13.5814728Z   )
2026-01-14T09:16:13.5815028Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:16:13.5816098Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0278]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:16:13.5817408Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4796082973480225, max_val=3.620413064956665)
2026-01-14T09:16:13.5817969Z   )
2026-01-14T09:16:13.5818149Z )
2026-01-14T09:16:13.5818252Z 
2026-01-14T09:16:13.5818256Z 
2026-01-14T09:16:13.5818259Z 
2026-01-14T09:16:13.5818355Z def forward(self, x):
2026-01-14T09:16:13.5818748Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:16:13.5819125Z     conv_weight = self.conv.weight
2026-01-14T09:16:13.5819414Z     conv_bias = self.conv.bias
2026-01-14T09:16:13.5819692Z     bn_weight = self.bn.weight
2026-01-14T09:16:13.5819962Z     bn_bias = self.bn.bias
2026-01-14T09:16:13.5820271Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:16:13.5820643Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:16:13.5820963Z     bn_running_var = self.bn.running_var
2026-01-14T09:16:13.5821370Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:16:13.5821822Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:16:13.5822399Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:16:13.5822996Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:16:13.5823433Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:16:13.5823896Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:16:13.5824379Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:16:13.5824944Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:16:13.5825565Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:16:13.5826255Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:16:13.5827393Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:16:13.5828420Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:16:13.5829032Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:16:13.5831072Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:16:13.5831705Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:17:01.5430174Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:17:01.5432310Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:17:01.5433170Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:17:01.5433695Z     
2026-01-14T09:17:01.5434066Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:17:01.5434547Z model fx: GraphModule(
2026-01-14T09:17:01.5435073Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:01.5436451Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:17:01.5438048Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:17:01.5438745Z   )
2026-01-14T09:17:01.5438970Z   (conv): ConvBn2d(
2026-01-14T09:17:01.5439313Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T09:17:01.5440126Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:17:01.5440765Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:01.5442115Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:17:01.5443902Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T09:17:01.5444621Z     )
2026-01-14T09:17:01.5444834Z   )
2026-01-14T09:17:01.5445187Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:01.5446505Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0278]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:17:01.5448075Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4796082973480225, max_val=3.620413064956665)
2026-01-14T09:17:01.5448771Z   )
2026-01-14T09:17:01.5448985Z )
2026-01-14T09:17:01.5449108Z 
2026-01-14T09:17:01.5449113Z 
2026-01-14T09:17:01.5449117Z 
2026-01-14T09:17:01.5449240Z def forward(self, x):
2026-01-14T09:17:01.5449687Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:17:01.5450414Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:17:01.5451141Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:17:01.5451744Z     return activation_post_process_1
2026-01-14T09:17:01.5452085Z     
2026-01-14T09:17:01.5452437Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:17:01.5452933Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5453286Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5453604Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5453921Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5454229Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5454550Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:17:01.5454766Z 
2026-01-14T09:17:01.5454868Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5455183Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5455489Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5455913Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5456231Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5456540Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:17:01.5456758Z 
2026-01-14T09:17:01.5456865Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5457173Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5457484Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5457794Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5458112Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5458494Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:17:01.5458927Z converted model pt2e: GraphModule(
2026-01-14T09:17:01.5459271Z   (conv): Module()
2026-01-14T09:17:01.5459526Z   (bn): Module()
2026-01-14T09:17:01.5459794Z   (_guards_fn): GuardsFn()
2026-01-14T09:17:01.5460078Z )
2026-01-14T09:17:01.5460202Z 
2026-01-14T09:17:01.5460207Z 
2026-01-14T09:17:01.5460212Z 
2026-01-14T09:17:01.5460328Z def forward(self, x):
2026-01-14T09:17:01.5460692Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:17:01.5461139Z     conv_bias = self.conv.bias
2026-01-14T09:17:01.5461974Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8)
2026-01-14T09:17:01.5463670Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:17:01.5464987Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:17:01.5465444Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:17:01.5466391Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0015061007579788566, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:17:01.5467913Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:17:01.5469277Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.02784322015941143, -3, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:17:01.5470713Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.02784322015941143, -3, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:17:01.5471889Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:17:01.5472329Z     
2026-01-14T09:17:01.5472635Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:17:01.5473035Z onverted model fx: GraphModule(
2026-01-14T09:17:01.5473502Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T09:17:01.5473968Z )
2026-01-14T09:17:01.5474087Z 
2026-01-14T09:17:01.5474091Z 
2026-01-14T09:17:01.5474095Z 
2026-01-14T09:17:01.5474186Z def forward(self, x):
2026-01-14T09:17:01.5474944Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:17:01.5476383Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:17:01.5477524Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:17:01.5478488Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.02784322015941143, -3, -128, 127, torch.int8);  conv = None
2026-01-14T09:17:01.5479910Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.02784322015941143, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:17:01.5480938Z     return dequantize_per_tensor_default_1
2026-01-14T09:17:01.5481230Z     
2026-01-14T09:17:01.5490400Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:17:01.5490864Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5491168Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5491446Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5491713Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5491980Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5492237Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:17:01.5492418Z 
2026-01-14T09:17:01.5492513Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5492780Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5493054Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5493316Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5493594Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5493858Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:17:01.5494046Z 
2026-01-14T09:17:01.5494133Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5494400Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5494658Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5494926Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5495187Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:17:01.5495575Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T09:17:01.5496060Z [32mPASSED[0m
2026-01-14T09:17:01.5496731Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T09:17:01.5497430Z   (conv): Module()
2026-01-14T09:17:01.5497656Z   (bn): Module()
2026-01-14T09:17:01.5497988Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:01.5499197Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:17:01.5500490Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:17:01.5501059Z   )
2026-01-14T09:17:01.5501271Z   (_guards_fn): GuardsFn()
2026-01-14T09:17:01.5501640Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:01.5502821Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:17:01.5504320Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:17:01.5505040Z   )
2026-01-14T09:17:01.5505359Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:01.5506435Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:17:01.5507696Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1459269523620605, max_val=2.376943349838257)
2026-01-14T09:17:01.5508266Z   )
2026-01-14T09:17:01.5508451Z )
2026-01-14T09:17:01.5508563Z 
2026-01-14T09:17:01.5508567Z 
2026-01-14T09:17:01.5508571Z 
2026-01-14T09:17:01.5508662Z def forward(self, x):
2026-01-14T09:17:01.5508979Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:17:01.5509346Z     conv_weight = self.conv.weight
2026-01-14T09:17:01.5509651Z     bn_weight = self.bn.weight
2026-01-14T09:17:01.5509925Z     bn_bias = self.bn.bias
2026-01-14T09:17:01.5510311Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:17:01.5510685Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:17:36.4309547Z     bn_running_var = self.bn.running_var
2026-01-14T09:17:36.4310093Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:17:36.4310660Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:17:36.4311359Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:17:36.4312126Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:17:36.4312641Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:17:36.4313191Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:17:36.4313781Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:17:36.4314454Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:17:36.4315335Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:17:36.4316491Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:17:36.4317657Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:17:36.4318392Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:17:36.4319990Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:17:36.4321344Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:17:36.4322151Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:17:36.4322680Z     
2026-01-14T09:17:36.4323268Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:17:36.4323763Z model fx: GraphModule(
2026-01-14T09:17:36.4324182Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:36.4325520Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:17:36.4327143Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:17:36.4327855Z   )
2026-01-14T09:17:36.4328080Z   (conv): ConvBn2d(
2026-01-14T09:17:36.4328414Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:17:36.4328999Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:17:36.4329633Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:36.4331017Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:17:36.4332883Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:17:36.4333831Z     )
2026-01-14T09:17:36.4334054Z   )
2026-01-14T09:17:36.4334410Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:36.4335776Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:17:36.4337351Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1459269523620605, max_val=2.376943349838257)
2026-01-14T09:17:36.4338140Z   )
2026-01-14T09:17:36.4338372Z )
2026-01-14T09:17:36.4338498Z 
2026-01-14T09:17:36.4338503Z 
2026-01-14T09:17:36.4338508Z 
2026-01-14T09:17:36.4338617Z def forward(self, x):
2026-01-14T09:17:36.4339073Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:17:36.4339780Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:17:36.4340518Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:17:36.4341102Z     return activation_post_process_1
2026-01-14T09:17:36.4341431Z     
2026-01-14T09:17:36.4341796Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:17:36.4342278Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:17:36.4342589Z           [0., 0., 0.],
2026-01-14T09:17:36.4342862Z           [0., 0., 0.]],
2026-01-14T09:17:36.4343050Z 
2026-01-14T09:17:36.4343148Z          [[0., 0., 0.],
2026-01-14T09:17:36.4343415Z           [0., 0., 0.],
2026-01-14T09:17:36.4343740Z           [0., 0., 0.]],
2026-01-14T09:17:36.4343924Z 
2026-01-14T09:17:36.4344028Z          [[0., 0., 0.],
2026-01-14T09:17:36.4344291Z           [0., 0., 0.],
2026-01-14T09:17:36.4344564Z           [0., 0., 0.]]],
2026-01-14T09:17:36.4344745Z 
2026-01-14T09:17:36.4344750Z 
2026-01-14T09:17:36.4344846Z         [[[0., 0., 0.],
2026-01-14T09:17:36.4345126Z           [0., 0., 0.],
2026-01-14T09:17:36.4345387Z           [0., 0., 0.]],
2026-01-14T09:17:36.4345636Z 
2026-01-14T09:17:36.4345736Z          [[0., 0., 0.],
2026-01-14T09:17:36.4346008Z           [0., 0., 0.],
2026-01-14T09:17:36.4346276Z           [0., 0., 0.]],
2026-01-14T09:17:36.4346453Z 
2026-01-14T09:17:36.4346560Z          [[0., 0., 0.],
2026-01-14T09:17:36.4346823Z           [0., 0., 0.],
2026-01-14T09:17:36.4347094Z           [0., 0., 0.]]],
2026-01-14T09:17:36.4347276Z 
2026-01-14T09:17:36.4347280Z 
2026-01-14T09:17:36.4347381Z         [[[0., 0., 0.],
2026-01-14T09:17:36.4347651Z           [0., 0., 0.],
2026-01-14T09:17:36.4348013Z           [0., 0., 0.]],
2026-01-14T09:17:36.4348207Z 
2026-01-14T09:17:36.4348307Z          [[0., 0., 0.],
2026-01-14T09:17:36.4348575Z           [0., 0., 0.],
2026-01-14T09:17:36.4348838Z           [0., 0., 0.]],
2026-01-14T09:17:36.4349014Z 
2026-01-14T09:17:36.4349124Z          [[0., 0., 0.],
2026-01-14T09:17:36.4349411Z           [0., 0., 0.],
2026-01-14T09:17:36.4349750Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:17:36.4350175Z converted model pt2e: GraphModule(
2026-01-14T09:17:36.4350539Z   (conv): Module()
2026-01-14T09:17:36.4350750Z   (bn): Module()
2026-01-14T09:17:36.4350976Z   (_guards_fn): GuardsFn()
2026-01-14T09:17:36.4351214Z )
2026-01-14T09:17:36.4351327Z 
2026-01-14T09:17:36.4351331Z 
2026-01-14T09:17:36.4351334Z 
2026-01-14T09:17:36.4351426Z def forward(self, x):
2026-01-14T09:17:36.4351739Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:17:36.4352514Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8)
2026-01-14T09:17:36.4353884Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:17:36.4354990Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:17:36.4355346Z     _scale_0 = self._scale_0
2026-01-14T09:17:36.4355626Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:17:36.4355947Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:17:36.4356953Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:17:36.4357951Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:17:36.4358901Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:17:36.4360386Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01773674599826336, -7, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:17:36.4361838Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01773674599826336, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:17:36.4362971Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:17:36.4363427Z     
2026-01-14T09:17:36.4363733Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:17:36.4364149Z onverted model fx: GraphModule(
2026-01-14T09:17:36.4364561Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:17:36.4364981Z )
2026-01-14T09:17:36.4365091Z 
2026-01-14T09:17:36.4365095Z 
2026-01-14T09:17:36.4365099Z 
2026-01-14T09:17:36.4365190Z def forward(self, x):
2026-01-14T09:17:36.4365877Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:17:36.4367267Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:17:36.4368447Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:17:36.4369396Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01773674599826336, -7, -128, 127, torch.int8);  conv = None
2026-01-14T09:17:36.4370898Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01773674599826336, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:17:36.4371888Z     return dequantize_per_tensor_default_1
2026-01-14T09:17:36.4372186Z     
2026-01-14T09:17:36.4372486Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:17:36.4372896Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:17:36.4373146Z           [0., 0., 0.],
2026-01-14T09:17:36.4373374Z           [0., 0., 0.]],
2026-01-14T09:17:36.4373528Z 
2026-01-14T09:17:36.4373616Z          [[0., 0., 0.],
2026-01-14T09:17:36.4373833Z           [0., 0., 0.],
2026-01-14T09:17:36.4374058Z           [0., 0., 0.]],
2026-01-14T09:17:36.4374205Z 
2026-01-14T09:17:36.4374289Z          [[0., 0., 0.],
2026-01-14T09:17:36.4374515Z           [0., 0., 0.],
2026-01-14T09:17:36.4374741Z           [0., 0., 0.]]],
2026-01-14T09:17:36.4374897Z 
2026-01-14T09:17:36.4374900Z 
2026-01-14T09:17:36.4374979Z         [[[0., 0., 0.],
2026-01-14T09:17:36.4375198Z           [0., 0., 0.],
2026-01-14T09:17:36.4375430Z           [0., 0., 0.]],
2026-01-14T09:17:36.4375584Z 
2026-01-14T09:17:36.4375663Z          [[0., 0., 0.],
2026-01-14T09:17:36.4375886Z           [0., 0., 0.],
2026-01-14T09:17:36.4376104Z           [0., 0., 0.]],
2026-01-14T09:17:36.4376251Z 
2026-01-14T09:17:36.4376338Z          [[0., 0., 0.],
2026-01-14T09:17:36.4376558Z           [0., 0., 0.],
2026-01-14T09:17:36.4376784Z           [0., 0., 0.]]],
2026-01-14T09:17:36.4376935Z 
2026-01-14T09:17:36.4376941Z 
2026-01-14T09:17:36.4377023Z         [[[0., 0., 0.],
2026-01-14T09:17:36.4377245Z           [0., 0., 0.],
2026-01-14T09:17:36.4377462Z           [0., 0., 0.]],
2026-01-14T09:17:36.4377615Z 
2026-01-14T09:17:36.4377693Z          [[0., 0., 0.],
2026-01-14T09:17:36.4377912Z           [0., 0., 0.],
2026-01-14T09:17:36.4378131Z           [0., 0., 0.]],
2026-01-14T09:17:36.4378280Z 
2026-01-14T09:17:36.4378363Z          [[0., 0., 0.],
2026-01-14T09:17:36.4378576Z           [0., 0., 0.],
2026-01-14T09:17:36.4378855Z           [0., 0., 0.]]]])
2026-01-14T09:17:36.4379110Z model pt2e: GraphModule(
2026-01-14T09:17:36.4379356Z   (conv): Module()
2026-01-14T09:17:36.4379585Z   (bn): Module()
2026-01-14T09:17:36.4379909Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:17:36.4380992Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:17:36.4382271Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:17:36.4382835Z   )
2026-01-14T09:17:36.4383039Z   (_guards_fn): GuardsFn()
2026-01-14T09:17:36.4383397Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:12.9072006Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:18:12.9073434Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:18:12.9074021Z   )
2026-01-14T09:18:12.9074342Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:12.9075548Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:12.9077058Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1475415229797363, max_val=2.368046283721924)
2026-01-14T09:18:12.9077638Z   )
2026-01-14T09:18:12.9077828Z )
2026-01-14T09:18:12.9077945Z 
2026-01-14T09:18:12.9077949Z 
2026-01-14T09:18:12.9077953Z 
2026-01-14T09:18:12.9078047Z def forward(self, x):
2026-01-14T09:18:12.9078551Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:18:12.9078926Z     conv_weight = self.conv.weight
2026-01-14T09:18:12.9079233Z     bn_weight = self.bn.weight
2026-01-14T09:18:12.9079513Z     bn_bias = self.bn.bias
2026-01-14T09:18:12.9079841Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:18:12.9080214Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:18:12.9080550Z     bn_running_var = self.bn.running_var
2026-01-14T09:18:12.9080958Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:18:12.9081433Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:18:12.9082019Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:18:12.9082624Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:18:12.9083070Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:18:12.9083529Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:18:12.9084038Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:18:12.9084995Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:18:12.9085798Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:18:12.9086762Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:18:12.9087706Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:18:12.9088313Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:18:12.9089418Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:18:12.9090639Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:18:12.9091313Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:18:12.9091741Z     
2026-01-14T09:18:12.9092048Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:18:12.9092449Z model fx: GraphModule(
2026-01-14T09:18:12.9092802Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:12.9093907Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:12.9095192Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:18:12.9095763Z   )
2026-01-14T09:18:12.9095962Z   (conv): ConvBn2d(
2026-01-14T09:18:12.9096236Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:18:12.9096729Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:18:12.9097257Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:12.9098325Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:18:12.9099682Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:18:12.9100260Z     )
2026-01-14T09:18:12.9100449Z   )
2026-01-14T09:18:12.9100744Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:12.9101940Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:12.9103227Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1475415229797363, max_val=2.368046283721924)
2026-01-14T09:18:12.9103786Z   )
2026-01-14T09:18:12.9103975Z )
2026-01-14T09:18:12.9104085Z 
2026-01-14T09:18:12.9104089Z 
2026-01-14T09:18:12.9104093Z 
2026-01-14T09:18:12.9104184Z def forward(self, x):
2026-01-14T09:18:12.9104571Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:18:12.9105175Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:18:12.9105788Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:18:12.9106270Z     return activation_post_process_1
2026-01-14T09:18:12.9106555Z     
2026-01-14T09:18:12.9106870Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:18:12.9107272Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:18:12.9107544Z           [0., 0., 0.],
2026-01-14T09:18:12.9107777Z           [0., 0., 0.]],
2026-01-14T09:18:12.9107938Z 
2026-01-14T09:18:12.9108025Z          [[0., 0., 0.],
2026-01-14T09:18:12.9108249Z           [0., 0., 0.],
2026-01-14T09:18:12.9108485Z           [0., 0., 0.]],
2026-01-14T09:18:12.9108637Z 
2026-01-14T09:18:12.9108727Z          [[0., 0., 0.],
2026-01-14T09:18:12.9108947Z           [0., 0., 0.],
2026-01-14T09:18:12.9109174Z           [0., 0., 0.]]],
2026-01-14T09:18:12.9109326Z 
2026-01-14T09:18:12.9109333Z 
2026-01-14T09:18:12.9109414Z         [[[0., 0., 0.],
2026-01-14T09:18:12.9109643Z           [0., 0., 0.],
2026-01-14T09:18:12.9109865Z           [0., 0., 0.]],
2026-01-14T09:18:12.9110021Z 
2026-01-14T09:18:12.9110102Z          [[0., 0., 0.],
2026-01-14T09:18:12.9110325Z           [0., 0., 0.],
2026-01-14T09:18:12.9110551Z           [0., 0., 0.]],
2026-01-14T09:18:12.9110703Z 
2026-01-14T09:18:12.9110791Z          [[0., 0., 0.],
2026-01-14T09:18:12.9111062Z           [0., 0., 0.],
2026-01-14T09:18:12.9111296Z           [0., 0., 0.]]],
2026-01-14T09:18:12.9111455Z 
2026-01-14T09:18:12.9111458Z 
2026-01-14T09:18:12.9111541Z         [[[0., 0., 0.],
2026-01-14T09:18:12.9111768Z           [0., 0., 0.],
2026-01-14T09:18:12.9111989Z           [0., 0., 0.]],
2026-01-14T09:18:12.9112144Z 
2026-01-14T09:18:12.9112223Z          [[0., 0., 0.],
2026-01-14T09:18:12.9112443Z           [0., 0., 0.],
2026-01-14T09:18:12.9112670Z           [0., 0., 0.]],
2026-01-14T09:18:12.9112819Z 
2026-01-14T09:18:12.9112909Z          [[0., 0., 0.],
2026-01-14T09:18:12.9113132Z           [0., 0., 0.],
2026-01-14T09:18:12.9113400Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:18:12.9113738Z converted model pt2e: GraphModule(
2026-01-14T09:18:12.9114019Z   (conv): Module()
2026-01-14T09:18:12.9114236Z   (bn): Module()
2026-01-14T09:18:12.9114467Z   (_guards_fn): GuardsFn()
2026-01-14T09:18:12.9114744Z )
2026-01-14T09:18:12.9114965Z 
2026-01-14T09:18:12.9114969Z 
2026-01-14T09:18:12.9114978Z 
2026-01-14T09:18:12.9115092Z def forward(self, x):
2026-01-14T09:18:12.9115487Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:18:12.9116447Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8)
2026-01-14T09:18:12.9117973Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:18:12.9119101Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:18:12.9119497Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:18:12.9120384Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:18:12.9121281Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:18:12.9122313Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:18:12.9123717Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01770818792283535, -7, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:18:12.9125389Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01770818792283535, -7, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:18:12.9126768Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:18:12.9127213Z     
2026-01-14T09:18:12.9127527Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:18:12.9127945Z onverted model fx: GraphModule(
2026-01-14T09:18:12.9128367Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:18:12.9128795Z )
2026-01-14T09:18:12.9128901Z 
2026-01-14T09:18:12.9128906Z 
2026-01-14T09:18:12.9128909Z 
2026-01-14T09:18:12.9129001Z def forward(self, x):
2026-01-14T09:18:12.9129692Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:18:12.9131081Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:18:12.9132228Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:18:12.9133193Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01770818792283535, -7, -128, 127, torch.int8);  conv = None
2026-01-14T09:18:12.9134598Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01770818792283535, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:18:12.9135647Z     return dequantize_per_tensor_default_1
2026-01-14T09:18:12.9135953Z     
2026-01-14T09:18:12.9136255Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:18:12.9136660Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:18:12.9136916Z           [0., 0., 0.],
2026-01-14T09:18:12.9137149Z           [0., 0., 0.]],
2026-01-14T09:18:12.9137301Z 
2026-01-14T09:18:12.9137382Z          [[0., 0., 0.],
2026-01-14T09:18:12.9137608Z           [0., 0., 0.],
2026-01-14T09:18:12.9137828Z           [0., 0., 0.]],
2026-01-14T09:18:12.9137983Z 
2026-01-14T09:18:12.9138063Z          [[0., 0., 0.],
2026-01-14T09:18:12.9138288Z           [0., 0., 0.],
2026-01-14T09:18:12.9138511Z           [0., 0., 0.]]],
2026-01-14T09:18:12.9138666Z 
2026-01-14T09:18:12.9138670Z 
2026-01-14T09:18:12.9138759Z         [[[0., 0., 0.],
2026-01-14T09:18:12.9138985Z           [0., 0., 0.],
2026-01-14T09:18:12.9139216Z           [0., 0., 0.]],
2026-01-14T09:18:12.9139365Z 
2026-01-14T09:18:12.9139445Z          [[0., 0., 0.],
2026-01-14T09:18:12.9139669Z           [0., 0., 0.],
2026-01-14T09:18:12.9139893Z           [0., 0., 0.]],
2026-01-14T09:18:12.9140048Z 
2026-01-14T09:18:19.7063060Z          [[0., 0., 0.],
2026-01-14T09:18:19.7063367Z           [0., 0., 0.],
2026-01-14T09:18:19.7063611Z           [0., 0., 0.]]],
2026-01-14T09:18:19.7063960Z 
2026-01-14T09:18:19.7063964Z 
2026-01-14T09:18:19.7064045Z         [[[0., 0., 0.],
2026-01-14T09:18:19.7064269Z           [0., 0., 0.],
2026-01-14T09:18:19.7064486Z           [0., 0., 0.]],
2026-01-14T09:18:19.7064635Z 
2026-01-14T09:18:19.7064719Z          [[0., 0., 0.],
2026-01-14T09:18:19.7064932Z           [0., 0., 0.],
2026-01-14T09:18:19.7065153Z           [0., 0., 0.]],
2026-01-14T09:18:19.7065300Z 
2026-01-14T09:18:19.7065378Z          [[0., 0., 0.],
2026-01-14T09:18:19.7065603Z           [0., 0., 0.],
2026-01-14T09:18:19.7065958Z           [0., 0., 0.]]]])
2026-01-14T09:18:19.7066223Z model pt2e: GraphModule(
2026-01-14T09:18:19.7066466Z   (conv1): Module()
2026-01-14T09:18:19.7066676Z   (bn1): Module()
2026-01-14T09:18:19.7066893Z   (conv2): Module()
2026-01-14T09:18:19.7067100Z   (bn2): Module()
2026-01-14T09:18:19.7067426Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:19.7068525Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:19.7069824Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:18:19.7070393Z   )
2026-01-14T09:18:19.7070588Z   (_guards_fn): GuardsFn()
2026-01-14T09:18:19.7070947Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:19.7072076Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:18:19.7073551Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1921, -0.1899, -0.1895]), max_val=tensor([0.1769, 0.1726, 0.1697]))
2026-01-14T09:18:19.7074268Z   )
2026-01-14T09:18:19.7074594Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:19.7075773Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:18:19.7077264Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:18:19.7078045Z   )
2026-01-14T09:18:19.7078350Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:19.7079418Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:19.7080681Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7323514223098755, max_val=2.7138354778289795)
2026-01-14T09:18:19.7081253Z   )
2026-01-14T09:18:19.7081545Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:19.7082598Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:19.7083876Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4053945541381836, max_val=1.4082176685333252)
2026-01-14T09:18:19.7084664Z   )
2026-01-14T09:18:19.7084840Z )
2026-01-14T09:18:19.7084947Z 
2026-01-14T09:18:19.7084951Z 
2026-01-14T09:18:19.7084965Z 
2026-01-14T09:18:19.7085056Z def forward(self, x):
2026-01-14T09:18:19.7094081Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:18:19.7094508Z     conv1_weight = self.conv1.weight
2026-01-14T09:18:19.7094812Z     bn1_weight = self.bn1.weight
2026-01-14T09:18:19.7095206Z     bn1_bias = self.bn1.bias
2026-01-14T09:18:19.7095474Z     conv2_weight = self.conv2.weight
2026-01-14T09:18:19.7095770Z     conv2_bias = self.conv2.bias
2026-01-14T09:18:19.7096040Z     bn2_weight = self.bn2.weight
2026-01-14T09:18:19.7096311Z     bn2_bias = self.bn2.bias
2026-01-14T09:18:19.7096632Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:18:19.7097017Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:18:19.7097339Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:18:19.7097821Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:18:19.7098200Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:18:19.7098519Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:18:19.7098922Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:18:19.7099375Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:18:19.7099957Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:18:19.7100722Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:18:19.7101337Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:18:19.7101775Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:18:19.7102220Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:18:19.7102715Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:18:19.7103280Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:18:19.7103914Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:18:19.7104595Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:18:19.7105224Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:18:19.7105679Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:18:19.7106152Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:18:19.7106665Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T09:18:19.7107254Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:18:19.7107914Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:18:19.7108986Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:18:19.7109918Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T09:18:19.7110524Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T09:18:19.7111592Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, False);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:18:19.7112715Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:18:19.7113785Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:18:19.7114780Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:18:19.7115433Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T09:18:19.7116077Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T09:18:19.7116703Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:18:19.7117753Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, False);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:18:19.7118964Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:18:19.7119612Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:18:19.7120019Z     
2026-01-14T09:18:19.7120464Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:18:19.7120856Z model fx: GraphModule(
2026-01-14T09:18:19.7121200Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:19.7122284Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:19.7123558Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:18:19.7124129Z   )
2026-01-14T09:18:19.7124328Z   (conv1): ConvBn2d(
2026-01-14T09:18:19.7124599Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:18:19.7125077Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:18:19.7125588Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:19.7126699Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:18:19.7128194Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:18:19.7128905Z     )
2026-01-14T09:18:19.7129088Z   )
2026-01-14T09:18:19.7129381Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:19.7130457Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:19.7131719Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7323514223098755, max_val=2.7138354778289795)
2026-01-14T09:18:19.7132335Z   )
2026-01-14T09:18:19.7132534Z   (conv2): ConvBn2d(
2026-01-14T09:18:19.7132777Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:18:19.7133236Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:18:19.7133755Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:55.4979837Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:18:55.4981942Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1921, -0.1899, -0.1895]), max_val=tensor([0.1769, 0.1726, 0.1697]))
2026-01-14T09:18:55.4982859Z     )
2026-01-14T09:18:55.4983084Z   )
2026-01-14T09:18:55.4983448Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:55.4985182Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:55.4986794Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4053945541381836, max_val=1.4082176685333252)
2026-01-14T09:18:55.4987515Z   )
2026-01-14T09:18:55.4987734Z )
2026-01-14T09:18:55.4987860Z 
2026-01-14T09:18:55.4987873Z 
2026-01-14T09:18:55.4988194Z 
2026-01-14T09:18:55.4988310Z def forward(self, x):
2026-01-14T09:18:55.4988769Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:18:55.4989511Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:18:55.4990281Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:18:55.4991032Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:18:55.4991987Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:18:55.4992576Z     return activation_post_process_2
2026-01-14T09:18:55.4992918Z     
2026-01-14T09:18:55.4993282Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:18:55.4993770Z diff: tensor([[[[0.]],
2026-01-14T09:18:55.4993959Z 
2026-01-14T09:18:55.4994067Z          [[0.]],
2026-01-14T09:18:55.4994223Z 
2026-01-14T09:18:55.4994317Z          [[0.]]],
2026-01-14T09:18:55.4994474Z 
2026-01-14T09:18:55.4994479Z 
2026-01-14T09:18:55.4994582Z         [[[0.]],
2026-01-14T09:18:55.4994732Z 
2026-01-14T09:18:55.4994920Z          [[0.]],
2026-01-14T09:18:55.4995084Z 
2026-01-14T09:18:55.4995180Z          [[0.]]],
2026-01-14T09:18:55.4995332Z 
2026-01-14T09:18:55.4995337Z 
2026-01-14T09:18:55.4995433Z         [[[0.]],
2026-01-14T09:18:55.4995591Z 
2026-01-14T09:18:55.4995685Z          [[0.]],
2026-01-14T09:18:55.4995836Z 
2026-01-14T09:18:55.4995976Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:18:55.4996364Z converted model pt2e: GraphModule(
2026-01-14T09:18:55.4996706Z   (conv1): Module()
2026-01-14T09:18:55.4996962Z   (bn1): Module()
2026-01-14T09:18:55.4997226Z   (conv2): Module()
2026-01-14T09:18:55.4997483Z   (bn2): Module()
2026-01-14T09:18:55.4997757Z   (_guards_fn): GuardsFn()
2026-01-14T09:18:55.4998042Z )
2026-01-14T09:18:55.4998176Z 
2026-01-14T09:18:55.4998181Z 
2026-01-14T09:18:55.4998185Z 
2026-01-14T09:18:55.4998292Z def forward(self, x):
2026-01-14T09:18:55.4998671Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:18:55.4999116Z     conv2_bias = self.conv2.bias
2026-01-14T09:18:55.4999966Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8)
2026-01-14T09:18:55.5001679Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:18:55.5003074Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:18:55.5003522Z     _scale_0 = self._scale_0
2026-01-14T09:18:55.5003852Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:18:55.5004214Z     _scale_1 = self._scale_1
2026-01-14T09:18:55.5004536Z     _zero_point_1 = self._zero_point_1
2026-01-14T09:18:55.5004938Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T09:18:55.5006216Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T09:18:55.5007515Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:18:55.5008725Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T09:18:55.5010540Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.01743602752685547, -29, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T09:18:55.5012093Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01743602752685547, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:18:55.5013107Z     quantize_per_channel = self._frozen_param1
2026-01-14T09:18:55.5014167Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:18:55.5015745Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T09:18:55.5017218Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.011033773422241211, -1, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T09:18:55.5018683Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011033773422241211, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:18:55.5019827Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:18:55.5020277Z     
2026-01-14T09:18:55.5020580Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:18:55.5020998Z onverted model fx: GraphModule(
2026-01-14T09:18:55.5021417Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:18:55.5021989Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:18:55.5022416Z )
2026-01-14T09:18:55.5022518Z 
2026-01-14T09:18:55.5022522Z 
2026-01-14T09:18:55.5022532Z 
2026-01-14T09:18:55.5022623Z def forward(self, x):
2026-01-14T09:18:55.5023303Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:18:55.5024683Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:18:55.5025828Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:18:55.5026792Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.01743602752685547, -29, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:18:55.5028217Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01743602752685547, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:18:55.5029476Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:18:55.5030459Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.011033773422241211, -1, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:18:55.5031882Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011033773422241211, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:18:55.5032878Z     return dequantize_per_tensor_default_2
2026-01-14T09:18:55.5033173Z     
2026-01-14T09:18:55.5033475Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:18:55.5033865Z diff: tensor([[[[0.]],
2026-01-14T09:18:55.5034031Z 
2026-01-14T09:18:55.5034111Z          [[0.]],
2026-01-14T09:18:55.5034241Z 
2026-01-14T09:18:55.5034330Z          [[0.]]],
2026-01-14T09:18:55.5034462Z 
2026-01-14T09:18:55.5034466Z 
2026-01-14T09:18:55.5034542Z         [[[0.]],
2026-01-14T09:18:55.5034676Z 
2026-01-14T09:18:55.5034752Z          [[0.]],
2026-01-14T09:18:55.5034942Z 
2026-01-14T09:18:55.5035034Z          [[0.]]],
2026-01-14T09:18:55.5035169Z 
2026-01-14T09:18:55.5035172Z 
2026-01-14T09:18:55.5035249Z         [[[0.]],
2026-01-14T09:18:55.5035374Z 
2026-01-14T09:18:55.5035458Z          [[0.]],
2026-01-14T09:18:55.5035582Z 
2026-01-14T09:18:55.5035713Z          [[0.]]]])
2026-01-14T09:18:55.5035949Z model pt2e: GraphModule(
2026-01-14T09:18:55.5036192Z   (conv1): Module()
2026-01-14T09:18:55.5036415Z   (bn1): Module()
2026-01-14T09:18:55.5036624Z   (conv2): Module()
2026-01-14T09:18:55.5036843Z   (bn2): Module()
2026-01-14T09:18:55.5037168Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:55.5038360Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:55.5039662Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:18:55.5040234Z   )
2026-01-14T09:18:55.5040453Z   (_guards_fn): GuardsFn()
2026-01-14T09:18:55.5040809Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:55.5041893Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:18:55.5043186Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1921343356370926, max_val=0.1768510341644287)
2026-01-14T09:18:55.5043758Z   )
2026-01-14T09:18:55.5044063Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:55.5045158Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:18:55.5046464Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T09:18:55.5047035Z   )
2026-01-14T09:18:55.5047335Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:18:55.5048411Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:18:55.5049687Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7288155555725098, max_val=2.7138354778289795)
2026-01-14T09:18:55.5050258Z   )
2026-01-14T09:18:55.5050552Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:19:24.3386029Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:19:24.3387319Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4025696516036987, max_val=1.4086220264434814)
2026-01-14T09:19:24.3387884Z   )
2026-01-14T09:19:24.3388070Z )
2026-01-14T09:19:24.3388187Z 
2026-01-14T09:19:24.3388192Z 
2026-01-14T09:19:24.3388196Z 
2026-01-14T09:19:24.3388293Z def forward(self, x):
2026-01-14T09:19:24.3388594Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:19:24.3388995Z     conv1_weight = self.conv1.weight
2026-01-14T09:19:24.3389307Z     bn1_weight = self.bn1.weight
2026-01-14T09:19:24.3389589Z     bn1_bias = self.bn1.bias
2026-01-14T09:19:24.3389877Z     conv2_weight = self.conv2.weight
2026-01-14T09:19:24.3390168Z     conv2_bias = self.conv2.bias
2026-01-14T09:19:24.3390448Z     bn2_weight = self.bn2.weight
2026-01-14T09:19:24.3390712Z     bn2_bias = self.bn2.bias
2026-01-14T09:19:24.3391039Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:19:24.3391411Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:19:24.3391738Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:19:24.3392100Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:19:24.3392470Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:19:24.3393057Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:19:24.3393449Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:19:24.3393905Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:19:24.3394473Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:19:24.3395316Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:19:24.3396106Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:19:24.3396533Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:19:24.3396983Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:19:24.3397462Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:19:24.3398023Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:19:24.3398651Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:19:24.3399335Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:19:24.3399944Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:19:24.3400386Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:19:24.3400866Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:19:24.3401377Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T09:19:24.3401973Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:19:24.3402625Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:19:24.3403579Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:19:24.3404521Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T09:19:24.3405126Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T09:19:24.3406204Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, False);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:19:24.3407420Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:19:24.3408528Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:19:24.3409554Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:19:24.3410145Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T09:19:24.3410804Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T09:19:24.3411428Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:19:24.3412466Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, False);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:19:24.3413602Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:19:24.3414245Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:19:24.3414657Z     
2026-01-14T09:19:24.3414965Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:19:24.3415348Z model fx: GraphModule(
2026-01-14T09:19:24.3415697Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:19:24.3416825Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:19:24.3418108Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:19:24.3418668Z   )
2026-01-14T09:19:24.3418851Z   (conv1): ConvBn2d(
2026-01-14T09:19:24.3419208Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:19:24.3419681Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:19:24.3420202Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:19:24.3421249Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:19:24.3422539Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T09:19:24.3423112Z     )
2026-01-14T09:19:24.3423287Z   )
2026-01-14T09:19:24.3423582Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:19:24.3424633Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:19:24.3425902Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7288155555725098, max_val=2.7138354778289795)
2026-01-14T09:19:24.3426463Z   )
2026-01-14T09:19:24.3426645Z   (conv2): ConvBn2d(
2026-01-14T09:19:24.3426889Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:19:24.3427328Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:19:24.3427851Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:19:24.3428925Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:19:24.3430203Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1921343356370926, max_val=0.1768510341644287)
2026-01-14T09:19:24.3430822Z     )
2026-01-14T09:19:24.3430995Z   )
2026-01-14T09:19:24.3431290Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:19:24.3432353Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:19:24.3433614Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4025696516036987, max_val=1.4086220264434814)
2026-01-14T09:19:24.3434174Z   )
2026-01-14T09:19:24.3434346Z )
2026-01-14T09:19:24.3434448Z 
2026-01-14T09:19:24.3434452Z 
2026-01-14T09:19:24.3434456Z 
2026-01-14T09:19:24.3434548Z def forward(self, x):
2026-01-14T09:19:24.3434970Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:19:24.3435565Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:19:24.3436179Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:19:24.3436783Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:19:24.3437386Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:19:24.3437847Z     return activation_post_process_2
2026-01-14T09:19:24.3438128Z     
2026-01-14T09:19:24.3438420Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:19:24.3438916Z diff: tensor([[[[0.]],
2026-01-14T09:19:24.3439066Z 
2026-01-14T09:19:24.3439143Z          [[0.]],
2026-01-14T09:19:24.3439274Z 
2026-01-14T09:19:24.3439349Z          [[0.]]],
2026-01-14T09:19:24.3439475Z 
2026-01-14T09:19:24.3439479Z 
2026-01-14T09:19:24.3439561Z         [[[0.]],
2026-01-14T09:19:24.3439682Z 
2026-01-14T09:19:24.3439757Z          [[0.]],
2026-01-14T09:19:24.3439882Z 
2026-01-14T09:19:24.3439963Z          [[0.]]],
2026-01-14T09:19:24.3440088Z 
2026-01-14T09:19:24.3440092Z 
2026-01-14T09:19:24.3440248Z         [[[0.]],
2026-01-14T09:19:24.3440381Z 
2026-01-14T09:19:24.3440457Z          [[0.]],
2026-01-14T09:19:24.3440576Z 
2026-01-14T09:19:24.3440680Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:19:24.3440997Z converted model pt2e: GraphModule(
2026-01-14T09:19:24.3441272Z   (conv1): Module()
2026-01-14T09:19:24.3441480Z   (bn1): Module()
2026-01-14T09:19:24.3441691Z   (conv2): Module()
2026-01-14T09:19:24.3441895Z   (bn2): Module()
2026-01-14T09:19:24.3442118Z   (_guards_fn): GuardsFn()
2026-01-14T09:19:24.3442349Z )
2026-01-14T09:19:24.3442454Z 
2026-01-14T09:19:24.3442458Z 
2026-01-14T09:19:24.3442462Z 
2026-01-14T09:19:24.3442547Z def forward(self, x):
2026-01-14T09:19:24.3442844Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:19:24.3443209Z     conv2_bias = self.conv2.bias
2026-01-14T09:19:24.3443868Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8)
2026-01-14T09:19:24.3445185Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:19:24.3446193Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:19:24.3446573Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T09:19:24.3447469Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.001512790797278285, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T09:19:24.3448372Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:20:25.4956463Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T09:20:25.4958682Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.017422160133719444, -29, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T09:20:25.4960541Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.017422160133719444, -29, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:20:25.4961797Z     quantize_per_tensor = self._frozen_param1
2026-01-14T09:20:25.4962891Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001512868795543909, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:20:25.4964686Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T09:20:25.4966405Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.011024280451238155, -1, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T09:20:25.4968225Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.011024280451238155, -1, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T09:20:25.4969638Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T09:20:25.4970181Z     
2026-01-14T09:20:25.4970686Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:20:25.4971184Z onverted model fx: GraphModule(
2026-01-14T09:20:25.4971678Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:20:25.4972370Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:20:25.4972878Z )
2026-01-14T09:20:25.4973007Z 
2026-01-14T09:20:25.4973012Z 
2026-01-14T09:20:25.4973021Z 
2026-01-14T09:20:25.4973130Z def forward(self, x):
2026-01-14T09:20:25.4974228Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:20:25.4975960Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:20:25.4977089Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:20:25.4978087Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.017422160133719444, -29, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:20:25.4979523Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.017422160133719444, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:20:25.4980679Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:20:25.4981633Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.011024280451238155, -1, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:20:25.4983038Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011024280451238155, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:20:25.4984008Z     return dequantize_per_tensor_default_2
2026-01-14T09:20:25.4984480Z     
2026-01-14T09:20:25.4984781Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:20:25.4985166Z diff: tensor([[[[0.]],
2026-01-14T09:20:25.4985322Z 
2026-01-14T09:20:25.4985399Z          [[0.]],
2026-01-14T09:20:25.4985525Z 
2026-01-14T09:20:25.4985603Z          [[0.]]],
2026-01-14T09:20:25.4985816Z 
2026-01-14T09:20:25.4985820Z 
2026-01-14T09:20:25.4985896Z         [[[0.]],
2026-01-14T09:20:25.4986024Z 
2026-01-14T09:20:25.4986103Z          [[0.]],
2026-01-14T09:20:25.4986227Z 
2026-01-14T09:20:25.4986302Z          [[0.]]],
2026-01-14T09:20:25.4986433Z 
2026-01-14T09:20:25.4986437Z 
2026-01-14T09:20:25.4986512Z         [[[0.]],
2026-01-14T09:20:25.4986634Z 
2026-01-14T09:20:25.4986710Z          [[0.]],
2026-01-14T09:20:25.4986839Z 
2026-01-14T09:20:25.4986916Z          [[0.]]]])
2026-01-14T09:20:25.4987348Z [32mPASSED[0m
2026-01-14T09:20:25.4988089Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T09:20:25.4989184Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T09:20:25.4989835Z   (conv): Module()
2026-01-14T09:20:25.4990052Z   (bn): Module()
2026-01-14T09:20:25.4990369Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:20:25.4991436Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:20:25.4992709Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:20:25.4993260Z   )
2026-01-14T09:20:25.4993459Z   (_guards_fn): GuardsFn()
2026-01-14T09:20:25.4993886Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:20:25.4995084Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:20:25.4996580Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1835, -0.1822, -0.1883]), max_val=tensor([0.1799, 0.1856, 0.1719]))
2026-01-14T09:20:25.4998888Z   )
2026-01-14T09:20:25.4999221Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:20:25.5000297Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:20:25.5010080Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2505061626434326)
2026-01-14T09:20:25.5010632Z   )
2026-01-14T09:20:25.5010803Z )
2026-01-14T09:20:25.5010904Z 
2026-01-14T09:20:25.5010916Z 
2026-01-14T09:20:25.5010920Z 
2026-01-14T09:20:25.5011007Z def forward(self, x):
2026-01-14T09:20:25.5011311Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:20:25.5011681Z     conv_weight = self.conv.weight
2026-01-14T09:20:25.5011967Z     conv_bias = self.conv.bias
2026-01-14T09:20:25.5012235Z     bn_weight = self.bn.weight
2026-01-14T09:20:25.5012506Z     bn_bias = self.bn.bias
2026-01-14T09:20:25.5012810Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:20:25.5013175Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:20:25.5013489Z     bn_running_var = self.bn.running_var
2026-01-14T09:20:25.5013887Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:20:25.5014334Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:20:25.5014907Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:20:25.5015503Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:20:25.5015922Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:20:25.5016373Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:20:25.5016850Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:20:25.5017484Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:20:25.5018098Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:20:25.5018831Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:20:25.5019928Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:20:25.5020925Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:20:25.5021525Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:20:25.5022165Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:20:25.5022790Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:20:25.5023822Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:20:25.5024819Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:20:25.5025397Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:20:25.5025987Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:20:25.5026452Z     
2026-01-14T09:20:25.5026754Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:20:25.5027140Z model fx: GraphModule(
2026-01-14T09:20:25.5027492Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:20:25.5028550Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:20:25.5029952Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:20:25.5030506Z   )
2026-01-14T09:20:25.5030707Z   (conv): ConvBnReLU2d(
2026-01-14T09:20:25.5030968Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:20:25.5031414Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:20:25.5031937Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:20:25.5033054Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:21:02.0556465Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1835, -0.1822, -0.1883]), max_val=tensor([0.1799, 0.1856, 0.1719]))
2026-01-14T09:21:02.0557424Z     )
2026-01-14T09:21:02.0557667Z   )
2026-01-14T09:21:02.0558038Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:02.0559423Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:21:02.0561027Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2505061626434326)
2026-01-14T09:21:02.0561675Z   )
2026-01-14T09:21:02.0561898Z )
2026-01-14T09:21:02.0562023Z 
2026-01-14T09:21:02.0562028Z 
2026-01-14T09:21:02.0562033Z 
2026-01-14T09:21:02.0562144Z def forward(self, x):
2026-01-14T09:21:02.0562606Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:21:02.0563324Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:21:02.0564265Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:21:02.0564844Z     return activation_post_process_1
2026-01-14T09:21:02.0565180Z     
2026-01-14T09:21:02.0565545Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:21:02.0566027Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:21:02.0566342Z           [0., 0., 0.],
2026-01-14T09:21:02.0566612Z           [0., 0., 0.]],
2026-01-14T09:21:02.0566799Z 
2026-01-14T09:21:02.0566899Z          [[0., 0., 0.],
2026-01-14T09:21:02.0567166Z           [0., 0., 0.],
2026-01-14T09:21:02.0567445Z           [0., 0., 0.]],
2026-01-14T09:21:02.0567625Z 
2026-01-14T09:21:02.0567735Z          [[0., 0., 0.],
2026-01-14T09:21:02.0568000Z           [0., 0., 0.],
2026-01-14T09:21:02.0568317Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:21:02.0568717Z converted model pt2e: GraphModule(
2026-01-14T09:21:02.0569076Z   (conv): Module()
2026-01-14T09:21:02.0569339Z   (bn): Module()
2026-01-14T09:21:02.0569619Z   (_guards_fn): GuardsFn()
2026-01-14T09:21:02.0569911Z )
2026-01-14T09:21:02.0570044Z 
2026-01-14T09:21:02.0570049Z 
2026-01-14T09:21:02.0570054Z 
2026-01-14T09:21:02.0570167Z def forward(self, x):
2026-01-14T09:21:02.0570538Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:21:02.0570978Z     conv_bias = self.conv.bias
2026-01-14T09:21:02.0571804Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:21:02.0573600Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:21:02.0574875Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:21:02.0575313Z     _scale_0 = self._scale_0
2026-01-14T09:21:02.0575641Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:21:02.0576043Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:21:02.0577441Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:21:02.0579367Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:21:02.0580608Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:21:02.0581723Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.004903945606201887, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:21:02.0583390Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004903945606201887, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:21:02.0584717Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:21:02.0585166Z     
2026-01-14T09:21:02.0585475Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:21:02.0585887Z onverted model fx: GraphModule(
2026-01-14T09:21:02.0586169Z   (conv): ConvReLU2d(
2026-01-14T09:21:02.0586531Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:21:02.0586941Z     (1): ReLU()
2026-01-14T09:21:02.0587145Z   )
2026-01-14T09:21:02.0587331Z )
2026-01-14T09:21:02.0587435Z 
2026-01-14T09:21:02.0587439Z 
2026-01-14T09:21:02.0587443Z 
2026-01-14T09:21:02.0587533Z def forward(self, x):
2026-01-14T09:21:02.0588208Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:21:02.0589570Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:21:02.0590775Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:21:02.0591739Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.004903945606201887, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:21:02.0593175Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004903945606201887, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:21:02.0594177Z     return dequantize_per_tensor_default_1
2026-01-14T09:21:02.0594478Z     
2026-01-14T09:21:02.0594781Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:21:02.0595250Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:21:02.0595501Z           [0., 0., 0.],
2026-01-14T09:21:02.0595740Z           [0., 0., 0.]],
2026-01-14T09:21:02.0595895Z 
2026-01-14T09:21:02.0595985Z          [[0., 0., 0.],
2026-01-14T09:21:02.0596207Z           [0., 0., 0.],
2026-01-14T09:21:02.0596431Z           [0., 0., 0.]],
2026-01-14T09:21:02.0596578Z 
2026-01-14T09:21:02.0596658Z          [[0., 0., 0.],
2026-01-14T09:21:02.0596881Z           [0., 0., 0.],
2026-01-14T09:21:02.0597101Z           [0., 0., 0.]]]])
2026-01-14T09:21:02.0597355Z model pt2e: GraphModule(
2026-01-14T09:21:02.0597593Z   (conv): Module()
2026-01-14T09:21:02.0597891Z   (bn): Module()
2026-01-14T09:21:02.0598205Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:02.0599292Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:21:02.0600561Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:21:02.0601232Z   )
2026-01-14T09:21:02.0601441Z   (_guards_fn): GuardsFn()
2026-01-14T09:21:02.0601799Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:02.0602867Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:21:02.0604138Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.1855725795030594)
2026-01-14T09:21:02.0604702Z   )
2026-01-14T09:21:02.0605008Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:02.0606072Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:21:02.0607297Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2396948337554932)
2026-01-14T09:21:02.0607815Z   )
2026-01-14T09:21:02.0607994Z )
2026-01-14T09:21:02.0608098Z 
2026-01-14T09:21:02.0608102Z 
2026-01-14T09:21:02.0608113Z 
2026-01-14T09:21:02.0608206Z def forward(self, x):
2026-01-14T09:21:02.0608517Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:21:02.0608896Z     conv_weight = self.conv.weight
2026-01-14T09:21:02.0609194Z     conv_bias = self.conv.bias
2026-01-14T09:21:02.0609480Z     bn_weight = self.bn.weight
2026-01-14T09:21:02.0609752Z     bn_bias = self.bn.bias
2026-01-14T09:21:02.0610063Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:21:02.0610438Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:21:02.0610760Z     bn_running_var = self.bn.running_var
2026-01-14T09:21:02.0611165Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:21:02.0611675Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:21:02.0612253Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:21:02.0612858Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:21:02.0613286Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:21:02.0613743Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:21:02.0614227Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:21:02.0614791Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:21:02.0615418Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:21:02.0616115Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:21:02.0617231Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:21:02.0618234Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:21:02.0618841Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:21:02.0619489Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:21:02.0620115Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:21:02.0621195Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:21:02.0622200Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:21:02.0622781Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:21:02.0623503Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:21:02.0623930Z     
2026-01-14T09:21:02.0624232Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:21:02.0624638Z model fx: GraphModule(
2026-01-14T09:21:02.0624988Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:02.0626064Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:21:52.8172184Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:21:52.8172772Z   )
2026-01-14T09:21:52.8172967Z   (conv): ConvBnReLU2d(
2026-01-14T09:21:52.8173238Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:21:52.8173697Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:21:52.8174239Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:52.8175314Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:21:52.8176612Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.1855725795030594)
2026-01-14T09:21:52.8177189Z     )
2026-01-14T09:21:52.8177369Z   )
2026-01-14T09:21:52.8177669Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:52.8178760Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:21:52.8180270Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2396948337554932)
2026-01-14T09:21:52.8180781Z   )
2026-01-14T09:21:52.8181004Z )
2026-01-14T09:21:52.8181105Z 
2026-01-14T09:21:52.8181109Z 
2026-01-14T09:21:52.8181113Z 
2026-01-14T09:21:52.8181204Z def forward(self, x):
2026-01-14T09:21:52.8181584Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:21:52.8182165Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:21:52.8182767Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:21:52.8183238Z     return activation_post_process_1
2026-01-14T09:21:52.8183505Z     
2026-01-14T09:21:52.8183811Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:21:52.8184379Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:21:52.8184631Z           [0., 0., 0.],
2026-01-14T09:21:52.8184847Z           [0., 0., 0.]],
2026-01-14T09:21:52.8185001Z 
2026-01-14T09:21:52.8185079Z          [[0., 0., 0.],
2026-01-14T09:21:52.8185295Z           [0., 0., 0.],
2026-01-14T09:21:52.8185514Z           [0., 0., 0.]],
2026-01-14T09:21:52.8185660Z 
2026-01-14T09:21:52.8185744Z          [[0., 0., 0.],
2026-01-14T09:21:52.8185956Z           [0., 0., 0.],
2026-01-14T09:21:52.8186208Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:21:52.8186558Z converted model pt2e: GraphModule(
2026-01-14T09:21:52.8186867Z   (conv): Module()
2026-01-14T09:21:52.8187073Z   (bn): Module()
2026-01-14T09:21:52.8187408Z   (_guards_fn): GuardsFn()
2026-01-14T09:21:52.8187636Z )
2026-01-14T09:21:52.8187741Z 
2026-01-14T09:21:52.8187746Z 
2026-01-14T09:21:52.8187750Z 
2026-01-14T09:21:52.8187839Z def forward(self, x):
2026-01-14T09:21:52.8188149Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:21:52.8188504Z     conv_bias = self.conv.bias
2026-01-14T09:21:52.8189170Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:21:52.8190681Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:21:52.8191704Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:21:52.8192086Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:21:52.8192967Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014826410915702581, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:21:52.8194375Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:21:52.8195400Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:21:52.8196272Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.004861548542976379, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:21:52.8197777Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.004861548542976379, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:21:52.8198904Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:21:52.8199350Z     
2026-01-14T09:21:52.8199646Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:21:52.8200050Z onverted model fx: GraphModule(
2026-01-14T09:21:52.8200319Z   (conv): ConvReLU2d(
2026-01-14T09:21:52.8200675Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:21:52.8201081Z     (1): ReLU()
2026-01-14T09:21:52.8201279Z   )
2026-01-14T09:21:52.8201459Z )
2026-01-14T09:21:52.8201633Z 
2026-01-14T09:21:52.8201637Z 
2026-01-14T09:21:52.8201641Z 
2026-01-14T09:21:52.8201737Z def forward(self, x):
2026-01-14T09:21:52.8202410Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:21:52.8203792Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:21:52.8204914Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:21:52.8205866Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.004861548542976379, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:21:52.8207285Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004861548542976379, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:21:52.8208290Z     return dequantize_per_tensor_default_1
2026-01-14T09:21:52.8208588Z     
2026-01-14T09:21:52.8208877Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:21:52.8209267Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:21:52.8209514Z           [0., 0., 0.],
2026-01-14T09:21:52.8209737Z           [0., 0., 0.]],
2026-01-14T09:21:52.8209883Z 
2026-01-14T09:21:52.8209961Z          [[0., 0., 0.],
2026-01-14T09:21:52.8210230Z           [0., 0., 0.],
2026-01-14T09:21:52.8210446Z           [0., 0., 0.]],
2026-01-14T09:21:52.8210603Z 
2026-01-14T09:21:52.8210683Z          [[0., 0., 0.],
2026-01-14T09:21:52.8210898Z           [0., 0., 0.],
2026-01-14T09:21:52.8211111Z           [0., 0., 0.]]]])
2026-01-14T09:21:52.8211571Z [32mPASSED[0m
2026-01-14T09:21:52.8212204Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_cuda model pt2e: GraphModule(
2026-01-14T09:21:52.8212879Z   (conv): Module()
2026-01-14T09:21:52.8213170Z   (bn): Module()
2026-01-14T09:21:52.8213489Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:52.8214790Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:21:52.8216262Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:21:52.8216814Z   )
2026-01-14T09:21:52.8217004Z   (_guards_fn): GuardsFn()
2026-01-14T09:21:52.8217354Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:52.8218719Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:21:52.8220511Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:21:52.8221332Z   )
2026-01-14T09:21:52.8221623Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:21:52.8222922Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:21:52.8224344Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0564441680908203)
2026-01-14T09:21:52.8224894Z   )
2026-01-14T09:21:52.8225076Z )
2026-01-14T09:21:52.8225180Z 
2026-01-14T09:21:52.8225188Z 
2026-01-14T09:21:52.8225192Z 
2026-01-14T09:21:52.8225282Z def forward(self, x):
2026-01-14T09:21:52.8225588Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:21:52.8225955Z     conv_weight = self.conv.weight
2026-01-14T09:21:52.8226237Z     conv_bias = self.conv.bias
2026-01-14T09:21:52.8226505Z     bn_weight = self.bn.weight
2026-01-14T09:21:52.8226766Z     bn_bias = self.bn.bias
2026-01-14T09:21:52.8227132Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:21:52.8227491Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:21:52.8227813Z     bn_running_var = self.bn.running_var
2026-01-14T09:21:52.8228202Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:21:52.8228650Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:21:52.8229222Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:21:52.8229811Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:21:52.8230237Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:21:52.8230676Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:21:52.8231158Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:21:52.8231703Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:21:52.8232376Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:21:52.8233045Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:21:52.8234134Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:21:52.8235181Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:21:52.8235911Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:21:52.8236555Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:21:52.8237194Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:22:38.9317650Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:22:38.9319810Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:22:38.9320440Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:22:38.9321142Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:22:38.9321570Z     
2026-01-14T09:22:38.9321895Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:22:38.9322289Z model fx: GraphModule(
2026-01-14T09:22:38.9322646Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:22:38.9323960Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:22:38.9325468Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:22:38.9326031Z   )
2026-01-14T09:22:38.9326227Z   (conv): ConvBnReLU2d(
2026-01-14T09:22:38.9326494Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:22:38.9326951Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:22:38.9327480Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:22:38.9329090Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:22:38.9330912Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:22:38.9331758Z     )
2026-01-14T09:22:38.9331967Z   )
2026-01-14T09:22:38.9332292Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:22:38.9333585Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:22:38.9334998Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0564441680908203)
2026-01-14T09:22:38.9335514Z   )
2026-01-14T09:22:38.9335696Z )
2026-01-14T09:22:38.9335806Z 
2026-01-14T09:22:38.9335810Z 
2026-01-14T09:22:38.9335814Z 
2026-01-14T09:22:38.9335906Z def forward(self, x):
2026-01-14T09:22:38.9336282Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:22:38.9337961Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:22:38.9338574Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:22:38.9339043Z     return activation_post_process_1
2026-01-14T09:22:38.9339325Z     
2026-01-14T09:22:38.9339625Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:22:38.9340024Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:22:38.9340280Z           [0., 0., 0.],
2026-01-14T09:22:38.9340672Z           [0., 0., 0.]],
2026-01-14T09:22:38.9340825Z 
2026-01-14T09:22:38.9340914Z          [[0., 0., 0.],
2026-01-14T09:22:38.9341133Z           [0., 0., 0.],
2026-01-14T09:22:38.9341357Z           [0., 0., 0.]],
2026-01-14T09:22:38.9341505Z 
2026-01-14T09:22:38.9341583Z          [[0., 0., 0.],
2026-01-14T09:22:38.9341806Z           [0., 0., 0.],
2026-01-14T09:22:38.9342099Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:22:38.9342528Z converted model pt2e: GraphModule(
2026-01-14T09:22:38.9342805Z   (conv): Module()
2026-01-14T09:22:38.9343028Z   (bn): Module()
2026-01-14T09:22:38.9343248Z   (_guards_fn): GuardsFn()
2026-01-14T09:22:38.9343494Z )
2026-01-14T09:22:38.9343599Z 
2026-01-14T09:22:38.9343603Z 
2026-01-14T09:22:38.9343607Z 
2026-01-14T09:22:38.9343709Z def forward(self, x):
2026-01-14T09:22:38.9344011Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:22:38.9344381Z     conv_bias = self.conv.bias
2026-01-14T09:22:38.9345049Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:22:38.9346405Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:22:38.9347415Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:22:38.9347770Z     _scale_0 = self._scale_0
2026-01-14T09:22:38.9348045Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:22:38.9348387Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:22:38.9349383Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:22:38.9350930Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:22:38.9351991Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:22:38.9361361Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.008064487017691135, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:22:38.9362891Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008064487017691135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:22:38.9364040Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:22:38.9364484Z     
2026-01-14T09:22:38.9364788Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:22:38.9365204Z onverted model fx: GraphModule(
2026-01-14T09:22:38.9365478Z   (conv): ConvReLU2d(
2026-01-14T09:22:38.9365848Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:22:38.9366249Z     (1): ReLU()
2026-01-14T09:22:38.9366453Z   )
2026-01-14T09:22:38.9366626Z )
2026-01-14T09:22:38.9366732Z 
2026-01-14T09:22:38.9366736Z 
2026-01-14T09:22:38.9366740Z 
2026-01-14T09:22:38.9366829Z def forward(self, x):
2026-01-14T09:22:38.9367507Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:22:38.9368961Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:22:38.9370094Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:22:38.9371115Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008064487017691135, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:22:38.9372585Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008064487017691135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:22:38.9373583Z     return dequantize_per_tensor_default_1
2026-01-14T09:22:38.9373870Z     
2026-01-14T09:22:38.9374172Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:22:38.9374571Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:22:38.9374823Z           [0., 0., 0.],
2026-01-14T09:22:38.9375041Z           [0., 0., 0.]],
2026-01-14T09:22:38.9375193Z 
2026-01-14T09:22:38.9375272Z          [[0., 0., 0.],
2026-01-14T09:22:38.9375494Z           [0., 0., 0.],
2026-01-14T09:22:38.9375707Z           [0., 0., 0.]],
2026-01-14T09:22:38.9375852Z 
2026-01-14T09:22:38.9375963Z          [[0., 0., 0.],
2026-01-14T09:22:38.9376270Z           [0., 0., 0.],
2026-01-14T09:22:38.9376600Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:22:38.9376971Z model pt2e: GraphModule(
2026-01-14T09:22:38.9377279Z   (conv): Module()
2026-01-14T09:22:38.9377536Z   (bn): Module()
2026-01-14T09:22:38.9377893Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:22:38.9379172Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:22:38.9380654Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:22:38.9381217Z   )
2026-01-14T09:22:38.9381412Z   (_guards_fn): GuardsFn()
2026-01-14T09:22:38.9381789Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:22:38.9383160Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:22:38.9384843Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:22:38.9388285Z   )
2026-01-14T09:22:38.9388600Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:22:38.9389915Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0080], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:22:38.9391319Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0522286891937256)
2026-01-14T09:22:38.9391838Z   )
2026-01-14T09:22:38.9392020Z )
2026-01-14T09:22:38.9392124Z 
2026-01-14T09:22:38.9392128Z 
2026-01-14T09:22:38.9392132Z 
2026-01-14T09:22:38.9392218Z def forward(self, x):
2026-01-14T09:22:38.9392534Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:22:38.9392903Z     conv_weight = self.conv.weight
2026-01-14T09:22:38.9393198Z     conv_bias = self.conv.bias
2026-01-14T09:22:38.9393484Z     bn_weight = self.bn.weight
2026-01-14T09:22:38.9393829Z     bn_bias = self.bn.bias
2026-01-14T09:22:38.9394142Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:22:38.9394497Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:22:38.9394887Z     bn_running_var = self.bn.running_var
2026-01-14T09:22:38.9395293Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:22:38.9395742Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:22:38.9396379Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:23:30.4132067Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:23:30.4134909Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:23:30.4135503Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:23:30.4136115Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:23:30.4136819Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:23:30.4137603Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:23:30.4138443Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:23:30.4139817Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:23:30.4141101Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:23:30.4141846Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:23:30.4142647Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:23:30.4143410Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:23:30.4144683Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:23:30.4145928Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:23:30.4146638Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:23:30.4147370Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:23:30.4148129Z     
2026-01-14T09:23:30.4148507Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:23:30.4148990Z model fx: GraphModule(
2026-01-14T09:23:30.4149415Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:23:30.4151168Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:23:30.4153059Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:23:30.4153764Z   )
2026-01-14T09:23:30.4154010Z   (conv): ConvBnReLU2d(
2026-01-14T09:23:30.4154317Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:23:30.4154965Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:23:30.4155608Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:23:30.4157195Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:23:30.4159080Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:23:30.4159899Z     )
2026-01-14T09:23:30.4160125Z   )
2026-01-14T09:23:30.4160475Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:23:30.4162095Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0080], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:23:30.4163980Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0522286891937256)
2026-01-14T09:23:30.4164616Z   )
2026-01-14T09:23:30.4164837Z )
2026-01-14T09:23:30.4164961Z 
2026-01-14T09:23:30.4164966Z 
2026-01-14T09:23:30.4164971Z 
2026-01-14T09:23:30.4165078Z def forward(self, x):
2026-01-14T09:23:30.4165531Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:23:30.4166247Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:23:30.4167029Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:23:30.4167635Z     return activation_post_process_1
2026-01-14T09:23:30.4167982Z     
2026-01-14T09:23:30.4168287Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:23:30.4168681Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:23:30.4168945Z           [0., 0., 0.],
2026-01-14T09:23:30.4169173Z           [0., 0., 0.]],
2026-01-14T09:23:30.4169332Z 
2026-01-14T09:23:30.4169413Z          [[0., 0., 0.],
2026-01-14T09:23:30.4169632Z           [0., 0., 0.],
2026-01-14T09:23:30.4169861Z           [0., 0., 0.]],
2026-01-14T09:23:30.4170010Z 
2026-01-14T09:23:30.4170091Z          [[0., 0., 0.],
2026-01-14T09:23:30.4170315Z           [0., 0., 0.],
2026-01-14T09:23:30.4170617Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:23:30.4170995Z converted model pt2e: GraphModule(
2026-01-14T09:23:30.4171281Z   (conv): Module()
2026-01-14T09:23:30.4171491Z   (bn): Module()
2026-01-14T09:23:30.4171723Z   (_guards_fn): GuardsFn()
2026-01-14T09:23:30.4171958Z )
2026-01-14T09:23:30.4172072Z 
2026-01-14T09:23:30.4172076Z 
2026-01-14T09:23:30.4172080Z 
2026-01-14T09:23:30.4172168Z def forward(self, x):
2026-01-14T09:23:30.4172470Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:23:30.4172836Z     conv_bias = self.conv.bias
2026-01-14T09:23:30.4173571Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:23:30.4174923Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:23:30.4175934Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:23:30.4176386Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:23:30.4177262Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:23:30.4178676Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:23:30.4179625Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:23:30.4180494Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.00804795604199171, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:23:30.4181916Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.00804795604199171, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:23:30.4183068Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:23:30.4183526Z     
2026-01-14T09:23:30.4183821Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:23:30.4184412Z onverted model fx: GraphModule(
2026-01-14T09:23:30.4184684Z   (conv): ConvReLU2d(
2026-01-14T09:23:30.4185053Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:23:30.4185461Z     (1): ReLU()
2026-01-14T09:23:30.4185661Z   )
2026-01-14T09:23:30.4185841Z )
2026-01-14T09:23:30.4186017Z 
2026-01-14T09:23:30.4186022Z 
2026-01-14T09:23:30.4186026Z 
2026-01-14T09:23:30.4186117Z def forward(self, x):
2026-01-14T09:23:30.4186790Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:23:30.4188179Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:23:30.4189364Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:23:30.4190313Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.00804795604199171, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:23:30.4191723Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.00804795604199171, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:23:30.4192703Z     return dequantize_per_tensor_default_1
2026-01-14T09:23:30.4193005Z     
2026-01-14T09:23:30.4193310Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:23:30.4193715Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:23:30.4193965Z           [0., 0., 0.],
2026-01-14T09:23:30.4194195Z           [0., 0., 0.]],
2026-01-14T09:23:30.4194347Z 
2026-01-14T09:23:30.4194427Z          [[0., 0., 0.],
2026-01-14T09:23:30.4194657Z           [0., 0., 0.],
2026-01-14T09:23:30.4194926Z           [0., 0., 0.]],
2026-01-14T09:23:30.4195084Z 
2026-01-14T09:23:30.4195166Z          [[0., 0., 0.],
2026-01-14T09:23:30.4195388Z           [0., 0., 0.],
2026-01-14T09:23:30.4195626Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:23:30.4196121Z [32mPASSED[0m
2026-01-14T09:23:30.4196791Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T09:23:30.4197589Z   (conv): Module()
2026-01-14T09:23:30.4197809Z   (bn): Module()
2026-01-14T09:23:30.4198136Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:23:30.4199289Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:23:30.4200555Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:23:30.4201118Z   )
2026-01-14T09:23:30.4201316Z   (_guards_fn): GuardsFn()
2026-01-14T09:23:30.4201676Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:23:30.4202824Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:23:30.4204311Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1866, -0.1825, -0.1912]), max_val=tensor([0.1747, 0.1914, 0.1702]))
2026-01-14T09:23:30.4205018Z   )
2026-01-14T09:23:30.4205319Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:08.0297219Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:08.0299093Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.984864354133606)
2026-01-14T09:24:08.0299740Z   )
2026-01-14T09:24:08.0299964Z )
2026-01-14T09:24:08.0300097Z 
2026-01-14T09:24:08.0300102Z 
2026-01-14T09:24:08.0300115Z 
2026-01-14T09:24:08.0300224Z def forward(self, x):
2026-01-14T09:24:08.0300719Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:24:08.0301171Z     conv_weight = self.conv.weight
2026-01-14T09:24:08.0301531Z     bn_weight = self.bn.weight
2026-01-14T09:24:08.0301853Z     bn_bias = self.bn.bias
2026-01-14T09:24:08.0302230Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:24:08.0302672Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:24:08.0303069Z     bn_running_var = self.bn.running_var
2026-01-14T09:24:08.0303578Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:24:08.0304133Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:24:08.0304836Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:24:08.0305559Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:24:08.0306070Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:24:08.0306609Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:24:08.0307195Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:24:08.0307873Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:24:08.0308631Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:24:08.0309795Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:24:08.0310944Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:24:08.0311675Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:24:08.0312969Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:24:08.0314303Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:24:08.0315111Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:24:08.0315835Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:24:08.0316353Z     
2026-01-14T09:24:08.0316844Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:08.0317337Z model fx: GraphModule(
2026-01-14T09:24:08.0317750Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:08.0319085Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:08.0320695Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:24:08.0321410Z   )
2026-01-14T09:24:08.0321647Z   (conv): ConvBnReLU2d(
2026-01-14T09:24:08.0321985Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:24:08.0322569Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:24:08.0323199Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:08.0324578Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:24:08.0326494Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1866, -0.1825, -0.1912]), max_val=tensor([0.1747, 0.1914, 0.1702]))
2026-01-14T09:24:08.0327387Z     )
2026-01-14T09:24:08.0327605Z   )
2026-01-14T09:24:08.0327959Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:08.0329345Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:08.0330858Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.984864354133606)
2026-01-14T09:24:08.0331531Z   )
2026-01-14T09:24:08.0331760Z )
2026-01-14T09:24:08.0331887Z 
2026-01-14T09:24:08.0331893Z 
2026-01-14T09:24:08.0331897Z 
2026-01-14T09:24:08.0332012Z def forward(self, x):
2026-01-14T09:24:08.0332459Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:24:08.0333180Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:24:08.0333907Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:24:08.0334484Z     return activation_post_process_1
2026-01-14T09:24:08.0334818Z     
2026-01-14T09:24:08.0335182Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:08.0335672Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:24:08.0335975Z           [0., 0., 0.],
2026-01-14T09:24:08.0336249Z           [0., 0., 0.]],
2026-01-14T09:24:08.0336452Z 
2026-01-14T09:24:08.0336539Z          [[0., 0., 0.],
2026-01-14T09:24:08.0336775Z           [0., 0., 0.],
2026-01-14T09:24:08.0336999Z           [0., 0., 0.]],
2026-01-14T09:24:08.0337159Z 
2026-01-14T09:24:08.0337240Z          [[0., 0., 0.],
2026-01-14T09:24:08.0337458Z           [0., 0., 0.],
2026-01-14T09:24:08.0337719Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:24:08.0338055Z converted model pt2e: GraphModule(
2026-01-14T09:24:08.0338327Z   (conv): Module()
2026-01-14T09:24:08.0338545Z   (bn): Module()
2026-01-14T09:24:08.0338764Z   (_guards_fn): GuardsFn()
2026-01-14T09:24:08.0339002Z )
2026-01-14T09:24:08.0339107Z 
2026-01-14T09:24:08.0339164Z 
2026-01-14T09:24:08.0339168Z 
2026-01-14T09:24:08.0339262Z def forward(self, x):
2026-01-14T09:24:08.0339573Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:24:08.0340328Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:24:08.0341784Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:24:08.0342790Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:24:08.0343139Z     _scale_0 = self._scale_0
2026-01-14T09:24:08.0343419Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:24:08.0343742Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:24:08.0344744Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:24:08.0345755Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:24:08.0346694Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:24:08.0347719Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:24:08.0348620Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007783781737089157, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:24:08.0350055Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007783781737089157, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:24:08.0351191Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:24:08.0351682Z     
2026-01-14T09:24:08.0351993Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:08.0352394Z onverted model fx: GraphModule(
2026-01-14T09:24:08.0352674Z   (conv): ConvReLU2d(
2026-01-14T09:24:08.0353040Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:24:08.0353444Z     (1): ReLU()
2026-01-14T09:24:08.0353648Z   )
2026-01-14T09:24:08.0353829Z )
2026-01-14T09:24:08.0353934Z 
2026-01-14T09:24:08.0353940Z 
2026-01-14T09:24:08.0353954Z 
2026-01-14T09:24:08.0354048Z def forward(self, x):
2026-01-14T09:24:08.0354721Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:24:08.0356149Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:24:08.0357290Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:24:08.0358245Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007783781737089157, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:24:08.0359662Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007783781737089157, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:24:08.0360673Z     return dequantize_per_tensor_default_1
2026-01-14T09:24:08.0360983Z     
2026-01-14T09:24:08.0361292Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:08.0361682Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:24:08.0361939Z           [0., 0., 0.],
2026-01-14T09:24:08.0362162Z           [0., 0., 0.]],
2026-01-14T09:24:08.0362317Z 
2026-01-14T09:24:08.0362456Z          [[0., 0., 0.],
2026-01-14T09:24:08.0362678Z           [0., 0., 0.],
2026-01-14T09:24:08.0362902Z           [0., 0., 0.]],
2026-01-14T09:24:08.0363050Z 
2026-01-14T09:24:08.0363138Z          [[0., 0., 0.],
2026-01-14T09:24:08.0363358Z           [0., 0., 0.],
2026-01-14T09:24:08.0363589Z           [0., 0., 0.]]]])
2026-01-14T09:24:08.0363836Z model pt2e: GraphModule(
2026-01-14T09:24:08.0364079Z   (conv): Module()
2026-01-14T09:24:08.0364310Z   (bn): Module()
2026-01-14T09:24:08.0364675Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:08.0365742Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:08.0366989Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:24:08.0367547Z   )
2026-01-14T09:24:08.0377463Z   (_guards_fn): GuardsFn()
2026-01-14T09:24:08.0377965Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:52.0208167Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:24:52.0209823Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T09:24:52.0210986Z   )
2026-01-14T09:24:52.0211435Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:52.0212777Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:52.0214440Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9838534593582153)
2026-01-14T09:24:52.0215248Z   )
2026-01-14T09:24:52.0215498Z )
2026-01-14T09:24:52.0215656Z 
2026-01-14T09:24:52.0215662Z 
2026-01-14T09:24:52.0215668Z 
2026-01-14T09:24:52.0215791Z def forward(self, x):
2026-01-14T09:24:52.0216167Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:24:52.0216622Z     conv_weight = self.conv.weight
2026-01-14T09:24:52.0216978Z     bn_weight = self.bn.weight
2026-01-14T09:24:52.0217306Z     bn_bias = self.bn.bias
2026-01-14T09:24:52.0217688Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:24:52.0218131Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:24:52.0218525Z     bn_running_var = self.bn.running_var
2026-01-14T09:24:52.0219008Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:24:52.0219566Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:24:52.0220269Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:24:52.0221002Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:24:52.0221521Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:24:52.0222055Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:24:52.0222643Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:24:52.0223321Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:24:52.0224087Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:24:52.0225253Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:24:52.0226399Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:24:52.0227134Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:24:52.0228538Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:24:52.0229778Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:24:52.0230487Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:24:52.0231326Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:24:52.0231862Z     
2026-01-14T09:24:52.0232218Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:52.0232705Z model fx: GraphModule(
2026-01-14T09:24:52.0233113Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:52.0234455Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:52.0236148Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:24:52.0236845Z   )
2026-01-14T09:24:52.0237085Z   (conv): ConvBnReLU2d(
2026-01-14T09:24:52.0237421Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:24:52.0238014Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:24:52.0240139Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:52.0241462Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:24:52.0243091Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T09:24:52.0243814Z     )
2026-01-14T09:24:52.0244092Z   )
2026-01-14T09:24:52.0244444Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:52.0245920Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:52.0247279Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9838534593582153)
2026-01-14T09:24:52.0247798Z   )
2026-01-14T09:24:52.0247982Z )
2026-01-14T09:24:52.0248088Z 
2026-01-14T09:24:52.0248093Z 
2026-01-14T09:24:52.0248097Z 
2026-01-14T09:24:52.0248191Z def forward(self, x):
2026-01-14T09:24:52.0248598Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:24:52.0249200Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:24:52.0249811Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:24:52.0250290Z     return activation_post_process_1
2026-01-14T09:24:52.0250576Z     
2026-01-14T09:24:52.0250875Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:52.0251296Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:24:52.0251552Z           [0., 0., 0.],
2026-01-14T09:24:52.0251786Z           [0., 0., 0.]],
2026-01-14T09:24:52.0251938Z 
2026-01-14T09:24:52.0252022Z          [[0., 0., 0.],
2026-01-14T09:24:52.0252253Z           [0., 0., 0.],
2026-01-14T09:24:52.0252476Z           [0., 0., 0.]],
2026-01-14T09:24:52.0252632Z 
2026-01-14T09:24:52.0252714Z          [[0., 0., 0.],
2026-01-14T09:24:52.0252942Z           [0., 0., 0.],
2026-01-14T09:24:52.0253201Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:24:52.0253545Z converted model pt2e: GraphModule(
2026-01-14T09:24:52.0253822Z   (conv): Module()
2026-01-14T09:24:52.0254044Z   (bn): Module()
2026-01-14T09:24:52.0254324Z   (_guards_fn): GuardsFn()
2026-01-14T09:24:52.0254572Z )
2026-01-14T09:24:52.0254676Z 
2026-01-14T09:24:52.0254680Z 
2026-01-14T09:24:52.0254684Z 
2026-01-14T09:24:52.0254774Z def forward(self, x):
2026-01-14T09:24:52.0255084Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:24:52.0255847Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:24:52.0257233Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:24:52.0258267Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:24:52.0258653Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:24:52.0259544Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001507229870185256, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:24:52.0260450Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:24:52.0261387Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:24:52.0262411Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:24:52.0263287Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007779817562550306, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:24:52.0264782Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007779817562550306, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:24:52.0265977Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:24:52.0266419Z     
2026-01-14T09:24:52.0266770Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:52.0267175Z onverted model fx: GraphModule(
2026-01-14T09:24:52.0267458Z   (conv): ConvReLU2d(
2026-01-14T09:24:52.0267826Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:24:52.0268223Z     (1): ReLU()
2026-01-14T09:24:52.0268432Z   )
2026-01-14T09:24:52.0268610Z )
2026-01-14T09:24:52.0268717Z 
2026-01-14T09:24:52.0268724Z 
2026-01-14T09:24:52.0268734Z 
2026-01-14T09:24:52.0268825Z def forward(self, x):
2026-01-14T09:24:52.0269505Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:24:52.0270899Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:24:52.0272059Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:24:52.0273026Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007779817562550306, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:24:52.0274460Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007779817562550306, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:24:52.0275554Z     return dequantize_per_tensor_default_1
2026-01-14T09:24:52.0275852Z     
2026-01-14T09:24:52.0276163Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:52.0276565Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:24:52.0276826Z           [0., 0., 0.],
2026-01-14T09:24:52.0277051Z           [0., 0., 0.]],
2026-01-14T09:24:52.0277205Z 
2026-01-14T09:24:52.0277347Z          [[0., 0., 0.],
2026-01-14T09:24:52.0277568Z           [0., 0., 0.],
2026-01-14T09:24:52.0277802Z           [0., 0., 0.]],
2026-01-14T09:24:52.0277951Z 
2026-01-14T09:24:52.0278042Z          [[0., 0., 0.],
2026-01-14T09:24:52.0278260Z           [0., 0., 0.],
2026-01-14T09:24:52.0278490Z           [0., 0., 0.]]]])
2026-01-14T09:24:52.0278963Z [32mPASSED[0m
2026-01-14T09:24:52.0279627Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T09:24:52.0280274Z   (conv): Module()
2026-01-14T09:24:52.0280610Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:56.4314509Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:24:56.4316583Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:24:56.4317538Z   )
2026-01-14T09:24:56.4317901Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:56.4319247Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:56.4320853Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:24:56.4321767Z   )
2026-01-14T09:24:56.4322005Z   (_guards_fn): GuardsFn()
2026-01-14T09:24:56.4322441Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:56.4323784Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:56.4325397Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5882599353790283)
2026-01-14T09:24:56.4326041Z   )
2026-01-14T09:24:56.4326260Z )
2026-01-14T09:24:56.4326407Z 
2026-01-14T09:24:56.4326420Z 
2026-01-14T09:24:56.4326425Z 
2026-01-14T09:24:56.4326558Z def forward(self, x):
2026-01-14T09:24:56.4326928Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:24:56.4327384Z     conv_weight = self.conv.weight
2026-01-14T09:24:56.4327999Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:24:56.4328751Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:24:56.4329307Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:24:56.4330319Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:24:56.4331380Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:24:56.4332024Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:24:56.4332764Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:24:56.4333294Z     
2026-01-14T09:24:56.4333656Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:56.4334159Z model fx: GraphModule(
2026-01-14T09:24:56.4334571Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:56.4335915Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:56.4337506Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:24:56.4338291Z   )
2026-01-14T09:24:56.4338532Z   (conv): ConvReLU2d(
2026-01-14T09:24:56.4338863Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:24:56.4339346Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:56.4340817Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:24:56.4342711Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:24:56.4343609Z     )
2026-01-14T09:24:56.4343824Z   )
2026-01-14T09:24:56.4344179Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:56.4345533Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:56.4347064Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5882599353790283)
2026-01-14T09:24:56.4347708Z   )
2026-01-14T09:24:56.4347916Z )
2026-01-14T09:24:56.4348037Z 
2026-01-14T09:24:56.4348042Z 
2026-01-14T09:24:56.4348046Z 
2026-01-14T09:24:56.4348156Z def forward(self, x):
2026-01-14T09:24:56.4348643Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:24:56.4349426Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:24:56.4350158Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:24:56.4350737Z     return activation_post_process_1
2026-01-14T09:24:56.4351066Z     
2026-01-14T09:24:56.4351424Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:56.4351910Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:24:56.4352264Z           [0., 0., 0.],
2026-01-14T09:24:56.4352533Z           [0., 0., 0.]],
2026-01-14T09:24:56.4352719Z 
2026-01-14T09:24:56.4352817Z          [[0., 0., 0.],
2026-01-14T09:24:56.4353089Z           [0., 0., 0.],
2026-01-14T09:24:56.4353353Z           [0., 0., 0.]],
2026-01-14T09:24:56.4353531Z 
2026-01-14T09:24:56.4353639Z          [[0., 0., 0.],
2026-01-14T09:24:56.4353900Z           [0., 0., 0.],
2026-01-14T09:24:56.4354214Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:24:56.4354618Z converted model pt2e: GraphModule(
2026-01-14T09:24:56.4355022Z   (conv): Module()
2026-01-14T09:24:56.4355288Z   (_guards_fn): GuardsFn()
2026-01-14T09:24:56.4355572Z )
2026-01-14T09:24:56.4355695Z 
2026-01-14T09:24:56.4355700Z 
2026-01-14T09:24:56.4355704Z 
2026-01-14T09:24:56.4355821Z def forward(self, x):
2026-01-14T09:24:56.4356202Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:24:56.4356675Z     _scale_0 = self._scale_0
2026-01-14T09:24:56.4357014Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:24:56.4357453Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:24:56.4358605Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:24:56.4360092Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:24:56.4361451Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:24:56.4362467Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:24:56.4363370Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:24:56.4364363Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:24:56.4365221Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006228470243513584, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:24:56.4366716Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006228470243513584, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:24:56.4367847Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:24:56.4368287Z     
2026-01-14T09:24:56.4368596Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:56.4369006Z onverted model fx: GraphModule(
2026-01-14T09:24:56.4369282Z   (conv): ConvReLU2d(
2026-01-14T09:24:56.4369682Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:24:56.4370133Z     (1): ReLU()
2026-01-14T09:24:56.4370329Z   )
2026-01-14T09:24:56.4370515Z )
2026-01-14T09:24:56.4370615Z 
2026-01-14T09:24:56.4370619Z 
2026-01-14T09:24:56.4370623Z 
2026-01-14T09:24:56.4370718Z def forward(self, x):
2026-01-14T09:24:56.4371398Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:24:56.4372849Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:24:56.4373988Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:24:56.4374946Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006228470243513584, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:24:56.4376438Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006228470243513584, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:24:56.4377479Z     return dequantize_per_tensor_default_1
2026-01-14T09:24:56.4377773Z     
2026-01-14T09:24:56.4378075Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:24:56.4378485Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:24:56.4378743Z           [0., 0., 0.],
2026-01-14T09:24:56.4378967Z           [0., 0., 0.]],
2026-01-14T09:24:56.4379117Z 
2026-01-14T09:24:56.4379202Z          [[0., 0., 0.],
2026-01-14T09:24:56.4379419Z           [0., 0., 0.],
2026-01-14T09:24:56.4379644Z           [0., 0., 0.]],
2026-01-14T09:24:56.4379790Z 
2026-01-14T09:24:56.4379869Z          [[0., 0., 0.],
2026-01-14T09:24:56.4380093Z           [0., 0., 0.],
2026-01-14T09:24:56.4380316Z           [0., 0., 0.]]]])
2026-01-14T09:24:56.4380572Z model pt2e: GraphModule(
2026-01-14T09:24:56.4380813Z   (conv): Module()
2026-01-14T09:24:56.4381143Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:56.4382245Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:24:56.4383520Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965116143226624, max_val=0.18703685700893402)
2026-01-14T09:24:56.4384291Z   )
2026-01-14T09:24:56.4384585Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:24:56.4385671Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:24:56.4387012Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:24:56.4387567Z   )
2026-01-14T09:24:56.4387764Z   (_guards_fn): GuardsFn()
2026-01-14T09:25:00.8657432Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:00.8659064Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:00.8660743Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5892566442489624)
2026-01-14T09:25:00.8661394Z   )
2026-01-14T09:25:00.8661633Z )
2026-01-14T09:25:00.8661766Z 
2026-01-14T09:25:00.8661771Z 
2026-01-14T09:25:00.8661775Z 
2026-01-14T09:25:00.8661892Z def forward(self, x):
2026-01-14T09:25:00.8662289Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:25:00.8662758Z     conv_weight = self.conv.weight
2026-01-14T09:25:00.8663385Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:25:00.8664162Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:25:00.8664735Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:25:00.8665765Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:25:00.8666924Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:25:00.8667599Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:25:00.8668372Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:25:00.8668965Z     
2026-01-14T09:25:00.8669347Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:25:00.8669839Z model fx: GraphModule(
2026-01-14T09:25:00.8670345Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:00.8671682Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:00.8673263Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:25:00.8673960Z   )
2026-01-14T09:25:00.8674190Z   (conv): ConvReLU2d(
2026-01-14T09:25:00.8674531Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:25:00.8675119Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:00.8676430Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:25:00.8678060Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965116143226624, max_val=0.18703685700893402)
2026-01-14T09:25:00.8678778Z     )
2026-01-14T09:25:00.8678998Z   )
2026-01-14T09:25:00.8679346Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:00.8680694Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:00.8682205Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5892566442489624)
2026-01-14T09:25:00.8682842Z   )
2026-01-14T09:25:00.8683060Z )
2026-01-14T09:25:00.8683183Z 
2026-01-14T09:25:00.8683188Z 
2026-01-14T09:25:00.8683193Z 
2026-01-14T09:25:00.8683304Z def forward(self, x):
2026-01-14T09:25:00.8683760Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:25:00.8684932Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:25:00.8685672Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:25:00.8686240Z     return activation_post_process_1
2026-01-14T09:25:00.8686575Z     
2026-01-14T09:25:00.8686936Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:25:00.8687514Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:25:00.8687871Z           [0., 0., 0.],
2026-01-14T09:25:00.8688148Z           [0., 0., 0.]],
2026-01-14T09:25:00.8688338Z 
2026-01-14T09:25:00.8688436Z          [[0., 0., 0.],
2026-01-14T09:25:00.8688699Z           [0., 0., 0.],
2026-01-14T09:25:00.8688969Z           [0., 0., 0.]],
2026-01-14T09:25:00.8689147Z 
2026-01-14T09:25:00.8689244Z          [[0., 0., 0.],
2026-01-14T09:25:00.8689513Z           [0., 0., 0.],
2026-01-14T09:25:00.8689826Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:25:00.8690229Z converted model pt2e: GraphModule(
2026-01-14T09:25:00.8690576Z   (conv): Module()
2026-01-14T09:25:00.8690841Z   (_guards_fn): GuardsFn()
2026-01-14T09:25:00.8691132Z )
2026-01-14T09:25:00.8691256Z 
2026-01-14T09:25:00.8691261Z 
2026-01-14T09:25:00.8691266Z 
2026-01-14T09:25:00.8691373Z def forward(self, x):
2026-01-14T09:25:00.8691739Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:25:00.8692232Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:25:00.8693601Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0014933162601664662, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:25:00.8695342Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:25:00.8697032Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:25:00.8698054Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:25:00.8699008Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:25:00.8699933Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:25:00.8700792Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006232379004359245, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:25:00.8702209Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.006232379004359245, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:25:00.8703339Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:25:00.8703784Z     
2026-01-14T09:25:00.8704082Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:25:00.8704494Z onverted model fx: GraphModule(
2026-01-14T09:25:00.8704766Z   (conv): ConvReLU2d(
2026-01-14T09:25:00.8705167Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:25:00.8705616Z     (1): ReLU()
2026-01-14T09:25:00.8705832Z   )
2026-01-14T09:25:00.8706016Z )
2026-01-14T09:25:00.8706119Z 
2026-01-14T09:25:00.8706124Z 
2026-01-14T09:25:00.8706127Z 
2026-01-14T09:25:00.8706216Z def forward(self, x):
2026-01-14T09:25:00.8706893Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:25:00.8708255Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:25:00.8709515Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:25:00.8710465Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006232379004359245, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:25:00.8711935Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006232379004359245, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:25:00.8712926Z     return dequantize_per_tensor_default_1
2026-01-14T09:25:00.8713224Z     
2026-01-14T09:25:00.8713518Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:25:00.8713915Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:25:00.8714163Z           [0., 0., 0.],
2026-01-14T09:25:00.8714390Z           [0., 0., 0.]],
2026-01-14T09:25:00.8714541Z 
2026-01-14T09:25:00.8714624Z          [[0., 0., 0.],
2026-01-14T09:25:00.8714922Z           [0., 0., 0.],
2026-01-14T09:25:00.8715140Z           [0., 0., 0.]],
2026-01-14T09:25:00.8715294Z 
2026-01-14T09:25:00.8715374Z          [[0., 0., 0.],
2026-01-14T09:25:00.8715594Z           [0., 0., 0.],
2026-01-14T09:25:00.8715821Z           [0., 0., 0.]]]])
2026-01-14T09:25:00.8716078Z model pt2e: GraphModule(
2026-01-14T09:25:00.8716321Z   (conv): Module()
2026-01-14T09:25:00.8716657Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:00.8717855Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:25:00.8719383Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:25:00.8720104Z   )
2026-01-14T09:25:00.8720443Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:00.8721526Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:00.8722776Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:25:00.8723339Z   )
2026-01-14T09:25:00.8723537Z   (_guards_fn): GuardsFn()
2026-01-14T09:25:00.8723896Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:00.8724976Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0080]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:00.8726233Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9872972965240479, max_val=1.0470484495162964)
2026-01-14T09:25:00.8726804Z   )
2026-01-14T09:25:00.8726981Z )
2026-01-14T09:25:00.8727099Z 
2026-01-14T09:25:00.8727103Z 
2026-01-14T09:25:00.8727106Z 
2026-01-14T09:25:00.8727200Z def forward(self, x):
2026-01-14T09:25:00.8727514Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:25:00.8727881Z     conv_weight = self.conv.weight
2026-01-14T09:25:00.8728389Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:25:00.8729051Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:25:00.8729516Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:25:00.8730331Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:25:05.3239090Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:25:05.3241123Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:25:05.3241652Z     
2026-01-14T09:25:05.3242022Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:25:05.3242503Z model fx: GraphModule(
2026-01-14T09:25:05.3242916Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:05.3244561Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:05.3246159Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:25:05.3246856Z   )
2026-01-14T09:25:05.3247078Z   (conv): Conv2d(
2026-01-14T09:25:05.3247397Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:25:05.3247875Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:05.3258574Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:25:05.3260550Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:25:05.3261569Z     )
2026-01-14T09:25:05.3261787Z   )
2026-01-14T09:25:05.3262144Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:05.3263474Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0080]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:05.3265116Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9872972965240479, max_val=1.0470484495162964)
2026-01-14T09:25:05.3265819Z   )
2026-01-14T09:25:05.3266030Z )
2026-01-14T09:25:05.3266164Z 
2026-01-14T09:25:05.3266169Z 
2026-01-14T09:25:05.3266173Z 
2026-01-14T09:25:05.3266281Z def forward(self, x):
2026-01-14T09:25:05.3266742Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:25:05.3267501Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:25:05.3268290Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:25:05.3268769Z     return activation_post_process_1
2026-01-14T09:25:05.3269054Z     
2026-01-14T09:25:05.3269392Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:25:05.3269806Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:25:05.3270067Z           [0., 0., 0.],
2026-01-14T09:25:05.3270287Z           [0., 0., 0.]],
2026-01-14T09:25:05.3270441Z 
2026-01-14T09:25:05.3270534Z          [[0., 0., 0.],
2026-01-14T09:25:05.3270749Z           [0., 0., 0.],
2026-01-14T09:25:05.3270972Z           [0., 0., 0.]],
2026-01-14T09:25:05.3271119Z 
2026-01-14T09:25:05.3271197Z          [[0., 0., 0.],
2026-01-14T09:25:05.3271419Z           [0., 0., 0.],
2026-01-14T09:25:05.3271675Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:25:05.3272014Z converted model pt2e: GraphModule(
2026-01-14T09:25:05.3272286Z   (conv): Module()
2026-01-14T09:25:05.3272518Z   (_guards_fn): GuardsFn()
2026-01-14T09:25:05.3272752Z )
2026-01-14T09:25:05.3272855Z 
2026-01-14T09:25:05.3272859Z 
2026-01-14T09:25:05.3272863Z 
2026-01-14T09:25:05.3272950Z def forward(self, x):
2026-01-14T09:25:05.3273255Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:25:05.3273608Z     _scale_0 = self._scale_0
2026-01-14T09:25:05.3273876Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:25:05.3274213Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:25:05.3275514Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:25:05.3276963Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:25:05.3278349Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:25:05.3279393Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:25:05.3280299Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:25:05.3281610Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.007977825589478016, -4, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:25:05.3283017Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007977825589478016, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:25:05.3284382Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:25:05.3284915Z     
2026-01-14T09:25:05.3285227Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:25:05.3285623Z onverted model fx: GraphModule(
2026-01-14T09:25:05.3286073Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:25:05.3286522Z )
2026-01-14T09:25:05.3286633Z 
2026-01-14T09:25:05.3286637Z 
2026-01-14T09:25:05.3286641Z 
2026-01-14T09:25:05.3286728Z def forward(self, x):
2026-01-14T09:25:05.3287471Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:25:05.3288826Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:25:05.3289972Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:25:05.3290943Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007977825589478016, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:25:05.3292365Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007977825589478016, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:25:05.3293328Z     return dequantize_per_tensor_default_1
2026-01-14T09:25:05.3293610Z     
2026-01-14T09:25:05.3293913Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:25:05.3294305Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:25:05.3294555Z           [0., 0., 0.],
2026-01-14T09:25:05.3294775Z           [0., 0., 0.]],
2026-01-14T09:25:05.3294929Z 
2026-01-14T09:25:05.3295007Z          [[0., 0., 0.],
2026-01-14T09:25:05.3295235Z           [0., 0., 0.],
2026-01-14T09:25:05.3295454Z           [0., 0., 0.]],
2026-01-14T09:25:05.3295604Z 
2026-01-14T09:25:05.3295691Z          [[0., 0., 0.],
2026-01-14T09:25:05.3295907Z           [0., 0., 0.],
2026-01-14T09:25:05.3296133Z           [0., 0., 0.]]]])
2026-01-14T09:25:05.3296374Z model pt2e: GraphModule(
2026-01-14T09:25:05.3296629Z   (conv): Module()
2026-01-14T09:25:05.3296937Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:05.3298015Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:25:05.3299406Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212539494037628, max_val=0.18097467720508575)
2026-01-14T09:25:05.3300000Z   )
2026-01-14T09:25:05.3300323Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:05.3301458Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:05.3302713Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:25:05.3303266Z   )
2026-01-14T09:25:05.3303459Z   (_guards_fn): GuardsFn()
2026-01-14T09:25:05.3303809Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:05.3304860Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:05.3306118Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9800506234169006, max_val=1.0470484495162964)
2026-01-14T09:25:05.3306696Z   )
2026-01-14T09:25:05.3306871Z )
2026-01-14T09:25:05.3306982Z 
2026-01-14T09:25:05.3306988Z 
2026-01-14T09:25:05.3307040Z 
2026-01-14T09:25:05.3307131Z def forward(self, x):
2026-01-14T09:25:05.3307433Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:25:05.3307805Z     conv_weight = self.conv.weight
2026-01-14T09:25:05.3308297Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:25:05.3308906Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:25:05.3309355Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:25:05.3310255Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:25:05.3311192Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:25:05.3311800Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:25:05.3312216Z     
2026-01-14T09:25:05.3312519Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:25:05.3312901Z model fx: GraphModule(
2026-01-14T09:25:05.3313248Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:05.3314301Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:25:05.3315611Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:25:05.3316169Z   )
2026-01-14T09:25:05.3316351Z   (conv): Conv2d(
2026-01-14T09:25:05.3316616Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:25:05.3317006Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:25:05.3318042Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:27:52.0952083Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212539494037628, max_val=0.18097467720508575)
2026-01-14T09:27:52.0953273Z     )
2026-01-14T09:27:52.0953655Z   )
2026-01-14T09:27:52.0954236Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:52.0955492Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:52.0957010Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9800506234169006, max_val=1.0470484495162964)
2026-01-14T09:27:52.0957579Z   )
2026-01-14T09:27:52.0957761Z )
2026-01-14T09:27:52.0957864Z 
2026-01-14T09:27:52.0957869Z 
2026-01-14T09:27:52.0957873Z 
2026-01-14T09:27:52.0958065Z def forward(self, x):
2026-01-14T09:27:52.0958448Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:27:52.0959041Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:27:52.0959645Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:27:52.0960117Z     return activation_post_process_1
2026-01-14T09:27:52.0960401Z     
2026-01-14T09:27:52.0960704Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:27:52.0961113Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:27:52.0961367Z           [0., 0., 0.],
2026-01-14T09:27:52.0961596Z           [0., 0., 0.]],
2026-01-14T09:27:52.0961746Z 
2026-01-14T09:27:52.0961827Z          [[0., 0., 0.],
2026-01-14T09:27:52.0962056Z           [0., 0., 0.],
2026-01-14T09:27:52.0962275Z           [0., 0., 0.]],
2026-01-14T09:27:52.0962443Z 
2026-01-14T09:27:52.0962523Z          [[0., 0., 0.],
2026-01-14T09:27:52.0962740Z           [0., 0., 0.],
2026-01-14T09:27:52.0963155Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:27:52.0963488Z converted model pt2e: GraphModule(
2026-01-14T09:27:52.0963771Z   (conv): Module()
2026-01-14T09:27:52.0964002Z   (_guards_fn): GuardsFn()
2026-01-14T09:27:52.0964240Z )
2026-01-14T09:27:52.0964360Z 
2026-01-14T09:27:52.0964364Z 
2026-01-14T09:27:52.0964368Z 
2026-01-14T09:27:52.0964483Z def forward(self, x):
2026-01-14T09:27:52.0964788Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:27:52.0965293Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:27:52.0966328Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0015127983642742038, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:27:52.0967682Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:27:52.0969052Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:27:52.0970086Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:27:52.0970979Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:27:52.0972293Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.007949408143758774, -5, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:27:52.0973721Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007949408143758774, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:27:52.0974820Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:27:52.0975281Z     
2026-01-14T09:27:52.0975575Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:27:52.0975984Z onverted model fx: GraphModule(
2026-01-14T09:27:52.0976433Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:27:52.0976892Z )
2026-01-14T09:27:52.0976996Z 
2026-01-14T09:27:52.0977000Z 
2026-01-14T09:27:52.0977053Z 
2026-01-14T09:27:52.0977144Z def forward(self, x):
2026-01-14T09:27:52.0977820Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:27:52.0979199Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:27:52.0980375Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:27:52.0981331Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007949408143758774, -5, -128, 127, torch.int8);  conv = None
2026-01-14T09:27:52.0982742Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007949408143758774, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:27:52.0983712Z     return dequantize_per_tensor_default_1
2026-01-14T09:27:52.0984013Z     
2026-01-14T09:27:52.0984543Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:27:52.0984941Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:27:52.0985191Z           [0., 0., 0.],
2026-01-14T09:27:52.0985418Z           [0., 0., 0.]],
2026-01-14T09:27:52.0985567Z 
2026-01-14T09:27:52.0985652Z          [[0., 0., 0.],
2026-01-14T09:27:52.0985871Z           [0., 0., 0.],
2026-01-14T09:27:52.0986174Z           [0., 0., 0.]],
2026-01-14T09:27:52.0986320Z 
2026-01-14T09:27:52.0986398Z          [[0., 0., 0.],
2026-01-14T09:27:52.0986615Z           [0., 0., 0.],
2026-01-14T09:27:52.0986832Z           [0., 0., 0.]]]])
2026-01-14T09:27:52.0987295Z [32mPASSED[0m
2026-01-14T09:27:52.0987968Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T09:27:52.0989131Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T09:27:52.0990129Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T09:27:52.0990767Z   (conv): Module()
2026-01-14T09:27:52.0991096Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:52.0992201Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:27:52.0993554Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2877]), max_val=tensor([-0.2877]))
2026-01-14T09:27:52.0994175Z   )
2026-01-14T09:27:52.0994480Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:52.0995651Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:52.0996907Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:27:52.0997473Z   )
2026-01-14T09:27:52.0997677Z   (_guards_fn): GuardsFn()
2026-01-14T09:27:52.0998030Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:52.0999102Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:52.1000362Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:27:52.1000934Z   )
2026-01-14T09:27:52.1001232Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:52.1002372Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:52.1003589Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:27:52.1004100Z   )
2026-01-14T09:27:52.1004284Z )
2026-01-14T09:27:52.1004457Z 
2026-01-14T09:27:52.1004461Z 
2026-01-14T09:27:52.1004467Z 
2026-01-14T09:27:52.1004564Z def forward(self, x):
2026-01-14T09:27:52.1004876Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:27:52.1005247Z     conv_weight = self.conv.weight
2026-01-14T09:27:52.1005746Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:27:52.1006271Z     conv_bias = self.conv.bias
2026-01-14T09:27:52.1006638Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:27:52.1007105Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:27:52.1007895Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:27:52.1008807Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:27:52.1009716Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:27:52.1010564Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:27:52.1011091Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:27:52.1011684Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:27:52.1012113Z     
2026-01-14T09:27:52.1012416Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:27:52.1012810Z model fx: GraphModule(
2026-01-14T09:27:52.1013206Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:52.1014303Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:52.1015604Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:27:52.1016174Z   )
2026-01-14T09:27:52.1016364Z   (conv): Conv2d(
2026-01-14T09:27:52.1016614Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T09:27:52.1016981Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:52.1018032Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:27:56.7842905Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2877]), max_val=tensor([-0.2877]))
2026-01-14T09:27:56.7843589Z     )
2026-01-14T09:27:56.7843787Z   )
2026-01-14T09:27:56.7844086Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:56.7845259Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:56.7846926Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:27:56.7847500Z   )
2026-01-14T09:27:56.7847722Z   (relu): ReLU(inplace=True)
2026-01-14T09:27:56.7848091Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:56.7849188Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:56.7850576Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:27:56.7851095Z   )
2026-01-14T09:27:56.7851286Z )
2026-01-14T09:27:56.7851398Z 
2026-01-14T09:27:56.7851402Z 
2026-01-14T09:27:56.7851406Z 
2026-01-14T09:27:56.7851571Z def forward(self, x):
2026-01-14T09:27:56.7851963Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:27:56.7852443Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:27:56.7852928Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:27:56.7853709Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:27:56.7854344Z     relu = self.relu(add);  add = None
2026-01-14T09:27:56.7854801Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:27:56.7855267Z     return activation_post_process_2
2026-01-14T09:27:56.7855546Z     
2026-01-14T09:27:56.7855840Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:27:56.7856237Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:27:56.7856491Z           [0., 0., 0.],
2026-01-14T09:27:56.7856759Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:27:56.7857171Z converted model pt2e: GraphModule(
2026-01-14T09:27:56.7857445Z   (conv): Module()
2026-01-14T09:27:56.7857679Z   (_guards_fn): GuardsFn()
2026-01-14T09:27:56.7857914Z )
2026-01-14T09:27:56.7858018Z 
2026-01-14T09:27:56.7858028Z 
2026-01-14T09:27:56.7858032Z 
2026-01-14T09:27:56.7858122Z def forward(self, x):
2026-01-14T09:27:56.7858429Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:27:56.7858795Z     _scale_0 = self._scale_0
2026-01-14T09:27:56.7859071Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:27:56.7859499Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:27:56.7860644Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:27:56.7861730Z     conv_bias = self.conv.bias
2026-01-14T09:27:56.7862398Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:27:56.7863610Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:27:56.7865084Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:27:56.7866151Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:27:56.7867142Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T09:27:56.7868571Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.003615050343796611, 43, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:27:56.7870028Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:27:56.7871515Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T09:27:56.7872472Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:27:56.7873320Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.003489378374069929, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:27:56.7874878Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:27:56.7876037Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:27:56.7876502Z     
2026-01-14T09:27:56.7876815Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:27:56.7877227Z onverted model fx: GraphModule(
2026-01-14T09:27:56.7877636Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T09:27:56.7878079Z   (relu): ReLU(inplace=True)
2026-01-14T09:27:56.7878329Z )
2026-01-14T09:27:56.7878445Z 
2026-01-14T09:27:56.7878449Z 
2026-01-14T09:27:56.7878453Z 
2026-01-14T09:27:56.7878547Z def forward(self, x):
2026-01-14T09:27:56.7879217Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:27:56.7880582Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:27:56.7881629Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:27:56.7882429Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003615050343796611, 43, -128, 127, torch.int8);  conv = None
2026-01-14T09:27:56.7883947Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:27:56.7886209Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:27:56.7886909Z     relu = self.relu(add);  add = None
2026-01-14T09:27:56.7887683Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003489378374069929, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:27:56.7889123Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:27:56.7890097Z     return dequantize_per_tensor_default_2
2026-01-14T09:27:56.7890389Z     
2026-01-14T09:27:56.7890685Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:27:56.7891079Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:27:56.7891330Z           [0., 0., 0.],
2026-01-14T09:27:56.7891557Z           [0., 0., 0.]]]])
2026-01-14T09:27:56.7891799Z model pt2e: GraphModule(
2026-01-14T09:27:56.7892037Z   (conv): Module()
2026-01-14T09:27:56.7892359Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:56.7893449Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:27:56.7894751Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28767645359039307, max_val=-0.28767645359039307)
2026-01-14T09:27:56.7895321Z   )
2026-01-14T09:27:56.7895618Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:56.7896717Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:56.7898137Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:27:56.7898704Z   )
2026-01-14T09:27:56.7898895Z   (_guards_fn): GuardsFn()
2026-01-14T09:27:56.7899247Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:56.7901510Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:56.7902767Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:27:56.7903329Z   )
2026-01-14T09:27:56.7903620Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:27:56.7904691Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:27:56.7905912Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:27:56.7906442Z   )
2026-01-14T09:27:56.7906618Z )
2026-01-14T09:27:56.7906720Z 
2026-01-14T09:27:56.7906723Z 
2026-01-14T09:27:56.7906731Z 
2026-01-14T09:27:56.7906819Z def forward(self, x):
2026-01-14T09:27:56.7907196Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:27:56.7907557Z     conv_weight = self.conv.weight
2026-01-14T09:27:56.7908052Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:27:56.7908567Z     conv_bias = self.conv.bias
2026-01-14T09:27:56.7908926Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:27:56.7909378Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:29:22.6984784Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:29:22.6985949Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:29:22.6987084Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:29:22.6988091Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:29:22.6988721Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:29:22.6989474Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:29:22.6990006Z     
2026-01-14T09:29:22.6990372Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:29:22.6990871Z model fx: GraphModule(
2026-01-14T09:29:22.6991292Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:29:22.6992629Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:29:22.6994216Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:29:22.6995013Z   )
2026-01-14T09:29:22.6995243Z   (conv): Conv2d(
2026-01-14T09:29:22.6995525Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T09:29:22.6995976Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:29:22.6997280Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:29:22.6999049Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28767645359039307, max_val=-0.28767645359039307)
2026-01-14T09:29:22.6999761Z     )
2026-01-14T09:29:22.6999987Z   )
2026-01-14T09:29:22.7000350Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:29:22.7001779Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:29:22.7003367Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:29:22.7004068Z   )
2026-01-14T09:29:22.7004316Z   (relu): ReLU(inplace=True)
2026-01-14T09:29:22.7004755Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:29:22.7006096Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:29:22.7007613Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:29:22.7008244Z   )
2026-01-14T09:29:22.7008470Z )
2026-01-14T09:29:22.7008597Z 
2026-01-14T09:29:22.7008602Z 
2026-01-14T09:29:22.7008607Z 
2026-01-14T09:29:22.7008723Z def forward(self, x):
2026-01-14T09:29:22.7009180Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:29:22.7009872Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:29:22.7010446Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:29:22.7011457Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:29:22.7012277Z     relu = self.relu(add);  add = None
2026-01-14T09:29:22.7012786Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:29:22.7013263Z     return activation_post_process_2
2026-01-14T09:29:22.7013540Z     
2026-01-14T09:29:22.7013841Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:29:22.7014237Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:29:22.7014495Z           [0., 0., 0.],
2026-01-14T09:29:22.7014759Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:29:22.7015100Z converted model pt2e: GraphModule(
2026-01-14T09:29:22.7015405Z   (conv): Module()
2026-01-14T09:29:22.7015630Z   (_guards_fn): GuardsFn()
2026-01-14T09:29:22.7015873Z )
2026-01-14T09:29:22.7015981Z 
2026-01-14T09:29:22.7015986Z 
2026-01-14T09:29:22.7015990Z 
2026-01-14T09:29:22.7016079Z def forward(self, x):
2026-01-14T09:29:22.7016387Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:29:22.7016793Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:29:22.7017809Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.002265168819576502, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:29:22.7018773Z     conv_bias = self.conv.bias
2026-01-14T09:29:22.7019432Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:29:22.7020648Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:29:22.7022111Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:29:22.7023164Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:29:22.7024158Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T09:29:22.7025610Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.003615050343796611, 43, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:29:22.7027111Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:29:22.7028605Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T09:29:22.7029481Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:29:22.7030313Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.003489378374069929, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:29:22.7031746Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:29:22.7032853Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:29:22.7033295Z     
2026-01-14T09:29:22.7033594Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:29:22.7034050Z onverted model fx: GraphModule(
2026-01-14T09:29:22.7034459Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T09:29:22.7034947Z   (relu): ReLU(inplace=True)
2026-01-14T09:29:22.7035200Z )
2026-01-14T09:29:22.7035307Z 
2026-01-14T09:29:22.7035312Z 
2026-01-14T09:29:22.7035316Z 
2026-01-14T09:29:22.7035404Z def forward(self, x):
2026-01-14T09:29:22.7036115Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:29:22.7037473Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:29:22.7038463Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:29:22.7039256Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003615050343796611, 43, -128, 127, torch.int8);  conv = None
2026-01-14T09:29:22.7040663Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:29:22.7042009Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:29:22.7042728Z     relu = self.relu(add);  add = None
2026-01-14T09:29:22.7043491Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003489378374069929, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:29:22.7044941Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:29:22.7045942Z     return dequantize_per_tensor_default_2
2026-01-14T09:29:22.7046245Z     
2026-01-14T09:29:22.7046548Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:29:22.7046940Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:29:22.7047200Z           [0., 0., 0.],
2026-01-14T09:29:22.7047423Z           [0., 0., 0.]]]])
2026-01-14T09:29:22.7047904Z [32mPASSED[0m
2026-01-14T09:29:22.7048708Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T09:29:22.7049848Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T09:29:22.7050901Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec [32mPASSED[0m
2026-01-14T09:29:22.7051905Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T09:29:22.7052568Z   (conv): Module()
2026-01-14T09:29:22.7052784Z   (bn): Module()
2026-01-14T09:29:22.7053133Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:06.0539315Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:06.0540981Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:30:06.0541676Z   )
2026-01-14T09:30:06.0541925Z   (_guards_fn): GuardsFn()
2026-01-14T09:30:06.0542350Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:06.0543789Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:30:06.0545967Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1872, -0.1882, -0.1827]), max_val=tensor([0.1805, 0.1400, 0.1829]))
2026-01-14T09:30:06.0546859Z   )
2026-01-14T09:30:06.0547216Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:06.0548638Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:06.0550216Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:30:06.0550912Z   )
2026-01-14T09:30:06.0551260Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:06.0552588Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:06.0554146Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:30:06.0554931Z   )
2026-01-14T09:30:06.0555162Z )
2026-01-14T09:30:06.0555287Z 
2026-01-14T09:30:06.0555292Z 
2026-01-14T09:30:06.0555300Z 
2026-01-14T09:30:06.0555410Z def forward(self, x):
2026-01-14T09:30:06.0555792Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:30:06.0556237Z     conv_weight = self.conv.weight
2026-01-14T09:30:06.0556595Z     conv_bias = self.conv.bias
2026-01-14T09:30:06.0556919Z     bn_weight = self.bn.weight
2026-01-14T09:30:06.0557273Z     bn_bias = self.bn.bias
2026-01-14T09:30:06.0557668Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:30:06.0558152Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:30:06.0558550Z     bn_running_var = self.bn.running_var
2026-01-14T09:30:06.0559031Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:30:06.0559593Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:30:06.0560296Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:30:06.0561013Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:30:06.0561637Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:30:06.0562178Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:30:06.0562769Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:30:06.0563434Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:30:06.0564199Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:30:06.0565129Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:30:06.0566493Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:30:06.0567732Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:30:06.0568458Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:30:06.0569261Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:30:06.0570021Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:30:06.0571276Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:30:06.0572676Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:30:06.0573688Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:30:06.0574673Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:30:06.0575451Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:30:06.0575969Z     
2026-01-14T09:30:06.0576390Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:30:06.0576875Z model fx: GraphModule(
2026-01-14T09:30:06.0577295Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:06.0578626Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:06.0580196Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:30:06.0580894Z   )
2026-01-14T09:30:06.0581121Z   (conv): ConvBn2d(
2026-01-14T09:30:06.0581415Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:30:06.0581956Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:30:06.0582598Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:06.0583990Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:30:06.0586088Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1872, -0.1882, -0.1827]), max_val=tensor([0.1805, 0.1400, 0.1829]))
2026-01-14T09:30:06.0586990Z     )
2026-01-14T09:30:06.0587209Z   )
2026-01-14T09:30:06.0587570Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:06.0588896Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:06.0590466Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:30:06.0591266Z   )
2026-01-14T09:30:06.0591580Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:30:06.0592126Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:06.0593350Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:06.0594616Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:30:06.0595232Z   )
2026-01-14T09:30:06.0595413Z )
2026-01-14T09:30:06.0595516Z 
2026-01-14T09:30:06.0595521Z 
2026-01-14T09:30:06.0595525Z 
2026-01-14T09:30:06.0595622Z def forward(self, x):
2026-01-14T09:30:06.0595993Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:30:06.0596573Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:30:06.0597179Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:30:06.0597866Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:30:06.0598529Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:30:06.0599034Z     return activation_post_process_2
2026-01-14T09:30:06.0599315Z     
2026-01-14T09:30:06.0599712Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:30:06.0600105Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:30:06.0600362Z           [0., 0., 0.],
2026-01-14T09:30:06.0600586Z           [0., 0., 0.]],
2026-01-14T09:30:06.0600744Z 
2026-01-14T09:30:06.0600824Z          [[0., 0., 0.],
2026-01-14T09:30:06.0601049Z           [0., 0., 0.],
2026-01-14T09:30:06.0601270Z           [0., 0., 0.]],
2026-01-14T09:30:06.0601417Z 
2026-01-14T09:30:06.0601506Z          [[0., 0., 0.],
2026-01-14T09:30:06.0601726Z           [0., 0., 0.],
2026-01-14T09:30:06.0602059Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:30:06.0602393Z converted model pt2e: GraphModule(
2026-01-14T09:30:06.0602674Z   (conv): Module()
2026-01-14T09:30:06.0602883Z   (bn): Module()
2026-01-14T09:30:06.0603112Z   (_guards_fn): GuardsFn()
2026-01-14T09:30:06.0603351Z )
2026-01-14T09:30:06.0603455Z 
2026-01-14T09:30:06.0603459Z 
2026-01-14T09:30:06.0603463Z 
2026-01-14T09:30:06.0603556Z def forward(self, x):
2026-01-14T09:30:06.0603876Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:30:06.0604243Z     conv_bias = self.conv.bias
2026-01-14T09:30:06.0604912Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:30:06.0606252Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:30:06.0607244Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:30:06.0607601Z     _scale_0 = self._scale_0
2026-01-14T09:30:06.0607873Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:30:06.0608205Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:30:06.0609201Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:30:06.0610726Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:30:06.0612085Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.014923675917088985, -46, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:30:13.6930344Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:30:13.6932061Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T09:30:13.6933663Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014923675917088985, -46, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:30:13.6935519Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:30:13.6936921Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:30:13.6937478Z     
2026-01-14T09:30:13.6937837Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:30:13.6938336Z onverted model fx: GraphModule(
2026-01-14T09:30:13.6938831Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:30:13.6939403Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:30:13.6939783Z )
2026-01-14T09:30:13.6939907Z 
2026-01-14T09:30:13.6939912Z 
2026-01-14T09:30:13.6939916Z 
2026-01-14T09:30:13.6940032Z def forward(self, x):
2026-01-14T09:30:13.6940970Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:30:13.6942696Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:30:13.6944113Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:30:13.6945373Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014923675917088985, -46, -128, 127, torch.int8);  conv = None
2026-01-14T09:30:13.6947171Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:30:13.6948666Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:30:13.6949966Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014923675917088985, -46, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:30:13.6951767Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:30:13.6952769Z     return dequantize_per_tensor_default_2
2026-01-14T09:30:13.6953063Z     
2026-01-14T09:30:13.6953363Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:30:13.6953759Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:30:13.6954008Z           [0., 0., 0.],
2026-01-14T09:30:13.6954234Z           [0., 0., 0.]],
2026-01-14T09:30:13.6954381Z 
2026-01-14T09:30:13.6954463Z          [[0., 0., 0.],
2026-01-14T09:30:13.6954688Z           [0., 0., 0.],
2026-01-14T09:30:13.6954971Z           [0., 0., 0.]],
2026-01-14T09:30:13.6955124Z 
2026-01-14T09:30:13.6955202Z          [[0., 0., 0.],
2026-01-14T09:30:13.6955415Z           [0., 0., 0.],
2026-01-14T09:30:13.6955639Z           [0., 0., 0.]]]])
2026-01-14T09:30:13.6955893Z model pt2e: GraphModule(
2026-01-14T09:30:13.6956131Z   (conv): Module()
2026-01-14T09:30:13.6956348Z   (bn): Module()
2026-01-14T09:30:13.6956666Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:13.6957882Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:13.6959150Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:30:13.6959711Z   )
2026-01-14T09:30:13.6959959Z   (_guards_fn): GuardsFn()
2026-01-14T09:30:13.6960314Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:13.6961398Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:30:13.6962672Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18815943598747253, max_val=0.1829397827386856)
2026-01-14T09:30:13.6963248Z   )
2026-01-14T09:30:13.6963557Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:13.6964612Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:13.6965875Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:30:13.6966478Z   )
2026-01-14T09:30:13.6966781Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:13.6967837Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:13.6969087Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:30:13.6969646Z   )
2026-01-14T09:30:13.6969891Z )
2026-01-14T09:30:13.6970016Z 
2026-01-14T09:30:13.6970021Z 
2026-01-14T09:30:13.6970026Z 
2026-01-14T09:30:13.6970125Z def forward(self, x):
2026-01-14T09:30:13.6970433Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:30:13.6970803Z     conv_weight = self.conv.weight
2026-01-14T09:30:13.6971100Z     conv_bias = self.conv.bias
2026-01-14T09:30:13.6971371Z     bn_weight = self.bn.weight
2026-01-14T09:30:13.6971640Z     bn_bias = self.bn.bias
2026-01-14T09:30:13.6971952Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:30:13.6972323Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:30:13.6972640Z     bn_running_var = self.bn.running_var
2026-01-14T09:30:13.6973042Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:30:13.6973491Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:30:13.6974068Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:30:13.6974666Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:30:13.6975086Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:30:13.6975538Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:30:13.6976017Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:30:13.6976577Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:30:13.6977206Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:30:13.6977878Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:30:13.6978987Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:30:13.6980036Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:30:13.6980641Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:30:13.6981287Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:30:13.6981905Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:30:13.6982970Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, False);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:30:13.6984062Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:30:13.6985071Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:30:13.6985866Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:30:13.6986489Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:30:13.6986905Z     
2026-01-14T09:30:13.6987206Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:30:13.6987597Z model fx: GraphModule(
2026-01-14T09:30:13.6987938Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:13.6989006Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:30:13.6990350Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:30:13.6990897Z   )
2026-01-14T09:30:13.6991092Z   (conv): ConvBn2d(
2026-01-14T09:30:13.6991332Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:30:13.6991853Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:30:13.6992373Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:13.6993436Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:30:13.6994730Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18815943598747253, max_val=0.1829397827386856)
2026-01-14T09:30:13.6995342Z     )
2026-01-14T09:30:13.6995529Z   )
2026-01-14T09:30:13.6995823Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:30:13.6996902Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:31:36.5969125Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:31:36.5969749Z   )
2026-01-14T09:31:36.5970001Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:31:36.5970438Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:31:36.5971557Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:31:36.5972872Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:31:36.5973439Z   )
2026-01-14T09:31:36.5973632Z )
2026-01-14T09:31:36.5973741Z 
2026-01-14T09:31:36.5973745Z 
2026-01-14T09:31:36.5973749Z 
2026-01-14T09:31:36.5973854Z def forward(self, x):
2026-01-14T09:31:36.5974232Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:31:36.5975093Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:31:36.5975704Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:31:36.5976359Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:31:36.5977155Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:31:36.5977680Z     return activation_post_process_2
2026-01-14T09:31:36.5977973Z     
2026-01-14T09:31:36.5978278Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:31:36.5978689Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:31:36.5978954Z           [0., 0., 0.],
2026-01-14T09:31:36.5979190Z           [0., 0., 0.]],
2026-01-14T09:31:36.5979345Z 
2026-01-14T09:31:36.5979429Z          [[0., 0., 0.],
2026-01-14T09:31:36.5979662Z           [0., 0., 0.],
2026-01-14T09:31:36.5979894Z           [0., 0., 0.]],
2026-01-14T09:31:36.5980050Z 
2026-01-14T09:31:36.5980137Z          [[0., 0., 0.],
2026-01-14T09:31:36.5980354Z           [0., 0., 0.],
2026-01-14T09:31:36.5980613Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:31:36.5980948Z converted model pt2e: GraphModule(
2026-01-14T09:31:36.5981223Z   (conv): Module()
2026-01-14T09:31:36.5981440Z   (bn): Module()
2026-01-14T09:31:36.5981659Z   (_guards_fn): GuardsFn()
2026-01-14T09:31:36.5981898Z )
2026-01-14T09:31:36.5982104Z 
2026-01-14T09:31:36.5982109Z 
2026-01-14T09:31:36.5982113Z 
2026-01-14T09:31:36.5982202Z def forward(self, x):
2026-01-14T09:31:36.5982513Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:31:36.5982877Z     conv_bias = self.conv.bias
2026-01-14T09:31:36.5983542Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:31:36.5985172Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:31:36.5986210Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:31:36.5986601Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:31:36.5996109Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014815704198554158, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:31:36.5997579Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:31:36.5998943Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.014958353713154793, -45, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:31:36.6000415Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:31:36.6001721Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T09:31:36.6002863Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014958353713154793, -45, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:31:36.6004301Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:31:36.6005422Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:31:36.6005871Z     
2026-01-14T09:31:36.6006172Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:31:36.6006730Z onverted model fx: GraphModule(
2026-01-14T09:31:36.6007138Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:31:36.6007607Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:31:36.6007924Z )
2026-01-14T09:31:36.6008030Z 
2026-01-14T09:31:36.6008034Z 
2026-01-14T09:31:36.6008038Z 
2026-01-14T09:31:36.6008128Z def forward(self, x):
2026-01-14T09:31:36.6008877Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:31:36.6010261Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:31:36.6011400Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:31:36.6012368Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014958353713154793, -45, -128, 127, torch.int8);  conv = None
2026-01-14T09:31:36.6013786Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:31:36.6014972Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:31:36.6016079Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014958353713154793, -45, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:31:36.6017529Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:31:36.6018506Z     return dequantize_per_tensor_default_2
2026-01-14T09:31:36.6018839Z     
2026-01-14T09:31:36.6019148Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:31:36.6019553Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:31:36.6019804Z           [0., 0., 0.],
2026-01-14T09:31:36.6020028Z           [0., 0., 0.]],
2026-01-14T09:31:36.6020178Z 
2026-01-14T09:31:36.6020258Z          [[0., 0., 0.],
2026-01-14T09:31:36.6020481Z           [0., 0., 0.],
2026-01-14T09:31:36.6020699Z           [0., 0., 0.]],
2026-01-14T09:31:36.6020863Z 
2026-01-14T09:31:36.6020945Z          [[0., 0., 0.],
2026-01-14T09:31:36.6021160Z           [0., 0., 0.],
2026-01-14T09:31:36.6021388Z           [0., 0., 0.]]]])
2026-01-14T09:31:36.6021851Z [32mPASSED[0m
2026-01-14T09:31:36.6022500Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_mobilenet_v2 [33mSKIPPED[0m
2026-01-14T09:31:36.6023482Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_resnet18 [33mSKIPPED[0m
2026-01-14T09:31:36.6024439Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizeMixQATAndPTQ::test_mixing_qat_ptq [33mSKIPPED[0m
2026-01-14T09:31:36.6025337Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add [32mPASSED[0m
2026-01-14T09:31:36.6026181Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add_relu [32mPASSED[0m
2026-01-14T09:31:36.6027040Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_conv2d [32mPASSED[0m
2026-01-14T09:31:36.6027941Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_dynamic_linear [32mPASSED[0m
2026-01-14T09:31:36.6028843Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_maxpool2d [32mPASSED[0m
2026-01-14T09:31:36.6029711Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq [32mPASSED[0m
2026-01-14T09:31:36.6030594Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq_per_channel [32mPASSED[0m
2026-01-14T09:31:36.6031591Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_static_linear [32mPASSED[0m
2026-01-14T09:31:36.6033013Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:36.6034952Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:36.6036773Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:36.6038577Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:36.6040382Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:36.6042204Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:36.6044073Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5828798Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5831239Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5833576Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5836027Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5838385Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5840701Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5843024Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5845349Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5847658Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5850085Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5852478Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5854779Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5857088Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5859402Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5861718Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5864134Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5866485Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5868839Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5871164Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5873477Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5875844Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5878158Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5880480Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5882789Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:39.5885321Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:39.5887634Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:39.5889035Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:31:39.5889561Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:39.5891143Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:31:39.5892544Z graph_break []
2026-01-14T09:31:39.5892854Z [32mPASSED[0m
2026-01-14T09:31:39.5894095Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:39.5895466Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:39.5895993Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:39.5897218Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:39.5898455Z graph_break []
2026-01-14T09:31:39.5898771Z [32mPASSED[0m
2026-01-14T09:31:39.5899985Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:39.5901357Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:39.5901874Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:39.5903804Z inductor [('pattern_matcher_nodes', 7), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_binary_matcher_nodes', 2), ('qlinear_weight_prepack_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:31:39.5905533Z graph_break []
2026-01-14T09:31:39.5905829Z [32mPASSED[0m
2026-01-14T09:31:39.5907057Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:39.5908420Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:39.5908932Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:39.5910162Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:39.5911262Z graph_break []
2026-01-14T09:31:39.5911554Z [32mPASSED[0m
2026-01-14T09:31:48.8169448Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8170956Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:31:48.8171530Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8172771Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8173883Z graph_break []
2026-01-14T09:31:48.8174611Z [32mPASSED[0m
2026-01-14T09:31:48.8175854Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8177242Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:48.8177758Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8179098Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8180220Z graph_break []
2026-01-14T09:31:48.8180517Z [32mPASSED[0m
2026-01-14T09:31:48.8181752Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8183143Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:31:48.8183658Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8185152Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8186268Z graph_break []
2026-01-14T09:31:48.8186575Z [32mPASSED[0m
2026-01-14T09:31:48.8187907Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8189290Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:48.8189812Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8191135Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8192255Z graph_break []
2026-01-14T09:31:48.8192546Z [32mPASSED[0m
2026-01-14T09:31:48.8193783Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8195262Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:48.8195779Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8197298Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8198699Z graph_break []
2026-01-14T09:31:48.8199007Z [32mPASSED[0m
2026-01-14T09:31:48.8200237Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8201599Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:31:48.8202123Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8203357Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8204480Z graph_break []
2026-01-14T09:31:48.8204778Z [32mPASSED[0m
2026-01-14T09:31:48.8205995Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8207443Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:31:48.8207956Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8209868Z inductor [('pattern_matcher_nodes', 8), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_nodes', 4), ('qlinear_binary_matcher_nodes', 2), ('qlinear_weight_prepack_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8211663Z graph_break []
2026-01-14T09:31:48.8211954Z [32mPASSED[0m
2026-01-14T09:31:48.8213168Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8214533Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:31:48.8215047Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8216272Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8217376Z graph_break []
2026-01-14T09:31:48.8217678Z [32mPASSED[0m
2026-01-14T09:31:48.8218957Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8220328Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:48.8220855Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8222123Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8223243Z graph_break []
2026-01-14T09:31:48.8223539Z [32mPASSED[0m
2026-01-14T09:31:48.8224762Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8226137Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:31:48.8226657Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8227877Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8228988Z graph_break []
2026-01-14T09:31:48.8229287Z [32mPASSED[0m
2026-01-14T09:31:48.8230508Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8231879Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:48.8232398Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8233631Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8234735Z graph_break []
2026-01-14T09:31:48.8235094Z [32mPASSED[0m
2026-01-14T09:31:48.8236311Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8237728Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:31:48.8238250Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8239472Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8240623Z graph_break []
2026-01-14T09:31:48.8240940Z [32mPASSED[0m
2026-01-14T09:31:48.8242197Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:48.8243589Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:31:48.8244098Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:48.8245630Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:31:48.8247024Z graph_break []
2026-01-14T09:31:48.8247317Z [32mPASSED[0m
2026-01-14T09:31:58.6760137Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6761813Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:31:58.6762344Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6763585Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6764705Z graph_break []
2026-01-14T09:31:58.6765306Z [32mPASSED[0m
2026-01-14T09:31:58.6766540Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6767914Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:31:58.6768439Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6769953Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6771345Z graph_break []
2026-01-14T09:31:58.6771640Z [32mPASSED[0m
2026-01-14T09:31:58.6772854Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6774246Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:31:58.6774776Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6776002Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6777101Z graph_break []
2026-01-14T09:31:58.6777393Z [32mPASSED[0m
2026-01-14T09:31:58.6778618Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6779980Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:31:58.6780606Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6781832Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6782942Z graph_break []
2026-01-14T09:31:58.6783238Z [32mPASSED[0m
2026-01-14T09:31:58.6784767Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6786145Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:31:58.6786657Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6787884Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6788996Z graph_break []
2026-01-14T09:31:58.6789292Z [32mPASSED[0m
2026-01-14T09:31:58.6790508Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6791863Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:31:58.6792454Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6793681Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6794778Z graph_break []
2026-01-14T09:31:58.6795176Z [32mPASSED[0m
2026-01-14T09:31:58.6798458Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6799849Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:31:58.6800361Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6801588Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6802696Z graph_break []
2026-01-14T09:31:58.6802989Z [32mPASSED[0m
2026-01-14T09:31:58.6804207Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6805563Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:58.6806080Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6807601Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6808996Z graph_break []
2026-01-14T09:31:58.6809290Z [32mPASSED[0m
2026-01-14T09:31:58.6810491Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6811840Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:31:58.6812357Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6813663Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6814775Z graph_break []
2026-01-14T09:31:58.6815062Z [32mPASSED[0m
2026-01-14T09:31:58.6816324Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6817684Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:58.6818196Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6819705Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6821096Z graph_break []
2026-01-14T09:31:58.6821390Z [32mPASSED[0m
2026-01-14T09:31:58.6822594Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6823933Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:31:58.6824456Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6825727Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6826831Z graph_break []
2026-01-14T09:31:58.6827127Z [32mPASSED[0m
2026-01-14T09:31:58.6828377Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6829747Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:58.6830255Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6831477Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6832586Z graph_break []
2026-01-14T09:31:58.6832873Z [32mPASSED[0m
2026-01-14T09:31:58.6834083Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:58.6835516Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:31:58.6836033Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:58.6837260Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:58.6838360Z graph_break []
2026-01-14T09:31:58.6838655Z [32mPASSED[0m
2026-01-14T09:31:59.7249279Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:59.7250436Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:31:59.7250882Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:59.7251868Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:59.7252972Z graph_break []
2026-01-14T09:31:59.7253429Z [32mPASSED[0m
2026-01-14T09:31:59.7254395Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:31:59.7255502Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:31:59.7256032Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:31:59.7257028Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:31:59.7257906Z graph_break []
2026-01-14T09:31:59.7258156Z [32mPASSED[0m
2026-01-14T09:31:59.7259238Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7261177Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7263521Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7265979Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7268419Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7270747Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7273060Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7275457Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7277767Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7280064Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7282348Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7284853Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7287167Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7289569Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7291915Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7294218Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7296568Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7298857Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7301147Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7303501Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7305784Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7308154Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7310469Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7312763Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7315139Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7317423Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7319679Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7321941Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7324212Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:31:59.7326603Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:31:59.7328461Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:32:11.0300384Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:32:11.0302678Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0304079Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:32:11.0304621Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0306142Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0307526Z graph_break []
2026-01-14T09:32:11.0307837Z [32mPASSED[0m
2026-01-14T09:32:11.0309183Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0310534Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:11.0311058Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0312381Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0313490Z graph_break []
2026-01-14T09:32:11.0313785Z [32mPASSED[0m
2026-01-14T09:32:11.0315105Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0316472Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:32:11.0316989Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0318563Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0319958Z graph_break []
2026-01-14T09:32:11.0320249Z [32mPASSED[0m
2026-01-14T09:32:11.0321463Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0322810Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:11.0323334Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0324575Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0325673Z graph_break []
2026-01-14T09:32:11.0325971Z [32mPASSED[0m
2026-01-14T09:32:11.0327191Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0328681Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:32:11.0329194Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0330470Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0331587Z graph_break []
2026-01-14T09:32:11.0331877Z [32mPASSED[0m
2026-01-14T09:32:11.0333101Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0334461Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:11.0334980Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0336211Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0337313Z graph_break []
2026-01-14T09:32:11.0337604Z [32mPASSED[0m
2026-01-14T09:32:11.0338819Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0340254Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:32:11.0340776Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0341998Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0343116Z graph_break []
2026-01-14T09:32:11.0343451Z [32mPASSED[0m
2026-01-14T09:32:11.0344674Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0346037Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:11.0346547Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0347777Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0348901Z graph_break []
2026-01-14T09:32:11.0349195Z [32mPASSED[0m
2026-01-14T09:32:11.0350408Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0351776Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:11.0352286Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0365168Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0366583Z graph_break []
2026-01-14T09:32:11.0366905Z [32mPASSED[0m
2026-01-14T09:32:11.0368133Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0369491Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:32:11.0370106Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0371330Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0372443Z graph_break []
2026-01-14T09:32:11.0372741Z [32mPASSED[0m
2026-01-14T09:32:11.0374004Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0375370Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:11.0375886Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0377402Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0378799Z graph_break []
2026-01-14T09:32:11.0379090Z [32mPASSED[0m
2026-01-14T09:32:11.0380306Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0381707Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:32:11.0382227Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:11.0383452Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:11.0384788Z graph_break []
2026-01-14T09:32:11.0385092Z [32mPASSED[0m
2026-01-14T09:32:11.0386407Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:11.0387783Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:11.0388302Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9784793Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9786000Z graph_break []
2026-01-14T09:32:22.9786526Z [32mPASSED[0m
2026-01-14T09:32:22.9787785Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9789195Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:32:22.9789736Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9790970Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9792077Z graph_break []
2026-01-14T09:32:22.9792377Z [32mPASSED[0m
2026-01-14T09:32:22.9793608Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9795082Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:22.9795601Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9796839Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9798149Z graph_break []
2026-01-14T09:32:22.9798455Z [32mPASSED[0m
2026-01-14T09:32:22.9799771Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9801132Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:32:22.9801656Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9802880Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9803987Z graph_break []
2026-01-14T09:32:22.9804287Z [32mPASSED[0m
2026-01-14T09:32:22.9805502Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9806863Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:32:22.9807376Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9808889Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9810392Z graph_break []
2026-01-14T09:32:22.9810684Z [32mPASSED[0m
2026-01-14T09:32:22.9812019Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9813381Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:32:22.9813892Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9815123Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9816227Z graph_break []
2026-01-14T09:32:22.9816527Z [32mPASSED[0m
2026-01-14T09:32:22.9817733Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9819087Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:32:22.9819606Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9821123Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9822574Z graph_break []
2026-01-14T09:32:22.9822863Z [32mPASSED[0m
2026-01-14T09:32:22.9824073Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9825425Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:32:22.9825939Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9827170Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9828341Z graph_break []
2026-01-14T09:32:22.9828629Z [32mPASSED[0m
2026-01-14T09:32:22.9829855Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9831268Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:32:22.9831798Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9833021Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9834130Z graph_break []
2026-01-14T09:32:22.9834434Z [32mPASSED[0m
2026-01-14T09:32:22.9835731Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9837096Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:32:22.9837610Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9838842Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9840008Z graph_break []
2026-01-14T09:32:22.9840300Z [32mPASSED[0m
2026-01-14T09:32:22.9841515Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9842871Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:32:22.9843444Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9844674Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9845777Z graph_break []
2026-01-14T09:32:22.9846078Z [32mPASSED[0m
2026-01-14T09:32:22.9847288Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9848644Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:32:22.9849179Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9850406Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9851517Z graph_break []
2026-01-14T09:32:22.9851808Z [32mPASSED[0m
2026-01-14T09:32:22.9853075Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9854435Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:22.9854950Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:22.9856463Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:32:22.9857849Z graph_break []
2026-01-14T09:32:22.9858219Z [32mPASSED[0m
2026-01-14T09:32:22.9859434Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:22.9860783Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:32:22.9861300Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8363076Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:46.8364010Z graph_break []
2026-01-14T09:32:46.8364461Z [32mPASSED[0m
2026-01-14T09:32:46.8365619Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8366766Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:46.8367206Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8368399Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:32:46.8369612Z graph_break []
2026-01-14T09:32:46.8369872Z [32mPASSED[0m
2026-01-14T09:32:46.8370813Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8371895Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:32:46.8372334Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8373417Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:46.8374306Z graph_break []
2026-01-14T09:32:46.8374551Z [32mPASSED[0m
2026-01-14T09:32:46.8375509Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8376580Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:46.8377006Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8377993Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:46.8378870Z graph_break []
2026-01-14T09:32:46.8379126Z [32mPASSED[0m
2026-01-14T09:32:46.8380070Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8381134Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:32:46.8381573Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8382556Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:46.8383442Z graph_break []
2026-01-14T09:32:46.8383681Z [32mPASSED[0m
2026-01-14T09:32:46.8385173Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8386414Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:32:46.8386838Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8387895Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:46.8388781Z graph_break []
2026-01-14T09:32:46.8389048Z [32mPASSED[0m
2026-01-14T09:32:46.8389994Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8391047Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:32:46.8391475Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8392451Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:32:46.8393335Z graph_break []
2026-01-14T09:32:46.8393587Z [32mPASSED[0m
2026-01-14T09:32:46.8394102Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_cpu unimplemented []
2026-01-14T09:32:46.8394823Z stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:32:46.8395254Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8395623Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8396830Z inductor [('pattern_matcher_nodes', 10), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:32:46.8397949Z graph_break []
2026-01-14T09:32:46.8398264Z [32mPASSED[0m
2026-01-14T09:32:46.8398840Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_input_dim_exceeds_2 unimplemented []
2026-01-14T09:32:46.8399576Z stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:32:46.8399953Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8400316Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8401554Z inductor [('pattern_matcher_nodes', 18), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:32:46.8402672Z graph_break []
2026-01-14T09:32:46.8402911Z [32mPASSED[0m
2026-01-14T09:32:46.8403445Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_qat_cpu unimplemented []
2026-01-14T09:32:46.8404106Z stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:32:46.8404450Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8404811Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8406025Z inductor [('pattern_matcher_nodes', 10), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:32:46.8407143Z graph_break []
2026-01-14T09:32:46.8407382Z [32mPASSED[0m
2026-01-14T09:32:46.8408143Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T09:32:46.8409346Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T09:32:46.8410600Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T09:32:46.8411797Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T09:32:46.8412856Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8413550Z stats [('calls_captured', 32), ('unique_graphs', 2)]
2026-01-14T09:32:46.8413984Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:32:46.8415550Z inductor [('pattern_matcher_nodes', 24), ('qlinear_weight_prepack_matcher_nodes', 16), ('pattern_matcher_count', 10), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_matcher_nodes', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('extern_calls', 4), ('qlinear_unary_matcher_count', 2), ('fxgraph_cache_miss', 1), ('fxgraph_cache_hit', 1)]
2026-01-14T09:32:46.8416992Z graph_break []
2026-01-14T09:32:46.8417239Z [32mPASSED[0m
2026-01-14T09:32:46.8417872Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8418612Z stats [('calls_captured', 25), ('unique_graphs', 1)]
2026-01-14T09:32:46.8419044Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:32:46.8421308Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_miss', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:32:46.8423492Z graph_break []
2026-01-14T09:32:46.8423735Z [32mPASSED[0m
2026-01-14T09:32:46.8424452Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 frames [('total', 1), ('ok', 1)]
2026-01-14T09:32:46.8425279Z stats [('calls_captured', 25), ('unique_graphs', 1)]
2026-01-14T09:32:46.8425728Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:35:48.3672832Z inductor [('pattern_matcher_nodes', 33), ('qlinear_weight_prepack_matcher_nodes', 18), ('pattern_matcher_count', 15), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('dequant_promotion_matcher_nodes', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_miss', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:35:48.3676361Z graph_break []
2026-01-14T09:35:48.3677136Z [32mPASSED[0m
2026-01-14T09:35:48.3677936Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:35:48.3679547Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:35:48.3680793Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3681493Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:35:48.3681926Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:35:48.3683413Z inductor [('pattern_matcher_nodes', 31), ('qlinear_unary_matcher_nodes', 21), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:35:48.3685299Z graph_break []
2026-01-14T09:35:48.3685576Z [32mPASSED[0m
2026-01-14T09:35:48.3686239Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:35:48.3687499Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2 frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3688340Z stats [('calls_captured', 32), ('unique_graphs', 2)]
2026-01-14T09:35:48.3688783Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:35:48.3690386Z inductor [('pattern_matcher_nodes', 40), ('qlinear_weight_prepack_matcher_nodes', 24), ('pattern_matcher_count', 18), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_matcher_nodes', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('extern_calls', 4), ('qlinear_unary_matcher_count', 2), ('fxgraph_cache_miss', 1), ('fxgraph_cache_hit', 1)]
2026-01-14T09:35:48.3692001Z graph_break []
2026-01-14T09:35:48.3692259Z [32mPASSED[0m
2026-01-14T09:35:48.3692963Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2_and_not_contiguous frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3693781Z stats [('calls_captured', 36), ('unique_graphs', 2)]
2026-01-14T09:35:48.3694369Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:35:48.3695906Z inductor [('pattern_matcher_nodes', 40), ('qlinear_weight_prepack_matcher_nodes', 24), ('pattern_matcher_count', 18), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_matcher_nodes', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('extern_calls', 4), ('qlinear_unary_matcher_count', 2), ('fxgraph_cache_miss', 1), ('fxgraph_cache_hit', 1)]
2026-01-14T09:35:48.3697447Z graph_break []
2026-01-14T09:35:48.3697692Z [32mPASSED[0m
2026-01-14T09:35:48.3698321Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:35:48.3699394Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:35:48.3700615Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:35:48.3701706Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mul_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3702393Z stats [('calls_captured', 9), ('unique_graphs', 1)]
2026-01-14T09:35:48.3702823Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:35:48.3704002Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_miss', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:35:48.3705106Z graph_break []
2026-01-14T09:35:48.3705351Z [32mPASSED[0m
2026-01-14T09:35:48.3705927Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3706621Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:35:48.3707043Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:35:48.3708492Z inductor [('pattern_matcher_nodes', 15), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:35:48.3709916Z graph_break []
2026-01-14T09:35:48.3710156Z [32mPASSED[0m
2026-01-14T09:35:48.3710800Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_input_dim_exceeds_2 frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3711540Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:35:48.3711975Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:35:48.3715595Z inductor [('pattern_matcher_nodes', 23), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 10), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:35:48.3716952Z graph_break []
2026-01-14T09:35:48.3717204Z [32mPASSED[0m
2026-01-14T09:35:48.3717854Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:35:48.3718969Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:35:48.3719950Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_dynamic_fp16 unimplemented []
2026-01-14T09:35:48.3720581Z stats [('calls_captured', 20), ('unique_graphs', 16)]
2026-01-14T09:35:48.3720933Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3721354Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:35:48.3722328Z inductor [('pattern_matcher_nodes', 15), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 5), ('extern_calls', 4), ('qlinear_weight_prepack_matcher_count', 2), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:35:48.3723210Z graph_break []
2026-01-14T09:35:48.3723463Z [32mPASSED[0m
2026-01-14T09:35:48.3724046Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_relu_dynamic_fp16 unimplemented []
2026-01-14T09:35:48.3724701Z stats [('calls_captured', 24), ('unique_graphs', 16)]
2026-01-14T09:35:48.3725050Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3725408Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:35:48.3726412Z inductor [('pattern_matcher_nodes', 17), ('qlinear_weight_prepack_matcher_nodes', 14), ('pattern_matcher_count', 5), ('extern_calls', 4), ('qlinear_weight_prepack_matcher_count', 2), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:35:48.3727294Z graph_break []
2026-01-14T09:35:48.3727542Z [32mPASSED[0m
2026-01-14T09:35:48.3728019Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d unimplemented []
2026-01-14T09:35:48.3728629Z stats [('calls_captured', 1959), ('unique_graphs', 224)]
2026-01-14T09:35:48.3728983Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3729344Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:35:48.3730729Z inductor [('pattern_matcher_nodes', 7), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qconv_unary_matcher_nodes', 2), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:35:48.3732000Z graph_break []
2026-01-14T09:35:48.3732237Z [32mPASSED[0m
2026-01-14T09:35:48.3732737Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add unimplemented []
2026-01-14T09:35:48.3733358Z stats [('calls_captured', 1969), ('unique_graphs', 224)]
2026-01-14T09:35:48.3733710Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:35:48.3734070Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:35:48.3736203Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 7), ('qconv2d_binary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_nodes', 2), ('extern_calls', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv2d_binary_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1)]
2026-01-14T09:35:48.3738320Z graph_break []
2026-01-14T09:35:48.3738606Z [32mPASSED[0m
2026-01-14T09:35:48.3739121Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add_relu unimplemented []
2026-01-14T09:40:10.6373015Z stats [('calls_captured', 1971), ('unique_graphs', 224)]
2026-01-14T09:40:10.6375430Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6375938Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6378728Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 7), ('qconv2d_binary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_nodes', 2), ('extern_calls', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv2d_binary_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1)]
2026-01-14T09:40:10.6381408Z graph_break []
2026-01-14T09:40:10.6382133Z [32mPASSED[0m
2026-01-14T09:40:10.6382819Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardswish unimplemented []
2026-01-14T09:40:10.6383645Z stats [('calls_captured', 1970), ('unique_graphs', 224)]
2026-01-14T09:40:10.6384481Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6384942Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6386853Z inductor [('pattern_matcher_nodes', 24), ('qconv_unary_matcher_nodes', 14), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:10.6388515Z graph_break []
2026-01-14T09:40:10.6388827Z [32mPASSED[0m
2026-01-14T09:40:10.6389480Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardtanh unimplemented []
2026-01-14T09:40:10.6390299Z stats [('calls_captured', 1970), ('unique_graphs', 224)]
2026-01-14T09:40:10.6390735Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6391171Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6392942Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:10.6394592Z graph_break []
2026-01-14T09:40:10.6394983Z [32mPASSED[0m
2026-01-14T09:40:10.6395617Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu unimplemented []
2026-01-14T09:40:10.6396419Z stats [('calls_captured', 1970), ('unique_graphs', 224)]
2026-01-14T09:40:10.6396843Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6397294Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6399059Z inductor [('pattern_matcher_nodes', 16), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:10.6400704Z graph_break []
2026-01-14T09:40:10.6401123Z [32mPASSED[0m
2026-01-14T09:40:10.6401762Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu6 unimplemented []
2026-01-14T09:40:10.6402583Z stats [('calls_captured', 1970), ('unique_graphs', 224)]
2026-01-14T09:40:10.6403012Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6403458Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6405339Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:10.6407049Z graph_break []
2026-01-14T09:40:10.6407350Z [32mPASSED[0m
2026-01-14T09:40:10.6407966Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_silu unimplemented []
2026-01-14T09:40:10.6408778Z stats [('calls_captured', 1970), ('unique_graphs', 224)]
2026-01-14T09:40:10.6409204Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6409646Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6411414Z inductor [('pattern_matcher_nodes', 22), ('qconv_unary_matcher_nodes', 12), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:10.6413148Z graph_break []
2026-01-14T09:40:10.6413450Z [32mPASSED[0m
2026-01-14T09:40:10.6414011Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qcat unimplemented []
2026-01-14T09:40:10.6414743Z stats [('calls_captured', 26), ('unique_graphs', 8)]
2026-01-14T09:40:10.6415159Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6415605Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6417645Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 7), ('qconv_unary_matcher_nodes', 4), ('qcat_matcher_nodes', 4), ('extern_calls', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('fxgraph_cache_bypass', 1), ('qcat_matcher_count', 1)]
2026-01-14T09:40:10.6419512Z graph_break []
2026-01-14T09:40:10.6419819Z [32mPASSED[0m
2026-01-14T09:40:10.6420449Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv1d_relu_cpu unimplemented []
2026-01-14T09:40:10.6421232Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:40:10.6421650Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6422084Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6423858Z inductor [('pattern_matcher_nodes', 13), ('qconv_weight_prepack_matcher_nodes', 6), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:10.6425585Z graph_break []
2026-01-14T09:40:10.6425870Z [32mPASSED[0m
2026-01-14T09:40:10.6426373Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_2 unimplemented []
2026-01-14T09:40:10.6426990Z stats [('calls_captured', 13), ('unique_graphs', 8)]
2026-01-14T09:40:10.6427343Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6427706Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6428866Z inductor [('pattern_matcher_nodes', 5), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qconv_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:40:10.6429987Z graph_break []
2026-01-14T09:40:10.6430236Z [32mPASSED[0m
2026-01-14T09:40:10.6430732Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_3 unimplemented []
2026-01-14T09:40:10.6431339Z stats [('calls_captured', 29), ('unique_graphs', 8)]
2026-01-14T09:40:10.6431684Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6432048Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6434447Z inductor [('pattern_matcher_nodes', 18), ('pattern_matcher_count', 8), ('qconv_weight_prepack_matcher_nodes', 7), ('qcat_matcher_nodes', 4), ('extern_calls', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_nodes', 2), ('qconv2d_binary_matcher_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv_unary_matcher_count', 1), ('qconv2d_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qcat_matcher_count', 1)]
2026-01-14T09:40:10.6436771Z graph_break []
2026-01-14T09:40:10.6437019Z [32mPASSED[0m
2026-01-14T09:40:10.6437591Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_broadcast_shapes_cpu unimplemented []
2026-01-14T09:40:10.6438279Z stats [('calls_captured', 15), ('unique_graphs', 8)]
2026-01-14T09:40:10.6438616Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6438983Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6440192Z inductor [('pattern_matcher_nodes', 5), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qconv_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:40:10.6441256Z graph_break []
2026-01-14T09:40:10.6441497Z [32mPASSED[0m
2026-01-14T09:40:10.6442037Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_cpu unimplemented []
2026-01-14T09:40:10.6442669Z stats [('calls_captured', 24), ('unique_graphs', 8)]
2026-01-14T09:40:10.6443009Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6443377Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:10.6444829Z inductor [('pattern_matcher_nodes', 16), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv2d_binary_matcher_nodes', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv2d_binary_matcher_count', 2), ('qconv2d_binary_lower_count', 2), ('qconv2d_binary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:10.6446195Z graph_break []
2026-01-14T09:40:10.6446440Z [32mPASSED[0m
2026-01-14T09:40:10.6447011Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:10.6447713Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:40:55.9495214Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9496692Z inductor [('pattern_matcher_nodes', 14), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv2d_binary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv2d_binary_matcher_count', 2), ('qconv2d_binary_lower_count', 2), ('qconv2d_binary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:40:55.9498061Z graph_break []
2026-01-14T09:40:55.9498516Z [32mPASSED[0m
2026-01-14T09:40:55.9499194Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:40:55.9500289Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:40:55.9501200Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_cpu unimplemented []
2026-01-14T09:40:55.9502098Z stats [('calls_captured', 28), ('unique_graphs', 8)]
2026-01-14T09:40:55.9502451Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9502819Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9504387Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv2d_binary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv2d_binary_matcher_count', 2), ('qconv2d_binary_lower_count', 2), ('qconv2d_binary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:55.9505770Z graph_break []
2026-01-14T09:40:55.9506023Z [32mPASSED[0m
2026-01-14T09:40:55.9506626Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9507339Z stats [('calls_captured', 20), ('unique_graphs', 1)]
2026-01-14T09:40:55.9507781Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9509322Z inductor [('pattern_matcher_nodes', 16), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv2d_binary_matcher_nodes', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv2d_binary_matcher_count', 2), ('qconv2d_binary_lower_count', 2), ('qconv2d_binary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:40:55.9510993Z graph_break []
2026-01-14T09:40:55.9511270Z [32mPASSED[0m
2026-01-14T09:40:55.9511947Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:40:55.9513337Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:40:55.9514440Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_cpu unimplemented []
2026-01-14T09:40:55.9515214Z stats [('calls_captured', 21), ('unique_graphs', 8)]
2026-01-14T09:40:55.9515572Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9516073Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9517494Z inductor [('pattern_matcher_nodes', 19), ('qconv_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qconv_unary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 3), ('qconv_unary_lower_count', 3), ('qconv_unary_lower_nodes', 3), ('extern_calls', 3), ('qconv_unary_matcher_count', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:55.9518789Z graph_break []
2026-01-14T09:40:55.9519061Z [32mPASSED[0m
2026-01-14T09:40:55.9519681Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_dequant_promotion_cpu unimplemented []
2026-01-14T09:40:55.9520359Z stats [('calls_captured', 24), ('unique_graphs', 8)]
2026-01-14T09:40:55.9520705Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9521077Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9523273Z inductor [('pattern_matcher_nodes', 22), ('qconv_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 10), ('qconv_unary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qconv_unary_matcher_count', 2), ('qconv2d_binary_matcher_nodes', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv2d_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1)]
2026-01-14T09:40:55.9525377Z graph_break []
2026-01-14T09:40:55.9525627Z [32mPASSED[0m
2026-01-14T09:40:55.9526187Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9526879Z stats [('calls_captured', 24), ('unique_graphs', 1)]
2026-01-14T09:40:55.9527307Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9528753Z inductor [('pattern_matcher_nodes', 19), ('qconv_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qconv_unary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 3), ('qconv_unary_lower_count', 3), ('qconv_unary_lower_nodes', 3), ('extern_calls', 3), ('qconv_unary_matcher_count', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:40:55.9530111Z graph_break []
2026-01-14T09:40:55.9530351Z [32mPASSED[0m
2026-01-14T09:40:55.9531027Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:40:55.9531920Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_cpu unimplemented []
2026-01-14T09:40:55.9532585Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:40:55.9532928Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9533304Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9534756Z inductor [('pattern_matcher_nodes', 23), ('qconv_unary_matcher_nodes', 13), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:55.9536064Z graph_break []
2026-01-14T09:40:55.9536314Z [32mPASSED[0m
2026-01-14T09:40:55.9536919Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9537688Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:40:55.9538127Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9539555Z inductor [('pattern_matcher_nodes', 23), ('qconv_unary_matcher_nodes', 13), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:40:55.9540847Z graph_break []
2026-01-14T09:40:55.9541090Z [32mPASSED[0m
2026-01-14T09:40:55.9541786Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:40:55.9542900Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:40:55.9543848Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_cpu unimplemented []
2026-01-14T09:40:55.9544486Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:40:55.9544829Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9545198Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9546616Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:40:55.9547929Z graph_break []
2026-01-14T09:40:55.9548166Z [32mPASSED[0m
2026-01-14T09:40:55.9548756Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9549481Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:40:55.9549950Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:40:55.9551336Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:40:55.9552664Z graph_break []
2026-01-14T09:40:55.9552915Z [32mPASSED[0m
2026-01-14T09:40:55.9553597Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:40:55.9554792Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:40:55.9555893Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:40:55.9556766Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_cpu unimplemented []
2026-01-14T09:40:55.9557418Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:40:55.9557757Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:40:55.9558132Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:43:56.8990833Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:43:56.8992551Z graph_break []
2026-01-14T09:43:56.8993054Z [32mPASSED[0m
2026-01-14T09:43:56.8993826Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_fp8_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.8995104Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:43:56.8995632Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:43:56.8997387Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:43:56.8999187Z graph_break []
2026-01-14T09:43:56.8999493Z [32mPASSED[0m
2026-01-14T09:43:56.9000131Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_cpu unimplemented []
2026-01-14T09:43:56.9000909Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:43:56.9001337Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.9001780Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:43:56.9003545Z inductor [('pattern_matcher_nodes', 15), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:43:56.9005188Z graph_break []
2026-01-14T09:43:56.9005482Z [32mPASSED[0m
2026-01-14T09:43:56.9006203Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_fp8_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.9007074Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:43:56.9007601Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:43:56.9009352Z inductor [('pattern_matcher_nodes', 15), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:43:56.9010980Z graph_break []
2026-01-14T09:43:56.9011278Z [32mPASSED[0m
2026-01-14T09:43:56.9012103Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_int8_mixed_bf16_xpu [33mSKIPPED[0m
2026-01-14T09:43:56.9013260Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_cpu unimplemented []
2026-01-14T09:43:56.9014174Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:43:56.9014585Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.9015029Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:43:56.9016883Z inductor [('pattern_matcher_nodes', 21), ('qconv_unary_matcher_nodes', 11), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:43:56.9018562Z graph_break []
2026-01-14T09:43:56.9018883Z [32mPASSED[0m
2026-01-14T09:43:56.9019605Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.9020472Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:43:56.9020993Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:43:56.9022756Z inductor [('pattern_matcher_nodes', 21), ('qconv_unary_matcher_nodes', 11), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:43:56.9024391Z graph_break []
2026-01-14T09:43:56.9024677Z [32mPASSED[0m
2026-01-14T09:43:56.9025502Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:43:56.9026895Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:43:56.9028092Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_with_concat_cpu unimplemented []
2026-01-14T09:43:56.9028957Z stats [('calls_captured', 32), ('unique_graphs', 8)]
2026-01-14T09:43:56.9029381Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.9029878Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:43:56.9032227Z inductor [('pattern_matcher_nodes', 30), ('pattern_matcher_count', 14), ('qconv_weight_prepack_matcher_nodes', 13), ('qconv_unary_matcher_nodes', 6), ('extern_calls', 6), ('qcat_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 4), ('qconv_unary_lower_count', 4), ('qconv_unary_lower_nodes', 4), ('qconv_unary_matcher_count', 3), ('dequant_promotion_matcher_count', 2), ('dequant_promotion_matcher_nodes', 2), ('fxgraph_cache_bypass', 1), ('qcat_matcher_count', 1)]
2026-01-14T09:43:56.9034467Z graph_break []
2026-01-14T09:43:56.9034841Z [32mPASSED[0m
2026-01-14T09:43:56.9035428Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qflatten unimplemented []
2026-01-14T09:43:56.9036175Z stats [('calls_captured', 27), ('unique_graphs', 8)]
2026-01-14T09:43:56.9036590Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.9037044Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:43:56.9039070Z inductor [('pattern_matcher_nodes', 12), ('pattern_matcher_count', 5), ('qconv_weight_prepack_matcher_nodes', 4), ('qconv_unary_matcher_nodes', 3), ('qreshape_matcher_nodes', 3), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qreshape_matcher_count', 1), ('extern_calls', 1)]
2026-01-14T09:43:56.9040975Z graph_break []
2026-01-14T09:43:56.9041274Z [32mPASSED[0m
2026-01-14T09:43:56.9042092Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_False unimplemented []
2026-01-14T09:43:56.9042908Z stats [('calls_captured', 56), ('unique_graphs', 16)]
2026-01-14T09:43:56.9043259Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.9043632Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:43:56.9045938Z inductor [('pattern_matcher_nodes', 102), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 10), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:43:56.9047978Z graph_break []
2026-01-14T09:43:56.9048229Z [32mPASSED[0m
2026-01-14T09:43:56.9048965Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_True unimplemented []
2026-01-14T09:43:56.9049770Z stats [('calls_captured', 60), ('unique_graphs', 16)]
2026-01-14T09:43:56.9050123Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.9050509Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:43:56.9052632Z inductor [('pattern_matcher_nodes', 101), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 9), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:43:56.9054700Z graph_break []
2026-01-14T09:43:56.9054951Z [32mPASSED[0m
2026-01-14T09:43:56.9055628Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_False unimplemented []
2026-01-14T09:43:56.9056418Z stats [('calls_captured', 56), ('unique_graphs', 16)]
2026-01-14T09:43:56.9056771Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:43:56.9057220Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:43:56.9059441Z inductor [('pattern_matcher_nodes', 102), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 10), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:43:56.9061461Z graph_break []
2026-01-14T09:43:56.9061713Z [32mPASSED[0m
2026-01-14T09:43:56.9062384Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_True unimplemented []
2026-01-14T09:46:46.8025301Z stats [('calls_captured', 60), ('unique_graphs', 16)]
2026-01-14T09:46:46.8027520Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:46:46.8028011Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:46:46.8030741Z inductor [('pattern_matcher_nodes', 101), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 9), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:46:46.8033338Z graph_break []
2026-01-14T09:46:46.8033849Z [32mPASSED[0m
2026-01-14T09:46:46.8034721Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_False unimplemented []
2026-01-14T09:46:46.8037649Z stats [('calls_captured', 64), ('unique_graphs', 16)]
2026-01-14T09:46:46.8038078Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:46:46.8047108Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:46:46.8050027Z inductor [('pattern_matcher_nodes', 106), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 14), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:46:46.8052595Z graph_break []
2026-01-14T09:46:46.8052940Z [32mPASSED[0m
2026-01-14T09:46:46.8053794Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_True unimplemented []
2026-01-14T09:46:46.8054847Z stats [('calls_captured', 68), ('unique_graphs', 16)]
2026-01-14T09:46:46.8055278Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:46:46.8055716Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:46:46.8058412Z inductor [('pattern_matcher_nodes', 105), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 13), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:46:46.8061111Z graph_break []
2026-01-14T09:46:46.8061400Z [32mPASSED[0m
2026-01-14T09:46:46.8062347Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_False unimplemented []
2026-01-14T09:46:46.8063349Z stats [('calls_captured', 64), ('unique_graphs', 16)]
2026-01-14T09:46:46.8063763Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:46:46.8064211Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:46:46.8066883Z inductor [('pattern_matcher_nodes', 106), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 14), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:46:46.8069423Z graph_break []
2026-01-14T09:46:46.8069727Z [32mPASSED[0m
2026-01-14T09:46:46.8070545Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_True unimplemented []
2026-01-14T09:46:46.8071528Z stats [('calls_captured', 68), ('unique_graphs', 16)]
2026-01-14T09:46:46.8071937Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:46:46.8072374Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:46:46.8075195Z inductor [('pattern_matcher_nodes', 105), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 13), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:46:46.8077801Z graph_break []
2026-01-14T09:46:46.8078100Z [32mPASSED[0m
2026-01-14T09:46:46.8079173Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:46:46.8080850Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:46:46.8082289Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:46:46.8083654Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:46:46.8085342Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:46:46.8086713Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:46:46.8088054Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:46:46.8089404Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:46:46.8090521Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_cpu unimplemented []
2026-01-14T09:46:46.8091123Z stats [('calls_captured', 16), ('unique_graphs', 8)]
2026-01-14T09:46:46.8091463Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:46:46.8091818Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:46:46.8093346Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:46:46.8094753Z graph_break []
2026-01-14T09:46:46.8094995Z [32mPASSED[0m
2026-01-14T09:46:46.8095557Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu unimplemented []
2026-01-14T09:46:46.8096232Z stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:46:46.8096577Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:46:46.8096946Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:46:46.8099128Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:46:46.8101468Z graph_break []
2026-01-14T09:46:46.8101727Z [32mPASSED[0m
2026-01-14T09:46:46.8102355Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 unimplemented []
2026-01-14T09:46:46.8103136Z stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:46:46.8103605Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:46:46.8104000Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:46:46.8106258Z inductor [('pattern_matcher_nodes', 33), ('qlinear_weight_prepack_matcher_nodes', 18), ('pattern_matcher_count', 15), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('dequant_promotion_matcher_nodes', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:46:46.8108532Z graph_break []
2026-01-14T09:46:46.8108802Z [32mPASSED[0m
2026-01-14T09:46:46.8109388Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_dynamic_cpu unimplemented []
2026-01-14T09:46:46.8110092Z stats [('calls_captured', 27), ('unique_graphs', 8)]
2026-01-14T09:47:30.7174710Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7175288Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7177975Z inductor [('pattern_matcher_nodes', 18), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:47:30.7179980Z graph_break []
2026-01-14T09:47:30.7180662Z [32mPASSED[0m
2026-01-14T09:47:30.7181418Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:47:30.7182648Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:47:30.7183653Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_cpu unimplemented []
2026-01-14T09:47:30.7184628Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:47:30.7184986Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7185381Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7187064Z inductor [('pattern_matcher_nodes', 31), ('qlinear_unary_matcher_nodes', 21), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:47:30.7188876Z graph_break []
2026-01-14T09:47:30.7189221Z [32mPASSED[0m
2026-01-14T09:47:30.7189963Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:47:30.7190906Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2 unimplemented []
2026-01-14T09:47:30.7191697Z stats [('calls_captured', 16), ('unique_graphs', 8)]
2026-01-14T09:47:30.7192109Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7192558Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7194134Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:47:30.7195626Z graph_break []
2026-01-14T09:47:30.7195900Z [32mPASSED[0m
2026-01-14T09:47:30.7196532Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2_and_not_contiguous unimplemented []
2026-01-14T09:47:30.7197284Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:47:30.7197636Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7198162Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7199680Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:47:30.7201157Z graph_break []
2026-01-14T09:47:30.7201421Z [32mPASSED[0m
2026-01-14T09:47:30.7202040Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:47:30.7203075Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:47:30.7204278Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:47:30.7205305Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mul_cpu unimplemented []
2026-01-14T09:47:30.7205919Z stats [('calls_captured', 17), ('unique_graphs', 8)]
2026-01-14T09:47:30.7206270Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7206640Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7208076Z inductor [('pattern_matcher_nodes', 7), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_unary_matcher_nodes', 2), ('qlinear_weight_prepack_matcher_count', 1), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:47:30.7209511Z graph_break []
2026-01-14T09:47:30.7209758Z [32mPASSED[0m
2026-01-14T09:47:30.7210263Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_cpu unimplemented []
2026-01-14T09:47:30.7210934Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:47:30.7211291Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7211658Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7213126Z inductor [('pattern_matcher_nodes', 15), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:47:30.7214492Z graph_break []
2026-01-14T09:47:30.7214735Z [32mPASSED[0m
2026-01-14T09:47:30.7215306Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_input_dim_exceeds_2 unimplemented []
2026-01-14T09:47:30.7215985Z stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:47:30.7216332Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7216710Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7218189Z inductor [('pattern_matcher_nodes', 23), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 10), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:47:30.7219607Z graph_break []
2026-01-14T09:47:30.7219849Z [32mPASSED[0m
2026-01-14T09:47:30.7220475Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:47:30.7221569Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:47:30.7222487Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qmaxpool2d unimplemented []
2026-01-14T09:47:30.7223230Z stats [('calls_captured', 19), ('unique_graphs', 8)]
2026-01-14T09:47:30.7223574Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7223954Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7225637Z inductor [('pattern_matcher_nodes', 12), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 4), ('qmaxpool2d_matcher_nodes', 4), ('qconv_unary_matcher_nodes', 3), ('extern_calls', 3), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qmaxpool2d_matcher_count', 1)]
2026-01-14T09:47:30.7227172Z graph_break []
2026-01-14T09:47:30.7227423Z [32mPASSED[0m
2026-01-14T09:47:30.7228303Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_False [32mPASSED[0m
2026-01-14T09:47:30.7229836Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_True [32mPASSED[0m
2026-01-14T09:47:30.7231314Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_False [32mPASSED[0m
2026-01-14T09:47:30.7232766Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_True [32mPASSED[0m
2026-01-14T09:47:30.7234204Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7235219Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:47:30.7235647Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7236665Z inductor [('pattern_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_nodes', 6), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:47:30.7237548Z graph_break []
2026-01-14T09:47:30.7237827Z [32mPASSED[0m
2026-01-14T09:47:30.7238656Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:47:30.7239595Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:47:30.7240036Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:47:30.7241241Z inductor [('pattern_matcher_nodes', 10), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:48:51.6892947Z graph_break []
2026-01-14T09:48:51.6893508Z [32mPASSED[0m
2026-01-14T09:48:51.6894634Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:48:51.6895845Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:48:51.6896370Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6897602Z inductor [('pattern_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_nodes', 6), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:48:51.6898721Z graph_break []
2026-01-14T09:48:51.6899025Z [32mPASSED[0m
2026-01-14T09:48:51.6900038Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:48:51.6901577Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:48:51.6902100Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6903325Z inductor [('pattern_matcher_nodes', 9), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:48:51.6904606Z graph_break []
2026-01-14T09:48:51.6904938Z [32mPASSED[0m
2026-01-14T09:48:51.6906184Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_False [32mPASSED[0m
2026-01-14T09:48:51.6908054Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_True [32mPASSED[0m
2026-01-14T09:48:51.6909926Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_False [32mPASSED[0m
2026-01-14T09:48:51.6911785Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_True [32mPASSED[0m
2026-01-14T09:48:51.6913554Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:48:51.6914745Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:48:51.6915487Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6916872Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 5), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:48:51.6918204Z graph_break []
2026-01-14T09:48:51.6918502Z [32mPASSED[0m
2026-01-14T09:48:51.6919619Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:48:51.6920781Z stats [('calls_captured', 14), ('unique_graphs', 1)]
2026-01-14T09:48:51.6921308Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6922987Z inductor [('pattern_matcher_nodes', 13), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 6), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:48:51.6924538Z graph_break []
2026-01-14T09:48:51.6924886Z [32mPASSED[0m
2026-01-14T09:48:51.6925888Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:48:51.6927057Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:48:51.6927597Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6928977Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 5), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:48:51.6930248Z graph_break []
2026-01-14T09:48:51.6930546Z [32mPASSED[0m
2026-01-14T09:48:51.6931541Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:48:51.6932694Z stats [('calls_captured', 14), ('unique_graphs', 1)]
2026-01-14T09:48:51.6933209Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6934658Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 5), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:48:51.6935978Z graph_break []
2026-01-14T09:48:51.6936262Z [32mPASSED[0m
2026-01-14T09:48:51.6937075Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_q_attention_block frames [('total', 1), ('ok', 1)]
2026-01-14T09:48:51.6937989Z stats [('calls_captured', 50), ('unique_graphs', 1)]
2026-01-14T09:48:51.6938517Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6940479Z inductor [('pattern_matcher_nodes', 81), ('pattern_matcher_count', 32), ('qlinear_weight_prepack_matcher_nodes', 24), ('extern_calls', 6), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('dequant_promotion_matcher_nodes', 2), ('fuse_attention', 1), ('dequant_promotion_matcher_count', 1), ('fxgraph_cache_miss', 1)]
2026-01-14T09:48:51.6942447Z graph_break []
2026-01-14T09:48:51.6942701Z [32mPASSED[0m
2026-01-14T09:48:51.6943375Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T09:48:51.6944458Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T09:48:51.6945629Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag_with_output_quant [33mSKIPPED[0m
2026-01-14T09:48:51.6946733Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block unimplemented []
2026-01-14T09:48:51.6947392Z stats [('calls_captured', 52), ('unique_graphs', 8)]
2026-01-14T09:48:51.6947732Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:48:51.6948097Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6949705Z inductor [('pattern_matcher_nodes', 81), ('pattern_matcher_count', 32), ('qlinear_weight_prepack_matcher_nodes', 24), ('extern_calls', 6), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('dequant_promotion_matcher_nodes', 2), ('fuse_attention', 1), ('dequant_promotion_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:48:51.6951141Z graph_break []
2026-01-14T09:48:51.6951388Z [32mPASSED[0m
2026-01-14T09:48:51.6951910Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qat_bn_conv2d unimplemented []
2026-01-14T09:48:51.6952570Z stats [('calls_captured', 1962), ('unique_graphs', 224)]
2026-01-14T09:48:51.6952924Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:48:51.6953286Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6954715Z inductor [('pattern_matcher_nodes', 7), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qconv_unary_matcher_nodes', 2), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:48:51.6956111Z graph_break []
2026-01-14T09:48:51.6956359Z [32mPASSED[0m
2026-01-14T09:48:51.6956973Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qconv2d_maxpool2d_linear_dynamic_cpu unimplemented []
2026-01-14T09:48:51.6957717Z stats [('calls_captured', 30), ('unique_graphs', 8)]
2026-01-14T09:48:51.6958148Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:48:51.6960530Z inductor [('pattern_matcher_nodes', 21), ('pattern_matcher_count', 8), ('qlinear_weight_prepack_matcher_nodes', 4), ('qconv_weight_prepack_matcher_nodes', 4), ('qmaxpool2d_matcher_nodes', 4), ('extern_calls', 4), ('qconv_unary_matcher_nodes', 3), ('qreshape_matcher_nodes', 3), ('qlinear_weight_prepack_matcher_count', 1), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qmaxpool2d_matcher_count', 1), ('qreshape_matcher_count', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1)]
2026-01-14T09:48:51.6962833Z graph_break []
2026-01-14T09:48:51.6963082Z [32mPASSED[0m
2026-01-14T09:48:51.6963835Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_adaptive_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T09:48:51.6964984Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_annotate_mul_tensor [32mPASSED[0m
2026-01-14T09:48:51.6966051Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_attention_block [32mPASSED[0m
2026-01-14T09:48:51.6967088Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T10:00:44.5806818Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe [32mPASSED[0m
2026-01-14T10:00:44.5807942Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_same_inputs [32mPASSED[0m
2026-01-14T10:00:44.5809066Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_single_input [32mPASSED[0m
2026-01-14T10:00:44.5810119Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d [32mPASSED[0m
2026-01-14T10:00:44.5811545Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary [32mPASSED[0m
2026-01-14T10:00:44.5812565Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary2 [32mPASSED[0m
2026-01-14T10:00:44.5813615Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary_unary [32mPASSED[0m
2026-01-14T10:00:44.5814861Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_serials_binary_unary [32mPASSED[0m
2026-01-14T10:00:44.5815944Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_unary [32mPASSED[0m
2026-01-14T10:00:44.5817040Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_dynamic_quant_linear [32mPASSED[0m
2026-01-14T10:00:44.5818146Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe [32mPASSED[0m
2026-01-14T10:00:44.5819246Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_linear_recipe [32mPASSED[0m
2026-01-14T10:00:44.5820326Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_maxpool2d_recipe [32mPASSED[0m
2026-01-14T10:00:44.5821391Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe [32mPASSED[0m
2026-01-14T10:00:44.5822426Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe2 [32mPASSED[0m
2026-01-14T10:00:44.5823410Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear [32mPASSED[0m
2026-01-14T10:00:44.5824402Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary [32mPASSED[0m
2026-01-14T10:00:44.5825428Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary2 [32mPASSED[0m
2026-01-14T10:00:44.5826496Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic [32mPASSED[0m
2026-01-14T10:00:44.5827647Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic_qat [32mPASSED[0m
2026-01-14T10:00:44.5828725Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_qat [32mPASSED[0m
2026-01-14T10:00:44.5829953Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary [32mPASSED[0m
2026-01-14T10:00:44.5831061Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic [32mPASSED[0m
2026-01-14T10:00:44.5832347Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic_qat [32mPASSED[0m
2026-01-14T10:00:44.5833512Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_qat [32mPASSED[0m
2026-01-14T10:00:44.5834624Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_serials [32mPASSED[0m
2026-01-14T10:00:44.5835816Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_dynamic_fp16 [32mPASSED[0m
2026-01-14T10:00:44.5836914Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary [32mPASSED[0m
2026-01-14T10:00:44.5837956Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic [32mPASSED[0m
2026-01-14T10:00:44.5839058Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic_qat [32mPASSED[0m
2026-01-14T10:00:44.5840143Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_qat [32mPASSED[0m
2026-01-14T10:00:44.5841234Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_lowering_to_x86 [33mSKIPPED[0m
2026-01-14T10:00:44.5842291Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_maxpool2d_recipe [32mPASSED[0m
2026-01-14T10:00:44.5843307Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d [32mPASSED[0m
2026-01-14T10:00:44.5844381Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary [32mPASSED[0m
2026-01-14T10:00:44.5845439Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary2 [32mPASSED[0m
2026-01-14T10:00:44.5846516Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary_unary [32mPASSED[0m
2026-01-14T10:00:44.5847588Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_unary [32mPASSED[0m
2026-01-14T10:00:44.5848672Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_dynamic_quant_linear [32mPASSED[0m
2026-01-14T10:00:44.5849844Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case1 [32mPASSED[0m
2026-01-14T10:00:44.5851084Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case2 [32mPASSED[0m
2026-01-14T10:00:44.5852355Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs [32mPASSED[0m
2026-01-14T10:00:44.5853569Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig [32mPASSED[0m
2026-01-14T10:00:44.5854770Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_for_dynamic_quant [32mPASSED[0m
2026-01-14T10:00:44.5856031Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_with_underscores [32mPASSED[0m
2026-01-14T10:00:44.5857269Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_with_mixed_configs [32mPASSED[0m
2026-01-14T10:00:44.5858367Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T10:00:44.5859491Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm_weight_in_bkn_layout [33mSKIPPED[0m
2026-01-14T10:00:44.5860633Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.5861788Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.5862926Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T10:00:44.5864043Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.5865162Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.5866290Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T10:00:44.5867364Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-1 [33mSKIPPED[0m
2026-01-14T10:00:44.5868390Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-2 [33mSKIPPED[0m
2026-01-14T10:00:44.5869519Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_create_tensor_out_of_inference_mode [33mSKIPPED[0m
2026-01-14T10:00:44.5870736Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_expected_gpu_kernel_fbgemm [33mSKIPPED[0m
2026-01-14T10:00:44.5872047Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.5873539Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.5875038Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.5876490Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.6099602Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.6101059Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.6102521Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.6103959Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.6105283Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.6106511Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.6107778Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes2 [33mSKIPPED[0m
2026-01-14T10:00:44.6108985Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes3 [33mSKIPPED[0m
2026-01-14T10:00:44.6110311Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.6111498Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.6112770Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes2 [33mSKIPPED[0m
2026-01-14T10:00:44.6113987Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes3 [33mSKIPPED[0m
2026-01-14T10:00:44.6115690Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6117700Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6119693Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6121751Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6123739Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6125804Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6127778Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6129763Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6131752Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6133742Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6135720Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6137745Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6139728Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6141795Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6143817Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6145773Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6148173Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6150152Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6152136Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6154161Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6156228Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6158215Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6160198Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6162174Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6164153Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6166107Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6168114Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6346540Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6350295Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6354398Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6359231Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6361204Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6363188Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6365167Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6367153Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6369202Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6371238Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6373208Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6375168Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6377184Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6379166Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6381157Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6383111Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6385296Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6387371Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6389406Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6391885Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6393860Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6395856Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6397844Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6399876Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6401906Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6403898Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6405851Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6407812Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6409770Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6411714Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6413692Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6415652Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6417640Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6419659Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6421652Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6585835Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T10:00:44.6587874Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T10:00:44.6589834Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6591824Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6593884Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6596006Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6598000Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6599995Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6601991Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6603988Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6605982Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6607965Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6609954Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6612000Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6614026Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6616002Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6618028Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6619999Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6621995Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6624072Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6626055Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6628146Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6630181Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6632171Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6634152Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6636207Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6638183Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6640172Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6642145Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6644171Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6646243Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6648740Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6650748Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6652744Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6825175Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6827276Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6829376Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6831357Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6833340Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6835364Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6837362Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6839343Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6841330Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6843317Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6845406Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6847458Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6849453Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6851424Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6853414Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6855389Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6857439Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6859474Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6861484Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6863477Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6865451Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6867493Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6869486Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6871468Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6873455Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6875489Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6877531Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6879560Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6881540Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6883517Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6885735Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6887761Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.6889844Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.6891885Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7062306Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7064317Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7066325Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7068359Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7070339Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7072348Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7074383Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7076604Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7078646Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7080761Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7082826Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7085105Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7087197Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7089360Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7091441Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7093574Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7095652Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7097710Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7099765Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7101808Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7103890Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7105924Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7108058Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7110195Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7112321Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7114421Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7116558Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7118706Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7120794Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7122923Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7125019Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7127132Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7129205Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7131283Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7302406Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7304479Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7306709Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7309061Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7311212Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7313364Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7315484Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7317564Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7319611Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7321663Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7323793Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7325892Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7328011Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7330090Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7332154Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7334205Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7336281Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7338402Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7340449Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7342556Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7344689Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7346752Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7348778Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7350846Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7352877Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7355019Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7357146Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7359262Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7361313Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7363339Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7365400Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7367517Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7369566Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7371622Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7536946Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7539170Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7541273Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7543362Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7545450Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7547549Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7549685Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7551762Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7553871Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7555987Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7558013Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7559987Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7561954Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7563934Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7565925Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7567961Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7570007Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7572046Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7574038Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7576026Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7578063Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7580049Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7582062Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7584292Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7586307Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7588279Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7590264Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7592257Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7594248Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7596290Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7598331Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7600307Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7602363Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7604400Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7778537Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7780828Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7782986Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7785207Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7787596Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7789851Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7791878Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7794054Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7796276Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7807452Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7809781Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7811832Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7814000Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7816342Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7818555Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7820747Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7822960Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7825040Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7827218Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7829431Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7831644Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7833733Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7835951Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7838140Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7840163Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7842338Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7844512Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7846530Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7848720Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7850860Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7853102Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7855154Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7857349Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.7859513Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.7861578Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8015801Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8018207Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8020243Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8022459Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8024473Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8026649Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8028888Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8030981Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8033108Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8035377Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8037669Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8039703Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8041922Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8044145Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8046249Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8048662Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8050968Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8053106Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8055329Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8057647Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8059765Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8062039Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8064305Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8066452Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8068696Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8070935Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8073216Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8075415Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8077766Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8080029Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8082144Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8084801Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8087019Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8089333Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8281022Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8283292Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8285820Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8287983Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8290212Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8292406Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8294584Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8296900Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8299033Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8301279Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8303360Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8305569Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8307898Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8310100Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8312308Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8314523Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8316699Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8318962Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8321184Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8323248Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8325396Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8327699Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8329897Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8331959Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8334192Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8336376Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8338438Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8340726Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8342974Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8345040Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8347248Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8349427Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8351489Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8353703Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8529952Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8532214Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8534387Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8536542Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8538908Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8541081Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8543166Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8545343Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8547502Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8549700Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8551998Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8554089Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8556361Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8558507Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8560680Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8562882Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T10:00:44.8564978Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T10:00:44.8567102Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8569265Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8571376Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8573376Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8575463Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8577631Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8579581Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8581760Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8583888Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8586072Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8588241Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8590350Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8592308Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8594376Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8596412Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8598580Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8600533Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8602782Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8774476Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8776657Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8778811Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8780791Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8782909Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8785377Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8787485Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8789651Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8791821Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8793921Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8796175Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8798395Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8800456Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8802590Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8804656Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8806954Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8809137Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8811338Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8813478Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8815492Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8817592Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8819750Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8821946Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8823979Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8826126Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8828346Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8830374Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8832562Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8834685Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8836751Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8838994Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8841152Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8843150Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.8845238Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.8847355Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9016673Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9018999Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9021096Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9023183Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9025283Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9027348Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9029320Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9031393Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9033473Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9035499Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9037545Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9039768Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9041940Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9043921Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9046016Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9048176Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9050119Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9052245Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9054196Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9056358Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9058390Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9060534Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9062696Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9064691Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9066822Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9068997Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9071001Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9073211Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9075351Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9077517Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9079538Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9081646Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9083865Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9086175Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9088478Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9361312Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9363527Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9365676Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9367759Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9369921Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9372050Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9374060Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9376224Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9377939Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_has_compatible_shallow_copy_type [33mSKIPPED[0m
2026-01-14T10:00:44.9379299Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_index_select [33mSKIPPED[0m
2026-01-14T10:00:44.9380580Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9382028Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9383602Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9385274Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9386559Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T10:00:44.9387893Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_per_row_config_before_dim [33mSKIPPED[0m
2026-01-14T10:00:44.9389121Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config0 [33mSKIPPED[0m
2026-01-14T10:00:44.9390228Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config1 [33mSKIPPED[0m
2026-01-14T10:00:44.9391310Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config2 [33mSKIPPED[0m
2026-01-14T10:00:44.9393685Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T10:00:44.9395325Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T10:00:44.9396741Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T10:00:44.9398190Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T10:00:44.9399724Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T10:00:44.9401186Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T10:00:44.9402662Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T10:00:44.9404071Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T10:00:44.9405564Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T10:00:44.9407014Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T10:00:44.9408534Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T10:00:44.9410063Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T10:00:44.9411466Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity0 [33mSKIPPED[0m
2026-01-14T10:00:44.9412903Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity1 [33mSKIPPED[0m
2026-01-14T10:00:44.9414072Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity0 [33mSKIPPED[0m
2026-01-14T10:00:44.9415298Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity1 [33mSKIPPED[0m
2026-01-14T10:00:44.9416476Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity0 [33mSKIPPED[0m
2026-01-14T10:00:44.9417769Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity1 [33mSKIPPED[0m
2026-01-14T10:00:44.9419100Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9420293Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9421655Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T10:00:44.9422818Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9424074Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9425291Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T10:00:44.9426511Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_dtype_layout [33mSKIPPED[0m
2026-01-14T10:00:44.9427647Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_transpose [33mSKIPPED[0m
2026-01-14T10:00:44.9428804Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_conv2d_weight [33mSKIPPED[0m
2026-01-14T10:00:44.9430026Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9431296Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:44.9432686Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:44.9433945Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:47.6445571Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T10:00:47.6447103Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T10:00:47.6448660Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T10:00:47.6450460Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T10:00:47.6451821Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6453153Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6454410Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_from_int4_tensor [33mSKIPPED[0m
2026-01-14T10:00:47.6455651Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6456892Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6458158Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6459447Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6460730Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6462075Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6463232Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_activation_prescaling [33mSKIPPED[0m
2026-01-14T10:00:47.6464216Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T10:00:47.6465244Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:47.6466211Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:47.6467165Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes2 [33mSKIPPED[0m
2026-01-14T10:00:47.6468135Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_linear [33mSKIPPED[0m
2026-01-14T10:00:47.6469171Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T10:00:47.6470163Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice [33mSKIPPED[0m
2026-01-14T10:00:47.6471204Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_and_copy_similar_to_vllm [33mSKIPPED[0m
2026-01-14T10:00:47.6472306Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_preserves_aliasing [33mSKIPPED[0m
2026-01-14T10:00:47.6473360Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes0 [33mSKIPPED[0m
2026-01-14T10:00:47.6474362Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes1 [33mSKIPPED[0m
2026-01-14T10:00:47.6475476Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes2 [33mSKIPPED[0m
2026-01-14T10:00:47.6476706Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6478130Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6479647Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_cant_initialize_in_cpu [33mSKIPPED[0m
2026-01-14T10:00:47.6481090Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_128 [33mSKIPPED[0m
2026-01-14T10:00:47.6482670Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_32 [33mSKIPPED[0m
2026-01-14T10:00:47.6484384Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_64 [33mSKIPPED[0m
2026-01-14T10:00:47.6485782Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_error_conditions [33mSKIPPED[0m
2026-01-14T10:00:47.6487128Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6488483Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6489830Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6491193Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6492623Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6493963Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6495433Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_mm_int4wo_device_cuda_bfloat16 [33mSKIPPED[0m
2026-01-14T10:00:47.6496819Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6498216Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6499654Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6501165Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6502561Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6503866Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6505241Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config0 [33mSKIPPED[0m
2026-01-14T10:00:47.6506708Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config1 [33mSKIPPED[0m
2026-01-14T10:00:47.6508068Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_to_device [33mSKIPPED[0m
2026-01-14T10:00:47.6509268Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_available_gpu_kernels [32mPASSED[0m
2026-01-14T10:00:47.6510446Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config0 [32mPASSED[0m
2026-01-14T10:00:47.6511573Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config1 [32mPASSED[0m
2026-01-14T10:00:47.6512692Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config2 [32mPASSED[0m
2026-01-14T10:00:47.6513876Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config3 [32mPASSED[0m
2026-01-14T10:00:47.6515071Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config0 [32mPASSED[0m
2026-01-14T10:00:47.6516204Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config1 [32mPASSED[0m
2026-01-14T10:02:20.4557864Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config2 [32mPASSED[0m
2026-01-14T10:02:20.4574340Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config3 [32mPASSED[0m
2026-01-14T10:02:20.4575955Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config0 [32mPASSED[0m
2026-01-14T10:02:20.4577285Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config1 [32mPASSED[0m
2026-01-14T10:02:20.4579053Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config2 [32mPASSED[0m
2026-01-14T10:02:20.4580341Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config3 [32mPASSED[0m
2026-01-14T10:02:20.4581863Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4583684Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4585642Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4587354Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4589098Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4590789Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4592678Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4594387Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4596167Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4597848Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4599583Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4601270Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4603105Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4604793Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4606580Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4608272Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4609959Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4611644Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4613338Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4615030Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4616801Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4618540Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4620230Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4621994Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4623693Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4625373Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4627045Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4628779Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4630463Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4632135Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4633814Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes0 [32mPASSED[0m
2026-01-14T10:02:20.4635581Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes1 [32mPASSED[0m
2026-01-14T10:02:20.4637048Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config0 [32mPASSED[0m
2026-01-14T10:02:20.4638323Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config1 [32mPASSED[0m
2026-01-14T10:02:20.4639642Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config2 [32mPASSED[0m
2026-01-14T10:02:20.4640912Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config3 [32mPASSED[0m
2026-01-14T10:02:20.4642236Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_cuda_bfloat16 [32mPASSED[0m
2026-01-14T10:02:20.4643647Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_cuda_float16 [32mPASSED[0m
2026-01-14T10:02:20.4644798Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T10:02:20.4645918Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_float16 [32mPASSED[0m
2026-01-14T10:02:20.4647010Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_cuda_bfloat16 [32mPASSED[0m
2026-01-14T10:02:20.4648086Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_cuda_float16 [32mPASSED[0m
2026-01-14T10:02:20.4649227Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T10:02:20.4650344Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_float16 [32mPASSED[0m
2026-01-14T10:02:20.4651490Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_cuda_bfloat16 [32mPASSED[0m
2026-01-14T10:02:20.4652549Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_cuda_float16 [32mPASSED[0m
2026-01-14T10:02:20.4653640Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T10:02:20.4654796Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_float16 [32mPASSED[0m
2026-01-14T10:02:20.4655909Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_cuda_bfloat16 [32mPASSED[0m
2026-01-14T10:02:20.4656970Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_cuda_float16 [32mPASSED[0m
2026-01-14T10:02:25.2053176Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T10:02:25.2055566Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_float16 [32mPASSED[0m
2026-01-14T10:02:25.2058156Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity0_bfloat16 [32mPASSED[0m
2026-01-14T10:02:25.2060294Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity1_bfloat16 [32mPASSED[0m
2026-01-14T10:02:25.2062614Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2065790Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2068856Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2072277Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2075399Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2078473Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2081583Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2084935Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2088066Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2091292Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2094401Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2097466Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2100566Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2103732Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2106846Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2110081Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2113164Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2117227Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2120247Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2123296Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2215833Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2218985Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2222155Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2225269Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2228333Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2231407Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2234489Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2237783Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2240973Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2244026Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2247046Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2250094Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2253210Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2256382Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2259625Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2262683Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2265694Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2268740Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2271965Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2275119Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2278193Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2281305Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2379563Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2382608Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2386086Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2389266Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2392420Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2395602Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2398897Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2402222Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2405383Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2408488Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2411573Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2414651Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2417795Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2420964Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2424052Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2427134Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2430355Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2433623Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2436839Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2439942Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2443030Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2446112Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2550960Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2554717Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2557920Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2561041Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2564119Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2567316Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2570484Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2573699Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2576845Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2579930Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2583075Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2586574Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2589736Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2592956Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2596148Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2599329Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2602466Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2605557Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2608706Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2611974Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2615120Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2618317Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2715886Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2720867Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2724013Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2727309Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2730507Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2733608Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2736696Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2739788Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2742937Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2746204Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2749368Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2752374Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2755369Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2758386Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2761440Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2764449Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2767439Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2770491Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2773511Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2776637Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2779770Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2782788Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2873242Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2876317Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2879468Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2882669Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2885936Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2888929Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2891935Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2894925Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2898092Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2901342Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2904384Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2907402Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2910510Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2913567Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2916651Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2919787Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2922823Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2925800Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2928807Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2931928Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.2935003Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.2938143Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3032054Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3038343Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3042053Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3045050Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3048083Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3051261Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3054318Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3057297Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3060459Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3063458Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3066524Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3069620Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3072787Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3075891Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3078896Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3081998Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3085156Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3088161Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3091343Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3094382Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3097492Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3100642Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3190361Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3193534Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3196645Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3199706Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3202880Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3206021Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3209194Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3212357Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3215411Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3218475Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3221648Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3224949Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3228067Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3231177Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3234191Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3237283Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3240425Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3243693Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3246776Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3249838Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3252876Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3256003Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3350398Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3353561Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3356686Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3359719Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3362821Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3365942Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3369101Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3372294Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3375362Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3378458Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3381631Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3384831Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3387944Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3391135Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3394199Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3397335Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3400672Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3403884Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3407049Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3410278Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3413415Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3416499Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3509533Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3515442Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3520475Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3523554Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3526839Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3530052Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3533192Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3536274Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3539462Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3542592Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3545705Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3548921Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3552110Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3555251Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3558384Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3561557Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3564711Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3567928Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3571161Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3574264Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3577350Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3580406Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3668554Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3671839Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3675128Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3678271Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3681424Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3684650Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3687887Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3691128Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3694280Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3697376Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3700456Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3703543Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3706692Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3710087Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3713252Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3716400Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3719485Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3722715Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3725871Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3729094Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3732238Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3735248Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3828848Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3832394Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3835437Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3838433Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3841427Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3844452Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3847569Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3850746Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3853798Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3856806Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3859816Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3862852Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3865990Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3869117Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3872181Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3875240Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3878327Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3881374Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3884583Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3887715Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3890827Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3893833Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3990081Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3993197Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.3996327Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.3999508Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4002634Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.4005689Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4008693Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.4011760Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4014818Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.4017940Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4021040Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.4024156Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4027154Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.4030209Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4042265Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.4045549Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4048627Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.4051644Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4054641Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.4057636Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4060749Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T10:02:25.4063912Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T10:02:25.4066057Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T10:02:33.6164284Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_ATEN_KLEIDIAI: 'opaque_aten_kleidiai'>} [33mSKIPPED[0m
2026-01-14T10:02:33.6166710Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>} [33mSKIPPED[0m
2026-01-14T10:02:33.6168664Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_conv2d [32mPASSED[0m
2026-01-14T10:02:33.6170237Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_embedding [32mPASSED[0m
2026-01-14T10:02:33.6172021Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T10:02:33.6174296Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config_with_unwrap [32mPASSED[0m
2026-01-14T10:02:33.6176212Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_intx_weight_only_config [32mPASSED[0m
2026-01-14T10:02:33.6178145Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T10:02:33.6179951Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_intx_weight_only_config [32mPASSED[0m
2026-01-14T10:02:33.6181610Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_linear [32mPASSED[0m
2026-01-14T10:02:33.6184359Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.6187867Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.6191250Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.6194613Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.6198057Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.6201610Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.6204967Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.6208328Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.6211709Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.6215125Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.6218570Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.6221950Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.6225309Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.6228641Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.6231986Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.6235405Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.6238806Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.6242248Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.6245634Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.6249056Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.8697320Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.8700902Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.8704355Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.8707749Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.8711127Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.8714521Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.8718000Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.8721419Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.8724920Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.8728390Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.8731842Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.8735254Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.8738656Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.8742162Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.8745562Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.8748936Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.8752322Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.8755773Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.8759174Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.8762632Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.8766127Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.8769525Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:33.8772927Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:33.8776304Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:33.8779715Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.1233671Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.1237257Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.1240651Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.1244096Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.1247488Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.1250878Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.1254284Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.1257826Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.1261333Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.1264762Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.1268194Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.1271689Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.1275258Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.1278672Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.1282088Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.1285704Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.1289117Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.1292536Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.1296052Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.1299519Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.1302942Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.1306352Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.1309733Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.1313259Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.1316784Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.3754947Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.3758367Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.3761770Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.3765150Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.3768506Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.3772002Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.3775528Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.3778909Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.3782258Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.3785830Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.3789360Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.3792751Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.3796210Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.3799626Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.3803016Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.3806381Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.3809794Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.3815235Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.3818688Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.3822058Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.3825422Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.3828834Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.3832263Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.3835723Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.3839065Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.6299481Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.6302958Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.6306317Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.6309668Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.6313216Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.6316664Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.6320037Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.6323409Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.6326832Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.6330272Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.6333646Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.6337052Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.6340423Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.6343783Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.6347213Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.6350682Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.6354088Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.6357540Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.6360915Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.6364323Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.6367807Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.6371274Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.6374628Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.6377977Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.6381336Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.8832158Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.8835674Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.8839174Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.8842570Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.8845947Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.8849314Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.8852664Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.8856170Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.8859527Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.8862927Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.8866307Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.8869655Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.8872997Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.8876476Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.8879917Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.8883289Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.8886995Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.8890367Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.8893930Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.8897360Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.8900741Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.8904109Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:34.8907485Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:34.8910839Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:34.8914182Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.1323209Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.1326856Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.1330253Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.1333635Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.1336989Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.1340452Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.1343961Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.1347365Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.1350731Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.1354127Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.1357587Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.1360952Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.1364354Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.1367817Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.1371380Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.1374860Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.1378296Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.1382092Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.1385820Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.1389237Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.1392685Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.1396108Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.1399486Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.1402957Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.1406593Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.3838097Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.3841577Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.3845013Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.3848435Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.3852028Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.3855435Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.3858846Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.3862252Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.3865700Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.3869103Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.3872536Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.3876361Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.3879805Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.3883310Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.3887048Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.3890549Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.3894088Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.3897508Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.3900925Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.3904408Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.3908102Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.3911651Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.3915254Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.3918877Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.3922423Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.6200024Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.6203554Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.6206599Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.6209364Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.6212057Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.6214798Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.6217467Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.6220122Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.6222806Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.6225546Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.6228290Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.6230979Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.6233667Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.6236388Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.6239160Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.6241850Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.6244574Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.6247240Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.6249905Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T10:02:35.6252561Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T10:02:35.6255239Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T10:02:35.6257323Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T10:02:35.6258904Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_intx_weight_only_config [32mPASSED[0m
2026-01-14T10:02:35.6260271Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice [32mPASSED[0m
2026-01-14T10:02:35.6261533Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice_and_copy_ [32mPASSED[0m
2026-01-14T10:02:35.6262802Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_to_dtype [32mPASSED[0m
2026-01-14T10:02:35.6263908Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_False [33mSKIPPED[0m
2026-01-14T10:02:35.6264875Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_True [33mSKIPPED[0m
2026-01-14T10:02:35.6265840Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_False [33mSKIPPED[0m
2026-01-14T10:02:35.6266801Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_True [33mSKIPPED[0m
2026-01-14T10:02:35.6267885Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7151436Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7153612Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7154931Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7156037Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7157134Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7158242Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7159348Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7160454Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7161580Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7162677Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7163986Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7165385Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7166810Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7168189Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7169694Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7171063Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7172436Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7173857Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7175219Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7176578Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7177932Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7179293Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7180630Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7182000Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7183453Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7185030Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7186389Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7187839Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7189203Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7190558Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7191904Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7193268Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7194638Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7196090Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7197441Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7198802Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7200166Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7201528Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7202869Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7204229Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7205689Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7207044Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7208465Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7209831Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7211190Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7212537Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T10:02:35.7213931Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T10:02:35.7215112Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_add_tensors [32mPASSED[0m
2026-01-14T10:02:35.7216203Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_inplace_operation [32mPASSED[0m
2026-01-14T10:02:35.7217264Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_pad_unpad [32mPASSED[0m
2026-01-14T10:02:35.7218452Z test/quantization/test_gptq.py::TestMultiTensorInputRecorder::test_multitensor_input_recorder [32mPASSED[0m
2026-01-14T10:02:35.7219552Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_calc_success [32mPASSED[0m
2026-01-14T10:02:35.7220549Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_row_errors [32mPASSED[0m
2026-01-14T10:02:35.7221598Z test/quantization/test_observer.py::TestQuantFlow::test_fixed_qparams_observer [32mPASSED[0m
2026-01-14T10:02:35.7222620Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_channel_affine [32mPASSED[0m
2026-01-14T10:02:35.7223654Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_tensor_affine [32mPASSED[0m
2026-01-14T10:02:35.7224607Z test/quantization/test_observer.py::TestQuantFlow::test_mse_observer [32mPASSED[0m
2026-01-14T10:02:35.7225725Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_False [32mPASSED[0m
2026-01-14T10:02:35.7227013Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_True [32mPASSED[0m
2026-01-14T10:02:35.7228076Z test/quantization/test_qat.py::TestQAT::test_composable_qat_quantizer [32mPASSED[0m
2026-01-14T10:02:35.7228972Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dtype [32mPASSED[0m
2026-01-14T10:02:35.7229985Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dynamic_and_range_learning [32mPASSED[0m
2026-01-14T10:02:35.7230982Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_eps [32mPASSED[0m
2026-01-14T10:02:35.7231897Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity [32mPASSED[0m
2026-01-14T10:02:35.7232931Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity_error_cases [32mPASSED[0m
2026-01-14T10:02:35.7233971Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_mapping_type [32mPASSED[0m
2026-01-14T10:02:51.5594310Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_torch_intx [32mPASSED[0m
2026-01-14T10:02:51.5595263Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_channel_group [32mPASSED[0m
2026-01-14T10:02:51.5596033Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token [32mPASSED[0m
2026-01-14T10:02:51.5596860Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5598077Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float16 [32mPASSED[0m
2026-01-14T10:02:51.5607263Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float32 [32mPASSED[0m
2026-01-14T10:02:51.5608057Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_embedding_4w [32mPASSED[0m
2026-01-14T10:02:51.5608964Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_4w [32mPASSED[0m
2026-01-14T10:02:51.5609703Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_8da4w [32mPASSED[0m
2026-01-14T10:02:51.5610509Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T10:02:51.5611402Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T10:02:51.5612164Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_repr [32mPASSED[0m
2026-01-14T10:02:51.5612939Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_int4_preshuffled_primitives [33mSKIPPED[0m
2026-01-14T10:02:51.5613717Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_primitives [33mSKIPPED[0m
2026-01-14T10:02:51.5614463Z test/quantization/test_qat.py::TestQAT::test_fbgemm_int4_weight_only_primitives [33mSKIPPED[0m
2026-01-14T10:02:51.5615213Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_config [32mPASSED[0m
2026-01-14T10:02:51.5616043Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity0 [32mPASSED[0m
2026-01-14T10:02:51.5616810Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity1 [32mPASSED[0m
2026-01-14T10:02:51.5617523Z test/quantization/test_qat.py::TestQAT::test_infer_fp8_int4_config [32mPASSED[0m
2026-01-14T10:02:51.5618267Z test/quantization/test_qat.py::TestQAT::test_infer_int4_weight_only_config [32mPASSED[0m
2026-01-14T10:02:51.5619083Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e [32mPASSED[0m
2026-01-14T10:02:51.5619862Z test/quantization/test_qat.py::TestQAT::test_nvfp4_fake_quanitzed_linear_mixed_precision [33mSKIPPED[0m
2026-01-14T10:02:51.5620619Z test/quantization/test_qat.py::TestQAT::test_qat_4w_embedding [32mPASSED[0m
2026-01-14T10:02:51.5621329Z test/quantization/test_qat.py::TestQAT::test_qat_4w_linear tensor(5.9366e-05, device='cuda:0', dtype=torch.bfloat16,
2026-01-14T10:02:51.5621925Z        grad_fn=<AbsBackward0>)
2026-01-14T10:02:51.5622231Z [32mPASSED[0m
2026-01-14T10:02:51.5622731Z test/quantization/test_qat.py::TestQAT::test_qat_4w_primitives tensor(0.0005, device='cuda:0', dtype=torch.bfloat16)
2026-01-14T10:02:51.5623331Z [32mPASSED[0m
2026-01-14T10:02:51.5623923Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer tensor(0.0038, device='cuda:0', dtype=torch.bfloat16, grad_fn=<AbsBackward0>)
2026-01-14T10:02:51.5624615Z [32mPASSED[0m
2026-01-14T10:02:51.5625083Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer_gradients [32mPASSED[0m
2026-01-14T10:02:51.5625754Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_eps [32mPASSED[0m
2026-01-14T10:02:51.5626396Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_linear [32mPASSED[0m
2026-01-14T10:02:51.5627109Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5627905Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float16 [32mPASSED[0m
2026-01-14T10:02:51.5628743Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float32 [32mPASSED[0m
2026-01-14T10:02:51.5629464Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer [32mPASSED[0m
2026-01-14T10:02:51.5630199Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant [32mPASSED[0m
2026-01-14T10:02:51.5631044Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant_backward [32mPASSED[0m
2026-01-14T10:02:51.5631907Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_gradients [32mPASSED[0m
2026-01-14T10:02:51.5632659Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_meta_weights [32mPASSED[0m
2026-01-14T10:02:51.5633442Z test/quantization/test_qat.py::TestQAT::test_qat_api_convert_no_quantization [32mPASSED[0m
2026-01-14T10:02:51.5634196Z test/quantization/test_qat.py::TestQAT::test_qat_api_deprecation [32mPASSED[0m
2026-01-14T10:02:51.5634936Z test/quantization/test_qat.py::TestQAT::test_qat_config_init [32mPASSED[0m
2026-01-14T10:02:51.5635591Z test/quantization/test_qat.py::TestQAT::test_qat_fp8a4w_quantizer [32mPASSED[0m
2026-01-14T10:02:51.5636229Z test/quantization/test_qat.py::TestQAT::test_qat_linear_bias [32mPASSED[0m
2026-01-14T10:02:51.5636989Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T10:02:51.5637852Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T10:02:51.5638688Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T10:02:51.5639533Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T10:02:51.5640237Z test/quantization/test_qat.py::TestQAT::test_qat_prototype_bc [32mPASSED[0m
2026-01-14T10:02:51.5640959Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T10:02:51.5641810Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T10:02:51.5642521Z test/quantization/test_qat.py::TestQAT::test_quantize_api_e2e [32mPASSED[0m
2026-01-14T10:02:51.5643172Z test/quantization/test_qat.py::TestQAT::test_quantize_api_errors [32mPASSED[0m
2026-01-14T10:02:51.5643893Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity0 [33mSKIPPED[0m
2026-01-14T10:02:51.5644723Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity1 [33mSKIPPED[0m
2026-01-14T10:02:51.5645453Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_int4 [33mSKIPPED[0m
2026-01-14T10:02:51.5646348Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T10:02:51.5647441Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T10:02:51.5648522Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T10:02:51.5649609Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T10:02:51.5650489Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_int4 [32mPASSED[0m
2026-01-14T10:02:51.5651327Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity0_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5652301Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity1_float32 [32mPASSED[0m
2026-01-14T10:02:51.5653269Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity2_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5654250Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity3_float32 [32mPASSED[0m
2026-01-14T10:02:51.5655225Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity4_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5656203Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity5_float32 [32mPASSED[0m
2026-01-14T10:02:51.5657181Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity6_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5658205Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity7_float32 [32mPASSED[0m
2026-01-14T10:02:51.5659244Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity10_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5660221Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity11_float32 [32mPASSED[0m
2026-01-14T10:02:51.5661256Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity8_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5662235Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity9_float32 [32mPASSED[0m
2026-01-14T10:02:51.5663204Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity12_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5664187Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity13_float32 [32mPASSED[0m
2026-01-14T10:02:51.5665167Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity14_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5666149Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity15_float32 [32mPASSED[0m
2026-01-14T10:02:51.5667134Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity16_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5668116Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity17_float32 [32mPASSED[0m
2026-01-14T10:02:51.5669206Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity18_bfloat16 [32mPASSED[0m
2026-01-14T10:02:51.5670186Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity19_float32 [32mPASSED[0m
2026-01-14T10:02:52.1883644Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity20_bfloat16 [32mPASSED[0m
2026-01-14T10:02:52.1885277Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity21_float32 [32mPASSED[0m
2026-01-14T10:02:52.1886278Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity22_bfloat16 [32mPASSED[0m
2026-01-14T10:02:52.1887273Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity23_float32 [32mPASSED[0m
2026-01-14T10:02:52.1888271Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity24_bfloat16 [32mPASSED[0m
2026-01-14T10:02:52.1889310Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity25_float32 [32mPASSED[0m
2026-01-14T10:02:52.1890300Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity26_bfloat16 [32mPASSED[0m
2026-01-14T10:02:52.1891277Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity27_float32 [32mPASSED[0m
2026-01-14T10:02:52.1892306Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity0_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1893382Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity1_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1894426Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity2_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1895467Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity3_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1896499Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity4_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1897543Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity5_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1898574Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity6_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1899752Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity7_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1900788Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity10_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1901912Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity11_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1902973Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity12_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1904020Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity13_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1905055Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity14_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1906097Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity15_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1907134Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity8_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1908568Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity9_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1910188Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity16_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1911631Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity17_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1912949Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity18_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1914268Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity19_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1915741Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity20_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1917074Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity21_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1918637Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity22_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1920166Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity23_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1921492Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity24_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1922827Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity25_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1924148Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity26_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1925466Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity27_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1926783Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity28_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1928123Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity29_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1929436Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity30_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1930754Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity31_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1932078Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity32_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1935148Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity33_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1936468Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity34_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1937769Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity35_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1939197Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity36_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1940540Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity37_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1941855Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity38_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1943182Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity39_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1944522Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity40_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1945848Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity41_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1947173Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity42_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1948537Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity43_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1949912Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity44_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1951240Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity45_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1952597Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity46_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1953917Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity47_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1955293Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity48_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1956628Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity49_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1957950Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity50_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1959258Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity51_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1960580Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity52_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1961919Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity53_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1963286Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity54_float32_module_type_linear [32mPASSED[0m
2026-01-14T10:02:52.1964624Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity55_float32_module_type_embedding [32mPASSED[0m
2026-01-14T10:02:52.1965851Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T10:03:27.8700353Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T10:03:27.8701214Z test/quantization/test_qat.py::TestQAT::test_quantize_api_prepare [32mPASSED[0m
2026-01-14T10:03:27.8702046Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls0 [32mPASSED[0m
2026-01-14T10:03:27.8703898Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls1 [32mPASSED[0m
2026-01-14T10:03:27.8705063Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls2 [32mPASSED[0m
2026-01-14T10:03:27.8706060Z test/quantization/test_qat.py::TestQAT::test_replace_linear_8da4w [32mPASSED[0m
2026-01-14T10:03:27.8707145Z test/quantization/test_qat.py::TestQAT::test_replace_linear_int4 [32mPASSED[0m
2026-01-14T10:03:27.8707987Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer [32mPASSED[0m
2026-01-14T10:03:27.8708813Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer_linear_bias [32mPASSED[0m
2026-01-14T10:03:27.8709637Z test/quantization/test_quant_api.py::TestQuantFlow::test_config_deprecation [32mPASSED[0m
2026-01-14T10:03:27.8710467Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_singleline [32mPASSED[0m
2026-01-14T10:03:27.8711628Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_eager_mode_impl [33mSKIPPED[0m
2026-01-14T10:03:27.8713022Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_unified_impl [33mSKIPPED[0m
2026-01-14T10:03:27.8714119Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4_wo_quant_save_load [33mSKIPPED[0m
2026-01-14T10:03:27.8715448Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T10:03:27.8716813Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T10:03:27.8717787Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T10:03:27.8718744Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T10:03:27.8720091Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T10:03:27.8721348Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T10:03:27.8722589Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T10:03:27.8723808Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T10:03:27.8724747Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T10:03:27.8725696Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T10:03:27.8726648Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T10:03:27.8727603Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T10:03:27.8728863Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cuda_serialization [32mPASSED[0m
2026-01-14T10:03:27.8729863Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8_wo_quant_save_load [32mPASSED[0m
2026-01-14T10:03:27.8731011Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8wo_quantized_model_to_device [32mPASSED[0m
2026-01-14T10:03:27.8732124Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_default [32mPASSED[0m
2026-01-14T10:03:27.8733183Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_embedding_linear [32mPASSED[0m
2026-01-14T10:03:27.8734218Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_module_name [32mPASSED[0m
2026-01-14T10:03:27.8735190Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_basic [32mPASSED[0m
2026-01-14T10:03:27.8736280Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_fullmatch [32mPASSED[0m
2026-01-14T10:03:27.8737270Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence [32mPASSED[0m
2026-01-14T10:03:27.8738343Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence2 [32mPASSED[0m
2026-01-14T10:03:27.8739428Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_skip [32mPASSED[0m
2026-01-14T10:03:27.8740445Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_model_streaming [32mPASSED[0m
2026-01-14T10:03:27.8741481Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type0 [32mPASSED[0m
2026-01-14T10:03:27.8742590Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type1 [32mPASSED[0m
2026-01-14T10:03:27.8743753Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load [32mPASSED[0m
2026-01-14T10:03:27.8744970Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load_map_location [32mPASSED[0m
2026-01-14T10:03:27.8746082Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config0 [32mPASSED[0m
2026-01-14T10:03:27.8747102Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config1 [32mPASSED[0m
2026-01-14T10:03:27.8748055Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config2 [32mPASSED[0m
2026-01-14T10:03:27.8748928Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config3 [32mPASSED[0m
2026-01-14T10:03:27.8749801Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config4 [32mPASSED[0m
2026-01-14T10:03:27.8750752Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config5 [32mPASSED[0m
2026-01-14T10:03:27.8751711Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config6 [32mPASSED[0m
2026-01-14T10:03:27.8752724Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config7 [32mPASSED[0m
2026-01-14T10:03:27.8753689Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config8 [32mPASSED[0m
2026-01-14T10:03:27.8754627Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config9 [32mPASSED[0m
2026-01-14T10:03:27.8755715Z test/quantization/test_quant_api.py::TestFqnToConfig::test_filter_fn_and_fqn_to_config_error [33mSKIPPED[0m
2026-01-14T10:03:27.8756753Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_module_config_and_fqn_config_both_specified [33mSKIPPED[0m
2026-01-14T10:03:27.8757775Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module [33mSKIPPED[0m
2026-01-14T10:03:27.8758788Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_module_swap [33mSKIPPED[0m
2026-01-14T10:03:27.8759801Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_param [33mSKIPPED[0m
2026-01-14T10:03:27.8760726Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_custom [33mSKIPPED[0m
2026-01-14T10:03:27.8761596Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_linear [33mSKIPPED[0m
2026-01-14T10:03:27.8762574Z test/quantization/test_quant_api.py::TestFqnToConfig::test_non_fqn_config_filter_fn_none [33mSKIPPED[0m
2026-01-14T10:03:27.8763633Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_module_over_param_regex [33mSKIPPED[0m
2026-01-14T10:03:27.8764779Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_default [33mSKIPPED[0m
2026-01-14T10:03:27.8765853Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module [33mSKIPPED[0m
2026-01-14T10:03:27.8767064Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module_regex [33mSKIPPED[0m
2026-01-14T10:03:27.8768147Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_default [33mSKIPPED[0m
2026-01-14T10:03:27.8769305Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_module_regex [33mSKIPPED[0m
2026-01-14T10:03:27.8770388Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param [33mSKIPPED[0m
2026-01-14T10:03:27.8771429Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param_regex [33mSKIPPED[0m
2026-01-14T10:03:27.8772392Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_exact [33mSKIPPED[0m
2026-01-14T10:03:27.8773245Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_regex [33mSKIPPED[0m
2026-01-14T10:03:27.8774156Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantized_model_streaming_fqn_config [33mSKIPPED[0m
2026-01-14T10:03:27.8775028Z test/quantization/test_quant_api.py::TestFqnToConfig::test_top_level_param [33mSKIPPED[0m
2026-01-14T10:03:27.8775996Z test/quantization/test_quant_api.py::TestFqnToConfig::test_unsupported_param_config_raises_not_implemented_error [33mSKIPPED[0m
2026-01-14T10:03:27.8777178Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_and_quantize_scale_only_sinq [32mPASSED[0m
2026-01-14T10:03:56.5714642Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym [32mPASSED[0m
2026-01-14T10:03:56.5719356Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym_no_clipping_err [32mPASSED[0m
2026-01-14T10:03:56.5720980Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym [32mPASSED[0m
2026-01-14T10:03:56.5722245Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym_eps [32mPASSED[0m
2026-01-14T10:03:56.5723468Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_sym [32mPASSED[0m
2026-01-14T10:03:56.5724693Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_token_asym [32mPASSED[0m
2026-01-14T10:03:56.5725892Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine [32mPASSED[0m
2026-01-14T10:03:56.5727164Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine_cachemask [32mPASSED[0m
2026-01-14T10:03:56.5728139Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_blockwise_scaling [32mPASSED[0m
2026-01-14T10:03:56.5729315Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_rowwise_scaling_3d_weight_axis_1 [32mPASSED[0m
2026-01-14T10:03:56.5730379Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric [32mPASSED[0m
2026-01-14T10:03:56.5731514Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric_memory [32mPASSED[0m
2026-01-14T10:03:56.5732528Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_groupwise_affine_qparams [32mPASSED[0m
2026-01-14T10:03:56.5733612Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_dequantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T10:03:56.5734772Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_quantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T10:03:56.5735861Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_maybe_expand_scale_to_tensor_shape [32mPASSED[0m
2026-01-14T10:03:56.5736923Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max [32mPASSED[0m
2026-01-14T10:03:56.5738152Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_dtype [32mPASSED[0m
2026-01-14T10:03:56.5739307Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_zero_input [32mPASSED[0m
2026-01-14T10:03:56.5740488Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym [32mPASSED[0m
2026-01-14T10:03:56.5741522Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d [32mPASSED[0m
2026-01-14T10:03:56.5742667Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d_multi_dim_reduction [32mPASSED[0m
2026-01-14T10:03:56.5743775Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_group_sym [32mPASSED[0m
2026-01-14T10:03:56.5744797Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_tensor_asym [32mPASSED[0m
2026-01-14T10:03:56.5745707Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_raises [32mPASSED[0m
2026-01-14T10:03:56.5746497Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity [33mSKIPPED[0m
2026-01-14T10:03:56.5747306Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity_scaled [33mSKIPPED[0m
2026-01-14T10:03:56.5748171Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_srelu [33mSKIPPED[0m
2026-01-14T10:03:56.5748957Z test/sparsity/test_activation24.py::test_srelu_fp8_semi_sparse_activation_linear [33mSKIPPED[0m
2026-01-14T10:03:56.5749775Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_eye [33mSKIPPED[0m
2026-01-14T10:03:56.5750599Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_random_tensor [33mSKIPPED[0m
2026-01-14T10:03:56.5751676Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification [33mSKIPPED[0m
2026-01-14T10:03:56.5752889Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification_compile [33mSKIPPED[0m
2026-01-14T10:03:56.5753893Z test/sparsity/test_sparse_api.py::TestSemiStructuredSparse::test_sparse [33mSKIPPED[0m
2026-01-14T10:03:56.5754862Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T10:03:56.5755799Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T10:03:56.5756752Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T10:03:56.5757693Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T10:03:56.5758634Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_quant_semi_sparse_compile_False [33mSKIPPED[0m
2026-01-14T10:03:56.5759636Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1 [32mPASSED[0m
2026-01-14T10:03:56.5760609Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024 [32mPASSED[0m
2026-01-14T10:03:56.5761593Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1 [32mPASSED[0m
2026-01-14T10:03:56.5762562Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1024 [32mPASSED[0m
2026-01-14T10:03:56.5763531Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False [32mPASSED[0m
2026-01-14T10:03:56.5764683Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_True [32mPASSED[0m
2026-01-14T10:03:56.5765648Z test/sparsity/test_supermask.py::TestSupermask::test_from_linear [32mPASSED[0m
2026-01-14T10:03:56.5766740Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_2 [32mPASSED[0m
2026-01-14T10:03:56.5767898Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_4 [32mPASSED[0m
2026-01-14T10:03:56.5769082Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_8 [32mPASSED[0m
2026-01-14T10:03:56.5770316Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_2 [32mPASSED[0m
2026-01-14T10:03:56.5771473Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_4 [32mPASSED[0m
2026-01-14T10:03:56.5772628Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_8 [32mPASSED[0m
2026-01-14T10:03:56.5773655Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4 [32mPASSED[0m
2026-01-14T10:03:56.5774658Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T10:03:56.5775588Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_prepare [32mPASSED[0m
2026-01-14T10:03:56.5776430Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_squash_mask [32mPASSED[0m
2026-01-14T10:03:56.5777385Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T10:03:56.5778488Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured_custom_config [32mPASSED[0m
2026-01-14T10:03:56.5779705Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_False [32mPASSED[0m
2026-01-14T10:03:56.5780836Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_True [32mPASSED[0m
2026-01-14T10:03:56.5781961Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cuda_compile_False [32mPASSED[0m
2026-01-14T10:03:56.5783141Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cuda_compile_True [32mPASSED[0m
2026-01-14T10:03:56.5784535Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_False [32mPASSED[0m
2026-01-14T10:03:56.5785755Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_True [32mPASSED[0m
2026-01-14T10:03:56.5786982Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cuda_compile_False [32mPASSED[0m
2026-01-14T10:03:56.5788200Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cuda_compile_True [32mPASSED[0m
2026-01-14T10:03:56.5789350Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T10:03:56.5790430Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_compile_device_cuda [32mPASSED[0m
2026-01-14T10:03:56.5791545Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T10:03:56.5792675Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_correctness_device_cuda [32mPASSED[0m
2026-01-14T10:03:56.5793773Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T10:03:56.5794948Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_compile_device_cuda [32mPASSED[0m
2026-01-14T10:03:56.5796057Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8309451Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_correctness_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8310596Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_Adam4bit [33mSKIPPED[0m
2026-01-14T10:14:32.8311681Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_AdamW4bit [33mSKIPPED[0m
2026-01-14T10:14:32.8313266Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_Adam8bit [33mSKIPPED[0m
2026-01-14T10:14:32.8314336Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_AdamW8bit [33mSKIPPED[0m
2026-01-14T10:14:32.8315554Z test/test_low_bit_optim.py::TestOptim::test_optim_bf16_stochastic_round_correctness_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8316881Z test/test_low_bit_optim.py::TestOptim::test_optim_bf16_stochastic_round_correctness_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8318115Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_1 [32mPASSED[0m
2026-01-14T10:14:32.8319375Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_2 [32mPASSED[0m
2026-01-14T10:14:32.8320618Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_True_grad_accum_1 [32mPASSED[0m
2026-01-14T10:14:32.8321683Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_save_load [32mPASSED[0m
2026-01-14T10:14:32.8322731Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8323929Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam4bit_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8325134Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8326451Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam8bit_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8327681Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8328927Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_AdamFp8_device_cuda [33mSKIPPED[0m
2026-01-14T10:14:32.8330288Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8331456Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8332581Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8333713Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_float32_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8334858Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8335992Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8337127Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8338256Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_float32_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8339393Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8340534Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_bfloat16_device_cuda [33mSKIPPED[0m
2026-01-14T10:14:32.8341656Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8342789Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_float32_device_cuda [33mSKIPPED[0m
2026-01-14T10:14:32.8343924Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8345076Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8346220Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8347464Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_float32_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8348609Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8349804Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8350996Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8352154Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_float32_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8353286Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8354435Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_bfloat16_device_cuda [33mSKIPPED[0m
2026-01-14T10:14:32.8355656Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8356836Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_float32_device_cuda [33mSKIPPED[0m
2026-01-14T10:14:32.8357939Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8358998Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam4bit_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8360111Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8361168Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam8bit_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8362219Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8363275Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_AdamFp8_device_cuda [33mSKIPPED[0m
2026-01-14T10:14:32.8364377Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape0_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8365434Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape0_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8366481Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape1_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8367534Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape1_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8368593Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape0_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8369633Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape0_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8370682Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape1_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8371730Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape1_device_cuda [32mPASSED[0m
2026-01-14T10:14:32.8372774Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape0_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8373824Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape0_device_cuda [33mSKIPPED[0m
2026-01-14T10:14:32.8374871Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape1_device_cpu [32mPASSED[0m
2026-01-14T10:14:32.8375932Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape1_device_cuda [33mSKIPPED[0m
2026-01-14T10:14:32.8377287Z test/test_low_bit_optim.py::TestFSDP2::test_fsdp2 I0114 10:13:13.390000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 0 with pid 20747
2026-01-14T10:14:32.8378685Z I0114 10:13:13.391000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 1 with pid 20748
2026-01-14T10:14:32.8379505Z dist init r=0, world=2
2026-01-14T10:14:32.8379797Z dist init r=1, world=2
2026-01-14T10:14:32.8380990Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T10:14:32.8382252Z   return func(*args, **kwargs)
2026-01-14T10:14:32.8383504Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T10:14:32.8385013Z   return func(*args, **kwargs)
2026-01-14T10:14:32.8386217Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T10:14:32.8387510Z   return func(*args, **kwargs)
2026-01-14T10:14:32.8387877Z [32mPASSED[0m
2026-01-14T10:14:32.8388824Z test/test_low_bit_optim.py::TestFSDP2::test_uneven_shard I0114 10:14:21.501000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 0 with pid 21494
2026-01-14T10:14:32.8390244Z I0114 10:14:21.502000 1007 site-packages/torch/testing/_internal/common_distributed.py:849] Started process 1 with pid 21495
2026-01-14T10:14:32.8391005Z dist init r=0, world=2
2026-01-14T10:14:32.8391289Z dist init r=1, world=2
2026-01-14T10:14:32.8391711Z [32mPASSED[0m
2026-01-14T10:14:32.8392352Z test/test_model_architecture.py::TestModels::test_ln_linear_activation_model_0_cpu [32mPASSED[0m
2026-01-14T10:14:32.8393384Z test/test_model_architecture.py::TestModels::test_ln_linear_activation_model_1_cuda [32mPASSED[0m
2026-01-14T10:14:32.8625790Z test/test_model_architecture.py::TestModels::test_toy_linear_model_0_cpu [32mPASSED[0m
2026-01-14T10:14:32.8626665Z test/test_model_architecture.py::TestModels::test_toy_linear_model_1_cuda [32mPASSED[0m
2026-01-14T10:14:32.8627710Z test/test_model_architecture.py::TestModels::test_transformer_block_0_cpu [32mPASSED[0m
2026-01-14T10:14:32.8628635Z test/test_model_architecture.py::TestModels::test_transformer_block_1_cuda [32mPASSED[0m
2026-01-14T10:14:32.8629769Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8631124Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8632463Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8633817Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8635223Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8636748Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8638348Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8639677Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8641011Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8642449Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8643761Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8645174Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8646532Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8647862Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8649219Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8650573Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8651903Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8653325Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8654673Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8656076Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8657742Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8659297Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8660627Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8661972Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8663317Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8664645Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8666032Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8667709Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8669136Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8670476Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8671863Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8673190Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8674572Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8675972Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8677301Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8678628Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8679959Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8681284Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8682672Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8684006Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8685640Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8687026Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8688374Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8689700Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8691030Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8692376Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8852722Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8854087Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8855423Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8856752Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8858086Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8859519Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8860884Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8862219Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8863555Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8864885Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8866204Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8867598Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8868922Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8870303Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8871626Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8873015Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8874333Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8875730Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8877114Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8878444Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8879791Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8881091Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8882428Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8883771Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8885316Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8886761Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8888102Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8889469Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8890801Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8892132Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8893442Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8894777Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8896111Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8897537Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8898867Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8900247Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8901563Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8902891Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8904217Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8905530Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8906909Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8908237Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8909551Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8910879Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8912204Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.8913518Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.8914945Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.8916255Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9087378Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9088738Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9090044Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9091327Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9092610Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9093889Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9095228Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9096518Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9097855Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9099131Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9100409Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9101699Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9102967Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9104247Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9105534Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9106809Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9108091Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9109383Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9110660Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9111939Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9113268Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9114582Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9115922Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9117510Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9119019Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9120292Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9121576Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9122827Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9124137Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9125418Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9126875Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9128422Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9129701Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9130962Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9132238Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9133510Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9134778Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9136054Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9137386Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9138653Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9139927Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9141257Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9142521Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9143838Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9145116Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9146380Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9147694Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9148972Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9150235Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9151555Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9477169Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9478443Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9479817Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9481069Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9482345Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9483616Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9485124Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9486380Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9487707Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9489000Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9490269Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9491544Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9492827Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9496367Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9497621Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9498970Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9500233Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9501500Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9502785Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9504039Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9505298Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9506677Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9507950Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9509279Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9510552Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9511797Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9513069Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9514333Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9515633Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9516956Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9518216Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9519459Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9520733Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9521994Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9523314Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9524573Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9525882Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9527134Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9528397Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9529664Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9530917Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9532191Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9533462Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9534748Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9536016Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9546346Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T10:14:32.9547779Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T10:14:32.9549064Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T10:14:32.9550146Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_2] [32mPASSED[0m
2026-01-14T10:14:32.9551030Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_4] [32mPASSED[0m
2026-01-14T10:14:32.9551921Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_8] [32mPASSED[0m
2026-01-14T10:14:32.9552811Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_2] [32mPASSED[0m
2026-01-14T10:14:37.7727444Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_4] [32mPASSED[0m
2026-01-14T10:14:37.7728412Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_8] [32mPASSED[0m
2026-01-14T10:14:37.7729333Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_2] [32mPASSED[0m
2026-01-14T10:14:37.7730250Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_4] [32mPASSED[0m
2026-01-14T10:14:37.7731148Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_8] [32mPASSED[0m
2026-01-14T10:14:37.7732039Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_2] [32mPASSED[0m
2026-01-14T10:14:37.7732946Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_4] [32mPASSED[0m
2026-01-14T10:14:37.7734134Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_8] [32mPASSED[0m
2026-01-14T10:14:37.7735042Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_2] [32mPASSED[0m
2026-01-14T10:14:37.7735964Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_4] [32mPASSED[0m
2026-01-14T10:14:37.7736965Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_8] [32mPASSED[0m
2026-01-14T10:14:37.7737826Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_2] [32mPASSED[0m
2026-01-14T10:14:37.7738649Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_4] [32mPASSED[0m
2026-01-14T10:14:37.7739482Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_8] [32mPASSED[0m
2026-01-14T10:14:37.7740318Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_2] [32mPASSED[0m
2026-01-14T10:14:37.7741146Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_4] [32mPASSED[0m
2026-01-14T10:14:37.7741962Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_8] [32mPASSED[0m
2026-01-14T10:14:37.7742779Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_2] [32mPASSED[0m
2026-01-14T10:14:37.7743604Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_4] [32mPASSED[0m
2026-01-14T10:14:37.7744517Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_8] [32mPASSED[0m
2026-01-14T10:14:37.7745329Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_2] [32mPASSED[0m
2026-01-14T10:14:37.7746147Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_4] [32mPASSED[0m
2026-01-14T10:14:37.7747056Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_8] [32mPASSED[0m
2026-01-14T10:14:37.7747874Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_2] [32mPASSED[0m
2026-01-14T10:14:37.7748741Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_4] [32mPASSED[0m
2026-01-14T10:14:37.7749545Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_8] [32mPASSED[0m
2026-01-14T10:14:37.7750471Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T10:14:37.7751458Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T10:14:37.7752457Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T10:14:37.7753452Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T10:14:37.7754435Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T10:14:37.7755506Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T10:14:37.7756495Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T10:14:37.7757508Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T10:14:37.7758515Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T10:14:37.7759520Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T10:14:37.7760523Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T10:14:37.7761578Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T10:14:37.7762576Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T10:14:37.7763626Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T10:14:37.7764632Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T10:14:37.7765643Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T10:14:37.7766655Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T10:14:37.7767660Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T10:14:37.7768723Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T10:14:37.7769723Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T10:14:37.7770753Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T10:14:37.7771819Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T10:14:37.7772819Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T10:14:37.7773830Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T10:14:37.7774879Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T10:14:37.7775886Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T10:14:37.7776914Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T10:14:37.7777922Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T10:14:37.7778988Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T10:14:37.7779988Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T10:14:37.7780986Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T10:14:37.7782001Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T10:14:37.7782995Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T10:14:37.7784003Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T10:14:37.7785189Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T10:14:37.7786215Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T10:14:37.7787235Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T10:14:37.7788241Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T10:14:37.7789344Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T10:14:37.7790367Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T10:14:37.7791432Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T10:14:37.7792444Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T10:14:37.7793443Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T10:14:37.7794437Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T10:14:37.7795494Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T10:14:42.0495918Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T10:14:42.0496996Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T10:14:42.0498016Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T10:14:42.0499208Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T10:14:42.0500216Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T10:14:42.0501218Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T10:14:42.0502312Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T10:14:42.0503317Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T10:14:42.0504329Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T10:14:42.0505344Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T10:14:42.0506350Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T10:14:42.0507361Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T10:14:42.0508360Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T10:14:42.0509391Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T10:14:42.0510434Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T10:14:42.0511452Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T10:14:42.0512493Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T10:14:42.0513536Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T10:14:42.0514589Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T10:14:42.0515703Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T10:14:42.0516805Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T10:14:42.0517856Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T10:14:42.0518985Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T10:14:42.0520013Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T10:14:42.0521047Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T10:14:42.0522064Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T10:14:42.0523129Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T10:14:42.0524174Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T10:14:42.0525207Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T10:14:42.0526272Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T10:14:42.0527366Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T10:14:42.0528416Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T10:14:42.0529474Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T10:14:42.0530569Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T10:14:42.0531632Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T10:14:42.0532669Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T10:14:42.0533707Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T10:14:42.0534765Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T10:14:42.0535807Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T10:14:42.0536859Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T10:14:42.0537906Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T10:14:42.0538941Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T10:14:42.0540000Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T10:14:42.0541045Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T10:14:42.0542095Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T10:14:42.0543150Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T10:14:42.0544245Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T10:14:42.0545302Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T10:14:42.0546357Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T10:14:42.0547444Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T10:14:42.0548508Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T10:14:42.0549552Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T10:14:42.0550613Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T10:14:42.0551676Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T10:14:42.0552717Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T10:14:42.0553771Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T10:14:42.0554906Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T10:14:42.0555949Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T10:14:42.0557002Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T10:14:42.0558097Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T10:14:42.0559151Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T10:14:42.0560200Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T10:14:42.0561258Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T10:14:42.0562321Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T10:14:42.0563370Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T10:14:50.9258468Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T10:14:50.9259594Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T10:14:50.9260654Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T10:14:50.9261700Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T10:14:50.9262737Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T10:14:50.9263799Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T10:14:50.9264835Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T10:14:50.9265885Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T10:14:50.9267093Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T10:14:50.9268142Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T10:14:50.9269137Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T10:14:50.9269943Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T10:14:50.9270736Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T10:14:50.9271537Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T10:14:50.9272323Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T10:14:50.9273150Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T10:14:50.9273944Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T10:14:50.9274743Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T10:14:50.9275607Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T10:14:50.9276480Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T10:14:50.9277270Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T10:14:50.9278053Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T10:14:50.9278846Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T10:14:50.9279707Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T10:14:50.9280511Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T10:14:50.9281317Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T10:14:50.9282115Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T10:14:50.9282958Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T10:14:50.9283748Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T10:14:50.9284711Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T10:14:50.9285504Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T10:14:50.9286298Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T10:14:50.9287089Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T10:14:50.9287878Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T10:14:50.9288681Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T10:14:50.9289472Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T10:14:50.9290261Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T10:14:50.9291058Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T10:14:50.9291840Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T10:14:50.9292747Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T10:14:50.9293529Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T10:14:50.9294329Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T10:14:50.9295129Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T10:14:50.9295975Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T10:14:50.9296786Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T10:14:50.9297587Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T10:14:50.9298391Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T10:14:50.9299196Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T10:14:50.9299987Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T10:14:50.9300793Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T10:14:50.9301592Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T10:14:50.9302440Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T10:14:50.9303301Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T10:14:50.9304095Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T10:14:50.9304895Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T10:14:50.9305743Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T10:14:50.9306546Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T10:14:50.9307349Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T10:14:50.9308136Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T10:14:50.9308937Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T10:14:50.9309721Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T10:14:50.9310535Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T10:14:50.9311338Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T10:14:50.9312127Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T10:14:50.9312937Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T10:14:50.9313732Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T10:14:50.9314529Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T10:14:50.9315378Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T10:14:50.9316171Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T10:14:50.9316981Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T10:14:50.9317671Z test/test_ops.py::test_swizzle_mm [33mSKIPPED[0m (ROCm not available)
2026-01-14T10:14:50.9318347Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9319148Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9319897Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9320659Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9321440Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9322181Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9322948Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9323679Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9324419Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9325157Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9676164Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9677670Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9679132Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9680613Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9682261Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9683134Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9683908Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9684814Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9685653Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9686405Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9687180Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9687960Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9688729Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9689497Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9690250Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9690982Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9691735Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9692479Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9693228Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9693954Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9694701Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9695432Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9696178Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9696939Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9697675Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9698505Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9699245Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9699999Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9700821Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9701585Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9702351Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9703115Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9703889Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9704661Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9705421Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9706199Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9706963Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9707733Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9708545Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9709266Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9710008Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9710741Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9711531Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9712265Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9712999Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9713732Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9714462Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9715253Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9715985Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9716728Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9717476Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9718207Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9718959Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9719715Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9720481Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9721248Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9721992Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9722748Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9723510Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9724331Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9725089Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9725854Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9726648Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9727385Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9728135Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9728880Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9729634Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9730388Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9731113Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9731853Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9732585Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9733339Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9734141Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9734881Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9735638Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9736380Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9737219Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9737977Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9738750Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9739527Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9740286Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9741047Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9741811Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9742584Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9743371Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9744143Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9744887Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:50.9745611Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:50.9746348Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0081323Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0082087Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0082861Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0083691Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0084611Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0085355Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0086097Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0086913Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0087668Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0088402Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0089144Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0089890Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0090661Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0091421Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0092169Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0092928Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0093671Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0094495Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0095264Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0096025Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0096788Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0097619Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0098344Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0099075Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0099825Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0100569Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0101305Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0102034Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0102804Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0103543Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0104288Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0105018Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0105769Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0106507Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0107253Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0108015Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0108767Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0109527Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0110342Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0111104Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0111848Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0112662Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0113423Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0114174Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0114982Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0124500Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0125354Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0126097Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0126819Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0127547Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0128273Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0129094Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0129804Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0130540Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0131291Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0132077Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0132871Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0133594Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0134347Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0135095Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0135838Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0136587Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0137329Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0138088Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0138837Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0139584Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0140350Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0141105Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0141869Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0142601Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0143317Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0144052Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0144840Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0145587Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0146315Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0147089Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0147821Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0148545Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0149288Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0150017Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0150755Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0151496Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0152227Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0152969Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0153725Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0154530Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0155344Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0156097Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0156847Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0157646Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0407603Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0408411Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T10:14:51.0409175Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T10:14:51.0410071Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0411054Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0412036Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0413027Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0414011Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0414985Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0415974Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0416955Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0417953Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0418917Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0419904Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0421009Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0421994Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0422990Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0424048Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0425062Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0426068Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0427043Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0428047Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0429046Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0430056Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0431048Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0432103Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0433118Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0434104Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0435210Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0436204Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0437192Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0438179Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0439172Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0440148Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0441134Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0442108Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0443078Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0444065Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0445038Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0446022Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0446997Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0447991Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0449023Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0450005Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0450990Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0452033Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0453032Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0454028Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0455008Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0456014Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0457004Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0457986Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0458968Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0459987Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0460983Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0461958Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0462976Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0463962Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0464940Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0465920Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0466896Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0467875Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0468863Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0469844Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0470825Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0471818Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0472810Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0473799Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0474764Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0475804Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0476802Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0728022Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0729049Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0730152Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0731158Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0732155Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0733148Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0734136Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0735131Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0736111Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0737089Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0738147Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0739128Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0740114Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0741086Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0742145Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0743143Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0744126Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0745121Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0746107Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0747134Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0748142Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0749130Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0750127Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0751127Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0752132Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0753145Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0754131Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0755193Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0756254Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0757224Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0758217Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0759243Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0760230Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0761210Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0762202Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0763262Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0764247Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0765224Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0766209Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0767224Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0768213Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0769193Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0770236Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0771246Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0772245Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0773237Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0774242Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0775258Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0776256Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0777244Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0778250Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0779248Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0780234Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0781217Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0782195Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0783191Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0784381Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0785346Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0786333Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0787395Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0788384Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0789369Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0790343Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0791336Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0792307Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0793287Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0794290Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0795400Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.0796391Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.0797368Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1047013Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1048060Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1049054Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1050047Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1051038Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1052049Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1053043Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1054020Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1055001Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1055988Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1056972Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1057958Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1058935Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1059925Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1060905Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1061939Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1062921Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1063962Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1064950Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1065940Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1066925Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1067934Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1068922Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1069910Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1070907Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1071975Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1072963Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1073935Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1075003Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1076086Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1077063Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1078041Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1079023Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1080013Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1080990Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1081959Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1082950Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1083937Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1085141Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1086121Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1087102Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1088108Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1089099Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1090161Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1091151Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1092146Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1093209Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1094207Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1095193Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1096205Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1097197Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1098176Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1099169Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1100172Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1101229Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1102197Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1103190Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1104246Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1105225Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1106196Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1107174Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1108170Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1109152Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1110120Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1111111Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1112089Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1113077Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1114063Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1115105Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1116109Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1329302Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1330401Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1331402Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1332411Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1333462Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1334446Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1335438Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T10:14:51.1336432Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T10:14:51.1337495Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1338585Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1339678Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1340763Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1341916Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1343001Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1344138Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1345212Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1346291Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1347378Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1348488Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1349580Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1350689Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1351796Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1352890Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1354002Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1355145Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1356263Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1357372Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1358535Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1359650Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1360765Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1361904Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1363057Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1364158Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1365272Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1366381Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1367474Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1368567Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1369709Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1370822Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1371926Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1373082Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1374185Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1375298Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1376399Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1377513Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1378625Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1379742Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1380858Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1381952Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1383060Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1384340Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1385433Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1386548Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1387739Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1388853Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1390030Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1391144Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1392254Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1393362Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1394477Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1395640Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1396748Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1608331Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1609467Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1610575Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1611780Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1612905Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1614005Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1615123Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1616233Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1617341Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1618452Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1619555Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1620661Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1621773Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1622885Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1624004Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1625116Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1626308Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1627427Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1628578Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1629669Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1630771Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1631873Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1632991Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1634091Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1635266Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1636377Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1637548Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1638666Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1639813Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1640913Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1642025Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1643128Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1644233Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1645334Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1646424Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1647531Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1648634Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1649740Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1650857Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1651950Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1653052Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1654207Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1655308Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1656406Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1657545Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1658644Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1659757Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1660876Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1661999Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1663125Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1664241Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1665408Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1666517Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1667624Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1668797Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1669928Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1671059Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1672192Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1673326Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1674452Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1675629Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1887183Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1888351Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1889479Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1890610Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1891731Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1900296Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1901411Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1902573Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1903797Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1904924Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1906044Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1907157Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1908280Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1909410Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1910537Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1911730Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1912841Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1913959Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1915220Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1916336Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1917438Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1918544Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1919652Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1920770Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1921888Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1922998Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1924119Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1925233Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1926346Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1927430Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1928570Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1929653Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1930713Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1931834Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1932903Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1933955Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1935019Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1936083Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1937153Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1938240Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1939392Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1940487Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1941574Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1942713Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1943810Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1944903Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1945990Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1947079Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1948148Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1949242Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1950329Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1951423Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1952513Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1953599Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1954682Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1955815Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1956959Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1958046Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1959176Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T10:14:51.1960253Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T10:14:51.1961343Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2166602Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2167740Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2168830Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2169927Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2171034Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2172248Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2173358Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2174529Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2175631Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2176737Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2177841Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2178953Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2180071Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2181174Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2182276Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2183375Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2184630Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2185738Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2186852Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2187951Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2189136Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2190237Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2192629Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2193750Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2194933Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2196035Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2197154Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2198254Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2199353Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2200464Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2201642Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2202746Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2203941Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2205046Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2206154Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2207247Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2208351Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2209449Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2210551Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2211659Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2212750Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2213849Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2214949Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2216043Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2217143Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2218286Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2219381Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2220474Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2221614Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2222709Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2223804Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2224895Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2225994Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2227084Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2228186Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2229330Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2230421Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2231513Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2232652Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2233740Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2234905Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2436040Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2438240Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2440420Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2442524Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2443653Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2444741Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2445833Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2446940Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2448049Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2449165Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2450378Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2451485Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2452661Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2453782Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2454883Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2456003Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2457122Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2458251Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2459381Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2460561Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2461695Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2462830Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2464015Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2465134Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2466250Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2467377Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2468502Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2469616Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2470747Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2471865Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2473038Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2474151Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2475316Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2476431Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2477550Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2478731Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2479849Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2481007Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2482138Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2483262Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2484614Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2485749Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2486860Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2487977Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2489164Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2490279Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2491408Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2492591Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2493712Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2494836Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2495962Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2497182Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype0-Xq_Wq_dtypes0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2498500Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype1-Xq_Wq_dtypes1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2499834Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype2-Xq_Wq_dtypes2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2501157Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype3-Xq_Wq_dtypes3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2502488Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype4-Xq_Wq_dtypes4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2503800Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype5-Xq_Wq_dtypes5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2505117Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype6-Xq_Wq_dtypes6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2506481Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype7-Xq_Wq_dtypes7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2669146Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype8-Xq_Wq_dtypes8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2671948Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype9-Xq_Wq_dtypes9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2673565Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype10-Xq_Wq_dtypes10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2674964Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype11-Xq_Wq_dtypes11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2676315Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype12-Xq_Wq_dtypes12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2677668Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype13-Xq_Wq_dtypes13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2679007Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype14-Xq_Wq_dtypes14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2680355Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype15-Xq_Wq_dtypes15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2681787Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype16-Xq_Wq_dtypes16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2683133Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype17-Xq_Wq_dtypes17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2684679Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype18-Xq_Wq_dtypes18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2686037Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype19-Xq_Wq_dtypes19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2687382Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype20-Xq_Wq_dtypes20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2688718Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype21-Xq_Wq_dtypes21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2690062Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype22-Xq_Wq_dtypes22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2691400Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype23-Xq_Wq_dtypes23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2692799Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype24-Xq_Wq_dtypes24-1-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2694146Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype25-Xq_Wq_dtypes25-1-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2695490Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype26-Xq_Wq_dtypes26-1-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2696835Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype27-Xq_Wq_dtypes27-1-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2698175Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype28-Xq_Wq_dtypes28-1-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2699575Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype29-Xq_Wq_dtypes29-1-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2700921Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype30-Xq_Wq_dtypes30-1-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2702321Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype31-Xq_Wq_dtypes31-1-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2703671Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype32-Xq_Wq_dtypes32-1-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2705020Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype33-Xq_Wq_dtypes33-1-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2706368Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype34-Xq_Wq_dtypes34-1-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2707707Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype35-Xq_Wq_dtypes35-1-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2709054Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype36-Xq_Wq_dtypes36-4-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2710459Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype37-Xq_Wq_dtypes37-4-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2711803Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype38-Xq_Wq_dtypes38-4-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2713194Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype39-Xq_Wq_dtypes39-4-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2714538Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype40-Xq_Wq_dtypes40-4-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2715941Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype41-Xq_Wq_dtypes41-4-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2717288Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype42-Xq_Wq_dtypes42-4-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2718623Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype43-Xq_Wq_dtypes43-4-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2719967Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype44-Xq_Wq_dtypes44-4-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2721313Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype45-Xq_Wq_dtypes45-4-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2722650Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype46-Xq_Wq_dtypes46-4-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2723992Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype47-Xq_Wq_dtypes47-4-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2725330Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype48-Xq_Wq_dtypes48-1-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2726669Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype49-Xq_Wq_dtypes49-1-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2728014Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype50-Xq_Wq_dtypes50-1-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2729420Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype51-Xq_Wq_dtypes51-1-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2730798Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype52-Xq_Wq_dtypes52-1-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2732150Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype53-Xq_Wq_dtypes53-1-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2733537Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype54-Xq_Wq_dtypes54-1-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2734886Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype55-Xq_Wq_dtypes55-1-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2736235Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype56-Xq_Wq_dtypes56-1-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2737577Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype57-Xq_Wq_dtypes57-1-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2897534Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype58-Xq_Wq_dtypes58-1-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2898984Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype59-Xq_Wq_dtypes59-1-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2900333Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype60-Xq_Wq_dtypes60-4-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2901738Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype61-Xq_Wq_dtypes61-4-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2903088Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype62-Xq_Wq_dtypes62-4-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2904429Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype63-Xq_Wq_dtypes63-4-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2905786Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype64-Xq_Wq_dtypes64-4-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2907133Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype65-Xq_Wq_dtypes65-4-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2908474Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype66-Xq_Wq_dtypes66-4-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2909820Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype67-Xq_Wq_dtypes67-4-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2911167Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype68-Xq_Wq_dtypes68-4-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2912499Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype69-Xq_Wq_dtypes69-4-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2913846Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype70-Xq_Wq_dtypes70-4-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2915232Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype71-Xq_Wq_dtypes71-4-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2916649Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype72-Xq_Wq_dtypes72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2917985Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype73-Xq_Wq_dtypes73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2919382Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype74-Xq_Wq_dtypes74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2920728Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype75-Xq_Wq_dtypes75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2922066Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype76-Xq_Wq_dtypes76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2923458Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype77-Xq_Wq_dtypes77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2924804Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype78-Xq_Wq_dtypes78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2926138Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype79-Xq_Wq_dtypes79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2927517Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype80-Xq_Wq_dtypes80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2928859Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype81-Xq_Wq_dtypes81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2930239Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype82-Xq_Wq_dtypes82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2931575Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype83-Xq_Wq_dtypes83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2932919Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype84-Xq_Wq_dtypes84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2934261Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype85-Xq_Wq_dtypes85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2935599Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype86-Xq_Wq_dtypes86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2936941Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype87-Xq_Wq_dtypes87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2938282Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype88-Xq_Wq_dtypes88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2939622Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype89-Xq_Wq_dtypes89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2940965Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype90-Xq_Wq_dtypes90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2942303Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype91-Xq_Wq_dtypes91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2943694Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype92-Xq_Wq_dtypes92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2945038Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype93-Xq_Wq_dtypes93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2946427Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype94-Xq_Wq_dtypes94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2947839Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype95-Xq_Wq_dtypes95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2949188Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype96-Xq_Wq_dtypes96-1-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2950519Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype97-Xq_Wq_dtypes97-1-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2951860Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype98-Xq_Wq_dtypes98-1-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2953250Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype99-Xq_Wq_dtypes99-1-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2954613Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype100-Xq_Wq_dtypes100-1-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2956053Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype101-Xq_Wq_dtypes101-1-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2957485Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype102-Xq_Wq_dtypes102-1-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2958863Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype103-Xq_Wq_dtypes103-1-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2960284Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype104-Xq_Wq_dtypes104-1-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2961655Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype105-Xq_Wq_dtypes105-1-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T10:14:51.2963026Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype106-Xq_Wq_dtypes106-1-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T10:14:51.2964406Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype107-Xq_Wq_dtypes107-1-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3121230Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype108-Xq_Wq_dtypes108-4-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3122665Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype109-Xq_Wq_dtypes109-4-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3124047Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype110-Xq_Wq_dtypes110-4-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3125414Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype111-Xq_Wq_dtypes111-4-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3126789Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype112-Xq_Wq_dtypes112-4-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3128155Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype113-Xq_Wq_dtypes113-4-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3129523Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype114-Xq_Wq_dtypes114-4-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3130977Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype115-Xq_Wq_dtypes115-4-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3132365Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype116-Xq_Wq_dtypes116-4-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3133826Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype117-Xq_Wq_dtypes117-4-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3135201Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype118-Xq_Wq_dtypes118-4-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3136568Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype119-Xq_Wq_dtypes119-4-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3137941Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype120-Xq_Wq_dtypes120-1-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3139318Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype121-Xq_Wq_dtypes121-1-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3140684Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype122-Xq_Wq_dtypes122-1-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3142122Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype123-Xq_Wq_dtypes123-1-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3143489Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype124-Xq_Wq_dtypes124-1-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3144910Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype125-Xq_Wq_dtypes125-1-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3146268Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype126-Xq_Wq_dtypes126-1-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3147636Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype127-Xq_Wq_dtypes127-1-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3149012Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype128-Xq_Wq_dtypes128-1-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3150401Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype129-Xq_Wq_dtypes129-1-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3151780Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype130-Xq_Wq_dtypes130-1-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3153148Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype131-Xq_Wq_dtypes131-1-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3154534Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype132-Xq_Wq_dtypes132-4-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3155965Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype133-Xq_Wq_dtypes133-4-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3157339Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype134-Xq_Wq_dtypes134-4-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3158707Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype135-Xq_Wq_dtypes135-4-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3160119Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype136-Xq_Wq_dtypes136-4-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3161495Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype137-Xq_Wq_dtypes137-4-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3162910Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype138-Xq_Wq_dtypes138-4-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3164277Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype139-Xq_Wq_dtypes139-4-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3165645Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype140-Xq_Wq_dtypes140-4-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3167023Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype141-Xq_Wq_dtypes141-4-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3168376Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype142-Xq_Wq_dtypes142-4-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3169748Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype143-Xq_Wq_dtypes143-4-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3171165Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype144-Xq_Wq_dtypes144-1-size_mnk144-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3172537Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype145-Xq_Wq_dtypes145-1-size_mnk145-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3173950Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype146-Xq_Wq_dtypes146-1-size_mnk146-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3175318Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype147-Xq_Wq_dtypes147-1-size_mnk147-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3176699Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype148-Xq_Wq_dtypes148-1-size_mnk148-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3178069Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype149-Xq_Wq_dtypes149-1-size_mnk149-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3179434Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype150-Xq_Wq_dtypes150-1-size_mnk150-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3180806Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype151-Xq_Wq_dtypes151-1-size_mnk151-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3182176Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype152-Xq_Wq_dtypes152-1-size_mnk152-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3183537Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype153-Xq_Wq_dtypes153-1-size_mnk153-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3185079Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype154-Xq_Wq_dtypes154-1-size_mnk154-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3186459Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype155-Xq_Wq_dtypes155-1-size_mnk155-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3187834Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype156-Xq_Wq_dtypes156-4-size_mnk156-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3538973Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype157-Xq_Wq_dtypes157-4-size_mnk157-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3540381Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype158-Xq_Wq_dtypes158-4-size_mnk158-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3541881Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype159-Xq_Wq_dtypes159-4-size_mnk159-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3543247Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype160-Xq_Wq_dtypes160-4-size_mnk160-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3544611Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype161-Xq_Wq_dtypes161-4-size_mnk161-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3545993Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype162-Xq_Wq_dtypes162-4-size_mnk162-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3547366Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype163-Xq_Wq_dtypes163-4-size_mnk163-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3548731Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype164-Xq_Wq_dtypes164-4-size_mnk164-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3550137Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype165-Xq_Wq_dtypes165-4-size_mnk165-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3551501Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype166-Xq_Wq_dtypes166-4-size_mnk166-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3552977Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype167-Xq_Wq_dtypes167-4-size_mnk167-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3554319Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype168-Xq_Wq_dtypes168-1-size_mnk168-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3555766Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype169-Xq_Wq_dtypes169-1-size_mnk169-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3557132Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype170-Xq_Wq_dtypes170-1-size_mnk170-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3558504Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype171-Xq_Wq_dtypes171-1-size_mnk171-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3559877Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype172-Xq_Wq_dtypes172-1-size_mnk172-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3561249Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype173-Xq_Wq_dtypes173-1-size_mnk173-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3562618Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype174-Xq_Wq_dtypes174-1-size_mnk174-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3563984Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype175-Xq_Wq_dtypes175-1-size_mnk175-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3565359Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype176-Xq_Wq_dtypes176-1-size_mnk176-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3566733Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype177-Xq_Wq_dtypes177-1-size_mnk177-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3568188Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype178-Xq_Wq_dtypes178-1-size_mnk178-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3569561Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype179-Xq_Wq_dtypes179-1-size_mnk179-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3570985Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype180-Xq_Wq_dtypes180-4-size_mnk180-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3572358Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype181-Xq_Wq_dtypes181-4-size_mnk181-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3573771Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype182-Xq_Wq_dtypes182-4-size_mnk182-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3575136Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype183-Xq_Wq_dtypes183-4-size_mnk183-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3576504Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype184-Xq_Wq_dtypes184-4-size_mnk184-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3577884Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype185-Xq_Wq_dtypes185-4-size_mnk185-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3579313Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype186-Xq_Wq_dtypes186-4-size_mnk186-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3580680Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype187-Xq_Wq_dtypes187-4-size_mnk187-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3582062Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype188-Xq_Wq_dtypes188-4-size_mnk188-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3583489Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype189-Xq_Wq_dtypes189-4-size_mnk189-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3595859Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype190-Xq_Wq_dtypes190-4-size_mnk190-False] [33mSKIPPED[0m
2026-01-14T10:14:51.3597226Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype191-Xq_Wq_dtypes191-4-size_mnk191-True] [33mSKIPPED[0m
2026-01-14T10:14:51.3598235Z test/test_utils.py::TestTorchVersion::test_torch_version_at_least [32mPASSED[0m
2026-01-14T10:14:51.3598906Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls [32mPASSED[0m
2026-01-14T10:14:51.3599625Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_attr [32mPASSED[0m
2026-01-14T10:14:51.3600429Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_data [32mPASSED[0m
2026-01-14T10:14:51.3601246Z test/test_utils.py::TestTorchAOBaseTensor::test_implements_and_torch_function_together [32mPASSED[0m
2026-01-14T10:14:51.3601986Z test/test_utils.py::TestTorchAOBaseTensor::test_print_arg_types [32mPASSED[0m
2026-01-14T10:14:51.3602333Z 
2026-01-14T10:14:51.3602582Z [33m=============================== warnings summary ===============================[0m
2026-01-14T10:14:51.3603155Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1
2026-01-14T10:14:51.3605118Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1: DeprecationWarning: Importing from torchao.dtypes.uintx.dyn_int8_act_int4_wei_cpu_layout is deprecated. Please use 'from torchao.prototype.dtypes import Int8DynamicActInt4WeightCPULayout' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T10:14:51.3607084Z     from .dyn_int8_act_int4_wei_cpu_layout import (
2026-01-14T10:14:51.3607326Z 
2026-01-14T10:14:51.3607597Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22
2026-01-14T10:14:51.3609515Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22: DeprecationWarning: Importing from torchao.dtypes.uintx.uintx_layout is deprecated. Please use 'from torchao.prototype.dtypes import UintxLayout, UintxTensor' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T10:14:51.3611161Z     from .uintx_layout import (
2026-01-14T10:14:51.3611342Z 
2026-01-14T10:14:51.3611589Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23
2026-01-14T10:14:51.3613473Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23: DeprecationWarning: Importing BlockSparseLayout from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import BlockSparseLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T10:14:51.3615199Z     from .uintx.block_sparse_layout import BlockSparseLayout
2026-01-14T10:14:51.3615481Z 
2026-01-14T10:14:51.3615728Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24
2026-01-14T10:14:51.3617591Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24: DeprecationWarning: Importing from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import CutlassInt4PackedLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T10:14:51.3619313Z     from .uintx.cutlass_int4_packed_layout import CutlassInt4PackedLayout
2026-01-14T10:14:51.3619650Z 
2026-01-14T10:14:51.3620110Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539: 2 warnings
2026-01-14T10:14:51.3620715Z test/core/test_config.py: 2 warnings
2026-01-14T10:14:51.3621017Z test/dtypes/test_uintx.py: 84 warnings
2026-01-14T10:14:51.3621316Z test/hqq/test_hqq_affine.py: 6 warnings
2026-01-14T10:14:51.3622471Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539: UserWarning: `UIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T10:14:51.3623662Z     warnings.warn(
2026-01-14T10:14:51.3623800Z 
2026-01-14T10:14:51.3624133Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T10:14:51.3624902Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T10:14:51.3625569Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7]
2026-01-14T10:14:51.3626190Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_print_quantized_module
2026-01-14T10:14:51.3626826Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_weights_only
2026-01-14T10:14:51.3627541Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cuda_bfloat16
2026-01-14T10:14:51.3629060Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209: UserWarning: `Int4DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T10:14:51.3630299Z     warnings.warn(
2026-01-14T10:14:51.3630436Z 
2026-01-14T10:14:51.3630816Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: 3 warnings
2026-01-14T10:14:51.3631401Z test/core/test_config.py: 2 warnings
2026-01-14T10:14:51.3631773Z test/dtypes/test_affine_quantized.py: 4 warnings
2026-01-14T10:14:51.3632135Z test/integration/test_integration.py: 6 warnings
2026-01-14T10:14:51.3632477Z test/quantization/test_qat.py: 6 warnings
2026-01-14T10:14:51.3632808Z test/quantization/test_quant_api.py: 2 warnings
2026-01-14T10:14:51.3634159Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: UserWarning: `Int8DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T10:14:51.3635416Z     warnings.warn(
2026-01-14T10:14:51.3635555Z 
2026-01-14T10:14:51.3635884Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T10:14:51.3636645Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T10:14:51.3637321Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14]
2026-01-14T10:14:51.3638645Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272: UserWarning: `GemliteUIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T10:14:51.3639814Z     warnings.warn(
2026-01-14T10:14:51.3639952Z 
2026-01-14T10:14:51.3640280Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: 1 warning
2026-01-14T10:14:51.3640864Z test/core/test_config.py: 1 warning
2026-01-14T10:14:51.3641166Z test/prototype/test_parq.py: 25 warnings
2026-01-14T10:14:51.3641502Z test/quantization/test_quant_api.py: 2 warnings
2026-01-14T10:14:51.3642770Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: UserWarning: Config Deprecation: _default is deprecated and will no longer be supported in a future release. Please see https://github.com/pytorch/ao/issues/3229 for more details.
2026-01-14T10:14:51.3643959Z     warnings.warn(
2026-01-14T10:14:51.3644137Z 
2026-01-14T10:14:51.3644416Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torch/jit/_script.py:365: 14 warnings
2026-01-14T10:14:51.3645481Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/jit/_script.py:365: DeprecationWarning: `torch.jit.script_method` is deprecated. Please switch to `torch.compile` or `torch.export`.
2026-01-14T10:14:51.3646350Z     warnings.warn(
2026-01-14T10:14:51.3646484Z 
2026-01-14T10:14:51.3646616Z test/prototype/mx_formats/test_mx_tensor.py:531
2026-01-14T10:14:51.3647782Z   /pytorch/ao/test/prototype/mx_formats/test_mx_tensor.py:531: PytestUnknownMarkWarning: Unknown pytest.mark.skipIf - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
2026-01-14T10:14:51.3648991Z     @pytest.mark.skipIf(not is_sm_at_least_90(), "Need sm90+")
2026-01-14T10:14:51.3649270Z 
2026-01-14T10:14:51.3649509Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torch/jit/_script.py:1487
2026-01-14T10:14:51.3650084Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torch/jit/_script.py:1487
2026-01-14T10:14:51.3651068Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/jit/_script.py:1487: DeprecationWarning: `torch.jit.script` is deprecated. Please switch to `torch.compile` or `torch.export`.
2026-01-14T10:14:51.3651907Z     warnings.warn(
2026-01-14T10:14:51.3652042Z 
2026-01-14T10:14:51.3652378Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360
2026-01-14T10:14:51.3654141Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360: UserWarning: `Float8StaticActivationFloat8WeightConfig` version 1 will be deleted in a future release of torchao. Please migrate to version 2 by setting version=2. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T10:14:51.3655653Z     warnings.warn(
2026-01-14T10:14:51.3655784Z 
2026-01-14T10:14:51.3655919Z test/dtypes/test_affine_quantized.py: 7 warnings
2026-01-14T10:14:51.3656297Z test/integration/test_integration.py: 52 warnings
2026-01-14T10:14:51.3656659Z test/quantization/test_quant_api.py: 8 warnings
2026-01-14T10:14:51.3658068Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T10:14:51.3659409Z     warnings.warn(
2026-01-14T10:14:51.3659544Z 
2026-01-14T10:14:51.3659682Z test/dtypes/test_affine_quantized.py: 10 warnings
2026-01-14T10:14:51.3660029Z test/hqq/test_hqq_affine.py: 1 warning
2026-01-14T10:14:51.3660356Z test/integration/test_integration.py: 18 warnings
2026-01-14T10:14:51.3660713Z test/quantization/test_quant_api.py: 17 warnings
2026-01-14T10:14:51.3662063Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:827: UserWarning: Config Deprecation: version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T10:14:51.3663423Z     warnings.warn(
2026-01-14T10:14:51.3663558Z 
2026-01-14T10:14:51.3663690Z test/dtypes/test_affine_quantized.py: 9 warnings
2026-01-14T10:14:51.3664033Z test/hqq/test_hqq_affine.py: 1 warning
2026-01-14T10:14:51.3664408Z test/integration/test_integration.py: 53 warnings
2026-01-14T10:14:51.3664771Z test/quantization/test_quant_api.py: 5 warnings
2026-01-14T10:14:51.3666485Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/tensor_core_tiled_layout.py:241: UserWarning: Models quantized with version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please upgrade torchao and quantize again, or download a newer torchao checkpoint, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T10:14:51.3668098Z     warnings.warn(
2026-01-14T10:14:51.3668231Z 
2026-01-14T10:14:51.3668369Z test/dtypes/test_affine_quantized.py: 1 warning
2026-01-14T10:14:51.3668728Z test/integration/test_integration.py: 18 warnings
2026-01-14T10:14:51.3669095Z test/quantization/test_quant_api.py: 30 warnings
2026-01-14T10:14:51.3670701Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/int4_cpu_layout.py:82: UserWarning: Models quantized with version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please upgrade torchao and quantize again, or download a newer torchao checkpoint, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T10:14:51.3672271Z     warnings.warn(
2026-01-14T10:14:51.3672404Z 
2026-01-14T10:14:51.3672646Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_bfloat16
2026-01-14T10:14:51.3674405Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/_inductor/select_algorithm.py:3584: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
2026-01-14T10:14:51.3676053Z     current_out_size = out_base.storage().size()
2026-01-14T10:14:51.3676281Z 
2026-01-14T10:14:51.3676468Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16
2026-01-14T10:14:51.3676930Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16
2026-01-14T10:14:51.3677384Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32
2026-01-14T10:14:51.3678742Z   /pytorch/ao/test/dtypes/test_nf4.py:224: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T10:14:51.3680266Z     torch.testing.assert_allclose(input_tensor, nf4_to_dtype, atol=0.13, rtol=0.13)
2026-01-14T10:14:51.3680629Z 
2026-01-14T10:14:51.3680817Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16
2026-01-14T10:14:51.3681269Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16
2026-01-14T10:14:51.3681724Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32
2026-01-14T10:14:51.3683169Z   /pytorch/ao/test/dtypes/test_nf4.py:230: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T10:14:51.3684626Z     torch.testing.assert_allclose(
2026-01-14T10:14:51.3684819Z 
2026-01-14T10:14:51.3684929Z test/float8/test_base.py: 36 warnings
2026-01-14T10:14:51.3686125Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/float8/float8_linear.py:261: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:881.)
2026-01-14T10:14:51.3687379Z     autocast_dtype = torch.get_autocast_gpu_dtype()
2026-01-14T10:14:51.3687623Z 
2026-01-14T10:14:51.3687827Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_0_cuda
2026-01-14T10:14:51.3688314Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_1_cuda
2026-01-14T10:14:51.3689809Z   /pytorch/ao/test/kernel/test_autotuner.py:50: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T10:14:51.3691153Z     torch.testing.assert_allclose(out32_1, out32_2)
2026-01-14T10:14:51.3691396Z 
2026-01-14T10:14:51.3691669Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_0_cuda
2026-01-14T10:14:51.3692210Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu
2026-01-14T10:14:51.3692778Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_2_cuda
2026-01-14T10:14:51.3693310Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu
2026-01-14T10:14:51.3694717Z   /pytorch/ao/test/kernel/test_autotuner.py:96: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T10:14:51.3696061Z     torch.testing.assert_allclose(out32_1, out32_2)
2026-01-14T10:14:51.3696305Z 
2026-01-14T10:14:51.3696614Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook
2026-01-14T10:14:51.3697957Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py:939: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1512.)
2026-01-14T10:14:51.3699093Z     return callable(*args, **kwargs)
2026-01-14T10:14:51.3699282Z 
2026-01-14T10:14:51.3699517Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace
2026-01-14T10:14:51.3700083Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace
2026-01-14T10:14:51.3701083Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/jit/_trace.py:1139: DeprecationWarning: `torch.jit.trace_method` is deprecated. Please switch to `torch.compile` or `torch.export`.
2026-01-14T10:14:51.3701937Z     warnings.warn(
2026-01-14T10:14:51.3702075Z 
2026-01-14T10:14:51.3702300Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace
2026-01-14T10:14:51.3703956Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/sparsifier/utils.py:134: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
2026-01-14T10:14:51.3705548Z     assert self.mask.shape == x.shape
2026-01-14T10:14:51.3705754Z 
2026-01-14T10:14:51.3705969Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler
2026-01-14T10:14:51.3706547Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step
2026-01-14T10:14:51.3707862Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/scheduler/base_scheduler.py:133: UserWarning: Detected call of `scheduler.step()` before `sparsifier.step()`. You have to make sure you run the sparsifier.step() BEFORE any calls to the scheduler.step().
2026-01-14T10:14:51.3709070Z     warnings.warn(
2026-01-14T10:14:51.3709206Z 
2026-01-14T10:14:51.3709531Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_complex_conv2d
2026-01-14T10:14:51.3710736Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/pruner/prune_functions.py:347: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
2026-01-14T10:14:51.3712087Z   Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)
2026-01-14T10:14:51.3712834Z     flattened_pruned_biases = torch.tensor(
2026-01-14T10:14:51.3713106Z 
2026-01-14T10:14:51.3713362Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu
2026-01-14T10:14:51.3714753Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:42: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T10:14:51.3716182Z     m, guards = torchdynamo.export(  # noqa: F841©
2026-01-14T10:14:51.3716430Z 
2026-01-14T10:14:51.3716673Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu
2026-01-14T10:14:51.3718077Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:86: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T10:14:51.3719363Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T10:14:51.3719601Z 
2026-01-14T10:14:51.3719911Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict
2026-01-14T10:14:51.3721357Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:118: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T10:14:51.3722627Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T10:14:51.3722885Z 
2026-01-14T10:14:51.3723090Z test/quantization/pt2e/test_numeric_debugger.py: 5 warnings
2026-01-14T10:14:51.3723519Z test/quantization/pt2e/test_quantize_pt2e.py: 2 warnings
2026-01-14T10:14:51.3723945Z test/quantization/pt2e/test_representation.py: 11 warnings
2026-01-14T10:14:51.3724411Z test/quantization/pt2e/test_x86inductor_quantizer.py: 153 warnings
2026-01-14T10:14:51.3725360Z   /opt/conda/envs/venv/lib/python3.10/copyreg.py:101: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
2026-01-14T10:14:51.3726222Z     return cls.__new__(cls, *args)
2026-01-14T10:14:51.3726404Z 
2026-01-14T10:14:51.3726566Z test/quantization/pt2e/test_quantize_pt2e.py: 18 warnings
2026-01-14T10:14:51.3727015Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 88 warnings
2026-01-14T10:14:51.3727509Z test/quantization/pt2e/test_representation.py: 8 warnings
2026-01-14T10:14:51.3728276Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/testing/pt2e/_xnnpack_quantizer.py:289: UserWarning: XNNPACKQuantizer is deprecated!
2026-01-14T10:14:51.3729054Z     warnings.warn(f"{self.__class__.__name__} is deprecated!")
2026-01-14T10:14:51.3729332Z 
2026-01-14T10:14:51.3729711Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_conv_linear_quantization
2026-01-14T10:14:51.3730448Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_quantizer
2026-01-14T10:14:51.3731453Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/testing/pt2e/utils.py:108: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T10:14:51.3732278Z   For migrations of users: 
2026-01-14T10:14:51.3733040Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T10:14:51.3734503Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T10:14:51.3735773Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T10:14:51.3736462Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T10:14:51.3736874Z     m_fx = prepare_fx(
2026-01-14T10:14:51.3737017Z 
2026-01-14T10:14:51.3737294Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported
2026-01-14T10:14:51.3738673Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:952: UserWarning: Was not able to add assertion to guarantee correct input x to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.
2026-01-14T10:14:51.3739898Z     warnings.warn(
2026-01-14T10:14:51.3740032Z 
2026-01-14T10:14:51.3740280Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T10:14:51.3740991Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node
2026-01-14T10:14:51.3741818Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node
2026-01-14T10:14:51.3742985Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/utils.py:145: UserWarning: must run observer before calling calculate_qparams. Returning default values.
2026-01-14T10:14:51.3743821Z     warnings.warn(
2026-01-14T10:14:51.3743954Z 
2026-01-14T10:14:51.3744200Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T10:14:51.3745333Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:1360: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point 
2026-01-14T10:14:51.3746309Z     warnings.warn(
2026-01-14T10:14:51.3746440Z 
2026-01-14T10:14:51.3746680Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_save_load
2026-01-14T10:14:51.3748974Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/export/pt2_archive/_package.py:792: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1581.)
2026-01-14T10:14:51.3751113Z     tensor = torch.frombuffer(
2026-01-14T10:14:51.3751292Z 
2026-01-14T10:14:51.3751730Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T10:14:51.3752636Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T10:14:51.3753600Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype
2026-01-14T10:14:51.3754542Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T10:14:51.3755491Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T10:14:51.3756402Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype
2026-01-14T10:14:51.3757249Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec
2026-01-14T10:14:51.3758584Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:263: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
2026-01-14T10:14:51.3759672Z     warnings.warn(
2026-01-14T10:14:51.3759806Z 
2026-01-14T10:14:51.3759989Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 48 warnings
2026-01-14T10:14:51.3760810Z   /pytorch/ao/test/quantization/pt2e/test_quantize_pt2e_qat.py:169: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T10:14:51.3761611Z   For migrations of users: 
2026-01-14T10:14:51.3762365Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T10:14:51.3763884Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T10:14:51.3765160Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T10:14:51.3765840Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T10:14:51.3766223Z     model_fx = prepare_qat_fx(
2026-01-14T10:14:51.3766394Z 
2026-01-14T10:14:51.3766571Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 48 warnings
2026-01-14T10:14:51.3767517Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/ao/quantization/fx/prepare.py:394: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T10:14:51.3768349Z   For migrations of users: 
2026-01-14T10:14:51.3769101Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T10:14:51.3770570Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T10:14:51.3771836Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T10:14:51.3772546Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T10:14:51.3773104Z     convert(root, mapping=module_to_qat_module, inplace=True, remove_qconfig=False)
2026-01-14T10:14:51.3773477Z 
2026-01-14T10:14:51.3773649Z test/quantization/pt2e/test_representation.py: 33 warnings
2026-01-14T10:14:51.3774816Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/utils.py:967: FutureWarning: `treespec.children_specs` is deprecated. Use `treespec.child(index)` to access a single child, or `treespec.children()` to get all children.
2026-01-14T10:14:51.3775920Z     args_spec = in_spec.children_specs[0]
2026-01-14T10:14:51.3776183Z 
2026-01-14T10:14:51.3776356Z test/quantization/pt2e/test_representation.py: 22 warnings
2026-01-14T10:14:51.3777509Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/utils.py:982: FutureWarning: `treespec.children_specs` is deprecated. Use `treespec.child(index)` to access a single child, or `treespec.children()` to get all children.
2026-01-14T10:14:51.3778627Z     args_spec.children_specs.append(LeafSpec())
2026-01-14T10:14:51.3778862Z 
2026-01-14T10:14:51.3779109Z test/quantization/pt2e/test_representation.py: 22 warnings
2026-01-14T10:14:51.3780196Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/utils.py:982: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
2026-01-14T10:14:51.3781235Z     args_spec.children_specs.append(LeafSpec())
2026-01-14T10:14:51.3781467Z 
2026-01-14T10:14:51.3781767Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_3
2026-01-14T10:14:51.3782540Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe
2026-01-14T10:14:51.3787534Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:1325: UserWarning: The input of maxpool2d is not quantized, skip annotate maxpool2d with config QuantizationConfig(input_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), output_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), weight=QuantizationSpec(dtype=torch.int8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.PerChannelMinMaxObserver'>, eps=0.000244140625){}, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, ch_axis=0, is_dynamic=False), bias=None, is_qat=False).
2026-01-14T10:14:51.3792275Z     warnings.warn(
2026-01-14T10:14:51.3792410Z 
2026-01-14T10:14:51.3792753Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block
2026-01-14T10:14:51.3793533Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block
2026-01-14T10:14:51.3794406Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qconv2d_maxpool2d_linear_dynamic_cpu
2026-01-14T10:14:51.3796024Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/_inductor/mkldnn_lowerings.py:764: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
2026-01-14T10:14:51.3797372Z     torch.tensor(w_zp_tensor, dtype=torch.int32), name=w_zp.get_name()
2026-01-14T10:14:51.3797682Z 
2026-01-14T10:14:51.3798172Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T10:14:51.3799457Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:484: UserWarning: Mixed dynamic and static quantization config is not supported.
2026-01-14T10:14:51.3800347Z     warnings.warn(
2026-01-14T10:14:51.3800482Z 
2026-01-14T10:14:51.3800970Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T10:14:51.3802319Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:383: UserWarning: Skip the quantization config for <class 'torch.nn.modules.linear.Linear'>.
2026-01-14T10:14:51.3803385Z     warnings.warn(
2026-01-14T10:14:51.3803519Z 
2026-01-14T10:14:51.3803726Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T10:14:51.3804891Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'IntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T10:14:51.3805987Z   
2026-01-14T10:14:51.3806312Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T10:17:07.8843494Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T10:17:07.8843895Z       # train (not shown)
2026-01-14T10:17:07.8844230Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T10:17:07.8844596Z   
2026-01-14T10:17:07.8844921Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T10:17:07.8845305Z   
2026-01-14T10:17:07.8845732Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T10:17:07.8846378Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T10:17:07.8846800Z       qat_config = QATConfig(
2026-01-14T10:17:07.8847092Z           activation_config=activation_config,
2026-01-14T10:17:07.8847419Z           weight_config=weight_config,
2026-01-14T10:17:07.8847708Z           step="prepare",
2026-01-14T10:17:07.8847951Z       )
2026-01-14T10:17:07.8848390Z       quantize_(model, qat_config)
2026-01-14T10:17:07.8848648Z   
2026-01-14T10:17:07.8848973Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T10:17:07.8849367Z           
2026-01-14T10:17:07.8849571Z     warnings.warn(
2026-01-14T10:17:07.8849709Z 
2026-01-14T10:17:07.8849942Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T10:17:07.8851271Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'FromIntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T10:17:07.8852364Z   
2026-01-14T10:17:07.8852690Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T10:17:07.8853205Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T10:17:07.8853570Z       # train (not shown)
2026-01-14T10:17:07.8853905Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T10:17:07.8854253Z   
2026-01-14T10:17:07.8854568Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T10:17:07.8854963Z   
2026-01-14T10:17:07.8855360Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T10:17:07.8855982Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T10:17:07.8856390Z       qat_config = QATConfig(
2026-01-14T10:17:07.8856688Z           activation_config=activation_config,
2026-01-14T10:17:07.8857016Z           weight_config=weight_config,
2026-01-14T10:17:07.8857308Z           step="prepare",
2026-01-14T10:17:07.8857605Z       )
2026-01-14T10:17:07.8857818Z       quantize_(model, qat_config)
2026-01-14T10:17:07.8858078Z   
2026-01-14T10:17:07.8858387Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T10:17:07.8858789Z           
2026-01-14T10:17:07.8858989Z     warnings.warn(
2026-01-14T10:17:07.8859138Z 
2026-01-14T10:17:07.8859473Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T10:17:07.8861254Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/blocksparse.py:198: UserWarning: Sparse BSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:49.)
2026-01-14T10:17:07.8862955Z     bsr_tensor = dense_tensor.to_sparse_bsr(blocksize)
2026-01-14T10:17:07.8863210Z 
2026-01-14T10:17:07.8863537Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T10:17:07.8865204Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=2048 K=1024 N=1 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T10:17:07.8866538Z     warn_once(
2026-01-14T10:17:07.8866676Z 
2026-01-14T10:17:07.8867003Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T10:17:07.8868631Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=1024 K=2048 N=1 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T10:17:07.8869962Z     warn_once(
2026-01-14T10:17:07.8870090Z 
2026-01-14T10:17:07.8870437Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024
2026-01-14T10:17:07.8872057Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=2048 K=1024 N=1024 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T10:17:07.8873455Z     warn_once(
2026-01-14T10:17:07.8873580Z 
2026-01-14T10:17:07.8873934Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024
2026-01-14T10:17:07.8875685Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=1024 K=2048 N=1024 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T10:17:07.8877100Z     warn_once(
2026-01-14T10:17:07.8877245Z 
2026-01-14T10:17:07.8877536Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False
2026-01-14T10:17:07.8879096Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=256 K=128 N=256 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.int8 out_dtype=torch.bfloat16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T10:17:07.8880416Z     warn_once(
2026-01-14T10:17:07.8880542Z 
2026-01-14T10:17:07.8880839Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False
2026-01-14T10:17:07.8882399Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=128 K=256 N=256 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.int8 out_dtype=torch.bfloat16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T10:17:07.8883711Z     warn_once(
2026-01-14T10:17:07.8883835Z 
2026-01-14T10:17:07.8884068Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4
2026-01-14T10:17:07.8885378Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/wanda.py:46: UserWarning: WandaSparsifier got semi_structured_bock_size=4, sparsity_level fixed to 50% (2:4) sparsity
2026-01-14T10:17:07.8886281Z     warnings.warn(
2026-01-14T10:17:07.8886471Z 
2026-01-14T10:17:07.8886708Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4
2026-01-14T10:17:07.8887321Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_unstructured
2026-01-14T10:17:07.8888094Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_prepare
2026-01-14T10:17:07.8888723Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_squash_mask
2026-01-14T10:17:07.8889306Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured
2026-01-14T10:17:07.8889995Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured_custom_config
2026-01-14T10:17:07.8891111Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/wanda.py:75: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T10:17:07.8891937Z   For migrations of users: 
2026-01-14T10:17:07.8892711Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T10:17:07.8894198Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T10:17:07.8895519Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T10:17:07.8896224Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T10:17:07.8896678Z     torch.ao.quantization.prepare(model, inplace=True)
2026-01-14T10:17:07.8896947Z 
2026-01-14T10:17:07.8897175Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-01-14T10:17:07.8898339Z [33m======== [32m2549 passed[0m, [33m[1m6421 skipped[0m, [33m[1m962 warnings[0m[33m in 6196.96s (1:43:16)[0m[33m =========[0m
2026-01-14T10:17:07.8956634Z ##[group]Run pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1
2026-01-14T10:17:07.8957108Z with:
2026-01-14T10:17:07.8957409Z   path: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:07.8957819Z   fail-on-empty: false
2026-01-14T10:17:07.8958070Z env:
2026-01-14T10:17:07.8958314Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:07.8958674Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:07.8958930Z   PR_NUMBER: 3500
2026-01-14T10:17:07.8960625Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:07.8962532Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:07.8963109Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:07.8963657Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:07.8964049Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:07.8964355Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:07.8964699Z ##[endgroup]
2026-01-14T10:17:07.9571949Z Prepare all required actions
2026-01-14T10:17:07.9615291Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T10:17:07.9615672Z with:
2026-01-14T10:17:07.9615946Z   directory: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T10:17:07.9616433Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T10:17:07.9616844Z env:
2026-01-14T10:17:07.9617114Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:07.9617485Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:07.9617737Z   PR_NUMBER: 3500
2026-01-14T10:17:07.9619435Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:07.9621423Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:07.9622014Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:07.9622575Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:07.9622969Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:07.9623295Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:07.9623638Z ##[endgroup]
2026-01-14T10:17:07.9649999Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T10:17:07.9650705Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T10:17:07.9670255Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T10:17:07.9670607Z env:
2026-01-14T10:17:07.9670873Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:07.9671227Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:07.9671484Z   PR_NUMBER: 3500
2026-01-14T10:17:07.9673197Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:07.9675283Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:07.9675880Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:07.9676445Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:07.9676835Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:07.9677157Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:07.9677644Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T10:17:07.9678190Z   DIRECTORY: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T10:17:07.9678535Z ##[endgroup]
2026-01-14T10:17:07.9936390Z Unable to find image '308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest' locally
2026-01-14T10:17:08.2395302Z latest: Pulling from tool/alpine
2026-01-14T10:17:08.2395680Z 540db60ca938: Pulling fs layer
2026-01-14T10:17:08.3482516Z 540db60ca938: Verifying Checksum
2026-01-14T10:17:08.3482940Z 540db60ca938: Download complete
2026-01-14T10:17:08.4648526Z 540db60ca938: Pull complete
2026-01-14T10:17:08.4759032Z Digest: sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T10:17:08.4802862Z Status: Downloaded newer image for 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T10:17:09.6106569Z Prepare all required actions
2026-01-14T10:17:09.6138046Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T10:17:09.6138410Z with:
2026-01-14T10:17:09.6138685Z   directory: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T10:17:09.6139152Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T10:17:09.6139569Z env:
2026-01-14T10:17:09.6139830Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:09.6140183Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:09.6140443Z   PR_NUMBER: 3500
2026-01-14T10:17:09.6142140Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:09.6144020Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:09.6144602Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:09.6145268Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:09.6145653Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:09.6145979Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:09.6146329Z ##[endgroup]
2026-01-14T10:17:09.6168957Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T10:17:09.6169659Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T10:17:09.6183713Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T10:17:09.6184079Z env:
2026-01-14T10:17:09.6184515Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:09.6184870Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:09.6185120Z   PR_NUMBER: 3500
2026-01-14T10:17:09.6186842Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:09.6188810Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:09.6189401Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:09.6190063Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:09.6190457Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:09.6190768Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:09.6191262Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T10:17:09.6191744Z   DIRECTORY: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T10:17:09.6192078Z ##[endgroup]
2026-01-14T10:17:10.5674359Z ##[group]Run # Only do these steps if we actually want to upload an artifact
2026-01-14T10:17:10.5675082Z [36;1m# Only do these steps if we actually want to upload an artifact[0m
2026-01-14T10:17:10.5675532Z [36;1mif [[ -n "${UPLOAD_ARTIFACT_NAME}" ]]; then[0m
2026-01-14T10:17:10.5676087Z [36;1m  # If the default execution path is followed then we should get a wheel in the dist/ folder[0m
2026-01-14T10:17:10.5676719Z [36;1m  # attempt to just grab whatever is in there and scoop it all up[0m
2026-01-14T10:17:10.5677218Z [36;1m  if find "dist/" -name "*.whl" >/dev/null 2>/dev/null; then[0m
2026-01-14T10:17:10.5677663Z [36;1m    mv -v dist/*.whl "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T10:17:10.5677991Z [36;1m  fi[0m
2026-01-14T10:17:10.5678274Z [36;1m  if [[ -d "artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T10:17:10.5678741Z [36;1m    mv -v artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T10:17:10.5679134Z [36;1m  fi[0m
2026-01-14T10:17:10.5679476Z [36;1m  if [[ -d "${RUNNER_TEMP}/artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T10:17:10.5680036Z [36;1m    mv -v "${RUNNER_TEMP}"/artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T10:17:10.5680492Z [36;1m  fi[0m
2026-01-14T10:17:10.5680709Z [36;1mfi[0m
2026-01-14T10:17:10.5680980Z [36;1m[0m
2026-01-14T10:17:10.5681250Z [36;1mupload_docs=0[0m
2026-01-14T10:17:10.5681790Z [36;1m# Check if there are files in the documentation folder to upload, note that[0m
2026-01-14T10:17:10.5682463Z [36;1m# empty folders do not count[0m
2026-01-14T10:17:10.5683143Z [36;1mif find "${RUNNER_DOCS_DIR}" -mindepth 1 -maxdepth 1 -type f | read -r; then[0m
2026-01-14T10:17:10.5684368Z [36;1m  # TODO: Add a check here to test if on ec2 because if we're not on ec2 then this[0m
2026-01-14T10:17:10.5685175Z [36;1m  # upload will probably not work correctly[0m
2026-01-14T10:17:10.5685706Z [36;1m  upload_docs=1[0m
2026-01-14T10:17:10.5686073Z [36;1mfi[0m
2026-01-14T10:17:10.5686550Z [36;1mecho "upload-docs=${upload_docs}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T10:17:10.5699455Z shell: /usr/bin/bash -e {0}
2026-01-14T10:17:10.5699722Z env:
2026-01-14T10:17:10.5699985Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:10.5700370Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:10.5700629Z   PR_NUMBER: 3500
2026-01-14T10:17:10.5702650Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:10.5704501Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:10.5705077Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:10.5705623Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:10.5706017Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:10.5706335Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:10.5706695Z   UPLOAD_ARTIFACT_NAME: 
2026-01-14T10:17:10.5706938Z ##[endgroup]
2026-01-14T10:17:10.5816473Z Prepare all required actions
2026-01-14T10:17:10.5868060Z ##[group]Run ./test-infra/.github/actions/teardown-linux
2026-01-14T10:17:10.5868440Z with:
2026-01-14T10:17:10.5868646Z env:
2026-01-14T10:17:10.5868899Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:10.5869347Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:10.5869601Z   PR_NUMBER: 3500
2026-01-14T10:17:10.5871289Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:10.5873150Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:10.5873759Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:10.5874304Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:10.5874696Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:10.5875087Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:10.5875440Z ##[endgroup]
2026-01-14T10:17:10.5899691Z ##[group]Run set -eou pipefail
2026-01-14T10:17:10.5899984Z [36;1mset -eou pipefail[0m
2026-01-14T10:17:10.5900232Z [36;1m[0m
2026-01-14T10:17:10.5900590Z [36;1mecho "Holding runner for 2 hours until all ssh sessions have logged out"[0m
2026-01-14T10:17:10.5901051Z [36;1mfor _ in $(seq 1440); do[0m
2026-01-14T10:17:10.5901384Z [36;1m    # Break if no ssh session exists anymore[0m
2026-01-14T10:17:10.5901724Z [36;1m    if [ "$(who)" = "" ]; then[0m
2026-01-14T10:17:10.5902017Z [36;1m      break[0m
2026-01-14T10:17:10.5902239Z [36;1m    fi[0m
2026-01-14T10:17:10.5902465Z [36;1m    echo "."[0m
2026-01-14T10:17:10.5902699Z [36;1m    sleep 5[0m
2026-01-14T10:17:10.5902934Z [36;1mdone[0m
2026-01-14T10:17:10.5912797Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T10:17:10.5913167Z env:
2026-01-14T10:17:10.5913421Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:10.5913782Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:10.5914044Z   PR_NUMBER: 3500
2026-01-14T10:17:10.5915875Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:10.5917951Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:10.5918555Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:10.5919149Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:10.5919555Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:10.5919866Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:10.5920221Z ##[endgroup]
2026-01-14T10:17:10.5952146Z Holding runner for 2 hours until all ssh sessions have logged out
2026-01-14T10:17:10.6048844Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T10:17:10.6049403Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T10:17:10.6049826Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T10:17:10.6050152Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T10:17:10.6050496Z [36;1m# Prune all of the docker images[0m
2026-01-14T10:17:10.6050834Z [36;1mdocker system prune -af[0m
2026-01-14T10:17:10.6060039Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T10:17:10.6060396Z env:
2026-01-14T10:17:10.6060870Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:10.6061229Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:10.6061476Z   PR_NUMBER: 3500
2026-01-14T10:17:10.6063146Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:10.6065113Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:10.6065688Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:10.6066248Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:10.6066631Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:10.6066942Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:10.6067298Z ##[endgroup]
2026-01-14T10:17:13.2378415Z 18321e05e6d6
2026-01-14T10:17:21.3700457Z Deleted Containers:
2026-01-14T10:17:21.3700866Z 18321e05e6d62478d0afb639811f60e8bbfed2aefc0290c47f1e3b30aefd4d85
2026-01-14T10:17:21.3701192Z 
2026-01-14T10:17:29.8847115Z Deleted Images:
2026-01-14T10:17:29.8847998Z untagged: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:29.8849629Z untagged: pytorch/almalinux-builder@sha256:38e012b20747e9f72b4c4dc2ffb4134a450ad6e57e64886e7daf42b9a8ffa9f2
2026-01-14T10:17:29.8851179Z deleted: sha256:bb1a1950b861327b13d8893bffd39e26f8e80f9318971babe6b3f9bab8d65d21
2026-01-14T10:17:29.8852472Z deleted: sha256:a54dbc7bc094481efb3d7798f26feac4f04f2c7d3b16372162cacf83ed2388ce
2026-01-14T10:17:29.8853782Z deleted: sha256:645a24a13a583a58c04ea348b38daba4a40b2bbe09eb2012e9d33e823ff99c8e
2026-01-14T10:17:29.8854754Z deleted: sha256:74c5765839aa7e92b734630a11e6a02dc4f9932142efb4becedf62941283e0cd
2026-01-14T10:17:29.8855411Z deleted: sha256:7a626ac79b7f4d3436fb97d7a7ca125845805c133303239c31f4eed62b556453
2026-01-14T10:17:29.8856033Z deleted: sha256:31c03ed8c3f72312100269f048fea1b331a93b53b496ce34be4bac621109f901
2026-01-14T10:17:29.8856676Z deleted: sha256:c32b905bbd58816c78ef90a77285dd4d9b1cdafdbaa7332cd398891b30feee8e
2026-01-14T10:17:29.8857337Z deleted: sha256:4dc58665c3bd3ca188c201fdcfdeb41b0118191cd6843ddeda62495ba0c15986
2026-01-14T10:17:29.8857985Z deleted: sha256:dad808738bccf06931c05520f69d148be75a61afd28065e9aee100d5af6133bd
2026-01-14T10:17:29.8858614Z deleted: sha256:6e036a485561034f6c52610c6a2c7f11e64060ce9e2f10b3d4064a87d091745a
2026-01-14T10:17:29.8859235Z deleted: sha256:ef2ba6b1ca100c37739c13afedd9c52143448d948239c375f611f5bbe19f175d
2026-01-14T10:17:29.8859887Z deleted: sha256:37d850998e8d82d40ffce6b7020d480daecaa091b6fbac01c04a0da1f90f7e8f
2026-01-14T10:17:29.8860787Z deleted: sha256:16a70495db3a28a89c3250c0824d0e3e08c22dced61a31110ef1c7f8c5b127cd
2026-01-14T10:17:29.8861426Z deleted: sha256:b7982627380d2b6bc6a223770c8c18cb45dcc8229c32e1160fcb416a32fc969a
2026-01-14T10:17:29.8862057Z deleted: sha256:a4d99473e3f02923cf34c61996bf5a25863e8ee02801d6634174d671e0ac7367
2026-01-14T10:17:29.8862681Z deleted: sha256:2c683ce33d69b13bbcfe1f405137ff2aea4213c8228876ff55a791116cdcf2e2
2026-01-14T10:17:29.8863314Z deleted: sha256:ffaa389b629375310a946fd02f2f26fcf3678b2c23d94f4aab82a0fc46214892
2026-01-14T10:17:29.8863943Z deleted: sha256:e7ce15ca67e07966f2da85c8d2242c7535a7c9ab1f63b2069834ffba95a5978c
2026-01-14T10:17:29.8864580Z deleted: sha256:63b0fcbf70a9ee9ece0aeb6610359975830e1646da68f5f7722c2e64426bd4c7
2026-01-14T10:17:29.8865207Z deleted: sha256:5c48134bdee035683ad0d4846f19aa135bd7b8735e8c0b6420d13e5779f720e4
2026-01-14T10:17:29.8865837Z deleted: sha256:badca1798f4ace2b0179b607780a5cce32170bedeb23d076335fc973ec72f34c
2026-01-14T10:17:29.8866483Z deleted: sha256:ae88b0e9396996f876f32bf01d80534d3cf5c06c395eba64f7dd66dda56fa55f
2026-01-14T10:17:29.8867114Z deleted: sha256:b52e19c766f22b187f4fcd4e90cfb1e4e3c547dfe7484bf5423db65775cf352f
2026-01-14T10:17:29.8867997Z deleted: sha256:1d80070b73e86e9afa159ca72ee6fc6bcf7f387d21c1d6dcd065fa877e678592
2026-01-14T10:17:29.8868623Z deleted: sha256:ff4f19608a1944c0c2807cd533515673285a9632dc74bf020e83e18630d1ae35
2026-01-14T10:17:29.8869150Z untagged: public.ecr.aws/docker/library/python:3.13
2026-01-14T10:17:29.8870030Z untagged: public.ecr.aws/docker/library/python@sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T10:17:29.8870852Z deleted: sha256:6b1b86f270ccdb848adf78330c7a27041a2f8e971cfd9c808e1ad503d236f9ae
2026-01-14T10:17:29.8871490Z deleted: sha256:ab3ff5992dd09a2d006ef37d701d92e11590962848a698a0824ab2129505b946
2026-01-14T10:17:29.8872109Z deleted: sha256:c839d2b1d0949c101d8e022855435eedb0179697af77be6012f911dfcb69742c
2026-01-14T10:17:29.8872752Z deleted: sha256:b3fb8a2c0606137f473565b54a51bb1e18dfca24cbc417e0f7a0b3d68395d9ea
2026-01-14T10:17:29.8873387Z deleted: sha256:a643465a85469890e6e498fe0d0ac4e6a251e77c92a179ac27085d4ffeb4c8da
2026-01-14T10:17:29.8874023Z deleted: sha256:09db7ba2ba0ebb76125f8bf37573369eb90202594586d30c6f9c202d968f4d00
2026-01-14T10:17:29.8874668Z deleted: sha256:ba4e59af8cdbb2e2cd899773f1cdbcb3027d48d9be333f5a823d9cccfd5c4a15
2026-01-14T10:17:29.8875372Z deleted: sha256:da7213941eca995ecec09e85fe1affcac44194792b48cbacdd3c0d9038bbaf9e
2026-01-14T10:17:29.8876002Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T10:17:29.8876864Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine@sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T10:17:29.8877757Z deleted: sha256:6dbb9cc54074106d46d4ccb330f2a40a682d49dda5f4844962b7dce9fe44aaec
2026-01-14T10:17:29.8878387Z deleted: sha256:b2d5eeeaba3a22b9b8aa97261957974a6bd65274ebd43e1d81d0a7b8b752b116
2026-01-14T10:17:29.8878768Z 
2026-01-14T10:17:29.8878885Z Total reclaimed space: 27.74GB
2026-01-14T10:17:29.8940971Z ##[group]Run set +e
2026-01-14T10:17:29.8941238Z [36;1mset +e[0m
2026-01-14T10:17:29.8941481Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T10:17:29.8941886Z [36;1m  sudo rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T10:17:29.8942240Z [36;1melse[0m
2026-01-14T10:17:29.8942521Z [36;1m  rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T10:17:29.8942851Z [36;1mfi[0m
2026-01-14T10:17:29.8943068Z [36;1mset -e[0m
2026-01-14T10:17:29.8953568Z shell: /usr/bin/bash -e {0}
2026-01-14T10:17:29.8953832Z env:
2026-01-14T10:17:29.8954090Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T10:17:29.8954451Z   REPOSITORY: pytorch/ao
2026-01-14T10:17:29.8954713Z   PR_NUMBER: 3500
2026-01-14T10:17:29.8956528Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T10:17:29.8958507Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T10:17:29.8972220Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T10:17:29.8972781Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T10:17:29.8973170Z   HAS_NVIDIA_GPU: true
2026-01-14T10:17:29.8973483Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T10:17:29.8973837Z   NO_SUDO: false
2026-01-14T10:17:29.8974046Z ##[endgroup]
2026-01-14T10:17:30.4098160Z Post job cleanup.
2026-01-14T10:17:30.5211143Z Post job cleanup.
2026-01-14T10:17:30.6214405Z [command]/usr/bin/git version
2026-01-14T10:17:30.6265560Z git version 2.50.1
2026-01-14T10:17:30.6312666Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/e24219eb-c91d-4e6e-a8a6-cf92147f28d8' before making global git config changes
2026-01-14T10:17:30.6313607Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T10:17:30.6318077Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T10:17:30.6371475Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T10:17:30.6413254Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T10:17:30.6823525Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T10:17:30.6852951Z http.https://github.com/.extraheader
2026-01-14T10:17:30.6865700Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader
2026-01-14T10:17:30.6904192Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T10:17:30.7409843Z A job completed hook has been configured by the self-hosted runner administrator
2026-01-14T10:17:30.7441377Z ##[group]Run '/home/ec2-user/runner-scripts/after_job.sh'
2026-01-14T10:17:30.7449560Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T10:17:30.7449942Z ##[endgroup]
2026-01-14T10:17:30.7572218Z [!ALERT!] Swap in detected! [!ALERT!]
2026-01-14T10:17:42.4716060Z [!ALERT!] Swap out detected [!ALERT!]
2026-01-14T10:18:01.4148370Z Cleaning up orphan processes
