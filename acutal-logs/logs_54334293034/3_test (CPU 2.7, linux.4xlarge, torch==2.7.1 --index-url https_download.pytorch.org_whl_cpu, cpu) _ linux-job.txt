2026-01-14T08:10:09.3521095Z Current runner version: '2.331.0'
2026-01-14T08:10:09.3527382Z Runner name: 'i-0ef88b6809c987313'
2026-01-14T08:10:09.3528127Z Runner group name: 'default'
2026-01-14T08:10:09.3528961Z Machine name: 'ip-10-0-73-141'
2026-01-14T08:10:09.3532250Z ##[group]GITHUB_TOKEN Permissions
2026-01-14T08:10:09.3534638Z Contents: read
2026-01-14T08:10:09.3535187Z Metadata: read
2026-01-14T08:10:09.3535878Z Packages: read
2026-01-14T08:10:09.3536491Z ##[endgroup]
2026-01-14T08:10:09.3538707Z Secret source: None
2026-01-14T08:10:09.3539443Z Prepare workflow directory
2026-01-14T08:10:09.4110734Z Prepare all required actions
2026-01-14T08:10:09.4151467Z Getting action download info
2026-01-14T08:10:09.7043992Z Download action repository 'actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683' (SHA:11bd71901bbe5b1630ceea73d27597364c9af683)
2026-01-14T08:10:09.9910313Z Download action repository 'pytorch/pytorch@main' (SHA:b321605fc7207c672be72497ceeb20cbb6367319)
2026-01-14T08:10:24.5488810Z Download action repository 'actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093' (SHA:d3f86a106a0bac45b974a628896c90dbdf5c8093)
2026-01-14T08:10:24.8927301Z Download action repository 'pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1' (SHA:a2c1430e2bddadbad9f49a6f9b879f062c6b19b1)
2026-01-14T08:10:25.0185530Z Download action repository 'actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02' (SHA:ea165f8d65b6e75b540449e92b4886f43607fa02)
2026-01-14T08:10:25.5538793Z Getting action download info
2026-01-14T08:10:25.7020220Z Getting action download info
2026-01-14T08:10:25.8512922Z Download action repository 'aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722' (SHA:ececac1a45f3b08a01d2dd070d28d111c5fe6722)
2026-01-14T08:10:26.0972996Z Download action repository 'aws-actions/amazon-ecr-login@062b18b96a7aff071d4dc91bc00c4c1a7945b076' (SHA:062b18b96a7aff071d4dc91bc00c4c1a7945b076)
2026-01-14T08:10:26.3327661Z Uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@refs/heads/main (479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:10:26.3332284Z ##[group] Inputs
2026-01-14T08:10:26.3334271Z   script: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:26.3336738Z   timeout: 180
2026-01-14T08:10:26.3336968Z   runner: linux.4xlarge
2026-01-14T08:10:26.3337237Z   upload-artifact: 
2026-01-14T08:10:26.3337782Z   upload-artifact-to-s3: false
2026-01-14T08:10:26.3338084Z   download-artifact: 
2026-01-14T08:10:26.3338326Z   repository: 
2026-01-14T08:10:26.3338572Z   fetch-depth: 1
2026-01-14T08:10:26.3338788Z   submodules: recursive
2026-01-14T08:10:26.3339047Z   ref: 
2026-01-14T08:10:26.3339289Z   test-infra-repository: pytorch/test-infra
2026-01-14T08:10:26.3339608Z   test-infra-ref: 
2026-01-14T08:10:26.3339879Z   use-custom-docker-registry: true
2026-01-14T08:10:26.3340204Z   docker-image: pytorch/almalinux-builder
2026-01-14T08:10:26.3340520Z   docker-build-dir: .ci/docker
2026-01-14T08:10:26.3340807Z   gpu-arch-type: cpu
2026-01-14T08:10:26.3341042Z   gpu-arch-version: 
2026-01-14T08:10:26.3341288Z   job-name: linux-job
2026-01-14T08:10:26.3341528Z   continue-on-error: false
2026-01-14T08:10:26.3341798Z   binary-matrix: 
2026-01-14T08:10:26.3342032Z   run-with-docker: true
2026-01-14T08:10:26.3342320Z   secrets-env: 
2026-01-14T08:10:26.3342532Z   no-sudo: false
2026-01-14T08:10:26.3342768Z ##[endgroup]
2026-01-14T08:10:26.3343346Z Complete job name: test (CPU 2.7, linux.4xlarge, torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu, cpu) / linux-job
2026-01-14T08:10:26.3888123Z A job started hook has been configured by the self-hosted runner administrator
2026-01-14T08:10:26.4004082Z ##[group]Run '/home/ec2-user/runner-scripts/before_job.sh'
2026-01-14T08:10:26.4013531Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:26.4014173Z ##[endgroup]
2026-01-14T08:10:27.6967946Z Runner Type: linux.4xlarge
2026-01-14T08:10:27.6968393Z Instance Type: c5.4xlarge
2026-01-14T08:10:27.6968667Z AMI Name: unknown
2026-01-14T08:10:27.6997329Z AMI ID: ami-068c0051b15cdb816
2026-01-14T08:10:33.1375943Z ##[group]Run set -euxo pipefail
2026-01-14T08:10:33.1376363Z [36;1mset -euxo pipefail[0m
2026-01-14T08:10:33.1376660Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T08:10:33.1377070Z [36;1m  echo "::group::Cleanup with-sudo debug output"[0m
2026-01-14T08:10:33.1377458Z [36;1m  sudo rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:10:33.1377777Z [36;1melse[0m
2026-01-14T08:10:33.1378056Z [36;1m  echo "::group::Cleanup no-sudo debug output"[0m
2026-01-14T08:10:33.1378413Z [36;1m  rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:10:33.1378712Z [36;1mfi[0m
2026-01-14T08:10:33.1378925Z [36;1m[0m
2026-01-14T08:10:33.1379162Z [36;1mmkdir -p "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:10:33.1379478Z [36;1mecho "::endgroup::"[0m
2026-01-14T08:10:33.1389172Z shell: /usr/bin/bash -e {0}
2026-01-14T08:10:33.1389445Z env:
2026-01-14T08:10:33.1389697Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:33.1390022Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:33.1390343Z   PR_NUMBER: 3500
2026-01-14T08:10:33.1392215Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:33.1394179Z   NO_SUDO: false
2026-01-14T08:10:33.1394406Z ##[endgroup]
2026-01-14T08:10:33.1421321Z + [[ false == \f\a\l\s\e ]]
2026-01-14T08:10:33.1434476Z ##[group]Cleanup with-sudo debug output
2026-01-14T08:10:33.1437940Z + echo '::group::Cleanup with-sudo debug output'
2026-01-14T08:10:33.1438385Z + sudo rm -rfv /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:10:33.2697105Z removed directory '/home/ec2-user/actions-runner/_work/ao/ao'
2026-01-14T08:10:33.2711470Z + mkdir -p /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:10:33.2722731Z + echo ::endgroup::
2026-01-14T08:10:33.2723350Z ##[endgroup]
2026-01-14T08:10:33.2879040Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:10:33.2879487Z with:
2026-01-14T08:10:33.2879725Z   repository: pytorch/test-infra
2026-01-14T08:10:33.2880015Z   path: test-infra
2026-01-14T08:10:33.2880256Z   submodules: recursive
2026-01-14T08:10:33.2880814Z   token: ***
2026-01-14T08:10:33.2881045Z   ssh-strict: true
2026-01-14T08:10:33.2881273Z   ssh-user: git
2026-01-14T08:10:33.2881496Z   persist-credentials: true
2026-01-14T08:10:33.2881774Z   clean: true
2026-01-14T08:10:33.2882000Z   sparse-checkout-cone-mode: true
2026-01-14T08:10:33.2882295Z   fetch-depth: 1
2026-01-14T08:10:33.2882523Z   fetch-tags: false
2026-01-14T08:10:33.2882747Z   show-progress: true
2026-01-14T08:10:33.2882984Z   lfs: false
2026-01-14T08:10:33.2883196Z   set-safe-directory: true
2026-01-14T08:10:33.2883450Z env:
2026-01-14T08:10:33.2883682Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:33.2884021Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:33.2884308Z   PR_NUMBER: 3500
2026-01-14T08:10:33.2886202Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:33.2888322Z ##[endgroup]
2026-01-14T08:10:33.4356697Z Syncing repository: pytorch/test-infra
2026-01-14T08:10:33.4357423Z ##[group]Getting Git version info
2026-01-14T08:10:33.4357875Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/test-infra'
2026-01-14T08:10:33.4358520Z [command]/usr/bin/git version
2026-01-14T08:10:33.4358803Z git version 2.50.1
2026-01-14T08:10:33.4377352Z ##[endgroup]
2026-01-14T08:10:33.4397319Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/c1ead06a-9f6f-46c2-b4a0-9f3428441f03' before making global git config changes
2026-01-14T08:10:33.4401549Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:10:33.4402440Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:10:33.4428197Z ##[group]Initializing the repository
2026-01-14T08:10:33.4432213Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:10:33.4464196Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:10:33.4464823Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:10:33.4465392Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:10:33.4465811Z hint:
2026-01-14T08:10:33.4466108Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:10:33.4466447Z hint:
2026-01-14T08:10:33.4466815Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:10:33.4467373Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:10:33.4467812Z hint:
2026-01-14T08:10:33.4468024Z hint: 	git branch -m <name>
2026-01-14T08:10:33.4468284Z hint:
2026-01-14T08:10:33.4468633Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:10:33.4469324Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.git/
2026-01-14T08:10:33.4474339Z [command]/usr/bin/git remote add origin https://github.com/pytorch/test-infra
2026-01-14T08:10:33.4499154Z ##[endgroup]
2026-01-14T08:10:33.4499579Z ##[group]Disabling automatic garbage collection
2026-01-14T08:10:33.4503606Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:10:33.4528329Z ##[endgroup]
2026-01-14T08:10:33.4529037Z ##[group]Setting up auth
2026-01-14T08:10:33.4533832Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:10:33.4558507Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:10:33.4839641Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:10:33.4863632Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:10:33.5233976Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:10:33.5292453Z ##[endgroup]
2026-01-14T08:10:33.5292892Z ##[group]Determining the default branch
2026-01-14T08:10:33.5295513Z Retrieving the default branch name
2026-01-14T08:10:33.8163843Z Default branch 'main'
2026-01-14T08:10:33.8164586Z ##[endgroup]
2026-01-14T08:10:33.8165029Z ##[group]Fetching the repository
2026-01-14T08:10:33.8173404Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/heads/main:refs/remotes/origin/main
2026-01-14T08:10:34.1359292Z From https://github.com/pytorch/test-infra
2026-01-14T08:10:34.1359738Z  * [new branch]      main       -> origin/main
2026-01-14T08:10:34.1380160Z ##[endgroup]
2026-01-14T08:10:34.1380570Z ##[group]Determining the checkout info
2026-01-14T08:10:34.1381522Z ##[endgroup]
2026-01-14T08:10:34.1385740Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:10:34.1426087Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:10:34.1450271Z ##[group]Checking out the ref
2026-01-14T08:10:34.1453623Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-01-14T08:10:34.2897980Z Switched to a new branch 'main'
2026-01-14T08:10:34.2899334Z branch 'main' set up to track 'origin/main'.
2026-01-14T08:10:34.2905712Z ##[endgroup]
2026-01-14T08:10:34.2906131Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:10:34.2911696Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:10:34.2951554Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:10:34.2978709Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:10:34.3004967Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:10:34.3029210Z ##[endgroup]
2026-01-14T08:10:34.3029589Z ##[group]Fetching submodules
2026-01-14T08:10:34.3034492Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:10:34.3315999Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:10:34.3582006Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:10:34.3845361Z ##[endgroup]
2026-01-14T08:10:34.3845794Z ##[group]Persisting credentials for submodules
2026-01-14T08:10:34.3849991Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:10:34.4112646Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:10:34.4375308Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:10:34.4643372Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:10:34.4903159Z ##[endgroup]
2026-01-14T08:10:34.4934213Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:10:34.4954439Z 479ee761cd164688ad6fe63fbc0f27d255b35fe1
2026-01-14T08:10:34.5157697Z Prepare all required actions
2026-01-14T08:10:34.5158212Z Getting action download info
2026-01-14T08:10:34.6423391Z Download action repository 'pytorch/test-infra@main' (SHA:479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:10:36.9016641Z Getting action download info
2026-01-14T08:10:37.0148570Z Download action repository 'nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482' (SHA:3e91a01664abd3c5cd539100d10d33b9c5b68482)
2026-01-14T08:10:37.2625937Z ##[group]Run ./test-infra/.github/actions/setup-linux
2026-01-14T08:10:37.2626285Z env:
2026-01-14T08:10:37.2626518Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:37.2626846Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:37.2627084Z   PR_NUMBER: 3500
2026-01-14T08:10:37.2628934Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:37.2630810Z ##[endgroup]
2026-01-14T08:10:37.2715055Z ##[group]Run set -euo pipefail
2026-01-14T08:10:37.2715368Z [36;1mset -euo pipefail[0m
2026-01-14T08:10:37.2715782Z [36;1mfunction get_ec2_metadata() {[0m
2026-01-14T08:10:37.2716135Z [36;1m  # Pulled from instance metadata endpoint for EC2[0m
2026-01-14T08:10:37.2716751Z [36;1m  # see https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html[0m
2026-01-14T08:10:37.2717298Z [36;1m  category=$1[0m
2026-01-14T08:10:37.2718203Z [36;1m  curl -H "X-aws-ec2-metadata-token: $(curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 30")" -fsSL "http://169.254.169.254/latest/meta-data/${category}"[0m
2026-01-14T08:10:37.2719145Z [36;1m}[0m
2026-01-14T08:10:37.2719386Z [36;1mecho "ami-id: $(get_ec2_metadata ami-id)"[0m
2026-01-14T08:10:37.2719790Z [36;1mecho "instance-id: $(get_ec2_metadata instance-id)"[0m
2026-01-14T08:10:37.2720249Z [36;1mecho "instance-type: $(get_ec2_metadata instance-type)"[0m
2026-01-14T08:10:37.2720638Z [36;1mecho "system info $(uname -a)"[0m
2026-01-14T08:10:37.2726466Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:37.2726828Z env:
2026-01-14T08:10:37.2727058Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:37.2727367Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:37.2727608Z   PR_NUMBER: 3500
2026-01-14T08:10:37.2729414Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:37.2731301Z ##[endgroup]
2026-01-14T08:10:37.2870425Z ami-id: ami-068c0051b15cdb816
2026-01-14T08:10:37.2968165Z instance-id: i-0ef88b6809c987313
2026-01-14T08:10:37.3059739Z instance-type: c5.4xlarge
2026-01-14T08:10:37.3070096Z system info Linux ip-10-0-73-141.ec2.internal 6.1.158-180.294.amzn2023.x86_64 #1 SMP PREEMPT_DYNAMIC Mon Dec  1 05:36:50 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
2026-01-14T08:10:37.3109020Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:10:37.3110029Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:10:37.3116060Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:37.3116419Z env:
2026-01-14T08:10:37.3116667Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:37.3117163Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:37.3117430Z   PR_NUMBER: 3500
2026-01-14T08:10:37.3119258Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:37.3121168Z ##[endgroup]
2026-01-14T08:10:37.3199645Z ##[group]Run if ! docker version >/dev/null 2>/dev/null; then
2026-01-14T08:10:37.3200118Z [36;1mif ! docker version >/dev/null 2>/dev/null; then[0m
2026-01-14T08:10:37.3200528Z [36;1m  if systemctl is-active --quiet docker; then[0m
2026-01-14T08:10:37.3200916Z [36;1m      echo "Docker daemon is running...";[0m
2026-01-14T08:10:37.3201229Z [36;1m  else[0m
2026-01-14T08:10:37.3201594Z [36;1m      echo "Starting docker daemon..." && sudo systemctl start docker;[0m
2026-01-14T08:10:37.3202022Z [36;1m  fi[0m
2026-01-14T08:10:37.3202217Z [36;1mfi[0m
2026-01-14T08:10:37.3207555Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:37.3207904Z env:
2026-01-14T08:10:37.3208148Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:37.3208615Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:37.3208869Z   PR_NUMBER: 3500
2026-01-14T08:10:37.3210701Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:37.3212714Z ##[endgroup]
2026-01-14T08:10:37.3463005Z ##[group]Run AWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")
2026-01-14T08:10:37.3463662Z [36;1mAWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")[0m
2026-01-14T08:10:37.3464181Z [36;1mretry () { "$@"  || (sleep 1 && "$@") || (sleep 2 && "$@") }[0m
2026-01-14T08:10:37.3464806Z [36;1mretry aws ecr get-login-password --region "$AWS_DEFAULT_REGION" | docker login --username AWS \[0m
2026-01-14T08:10:37.3465564Z [36;1m    --password-stdin "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com"[0m
2026-01-14T08:10:37.3471434Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:37.3471797Z env:
2026-01-14T08:10:37.3472028Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:37.3472363Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:37.3472604Z   PR_NUMBER: 3500
2026-01-14T08:10:37.3474445Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:37.3476346Z   AWS_RETRY_MODE: standard
2026-01-14T08:10:37.3476591Z   AWS_MAX_ATTEMPTS: 5
2026-01-14T08:10:37.3476848Z   AWS_DEFAULT_REGION: us-east-1
2026-01-14T08:10:37.3477104Z ##[endgroup]
2026-01-14T08:10:38.3800530Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:10:38.3801166Z Configure a credential helper to remove this warning. See
2026-01-14T08:10:38.3801816Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:10:38.3802279Z 
2026-01-14T08:10:38.3802460Z Login Succeeded
2026-01-14T08:10:38.4057487Z ##[group]Run env | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"
2026-01-14T08:10:38.4058284Z [36;1menv | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:10:38.4058817Z [36;1menv | grep '^CI' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:10:38.4059320Z [36;1menv | grep '^RUNNER' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:10:38.4065559Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:38.4065933Z env:
2026-01-14T08:10:38.4066178Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:38.4066506Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:38.4066759Z   PR_NUMBER: 3500
2026-01-14T08:10:38.4068609Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:38.4070507Z ##[endgroup]
2026-01-14T08:10:38.4174486Z ##[group]Run RUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"
2026-01-14T08:10:38.4174967Z [36;1mRUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"[0m
2026-01-14T08:10:38.4175370Z [36;1msudo rm -rf "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:10:38.4175709Z [36;1mmkdir -p "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:10:38.4176297Z [36;1mecho "RUNNER_ARTIFACT_DIR=${RUNNER_ARTIFACT_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:10:38.4176730Z [36;1m[0m
2026-01-14T08:10:38.4177018Z [36;1mRUNNER_TEST_RESULTS_DIR="${RUNNER_TEMP}/test-results"[0m
2026-01-14T08:10:38.4177447Z [36;1msudo rm -rf "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:10:38.4177807Z [36;1mmkdir -p "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:10:38.4178293Z [36;1mecho "RUNNER_TEST_RESULTS_DIR=${RUNNER_TEST_RESULTS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:10:38.4178745Z [36;1m[0m
2026-01-14T08:10:38.4178993Z [36;1mRUNNER_DOCS_DIR="${RUNNER_TEMP}/docs"[0m
2026-01-14T08:10:38.4179337Z [36;1msudo rm -rf "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:10:38.4179644Z [36;1mmkdir -p "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:10:38.4180046Z [36;1mecho "RUNNER_DOCS_DIR=${RUNNER_DOCS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:10:38.4185529Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:38.4185899Z env:
2026-01-14T08:10:38.4186140Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:38.4186472Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:38.4186710Z   PR_NUMBER: 3500
2026-01-14T08:10:38.4188559Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:38.4190445Z ##[endgroup]
2026-01-14T08:10:38.9556253Z ##[group]Run needs=0
2026-01-14T08:10:38.9556532Z [36;1mneeds=0[0m
2026-01-14T08:10:38.9556927Z [36;1mif lspci -v | grep -e 'controller.*NVIDIA' >/dev/null 2>/dev/null; then[0m
2026-01-14T08:10:38.9557370Z [36;1m  needs=1[0m
2026-01-14T08:10:38.9557584Z [36;1mfi[0m
2026-01-14T08:10:38.9557852Z [36;1mecho "does=${needs}" >> $GITHUB_OUTPUT[0m
2026-01-14T08:10:38.9563680Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:38.9564055Z env:
2026-01-14T08:10:38.9564307Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:38.9564634Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:38.9564893Z   PR_NUMBER: 3500
2026-01-14T08:10:38.9566888Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:38.9568927Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:10:38.9569516Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:10:38.9570073Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:10:38.9570466Z ##[endgroup]
2026-01-14T08:10:38.9816835Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T08:10:38.9817417Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T08:10:38.9817849Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T08:10:38.9818161Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T08:10:38.9818504Z [36;1m# Prune all of the docker images[0m
2026-01-14T08:10:38.9818824Z [36;1mdocker system prune -af[0m
2026-01-14T08:10:38.9824194Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:38.9824549Z env:
2026-01-14T08:10:38.9824795Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:38.9825116Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:38.9825370Z   PR_NUMBER: 3500
2026-01-14T08:10:38.9827232Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:38.9829415Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:10:38.9830013Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:10:38.9830583Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:10:38.9830959Z ##[endgroup]
2026-01-14T08:10:39.0095721Z "docker stop" requires at least 1 argument.
2026-01-14T08:10:39.0096091Z See 'docker stop --help'.
2026-01-14T08:10:39.0096261Z 
2026-01-14T08:10:39.0096418Z Usage:  docker stop [OPTIONS] CONTAINER [CONTAINER...]
2026-01-14T08:10:39.0096682Z 
2026-01-14T08:10:39.0096814Z Stop one or more running containers
2026-01-14T08:10:39.0264205Z Total reclaimed space: 0B
2026-01-14T08:10:39.0344447Z ##[group]Run ./test-infra/.github/actions/setup-ssh
2026-01-14T08:10:39.0344825Z with:
2026-01-14T08:10:39.0345433Z   github-secret: ***
2026-01-14T08:10:39.0346160Z   instructions: All testing is done inside the container, to start an interactive session run:
   docker exec -it $(docker container ps --format '{{.ID}}') bash

2026-01-14T08:10:39.0346945Z   activate-with-label: false
2026-01-14T08:10:39.0347202Z   label: with-ssh
2026-01-14T08:10:39.0347440Z   remove-existing-keys: true
2026-01-14T08:10:39.0347702Z   fail-silently: true
2026-01-14T08:10:39.0347932Z env:
2026-01-14T08:10:39.0348158Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:39.0348647Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:39.0349024Z   PR_NUMBER: 3500
2026-01-14T08:10:39.0351218Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:39.0353290Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:10:39.0353865Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:10:39.0354423Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:10:39.0354797Z ##[endgroup]
2026-01-14T08:10:39.1398507Z Please see https://github.com/pytorch/pytorch/wiki/Debugging-using-with-ssh-for-Github-Actions for more info.
2026-01-14T08:10:39.7835399Z Grabbing public ssh keys from https://github.com/zxd1997066.keys
2026-01-14T08:10:39.8651783Z ~/.ssh/authorized_keys file found on node, removing ~/.ssh and starting fresh
2026-01-14T08:10:39.8666054Z Public keys pulled and installed to /home/ec2-user/.ssh/authorized_keys
2026-01-14T08:10:39.8702100Z Login using: ssh ec2-user@ec2-44-220-193-107.compute-1.amazonaws.com
2026-01-14T08:10:39.8703016Z All testing is done inside the container, to start an interactive session run:
2026-01-14T08:10:39.8703612Z    docker exec -it $(docker container ps --format '{{.ID}}') bash
2026-01-14T08:10:39.8854634Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:10:39.8855054Z with:
2026-01-14T08:10:39.8855272Z   repository: pytorch/ao
2026-01-14T08:10:39.8855538Z   ref: refs/pull/3500/merge
2026-01-14T08:10:39.8855786Z   path: pytorch/ao
2026-01-14T08:10:39.8856016Z   fetch-depth: 1
2026-01-14T08:10:39.8856233Z   submodules: recursive
2026-01-14T08:10:39.8856626Z   token: ***
2026-01-14T08:10:39.8856826Z   ssh-strict: true
2026-01-14T08:10:39.8857049Z   ssh-user: git
2026-01-14T08:10:39.8857267Z   persist-credentials: true
2026-01-14T08:10:39.8857527Z   clean: true
2026-01-14T08:10:39.8857905Z   sparse-checkout-cone-mode: true
2026-01-14T08:10:39.8858182Z   fetch-tags: false
2026-01-14T08:10:39.8858414Z   show-progress: true
2026-01-14T08:10:39.8858635Z   lfs: false
2026-01-14T08:10:39.8858855Z   set-safe-directory: true
2026-01-14T08:10:39.8859094Z env:
2026-01-14T08:10:39.8859332Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:39.8859692Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:39.8859936Z   PR_NUMBER: 3500
2026-01-14T08:10:39.8861767Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:39.8863807Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:10:39.8864396Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:10:39.8864932Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:10:39.8865315Z ##[endgroup]
2026-01-14T08:10:39.9794676Z Syncing repository: pytorch/ao
2026-01-14T08:10:39.9802339Z ##[group]Getting Git version info
2026-01-14T08:10:39.9802808Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao'
2026-01-14T08:10:39.9827731Z [command]/usr/bin/git version
2026-01-14T08:10:39.9868548Z git version 2.50.1
2026-01-14T08:10:39.9891633Z ##[endgroup]
2026-01-14T08:10:39.9902446Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/0b3b7300-ada9-454e-a8bd-6583a6f46c80' before making global git config changes
2026-01-14T08:10:39.9903398Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:10:39.9906977Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:10:39.9932390Z ##[group]Initializing the repository
2026-01-14T08:10:39.9936447Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:10:39.9969025Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:10:39.9970117Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:10:39.9971107Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:10:39.9971811Z hint:
2026-01-14T08:10:39.9972364Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:10:39.9972977Z hint:
2026-01-14T08:10:39.9973531Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:10:39.9974537Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:10:39.9975297Z hint:
2026-01-14T08:10:39.9975635Z hint: 	git branch -m <name>
2026-01-14T08:10:39.9976058Z hint:
2026-01-14T08:10:39.9976638Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:10:39.9977897Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/
2026-01-14T08:10:39.9981909Z [command]/usr/bin/git remote add origin https://github.com/pytorch/ao
2026-01-14T08:10:40.0016772Z ##[endgroup]
2026-01-14T08:10:40.0017801Z ##[group]Disabling automatic garbage collection
2026-01-14T08:10:40.0021947Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:10:40.0046709Z ##[endgroup]
2026-01-14T08:10:40.0047370Z ##[group]Setting up auth
2026-01-14T08:10:40.0053308Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:10:40.0077973Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:10:40.0344827Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:10:40.0370784Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:10:40.0631915Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:10:40.0670905Z ##[endgroup]
2026-01-14T08:10:40.0671301Z ##[group]Fetching the repository
2026-01-14T08:10:40.0685763Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/pull/3500/merge:refs/remotes/pull/3500/merge
2026-01-14T08:10:40.7498733Z From https://github.com/pytorch/ao
2026-01-14T08:10:40.7499175Z  * [new ref]         refs/pull/3500/merge -> pull/3500/merge
2026-01-14T08:10:40.7519026Z ##[endgroup]
2026-01-14T08:10:40.7519507Z ##[group]Determining the checkout info
2026-01-14T08:10:40.7521596Z ##[endgroup]
2026-01-14T08:10:40.7526208Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:10:40.7558800Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:10:40.7583041Z ##[group]Checking out the ref
2026-01-14T08:10:40.7586980Z [command]/usr/bin/git checkout --progress --force refs/remotes/pull/3500/merge
2026-01-14T08:10:40.8694662Z Note: switching to 'refs/remotes/pull/3500/merge'.
2026-01-14T08:10:40.8694953Z 
2026-01-14T08:10:40.8695186Z You are in 'detached HEAD' state. You can look around, make experimental
2026-01-14T08:10:40.8695729Z changes and commit them, and you can discard any commits you make in this
2026-01-14T08:10:40.8696278Z state without impacting any branches by switching back to a branch.
2026-01-14T08:10:40.8696593Z 
2026-01-14T08:10:40.8696801Z If you want to create a new branch to retain commits you create, you may
2026-01-14T08:10:40.8697308Z do so (now or later) by using -c with the switch command. Example:
2026-01-14T08:10:40.8697620Z 
2026-01-14T08:10:40.8697742Z   git switch -c <new-branch-name>
2026-01-14T08:10:40.8697935Z 
2026-01-14T08:10:40.8698040Z Or undo this operation with:
2026-01-14T08:10:40.8698218Z 
2026-01-14T08:10:40.8698316Z   git switch -
2026-01-14T08:10:40.8698441Z 
2026-01-14T08:10:40.8698674Z Turn off this advice by setting config variable advice.detachedHead to false
2026-01-14T08:10:40.8699035Z 
2026-01-14T08:10:40.8699422Z HEAD is now at b34f898 Merge f07387cd29b2a97703e501a48808c413bf9d95ea into 985d970b5e16b58c1e5b8bab440169d3da78cf16
2026-01-14T08:10:40.8704384Z ##[endgroup]
2026-01-14T08:10:40.8705057Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:10:40.8710015Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:10:40.8744415Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:10:40.8770232Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:10:40.8796631Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:10:40.8818481Z ##[endgroup]
2026-01-14T08:10:40.8819173Z ##[group]Fetching submodules
2026-01-14T08:10:40.8822512Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:10:40.9086262Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:10:40.9342969Z Submodule 'third_party/cutlass' (https://github.com/NVIDIA/cutlass) registered for path 'third_party/cutlass'
2026-01-14T08:10:40.9367103Z Cloning into '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/third_party/cutlass'...
2026-01-14T08:10:42.9801874Z From https://github.com/NVIDIA/cutlass
2026-01-14T08:10:42.9802569Z  * branch            e51efbfe18fe4f4cbb66ab814c55bf4aa0185491 -> FETCH_HEAD
2026-01-14T08:10:43.5897875Z Submodule path 'third_party/cutlass': checked out 'e51efbfe18fe4f4cbb66ab814c55bf4aa0185491'
2026-01-14T08:10:43.5934090Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:10:43.6195597Z Entering 'third_party/cutlass'
2026-01-14T08:10:43.6252156Z ##[endgroup]
2026-01-14T08:10:43.6252581Z ##[group]Persisting credentials for submodules
2026-01-14T08:10:43.6258059Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:10:43.6508757Z Entering 'third_party/cutlass'
2026-01-14T08:10:43.6582205Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:10:43.6836149Z Entering 'third_party/cutlass'
2026-01-14T08:10:43.6886283Z file:/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/modules/third_party/cutlass/config	remote.origin.url
2026-01-14T08:10:43.6935323Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:10:43.7191263Z Entering 'third_party/cutlass'
2026-01-14T08:10:43.7250658Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:10:43.7508720Z Entering 'third_party/cutlass'
2026-01-14T08:10:43.7567480Z ##[endgroup]
2026-01-14T08:10:43.7598357Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:10:43.7617315Z b34f89824bef6a4573349bfbefa82a7db14ede35
2026-01-14T08:10:43.7850778Z Prepare all required actions
2026-01-14T08:10:43.7851339Z Getting action download info
2026-01-14T08:10:43.9121401Z Download action repository 'nick-fields/retry@v3.0.0' (SHA:7152eba30c6575329ac0576536151aca5a72780e)
2026-01-14T08:10:44.1175811Z ##[group]Run ./test-infra/.github/actions/calculate-docker-image
2026-01-14T08:10:44.1176198Z with:
2026-01-14T08:10:44.1176453Z   use-custom-docker-registry: true
2026-01-14T08:10:44.1176794Z   docker-image-name: pytorch/almalinux-builder:cpu
2026-01-14T08:10:44.1177153Z   docker-build-dir: .ci/docker
2026-01-14T08:10:44.1177442Z   working-directory: pytorch/ao
2026-01-14T08:10:44.1177721Z   docker-build-script: ./build.sh
2026-01-14T08:10:44.1178100Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:10:44.1178478Z   force-push: false
2026-01-14T08:10:44.1178700Z env:
2026-01-14T08:10:44.1178922Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:44.1179254Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:44.1179534Z   PR_NUMBER: 3500
2026-01-14T08:10:44.1181380Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:44.1183416Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:10:44.1183997Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:10:44.1184538Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:10:44.1184923Z ##[endgroup]
2026-01-14T08:10:44.1215647Z ##[group]Run set -ex
2026-01-14T08:10:44.1215933Z [36;1mset -ex[0m
2026-01-14T08:10:44.1216155Z [36;1m[0m
2026-01-14T08:10:44.1216555Z [36;1m# If the docker build directory or the build script doesn't exist, the action will[0m
2026-01-14T08:10:44.1217245Z [36;1m# gracefully return the docker image name as it is.  Pulling docker image in Linux[0m
2026-01-14T08:10:44.1217819Z [36;1m# job could then download the pre-built image as usual[0m
2026-01-14T08:10:44.1218575Z [36;1mif [[ -d "${DOCKER_BUILD_DIR}" ]] && [[ -f "${DOCKER_BUILD_DIR}/${DOCKER_BUILD_SCRIPT}" ]] && [[ "${USE_CUSTOM_DOCKER_REGISTRY}" == "true" ]]; then[0m
2026-01-14T08:10:44.1219434Z [36;1m  echo "skip=false" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:10:44.1219756Z [36;1melse[0m
2026-01-14T08:10:44.1220015Z [36;1m  echo "skip=true" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:10:44.1220450Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:10:44.1220863Z [36;1m[0m
2026-01-14T08:10:44.1221427Z [36;1m  echo "Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ${REPO_NAME} repo..."[0m
2026-01-14T08:10:44.1222093Z [36;1m  exit 0[0m
2026-01-14T08:10:44.1222313Z [36;1mfi[0m
2026-01-14T08:10:44.1222503Z [36;1m[0m
2026-01-14T08:10:44.1222844Z [36;1mif [[ "${DOCKER_IMAGE_NAME}" == *"${DOCKER_REGISTRY}/${REPO_NAME}"* ]]; then[0m
2026-01-14T08:10:44.1223447Z [36;1m  # The docker image name already includes the ECR prefix and tag, so we can just[0m
2026-01-14T08:10:44.1224000Z [36;1m  # use it as it is, but first let's extract the tag[0m
2026-01-14T08:10:44.1224481Z [36;1m  DOCKER_TAG=$(echo "${DOCKER_IMAGE_NAME}" | awk -F '[:,]' '{print $2}')[0m
2026-01-14T08:10:44.1225001Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:10:44.1225492Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:10:44.1225889Z [36;1melse[0m
2026-01-14T08:10:44.1226152Z [36;1m  if [[ "${DOCKER_IMAGE_NAME}" == *:* ]]; then[0m
2026-01-14T08:10:44.1226530Z [36;1m    CUSTOM_TAG_PREFIX=${DOCKER_IMAGE_NAME#*:}[0m
2026-01-14T08:10:44.1227044Z [36;1m    DOCKER_IMAGE_NAME=${DOCKER_IMAGE_NAME%%:*}[0m
2026-01-14T08:10:44.1227372Z [36;1m  fi[0m
2026-01-14T08:10:44.1227836Z [36;1m  DOCKER_TAG=${CUSTOM_TAG_PREFIX:+${CUSTOM_TAG_PREFIX}-}$(git rev-parse HEAD:"${DOCKER_BUILD_DIR}")[0m
2026-01-14T08:10:44.1228472Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:10:44.1229119Z [36;1m  echo "docker-image=${DOCKER_REGISTRY}/${REPO_NAME}/${DOCKER_IMAGE_NAME}:${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:10:44.1229854Z [36;1m  echo "custom-tag-prefix=${CUSTOM_TAG_PREFIX}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:10:44.1230280Z [36;1mfi[0m
2026-01-14T08:10:44.1235969Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:44.1236328Z env:
2026-01-14T08:10:44.1236580Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:44.1236921Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:44.1237165Z   PR_NUMBER: 3500
2026-01-14T08:10:44.1239019Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:44.1241056Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:10:44.1241626Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:10:44.1242179Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:10:44.1242553Z   REPO_NAME: ao
2026-01-14T08:10:44.1242823Z   DOCKER_IMAGE_NAME: pytorch/almalinux-builder:cpu
2026-01-14T08:10:44.1243165Z   DOCKER_BUILD_DIR: .ci/docker
2026-01-14T08:10:44.1243451Z   DOCKER_BUILD_SCRIPT: ./build.sh
2026-01-14T08:10:44.1243830Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:10:44.1244219Z   USE_CUSTOM_DOCKER_REGISTRY: true
2026-01-14T08:10:44.1244507Z   CUSTOM_TAG_PREFIX: 
2026-01-14T08:10:44.1244730Z ##[endgroup]
2026-01-14T08:10:44.1270721Z + [[ -d .ci/docker ]]
2026-01-14T08:10:44.1270984Z + echo skip=true
2026-01-14T08:10:44.1271486Z + echo docker-image=pytorch/almalinux-builder:cpu
2026-01-14T08:10:44.1272370Z + echo 'Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...'
2026-01-14T08:10:44.1272991Z + exit 0
2026-01-14T08:10:44.1273476Z Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...
2026-01-14T08:10:44.1314047Z ##[group]Run set -eux
2026-01-14T08:10:44.1314317Z [36;1mset -eux[0m
2026-01-14T08:10:44.1314757Z [36;1m# It's ok if this steps fails, it would then be an anonymous user like what we used to have[0m
2026-01-14T08:10:44.1315975Z [36;1maws secretsmanager get-secret-value --secret-id docker_hub_readonly_token | jq --raw-output '.SecretString' | jq -r .docker_hub_readonly_token | docker login --username pytorchbot --password-stdin || true[0m
2026-01-14T08:10:44.1321858Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:44.1322216Z env:
2026-01-14T08:10:44.1322470Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:44.1322797Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:44.1323067Z   PR_NUMBER: 3500
2026-01-14T08:10:44.1324900Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:44.1326928Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:10:44.1327643Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:10:44.1328206Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:10:44.1328587Z ##[endgroup]
2026-01-14T08:10:44.1353878Z + aws secretsmanager get-secret-value --secret-id docker_hub_readonly_token
2026-01-14T08:10:44.1354819Z + jq --raw-output .SecretString
2026-01-14T08:10:44.1355932Z + jq -r .docker_hub_readonly_token
2026-01-14T08:10:44.1357142Z + docker login --username pytorchbot --password-stdin
2026-01-14T08:10:44.7033161Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:10:44.7033802Z Configure a credential helper to remove this warning. See
2026-01-14T08:10:44.7034368Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:10:44.7034764Z 
2026-01-14T08:10:44.7034854Z Login Succeeded
2026-01-14T08:10:44.7121203Z Prepare all required actions
2026-01-14T08:10:44.7167451Z ##[group]Run ./test-infra/.github/actions/pull-docker-image
2026-01-14T08:10:44.7167818Z with:
2026-01-14T08:10:44.7168073Z   docker-image: pytorch/almalinux-builder:cpu
2026-01-14T08:10:44.7168502Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:10:44.7168871Z env:
2026-01-14T08:10:44.7169109Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:44.7169439Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:44.7169690Z   PR_NUMBER: 3500
2026-01-14T08:10:44.7171561Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:44.7173704Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:10:44.7174274Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:10:44.7174823Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:10:44.7175193Z ##[endgroup]
2026-01-14T08:10:44.7393289Z ##[group]Run set -x
2026-01-14T08:10:44.7393560Z [36;1mset -x[0m
2026-01-14T08:10:44.7393916Z [36;1mset +e[0m
2026-01-14T08:10:44.7394130Z [36;1m[0m
2026-01-14T08:10:44.7394324Z [36;1mlogin() {[0m
2026-01-14T08:10:44.7394811Z [36;1m  aws ecr get-login-password --region us-east-1 | docker login -u AWS --password-stdin "$1"[0m
2026-01-14T08:10:44.7395336Z [36;1m}[0m
2026-01-14T08:10:44.7395540Z [36;1m[0m
2026-01-14T08:10:44.7395728Z [36;1mretry () {[0m
2026-01-14T08:10:44.7395997Z [36;1m  $*  || (sleep 1 && $*) || (sleep 2 && $*)[0m
2026-01-14T08:10:44.7396300Z [36;1m}[0m
2026-01-14T08:10:44.7396505Z [36;1m[0m
2026-01-14T08:10:44.7396730Z [36;1mretry login "${DOCKER_REGISTRY}"[0m
2026-01-14T08:10:44.7397014Z [36;1m[0m
2026-01-14T08:10:44.7397506Z [36;1mIMAGE_SIZE=$(docker manifest inspect "${DOCKER_IMAGE}" | jq '[.layers[].size, .config.size] | add / 1024 / 1024')[0m
2026-01-14T08:10:44.7398171Z [36;1mecho "Compressed size of image in MB: ${IMAGE_SIZE}"[0m
2026-01-14T08:10:44.7398539Z [36;1m[0m
2026-01-14T08:10:44.7398724Z [36;1mset -e[0m
2026-01-14T08:10:44.7399059Z [36;1m# ignore output since only exit code is used for conditional[0m
2026-01-14T08:10:44.7399550Z [36;1m# only pull docker image if it's not available locally[0m
2026-01-14T08:10:44.7400083Z [36;1mif ! docker inspect --type=image "${DOCKER_IMAGE}" >/dev/null 2>/dev/null; then[0m
2026-01-14T08:10:44.7400591Z [36;1m  retry docker pull "${DOCKER_IMAGE}"[0m
2026-01-14T08:10:44.7400895Z [36;1mfi[0m
2026-01-14T08:10:44.7406751Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:10:44.7407105Z env:
2026-01-14T08:10:44.7407361Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:10:44.7407687Z   REPOSITORY: pytorch/ao
2026-01-14T08:10:44.7407945Z   PR_NUMBER: 3500
2026-01-14T08:10:44.7409786Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:10:44.7411811Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:10:44.7412510Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:10:44.7413060Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:10:44.7413689Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:10:44.7414080Z ##[endgroup]
2026-01-14T08:10:44.7438194Z + set +e
2026-01-14T08:10:44.7438555Z + retry login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:10:44.7438989Z + login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:10:44.7441591Z + aws ecr get-login-password --region us-east-1
2026-01-14T08:10:44.7442706Z + docker login -u AWS --password-stdin 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:10:45.2705109Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:10:45.2706138Z Configure a credential helper to remove this warning. See
2026-01-14T08:10:45.2706967Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:10:45.2707366Z 
2026-01-14T08:10:45.2707462Z Login Succeeded
2026-01-14T08:10:45.2724959Z ++ docker manifest inspect pytorch/almalinux-builder:cpu
2026-01-14T08:10:45.2725450Z ++ jq '[.layers[].size, .config.size] | add / 1024 / 1024'
2026-01-14T08:10:45.4645378Z + IMAGE_SIZE=1525.285717010498
2026-01-14T08:10:45.4645764Z + echo 'Compressed size of image in MB: 1525.285717010498'
2026-01-14T08:10:45.4646126Z + set -e
2026-01-14T08:10:45.4646368Z Compressed size of image in MB: 1525.285717010498
2026-01-14T08:10:45.4646803Z + docker inspect --type=image pytorch/almalinux-builder:cpu
2026-01-14T08:10:45.4777015Z + retry docker pull pytorch/almalinux-builder:cpu
2026-01-14T08:10:45.4777424Z + docker pull pytorch/almalinux-builder:cpu
2026-01-14T08:10:45.6603869Z cpu: Pulling from pytorch/almalinux-builder
2026-01-14T08:10:45.6604412Z 19877a9af8e3: Pulling fs layer
2026-01-14T08:10:45.6604866Z 58aaae3842a2: Pulling fs layer
2026-01-14T08:10:45.6605298Z 382853493dc2: Pulling fs layer
2026-01-14T08:10:45.6605677Z 563cf1069f7b: Pulling fs layer
2026-01-14T08:10:45.6606205Z 251bdb0cedd5: Pulling fs layer
2026-01-14T08:10:45.6606476Z 4da5a0ade24c: Pulling fs layer
2026-01-14T08:10:45.6606763Z fe7be11bba3d: Pulling fs layer
2026-01-14T08:10:45.6607063Z 4f4fb700ef54: Pulling fs layer
2026-01-14T08:10:45.6607335Z 88c23a48216f: Pulling fs layer
2026-01-14T08:10:45.6607605Z ff463c5f233f: Pulling fs layer
2026-01-14T08:10:45.6607864Z ebc15953b9e3: Pulling fs layer
2026-01-14T08:10:45.6608196Z 433b8f4bfff9: Pulling fs layer
2026-01-14T08:10:45.6608452Z 41a959fc46e5: Pulling fs layer
2026-01-14T08:10:45.6608722Z 48b1ad7a6bb8: Pulling fs layer
2026-01-14T08:10:45.6608981Z 3cc82db6c32f: Pulling fs layer
2026-01-14T08:10:45.6609260Z fe7be11bba3d: Waiting
2026-01-14T08:10:45.6609483Z ff463c5f233f: Waiting
2026-01-14T08:10:45.6609722Z 8d47606e1e2c: Pulling fs layer
2026-01-14T08:10:45.6609971Z 41a959fc46e5: Waiting
2026-01-14T08:10:45.6610204Z 48b1ad7a6bb8: Waiting
2026-01-14T08:10:45.6610449Z a7fa2cf3c146: Pulling fs layer
2026-01-14T08:10:45.6610701Z 3cc82db6c32f: Waiting
2026-01-14T08:10:45.6610935Z 251bdb0cedd5: Waiting
2026-01-14T08:10:45.6611153Z 8d47606e1e2c: Waiting
2026-01-14T08:10:45.6611411Z ebc15953b9e3: Waiting
2026-01-14T08:10:45.6611715Z 563cf1069f7b: Waiting
2026-01-14T08:10:45.6612058Z 4da5a0ade24c: Waiting
2026-01-14T08:10:45.6612431Z a7fa2cf3c146: Waiting
2026-01-14T08:10:45.6612675Z 4f4fb700ef54: Waiting
2026-01-14T08:10:45.9653030Z 382853493dc2: Verifying Checksum
2026-01-14T08:10:45.9653371Z 382853493dc2: Download complete
2026-01-14T08:10:46.4974505Z 19877a9af8e3: Verifying Checksum
2026-01-14T08:10:46.4974851Z 19877a9af8e3: Download complete
2026-01-14T08:10:46.8088411Z 563cf1069f7b: Verifying Checksum
2026-01-14T08:10:46.8088816Z 563cf1069f7b: Download complete
2026-01-14T08:10:46.8618988Z 4da5a0ade24c: Verifying Checksum
2026-01-14T08:10:46.8619344Z 4da5a0ade24c: Download complete
2026-01-14T08:10:47.4995868Z fe7be11bba3d: Verifying Checksum
2026-01-14T08:10:47.4996229Z fe7be11bba3d: Download complete
2026-01-14T08:10:47.5476868Z 4f4fb700ef54: Download complete
2026-01-14T08:10:47.7783668Z 88c23a48216f: Verifying Checksum
2026-01-14T08:10:47.7784046Z 88c23a48216f: Download complete
2026-01-14T08:10:47.9045295Z ff463c5f233f: Verifying Checksum
2026-01-14T08:10:47.9045893Z ff463c5f233f: Download complete
2026-01-14T08:10:48.4471463Z 19877a9af8e3: Pull complete
2026-01-14T08:10:48.5211741Z 58aaae3842a2: Verifying Checksum
2026-01-14T08:10:48.5212167Z 58aaae3842a2: Download complete
2026-01-14T08:10:48.5681779Z 433b8f4bfff9: Verifying Checksum
2026-01-14T08:10:48.6348751Z 433b8f4bfff9: Download complete
2026-01-14T08:10:48.6349112Z 41a959fc46e5: Verifying Checksum
2026-01-14T08:10:48.6349389Z 41a959fc46e5: Download complete
2026-01-14T08:10:48.6791343Z 48b1ad7a6bb8: Download complete
2026-01-14T08:10:48.8541260Z 3cc82db6c32f: Verifying Checksum
2026-01-14T08:10:48.8541593Z 3cc82db6c32f: Download complete
2026-01-14T08:10:48.9008229Z 8d47606e1e2c: Verifying Checksum
2026-01-14T08:10:48.9008569Z 8d47606e1e2c: Download complete
2026-01-14T08:10:50.1513631Z 251bdb0cedd5: Verifying Checksum
2026-01-14T08:10:50.1514050Z 251bdb0cedd5: Download complete
2026-01-14T08:10:51.4071925Z 58aaae3842a2: Pull complete
2026-01-14T08:10:51.5797157Z 382853493dc2: Pull complete
2026-01-14T08:10:51.9032707Z 563cf1069f7b: Pull complete
2026-01-14T08:10:54.9052603Z ebc15953b9e3: Verifying Checksum
2026-01-14T08:10:54.9052985Z ebc15953b9e3: Download complete
2026-01-14T08:10:56.8660888Z 251bdb0cedd5: Pull complete
2026-01-14T08:10:57.0209887Z 4da5a0ade24c: Pull complete
2026-01-14T08:10:57.3584331Z a7fa2cf3c146: Verifying Checksum
2026-01-14T08:10:57.3584705Z a7fa2cf3c146: Download complete
2026-01-14T08:10:58.1785839Z fe7be11bba3d: Pull complete
2026-01-14T08:10:58.4001319Z 4f4fb700ef54: Pull complete
2026-01-14T08:10:58.7053838Z 88c23a48216f: Pull complete
2026-01-14T08:10:58.8784868Z ff463c5f233f: Pull complete
2026-01-14T08:11:10.2483579Z ebc15953b9e3: Pull complete
2026-01-14T08:11:10.2692399Z 433b8f4bfff9: Pull complete
2026-01-14T08:11:10.2905385Z 41a959fc46e5: Pull complete
2026-01-14T08:11:10.3113796Z 48b1ad7a6bb8: Pull complete
2026-01-14T08:11:10.5799216Z 3cc82db6c32f: Pull complete
2026-01-14T08:11:10.6210738Z 8d47606e1e2c: Pull complete
2026-01-14T08:11:24.8400512Z a7fa2cf3c146: Pull complete
2026-01-14T08:11:24.9504372Z Digest: sha256:66286600d3e57d1bc722d6fe6e53c8526ec521021cec2eaad02c70f350ba2d23
2026-01-14T08:11:24.9797109Z Status: Downloaded newer image for pytorch/almalinux-builder:cpu
2026-01-14T08:11:24.9950454Z docker.io/pytorch/almalinux-builder:cpu
2026-01-14T08:11:24.9996903Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:11:24.9997971Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:11:25.0007136Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:11:25.0007508Z env:
2026-01-14T08:11:25.0007747Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:11:25.0008084Z   REPOSITORY: pytorch/ao
2026-01-14T08:11:25.0008339Z   PR_NUMBER: 3500
2026-01-14T08:11:25.0010221Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:11:25.0012368Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:11:25.0012954Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:11:25.0013508Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:11:25.0013882Z ##[endgroup]
2026-01-14T08:11:25.0159067Z ##[group]Run set -ex
2026-01-14T08:11:25.0159348Z [36;1mset -ex[0m
2026-01-14T08:11:25.0159565Z [36;1m{[0m
2026-01-14T08:11:25.0159775Z [36;1m  echo "#!/usr/bin/env bash";[0m
2026-01-14T08:11:25.0160094Z [36;1m  echo "set -eou pipefail";[0m
2026-01-14T08:11:25.0160393Z [36;1m  # shellcheck disable=SC2016[0m
2026-01-14T08:11:25.0160736Z [36;1m  echo 'eval "$(conda shell.bash hook)"';[0m
2026-01-14T08:11:25.0161150Z [36;1m  echo "set -x";[0m
2026-01-14T08:11:25.0161416Z [36;1m  echo "${SCRIPT}";[0m
2026-01-14T08:11:25.0161705Z [36;1m} > "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:11:25.0162033Z [36;1mchmod +x "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:11:25.0162663Z [36;1mpython3 "/home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py" ""[0m
2026-01-14T08:11:25.0168606Z shell: /usr/bin/bash -e {0}
2026-01-14T08:11:25.0168861Z env:
2026-01-14T08:11:25.0169112Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:11:25.0169485Z   REPOSITORY: pytorch/ao
2026-01-14T08:11:25.0169733Z   PR_NUMBER: 3500
2026-01-14T08:11:25.0171568Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:11:25.0173712Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:11:25.0174284Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:11:25.0175021Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:11:25.0175666Z   ALL_SECRETS: {
  "github_token": "***"
}
2026-01-14T08:11:25.0175958Z ##[endgroup]
2026-01-14T08:11:25.0198952Z + echo '#!/usr/bin/env bash'
2026-01-14T08:11:25.0199252Z + echo 'set -eou pipefail'
2026-01-14T08:11:25.0199567Z + echo 'eval "$(conda shell.bash hook)"'
2026-01-14T08:11:25.0199870Z + echo 'set -x'
2026-01-14T08:11:25.0200228Z + echo 'conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:11:25.0200686Z conda activate venv
2026-01-14T08:11:25.0200928Z python -m pip install --upgrade pip
2026-01-14T08:11:25.0201376Z pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
2026-01-14T08:11:25.0201821Z sed -i '\'''\'' dev-requirements.txt
2026-01-14T08:11:25.0202134Z pip install -r dev-requirements.txt
2026-01-14T08:11:25.0202445Z pip install . --no-build-isolation
2026-01-14T08:11:25.0202761Z export CONDA=$(dirname $(dirname $(which conda)))
2026-01-14T08:11:25.0203150Z export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
2026-01-14T08:11:25.0203488Z pytest test --verbose -s
2026-01-14T08:11:25.0203734Z '
2026-01-14T08:11:25.0204017Z + chmod +x /home/ec2-user/actions-runner/_work/_temp/exec_script
2026-01-14T08:11:25.0210409Z + python3 /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py ''
2026-01-14T08:12:03.4262012Z Running command: 
2026-01-14T08:12:03.4268984Z         docker run             -e PR_NUMBER             -e RUNNER_ARTIFACT_DIR=/artifacts             -e RUNNER_DOCS_DIR=/docs             -e RUNNER_TEST_RESULTS_DIR=/test-results             --env-file="/home/ec2-user/actions-runner/_work/_temp/github_env_20985547555"             `# It is unknown why the container sees a different value for this.`             -e GITHUB_STEP_SUMMARY             -e SECRET_GITHUB_TOKEN             --cap-add=SYS_PTRACE             --detach             --ipc=host             --security-opt seccomp=unconfined             --shm-size=2g             --tty             --ulimit stack=10485760:83886080             --ulimit core=0                          -v "/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao:/pytorch/ao"             -v "/home/ec2-user/actions-runner/_work/ao/ao/test-infra:/test-infra"             -v "/home/ec2-user/actions-runner/_work/_temp/artifacts:/artifacts"             -v "/home/ec2-user/actions-runner/_work/_temp/docs:/docs"             -v "/home/ec2-user/actions-runner/_work/_temp/test-results:/test-results"             -v "/home/ec2-user/actions-runner/_work/_temp/exec_script:/exec"             -v "/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_a113dad8-95e1-479d-ae54-3011d78e43dd":"/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_a113dad8-95e1-479d-ae54-3011d78e43dd"             -w /pytorch/ao             "pytorch/almalinux-builder:cpu"
2026-01-14T08:12:03.4274911Z         
2026-01-14T08:12:03.4275224Z bb906dca78c72976258a0b88307c77037106f7dc3b285e5af7aeed400cdfd2bb
2026-01-14T08:12:03.4275970Z Running command: docker exec -t bb906dca78c72976258a0b88307c77037106f7dc3b285e5af7aeed400cdfd2bb /exec
2026-01-14T08:12:03.4276650Z + conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:12:03.4277079Z + local cmd=create
2026-01-14T08:12:03.4277293Z + case "$cmd" in
2026-01-14T08:12:03.4277660Z + __conda_exe create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:12:03.4278282Z + /opt/conda/bin/conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:12:03.4278776Z Could not load conda plugin `menuinst`:
2026-01-14T08:12:03.4278986Z 
2026-01-14T08:12:03.4279113Z Plugin requires `conda` to be installed.
2026-01-14T08:12:03.4280048Z Collecting package metadata (current_repodata.json): - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - done
2026-01-14T08:12:03.4281139Z Solving environment: | unsuccessful attempt using repodata from current_repodata.json, retrying with next repodata source.
2026-01-14T08:12:03.4282892Z Collecting package metadata (repodata.json): - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ done
2026-01-14T08:12:03.4283938Z Solving environment: / - \ | / - done
2026-01-14T08:12:03.4284190Z 
2026-01-14T08:12:03.4284195Z 
2026-01-14T08:12:03.4284325Z ==> WARNING: A newer version of conda exists. <==
2026-01-14T08:12:03.4284669Z   current version: 23.5.2
2026-01-14T08:12:03.4284919Z   latest version: 25.11.1
2026-01-14T08:12:03.4285076Z 
2026-01-14T08:12:03.4285190Z Please update conda by running
2026-01-14T08:12:03.4285369Z 
2026-01-14T08:12:03.4285483Z     $ conda update -n base -c defaults conda
2026-01-14T08:12:03.4285718Z 
2026-01-14T08:12:03.4285920Z Or to minimize the number of packages updated during conda update use
2026-01-14T08:12:03.4286234Z 
2026-01-14T08:12:03.4286335Z      conda install conda=25.11.1
2026-01-14T08:12:03.4286531Z 
2026-01-14T08:12:03.4286536Z 
2026-01-14T08:12:03.4286540Z 
2026-01-14T08:12:03.4286628Z ## Package Plan ##
2026-01-14T08:12:03.4286764Z 
2026-01-14T08:12:03.4286898Z   environment location: /opt/conda/envs/venv
2026-01-14T08:12:03.4287122Z 
2026-01-14T08:12:03.4287217Z   added / updated specs:
2026-01-14T08:12:03.4287471Z     - libgcc-ng=11.2.0
2026-01-14T08:12:03.4287706Z     - libstdcxx-ng=11.2.0
2026-01-14T08:12:03.4287953Z     - python=3.10
2026-01-14T08:12:03.4288081Z 
2026-01-14T08:12:03.4288085Z 
2026-01-14T08:12:03.4288215Z The following packages will be downloaded:
2026-01-14T08:12:03.4288433Z 
2026-01-14T08:12:03.4288548Z     package                    |            build
2026-01-14T08:12:03.4288884Z     ---------------------------|-----------------
2026-01-14T08:12:03.4289250Z     bzip2-1.0.8                |       h5eee18b_6         262 KB
2026-01-14T08:12:03.4289679Z     ld_impl_linux-64-2.44      |       h153f514_2         672 KB
2026-01-14T08:12:03.4290186Z     libffi-3.4.4               |       h6a678d5_1         141 KB
2026-01-14T08:12:03.4290605Z     libnsl-2.0.0               |       h5eee18b_0          31 KB
2026-01-14T08:12:03.4291017Z     libxcb-1.17.0              |       h9b100fa_0         430 KB
2026-01-14T08:12:03.4291420Z     libzlib-1.3.1              |       hb25bd0a_0          59 KB
2026-01-14T08:12:03.4291835Z     ncurses-6.5                |       h7934f7d_0         1.1 MB
2026-01-14T08:12:03.4292327Z     pip-25.3                   |     pyhc872135_0         1.1 MB
2026-01-14T08:12:03.4292754Z     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
2026-01-14T08:12:03.4293173Z     python-3.10.19             |       h6fa692b_0        24.5 MB
2026-01-14T08:12:03.4293592Z     readline-8.3               |       hc2a1206_0         471 KB
2026-01-14T08:12:03.4294028Z     setuptools-80.9.0          |  py310h06a4308_0         1.4 MB
2026-01-14T08:12:03.4294442Z     sqlite-3.51.0              |       h2a70700_0         1.2 MB
2026-01-14T08:12:03.4294845Z     tk-8.6.15                  |       h54e0aa7_0         3.4 MB
2026-01-14T08:12:03.4295235Z     tzdata-2025b               |       h04d1e81_0         116 KB
2026-01-14T08:12:03.4295645Z     wheel-0.45.1               |  py310h06a4308_0         115 KB
2026-01-14T08:12:03.4296054Z     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
2026-01-14T08:12:03.4296487Z     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
2026-01-14T08:12:03.4296917Z     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
2026-01-14T08:12:03.4297371Z     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
2026-01-14T08:12:03.4297787Z     xz-5.6.4                   |       h5eee18b_1         567 KB
2026-01-14T08:12:03.4298163Z     zlib-1.3.1                 |       hb25bd0a_0          96 KB
2026-01-14T08:12:03.4298629Z     ------------------------------------------------------------
2026-01-14T08:12:03.4298995Z                                            Total:        37.1 MB
2026-01-14T08:12:03.4299240Z 
2026-01-14T08:12:03.4299369Z The following NEW packages will be INSTALLED:
2026-01-14T08:12:03.4299598Z 
2026-01-14T08:12:03.4299819Z   _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main 
2026-01-14T08:12:03.4300280Z   _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu 
2026-01-14T08:12:03.4300736Z   bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 
2026-01-14T08:12:03.4301234Z   ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 
2026-01-14T08:12:03.4301825Z   expat              pkgs/main/linux-64::expat-2.7.3-h3385a95_0 
2026-01-14T08:12:03.4302309Z   ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 
2026-01-14T08:12:03.4302795Z   libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 
2026-01-14T08:12:03.4303259Z   libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 
2026-01-14T08:12:03.4303715Z   libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 
2026-01-14T08:12:03.4304168Z   libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 
2026-01-14T08:12:03.4304631Z   libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 
2026-01-14T08:12:03.4305121Z   libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 
2026-01-14T08:12:03.4305575Z   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
2026-01-14T08:12:03.4306009Z   libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 
2026-01-14T08:12:03.4306465Z   ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 
2026-01-14T08:12:03.4306904Z   openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 
2026-01-14T08:12:03.4307346Z   pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 
2026-01-14T08:12:03.4307823Z   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
2026-01-14T08:12:03.4308307Z   python             pkgs/main/linux-64::python-3.10.19-h6fa692b_0 
2026-01-14T08:12:03.4308843Z   readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 
2026-01-14T08:12:03.4309333Z   setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 
2026-01-14T08:12:03.4309831Z   sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 
2026-01-14T08:12:03.4310254Z   tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 
2026-01-14T08:12:03.4310655Z   tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 
2026-01-14T08:12:03.4311103Z   wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 
2026-01-14T08:12:03.4311577Z   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
2026-01-14T08:12:03.4312081Z   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
2026-01-14T08:12:03.4312599Z   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
2026-01-14T08:12:03.4313140Z   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
2026-01-14T08:12:03.4315371Z   xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 
2026-01-14T08:12:03.4315795Z   zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 
2026-01-14T08:12:03.4316068Z 
2026-01-14T08:12:03.4316073Z 
2026-01-14T08:12:03.4316077Z 
2026-01-14T08:12:03.4316187Z Downloading and Extracting Packages
2026-01-14T08:12:03.4316387Z 
2026-01-14T08:12:03.4316552Z libxcb-1.17.0        | 430 KB    | :   0% 0/1 [00:00<?, ?it/s]
2026-01-14T08:12:03.4316813Z 
2026-01-14T08:12:03.4317118Z zlib-1.3.1           | 96 KB     | :   0% 0/1 [00:00<?, ?it/s][A
2026-01-14T08:12:03.4317395Z 
2026-01-14T08:12:03.4317399Z 
2026-01-14T08:12:03.4317653Z tk-8.6.15            | 3.4 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A
2026-01-14T08:12:03.4318005Z 
2026-01-14T08:12:03.4318011Z 
2026-01-14T08:12:03.4318016Z 
2026-01-14T08:12:03.4318381Z readline-8.3         | 471 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A
2026-01-14T08:12:03.4320049Z 
2026-01-14T08:12:03.4320054Z 
2026-01-14T08:12:03.4320059Z 
2026-01-14T08:12:03.4320063Z 
2026-01-14T08:12:03.4320416Z setuptools-80.9.0    | 1.4 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A
2026-01-14T08:12:03.4320781Z 
2026-01-14T08:12:03.4320785Z 
2026-01-14T08:12:03.4320789Z 
2026-01-14T08:12:03.4320793Z 
2026-01-14T08:12:03.4320797Z 
2026-01-14T08:12:03.4321089Z libffi-3.4.4         | 141 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A
2026-01-14T08:12:03.4321429Z 
2026-01-14T08:12:03.4321434Z 
2026-01-14T08:12:03.4321438Z 
2026-01-14T08:12:03.4321455Z 
2026-01-14T08:12:03.4321459Z 
2026-01-14T08:12:03.4321463Z 
2026-01-14T08:12:03.4321757Z ncurses-6.5          | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A
2026-01-14T08:12:03.4322096Z 
2026-01-14T08:12:03.4322100Z 
2026-01-14T08:12:03.4322104Z 
2026-01-14T08:12:03.4322108Z 
2026-01-14T08:12:03.4322112Z 
2026-01-14T08:12:03.4322116Z 
2026-01-14T08:12:03.4322127Z 
2026-01-14T08:12:03.4322448Z sqlite-3.51.0        | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A
2026-01-14T08:12:03.4322798Z 
2026-01-14T08:12:03.4322802Z 
2026-01-14T08:12:03.4322806Z 
2026-01-14T08:12:03.4322810Z 
2026-01-14T08:12:03.4322818Z 
2026-01-14T08:12:03.4322823Z 
2026-01-14T08:12:03.4322827Z 
2026-01-14T08:12:03.4322831Z 
2026-01-14T08:12:03.4323182Z xorg-libxau-1.0.12   | 13 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A
2026-01-14T08:12:03.4323560Z 
2026-01-14T08:12:03.4323564Z 
2026-01-14T08:12:03.4323569Z 
2026-01-14T08:12:03.4323574Z 
2026-01-14T08:12:03.4323578Z 
2026-01-14T08:12:03.4323582Z 
2026-01-14T08:12:03.4323586Z 
2026-01-14T08:12:03.4323590Z 
2026-01-14T08:12:03.4323594Z 
2026-01-14T08:12:03.4323941Z tzdata-2025b         | 116 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A
2026-01-14T08:12:03.4324319Z 
2026-01-14T08:12:03.4324323Z 
2026-01-14T08:12:03.4324327Z 
2026-01-14T08:12:03.4324332Z 
2026-01-14T08:12:03.4324335Z 
2026-01-14T08:12:03.4324345Z 
2026-01-14T08:12:03.4324349Z 
2026-01-14T08:12:03.4324353Z 
2026-01-14T08:12:03.4324357Z 
2026-01-14T08:12:03.4324361Z 
2026-01-14T08:12:03.4324690Z xz-5.6.4             | 567 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:03.4325162Z 
2026-01-14T08:12:03.4325169Z 
2026-01-14T08:12:03.4325173Z 
2026-01-14T08:12:03.4325177Z 
2026-01-14T08:12:03.4325181Z 
2026-01-14T08:12:03.4325185Z 
2026-01-14T08:12:03.4325189Z 
2026-01-14T08:12:03.4325193Z 
2026-01-14T08:12:03.4325197Z 
2026-01-14T08:12:03.4325201Z 
2026-01-14T08:12:03.4325205Z 
2026-01-14T08:12:03.4325583Z xorg-libx11-1.8.12   | 895 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:03.4326218Z 
2026-01-14T08:12:03.4326224Z 
2026-01-14T08:12:03.4326229Z 
2026-01-14T08:12:03.4326234Z 
2026-01-14T08:12:03.4326239Z 
2026-01-14T08:12:03.4326245Z 
2026-01-14T08:12:03.4326252Z 
2026-01-14T08:12:03.4326256Z 
2026-01-14T08:12:03.4326261Z 
2026-01-14T08:12:03.4326266Z 
2026-01-14T08:12:03.4326276Z 
2026-01-14T08:12:03.4326296Z 
2026-01-14T08:12:06.1288494Z xorg-xorgproto-2024. | 580 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1289217Z 
2026-01-14T08:12:06.1289227Z 
2026-01-14T08:12:06.1289268Z 
2026-01-14T08:12:06.1289275Z 
2026-01-14T08:12:06.1289283Z 
2026-01-14T08:12:06.1289288Z 
2026-01-14T08:12:06.1289293Z 
2026-01-14T08:12:06.1289316Z 
2026-01-14T08:12:06.1289321Z 
2026-01-14T08:12:06.1289326Z 
2026-01-14T08:12:06.1289331Z 
2026-01-14T08:12:06.1289336Z 
2026-01-14T08:12:06.1289341Z 
2026-01-14T08:12:06.1289852Z python-3.10.19       | 24.5 MB   | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1290521Z 
2026-01-14T08:12:06.1290531Z 
2026-01-14T08:12:06.1290540Z 
2026-01-14T08:12:06.1290559Z 
2026-01-14T08:12:06.1290568Z 
2026-01-14T08:12:06.1290573Z 
2026-01-14T08:12:06.1290581Z 
2026-01-14T08:12:06.1290589Z 
2026-01-14T08:12:06.1290596Z 
2026-01-14T08:12:06.1290603Z 
2026-01-14T08:12:06.1290846Z 
2026-01-14T08:12:06.1290850Z 
2026-01-14T08:12:06.1290854Z 
2026-01-14T08:12:06.1290857Z 
2026-01-14T08:12:06.1291229Z xorg-libxdmcp-1.1.5  | 19 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1291615Z 
2026-01-14T08:12:06.1291625Z 
2026-01-14T08:12:06.1291629Z 
2026-01-14T08:12:06.1291633Z 
2026-01-14T08:12:06.1291636Z 
2026-01-14T08:12:06.1291640Z 
2026-01-14T08:12:06.1291643Z 
2026-01-14T08:12:06.1291647Z 
2026-01-14T08:12:06.1291650Z 
2026-01-14T08:12:06.1291654Z 
2026-01-14T08:12:06.1291657Z 
2026-01-14T08:12:06.1291661Z 
2026-01-14T08:12:06.1291664Z 
2026-01-14T08:12:06.1291667Z 
2026-01-14T08:12:06.1291671Z 
2026-01-14T08:12:06.1292075Z libnsl-2.0.0         | 31 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1292612Z 
2026-01-14T08:12:06.1292619Z 
2026-01-14T08:12:06.1292624Z 
2026-01-14T08:12:06.1292630Z 
2026-01-14T08:12:06.1292636Z 
2026-01-14T08:12:06.1292642Z 
2026-01-14T08:12:06.1292656Z 
2026-01-14T08:12:06.1292662Z 
2026-01-14T08:12:06.1292668Z 
2026-01-14T08:12:06.1292673Z 
2026-01-14T08:12:06.1292679Z 
2026-01-14T08:12:06.1292684Z 
2026-01-14T08:12:06.1292689Z 
2026-01-14T08:12:06.1292693Z 
2026-01-14T08:12:06.1292698Z 
2026-01-14T08:12:06.1292715Z 
2026-01-14T08:12:06.1293319Z pthread-stubs-0.3    | 5 KB      | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1293708Z 
2026-01-14T08:12:06.1293712Z 
2026-01-14T08:12:06.1293716Z 
2026-01-14T08:12:06.1293719Z 
2026-01-14T08:12:06.1293722Z 
2026-01-14T08:12:06.1293726Z 
2026-01-14T08:12:06.1293730Z 
2026-01-14T08:12:06.1293733Z 
2026-01-14T08:12:06.1293736Z 
2026-01-14T08:12:06.1293740Z 
2026-01-14T08:12:06.1293756Z 
2026-01-14T08:12:06.1293759Z 
2026-01-14T08:12:06.1293763Z 
2026-01-14T08:12:06.1293766Z 
2026-01-14T08:12:06.1293770Z 
2026-01-14T08:12:06.1293773Z 
2026-01-14T08:12:06.1293777Z 
2026-01-14T08:12:06.1294350Z ld_impl_linux-64-2.4 | 672 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1294752Z 
2026-01-14T08:12:06.1294756Z 
2026-01-14T08:12:06.1294759Z 
2026-01-14T08:12:06.1294775Z 
2026-01-14T08:12:06.1294779Z 
2026-01-14T08:12:06.1294783Z 
2026-01-14T08:12:06.1294786Z 
2026-01-14T08:12:06.1294934Z 
2026-01-14T08:12:06.1294938Z 
2026-01-14T08:12:06.1294942Z 
2026-01-14T08:12:06.1294945Z 
2026-01-14T08:12:06.1294949Z 
2026-01-14T08:12:06.1294952Z 
2026-01-14T08:12:06.1294955Z 
2026-01-14T08:12:06.1294959Z 
2026-01-14T08:12:06.1294962Z 
2026-01-14T08:12:06.1294966Z 
2026-01-14T08:12:06.1294969Z 
2026-01-14T08:12:06.1295340Z bzip2-1.0.8          | 262 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1295730Z 
2026-01-14T08:12:06.1295734Z 
2026-01-14T08:12:06.1295738Z 
2026-01-14T08:12:06.1295741Z 
2026-01-14T08:12:06.1295745Z 
2026-01-14T08:12:06.1295748Z 
2026-01-14T08:12:06.1295752Z 
2026-01-14T08:12:06.1295755Z 
2026-01-14T08:12:06.1295758Z 
2026-01-14T08:12:06.1295767Z 
2026-01-14T08:12:06.1295771Z 
2026-01-14T08:12:06.1295774Z 
2026-01-14T08:12:06.1295778Z 
2026-01-14T08:12:06.1295781Z 
2026-01-14T08:12:06.1295784Z 
2026-01-14T08:12:06.1295788Z 
2026-01-14T08:12:06.1295791Z 
2026-01-14T08:12:06.1295795Z 
2026-01-14T08:12:06.1295815Z 
2026-01-14T08:12:06.1296077Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1296467Z 
2026-01-14T08:12:06.1296765Z zlib-1.3.1           | 96 KB     | :  17% 0.16692817116658176/1 [00:00<00:00,  1.10s/it][A
2026-01-14T08:12:06.1297095Z 
2026-01-14T08:12:06.1297099Z 
2026-01-14T08:12:06.1297396Z tk-8.6.15            | 3.4 MB    | :   0% 0.00453827661272385/1 [00:00<00:41, 41.32s/it][A[A
2026-01-14T08:12:06.1297770Z 
2026-01-14T08:12:06.1297787Z 
2026-01-14T08:12:06.1297790Z 
2026-01-14T08:12:06.1298120Z readline-8.3         | 471 KB    | :   3% 0.03400397653924861/1 [00:00<00:05,  5.55s/it][A[A[A
2026-01-14T08:12:06.1298657Z libxcb-1.17.0        | 430 KB    | :   4% 0.03717806167600808/1 [00:00<00:05,  5.26s/it]
2026-01-14T08:12:06.1299060Z 
2026-01-14T08:12:06.1299064Z 
2026-01-14T08:12:06.1299067Z 
2026-01-14T08:12:06.1299072Z 
2026-01-14T08:12:06.1299434Z setuptools-80.9.0    | 1.4 MB    | :   1% 0.010887210650647725/1 [00:00<00:17, 17.80s/it][A[A[A[A
2026-01-14T08:12:06.1299825Z 
2026-01-14T08:12:06.1300112Z zlib-1.3.1           | 96 KB     | : 100% 1.0/1 [00:00<00:00,  1.10s/it]                [A
2026-01-14T08:12:06.1300428Z 
2026-01-14T08:12:06.1300432Z 
2026-01-14T08:12:06.1300436Z 
2026-01-14T08:12:06.1300439Z 
2026-01-14T08:12:06.1300443Z 
2026-01-14T08:12:06.1300812Z libffi-3.4.4         | 141 KB    | :  11% 0.11323440988036575/1 [00:00<00:01,  1.93s/it][A[A[A[A[A
2026-01-14T08:12:06.1301181Z 
2026-01-14T08:12:06.1301185Z 
2026-01-14T08:12:06.1301189Z 
2026-01-14T08:12:06.1301192Z 
2026-01-14T08:12:06.1301196Z 
2026-01-14T08:12:06.1301199Z 
2026-01-14T08:12:06.1301571Z ncurses-6.5          | 1.1 MB    | :   1% 0.014401655346517857/1 [00:00<00:16, 16.93s/it][A[A[A[A[A[A
2026-01-14T08:12:06.1301975Z 
2026-01-14T08:12:06.1301979Z 
2026-01-14T08:12:06.1301983Z 
2026-01-14T08:12:06.1301986Z 
2026-01-14T08:12:06.1301990Z 
2026-01-14T08:12:06.1301993Z 
2026-01-14T08:12:06.1301996Z 
2026-01-14T08:12:06.1302379Z sqlite-3.51.0        | 1.2 MB    | :   1% 0.013350140517073497/1 [00:00<00:18, 18.32s/it][A[A[A[A[A[A[A
2026-01-14T08:12:06.1302781Z 
2026-01-14T08:12:06.1302785Z 
2026-01-14T08:12:06.1302789Z 
2026-01-14T08:12:06.1302792Z 
2026-01-14T08:12:06.1302796Z 
2026-01-14T08:12:06.1302799Z 
2026-01-14T08:12:06.1302803Z 
2026-01-14T08:12:06.1302806Z 
2026-01-14T08:12:06.1303134Z xorg-libxau-1.0.12   | 13 KB     | : 100% 1.0/1 [00:00<00:00,  3.84it/s][A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1303504Z 
2026-01-14T08:12:06.1303507Z 
2026-01-14T08:12:06.1303511Z 
2026-01-14T08:12:06.1303514Z 
2026-01-14T08:12:06.1303518Z 
2026-01-14T08:12:06.1303521Z 
2026-01-14T08:12:06.1303525Z 
2026-01-14T08:12:06.1303529Z 
2026-01-14T08:12:06.1303532Z 
2026-01-14T08:12:06.1303939Z tzdata-2025b         | 116 KB    | :  14% 0.13742430088406501/1 [00:00<00:01,  1.93s/it][A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1304373Z 
2026-01-14T08:12:06.1304376Z 
2026-01-14T08:12:06.1304380Z 
2026-01-14T08:12:06.1304755Z readline-8.3         | 471 KB    | : 100% 1.0/1 [00:00<00:00,  5.55s/it]                [A[A[A
2026-01-14T08:12:06.1305100Z 
2026-01-14T08:12:06.1305104Z 
2026-01-14T08:12:06.1305107Z 
2026-01-14T08:12:06.1305111Z 
2026-01-14T08:12:06.1305126Z 
2026-01-14T08:12:06.1305129Z 
2026-01-14T08:12:06.1305133Z 
2026-01-14T08:12:06.1305136Z 
2026-01-14T08:12:06.1305140Z 
2026-01-14T08:12:06.1305143Z 
2026-01-14T08:12:06.1305147Z 
2026-01-14T08:12:06.1305150Z 
2026-01-14T08:12:06.1305620Z xorg-xorgproto-2024. | 580 KB    | :   3% 0.02757436782092818/1 [00:00<00:11, 11.35s/it][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1306090Z 
2026-01-14T08:12:06.1306105Z 
2026-01-14T08:12:06.1306109Z 
2026-01-14T08:12:06.1306112Z 
2026-01-14T08:12:06.1306116Z 
2026-01-14T08:12:06.1306124Z 
2026-01-14T08:12:06.1306127Z 
2026-01-14T08:12:06.1306131Z 
2026-01-14T08:12:06.1306134Z 
2026-01-14T08:12:06.1306137Z 
2026-01-14T08:12:06.1306539Z xz-5.6.4             | 567 KB    | :   3% 0.028233137059266496/1 [00:00<00:11, 11.32s/it][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1306954Z 
2026-01-14T08:12:06.1306957Z 
2026-01-14T08:12:06.1306961Z 
2026-01-14T08:12:06.1306965Z 
2026-01-14T08:12:06.1306968Z 
2026-01-14T08:12:06.1306972Z 
2026-01-14T08:12:06.1306975Z 
2026-01-14T08:12:06.1306978Z 
2026-01-14T08:12:06.1306982Z 
2026-01-14T08:12:06.1306985Z 
2026-01-14T08:12:06.1306989Z 
2026-01-14T08:12:06.1306992Z 
2026-01-14T08:12:06.1306996Z 
2026-01-14T08:12:06.1306999Z 
2026-01-14T08:12:06.1307453Z xorg-libxdmcp-1.1.5  | 19 KB     | :  85% 0.85067497403946/1 [00:00<00:00,  2.64it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1307923Z 
2026-01-14T08:12:06.1307926Z 
2026-01-14T08:12:06.1307930Z 
2026-01-14T08:12:06.1307933Z 
2026-01-14T08:12:06.1307937Z 
2026-01-14T08:12:06.1307990Z 
2026-01-14T08:12:06.1307994Z 
2026-01-14T08:12:06.1307998Z 
2026-01-14T08:12:06.1308001Z 
2026-01-14T08:12:06.1308004Z 
2026-01-14T08:12:06.1308008Z 
2026-01-14T08:12:06.1308011Z 
2026-01-14T08:12:06.1308015Z 
2026-01-14T08:12:06.1308495Z python-3.10.19       | 24.5 MB   | :   0% 0.0006386825426160966/1 [00:00<08:31, 511.52s/it][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1308950Z 
2026-01-14T08:12:06.1308954Z 
2026-01-14T08:12:06.1308957Z 
2026-01-14T08:12:06.1308961Z 
2026-01-14T08:12:06.1308964Z 
2026-01-14T08:12:06.1308968Z 
2026-01-14T08:12:06.1308971Z 
2026-01-14T08:12:06.1308974Z 
2026-01-14T08:12:06.1308978Z 
2026-01-14T08:12:06.1308981Z 
2026-01-14T08:12:06.1308985Z 
2026-01-14T08:12:06.1309439Z xorg-libx11-1.8.12   | 895 KB    | :   2% 0.017882324178246957/1 [00:00<00:18, 18.54s/it][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1310073Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:00<00:00,  3.24it/s]                
2026-01-14T08:12:06.1310563Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:00<00:00,  3.24it/s]
2026-01-14T08:12:06.1310845Z 
2026-01-14T08:12:06.1310848Z 
2026-01-14T08:12:06.1310852Z 
2026-01-14T08:12:06.1310855Z 
2026-01-14T08:12:06.1310859Z 
2026-01-14T08:12:06.1310862Z 
2026-01-14T08:12:06.1310865Z 
2026-01-14T08:12:06.1310872Z 
2026-01-14T08:12:06.1310876Z 
2026-01-14T08:12:06.1310879Z 
2026-01-14T08:12:06.1310894Z 
2026-01-14T08:12:06.1310898Z 
2026-01-14T08:12:06.1310901Z 
2026-01-14T08:12:06.1310905Z 
2026-01-14T08:12:06.1310908Z 
2026-01-14T08:12:06.1311356Z libnsl-2.0.0         | 31 KB     | :  52% 0.515966492410405/1 [00:00<00:00,  1.43it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1311806Z 
2026-01-14T08:12:06.1311809Z 
2026-01-14T08:12:06.1311813Z 
2026-01-14T08:12:06.1311817Z 
2026-01-14T08:12:06.1311831Z 
2026-01-14T08:12:06.1311835Z 
2026-01-14T08:12:06.1311838Z 
2026-01-14T08:12:06.1311841Z 
2026-01-14T08:12:06.1311845Z 
2026-01-14T08:12:06.1311848Z 
2026-01-14T08:12:06.1311852Z 
2026-01-14T08:12:06.1311855Z 
2026-01-14T08:12:06.1311863Z 
2026-01-14T08:12:06.1311867Z 
2026-01-14T08:12:06.1311870Z 
2026-01-14T08:12:06.1311874Z 
2026-01-14T08:12:06.1312332Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  2.63it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1312768Z 
2026-01-14T08:12:06.1312772Z 
2026-01-14T08:12:06.1312776Z 
2026-01-14T08:12:06.1312779Z 
2026-01-14T08:12:06.1312782Z 
2026-01-14T08:12:06.1312786Z 
2026-01-14T08:12:06.1312790Z 
2026-01-14T08:12:06.1312793Z 
2026-01-14T08:12:06.1312796Z 
2026-01-14T08:12:06.1312800Z 
2026-01-14T08:12:06.1312803Z 
2026-01-14T08:12:06.1312807Z 
2026-01-14T08:12:06.1312810Z 
2026-01-14T08:12:06.1312814Z 
2026-01-14T08:12:06.1312817Z 
2026-01-14T08:12:06.1312821Z 
2026-01-14T08:12:06.1312824Z 
2026-01-14T08:12:06.1313336Z ld_impl_linux-64-2.4 | 672 KB    | :   2% 0.02380578754961961/1 [00:00<00:15, 16.22s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1313827Z 
2026-01-14T08:12:06.1313830Z 
2026-01-14T08:12:06.1313838Z 
2026-01-14T08:12:06.1313841Z 
2026-01-14T08:12:06.1313845Z 
2026-01-14T08:12:06.1313848Z 
2026-01-14T08:12:06.1313852Z 
2026-01-14T08:12:06.1313855Z 
2026-01-14T08:12:06.1313858Z 
2026-01-14T08:12:06.1313862Z 
2026-01-14T08:12:06.1313866Z 
2026-01-14T08:12:06.1313872Z 
2026-01-14T08:12:06.1313876Z 
2026-01-14T08:12:06.1313891Z 
2026-01-14T08:12:06.1313895Z 
2026-01-14T08:12:06.1313898Z 
2026-01-14T08:12:06.1313902Z 
2026-01-14T08:12:06.1313905Z 
2026-01-14T08:12:06.1314383Z bzip2-1.0.8          | 262 KB    | :   6% 0.06104685823297961/1 [00:00<00:06,  6.55s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1314856Z 
2026-01-14T08:12:06.1314860Z 
2026-01-14T08:12:06.1314864Z 
2026-01-14T08:12:06.1314867Z 
2026-01-14T08:12:06.1314882Z 
2026-01-14T08:12:06.1314885Z 
2026-01-14T08:12:06.1314888Z 
2026-01-14T08:12:06.1314892Z 
2026-01-14T08:12:06.1314896Z 
2026-01-14T08:12:06.1314899Z 
2026-01-14T08:12:06.1314903Z 
2026-01-14T08:12:06.1314906Z 
2026-01-14T08:12:06.1314960Z 
2026-01-14T08:12:06.1314964Z 
2026-01-14T08:12:06.1314967Z 
2026-01-14T08:12:06.1314971Z 
2026-01-14T08:12:06.1314974Z 
2026-01-14T08:12:06.1314978Z 
2026-01-14T08:12:06.1314981Z 
2026-01-14T08:12:06.1315243Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1315561Z 
2026-01-14T08:12:06.1315565Z 
2026-01-14T08:12:06.1315568Z 
2026-01-14T08:12:06.1315572Z 
2026-01-14T08:12:06.1315575Z 
2026-01-14T08:12:06.1315579Z 
2026-01-14T08:12:06.1315582Z 
2026-01-14T08:12:06.1315586Z 
2026-01-14T08:12:06.1315589Z 
2026-01-14T08:12:06.1315593Z 
2026-01-14T08:12:06.1315596Z 
2026-01-14T08:12:06.1315600Z 
2026-01-14T08:12:06.1315603Z 
2026-01-14T08:12:06.1316062Z python-3.10.19       | 24.5 MB   | :  15% 0.15200644514263098/1 [00:00<00:01,  2.17s/it]   [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1316513Z 
2026-01-14T08:12:06.1316517Z 
2026-01-14T08:12:06.1316521Z 
2026-01-14T08:12:06.1316524Z 
2026-01-14T08:12:06.1316528Z 
2026-01-14T08:12:06.1316863Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  2.43it/s]                [A[A[A[A[A
2026-01-14T08:12:06.1317236Z 
2026-01-14T08:12:06.1317239Z 
2026-01-14T08:12:06.1317243Z 
2026-01-14T08:12:06.1317247Z 
2026-01-14T08:12:06.1317250Z 
2026-01-14T08:12:06.1317533Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  2.43it/s][A[A[A[A[A
2026-01-14T08:12:06.1317849Z 
2026-01-14T08:12:06.1317964Z 
2026-01-14T08:12:06.1317968Z 
2026-01-14T08:12:06.1317971Z 
2026-01-14T08:12:06.1317975Z 
2026-01-14T08:12:06.1317978Z 
2026-01-14T08:12:06.1317981Z 
2026-01-14T08:12:06.1317985Z 
2026-01-14T08:12:06.1318315Z xorg-libxau-1.0.12   | 13 KB     | : 100% 1.0/1 [00:00<00:00,  3.84it/s][A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1318668Z 
2026-01-14T08:12:06.1318684Z 
2026-01-14T08:12:06.1318688Z 
2026-01-14T08:12:06.1318691Z 
2026-01-14T08:12:06.1318695Z 
2026-01-14T08:12:06.1318698Z 
2026-01-14T08:12:06.1318701Z 
2026-01-14T08:12:06.1318705Z 
2026-01-14T08:12:06.1318708Z 
2026-01-14T08:12:06.1318716Z 
2026-01-14T08:12:06.1318719Z 
2026-01-14T08:12:06.1318723Z 
2026-01-14T08:12:06.1318726Z 
2026-01-14T08:12:06.1319164Z python-3.10.19       | 24.5 MB   | :  34% 0.34424989047007604/1 [00:00<00:00,  1.11s/it][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1319690Z 
2026-01-14T08:12:06.1319694Z 
2026-01-14T08:12:06.1319698Z 
2026-01-14T08:12:06.1319701Z 
2026-01-14T08:12:06.1319705Z 
2026-01-14T08:12:06.1319708Z 
2026-01-14T08:12:06.1319712Z 
2026-01-14T08:12:06.1319715Z 
2026-01-14T08:12:06.1319719Z 
2026-01-14T08:12:06.1319722Z 
2026-01-14T08:12:06.1319726Z 
2026-01-14T08:12:06.1319729Z 
2026-01-14T08:12:06.1319732Z 
2026-01-14T08:12:06.1320170Z python-3.10.19       | 24.5 MB   | :  53% 0.5326612405418245/1 [00:00<00:00,  1.20it/s] [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1320621Z 
2026-01-14T08:12:06.1320625Z 
2026-01-14T08:12:06.1320628Z 
2026-01-14T08:12:06.1320632Z 
2026-01-14T08:12:06.1320635Z 
2026-01-14T08:12:06.1320639Z 
2026-01-14T08:12:06.1320642Z 
2026-01-14T08:12:06.1320650Z 
2026-01-14T08:12:06.1320653Z 
2026-01-14T08:12:06.1320657Z 
2026-01-14T08:12:06.1320660Z 
2026-01-14T08:12:06.1320663Z 
2026-01-14T08:12:06.1320667Z 
2026-01-14T08:12:06.1321114Z python-3.10.19       | 24.5 MB   | :  70% 0.7038281619629384/1 [00:00<00:00,  1.35it/s][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1321549Z 
2026-01-14T08:12:06.1321553Z 
2026-01-14T08:12:06.1321556Z 
2026-01-14T08:12:06.1321560Z 
2026-01-14T08:12:06.1321563Z 
2026-01-14T08:12:06.1321567Z 
2026-01-14T08:12:06.1321570Z 
2026-01-14T08:12:06.1321574Z 
2026-01-14T08:12:06.1321577Z 
2026-01-14T08:12:06.1321581Z 
2026-01-14T08:12:06.1321584Z 
2026-01-14T08:12:06.1321588Z 
2026-01-14T08:12:06.1321591Z 
2026-01-14T08:12:06.1322032Z python-3.10.19       | 24.5 MB   | :  88% 0.8832979564380615/1 [00:00<00:00,  1.48it/s][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1322470Z 
2026-01-14T08:12:06.1322474Z 
2026-01-14T08:12:06.1322764Z tk-8.6.15            | 3.4 MB    | : 100% 1.0/1 [00:00<00:00,  1.16it/s]                [A[A
2026-01-14T08:12:06.1323139Z 
2026-01-14T08:12:06.1323143Z 
2026-01-14T08:12:06.1323386Z tk-8.6.15            | 3.4 MB    | : 100% 1.0/1 [00:00<00:00,  1.16it/s][A[A
2026-01-14T08:12:06.1323665Z 
2026-01-14T08:12:06.1323669Z 
2026-01-14T08:12:06.1323689Z 
2026-01-14T08:12:06.1323693Z 
2026-01-14T08:12:06.1323697Z 
2026-01-14T08:12:06.1323700Z 
2026-01-14T08:12:06.1323703Z 
2026-01-14T08:12:06.1323707Z 
2026-01-14T08:12:06.1323710Z 
2026-01-14T08:12:06.1324085Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:00<00:00,  1.08it/s]                [A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1324475Z 
2026-01-14T08:12:06.1324479Z 
2026-01-14T08:12:06.1324495Z 
2026-01-14T08:12:06.1324499Z 
2026-01-14T08:12:06.1324502Z 
2026-01-14T08:12:06.1324506Z 
2026-01-14T08:12:06.1324509Z 
2026-01-14T08:12:06.1324513Z 
2026-01-14T08:12:06.1324516Z 
2026-01-14T08:12:06.1324843Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:00<00:00,  1.08it/s][A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1325198Z 
2026-01-14T08:12:06.1325202Z 
2026-01-14T08:12:06.1325205Z 
2026-01-14T08:12:06.1325220Z 
2026-01-14T08:12:06.1325224Z 
2026-01-14T08:12:06.1325227Z 
2026-01-14T08:12:06.1325231Z 
2026-01-14T08:12:06.1325591Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.05it/s]                 [A[A[A[A[A[A[A
2026-01-14T08:12:06.1325965Z 
2026-01-14T08:12:06.1325969Z 
2026-01-14T08:12:06.1325972Z 
2026-01-14T08:12:06.1325976Z 
2026-01-14T08:12:06.1325979Z 
2026-01-14T08:12:06.1325996Z 
2026-01-14T08:12:06.1325999Z 
2026-01-14T08:12:06.1326298Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.05it/s][A[A[A[A[A[A[A
2026-01-14T08:12:06.1326629Z 
2026-01-14T08:12:06.1326632Z 
2026-01-14T08:12:06.1326636Z 
2026-01-14T08:12:06.1326639Z 
2026-01-14T08:12:06.1326643Z 
2026-01-14T08:12:06.1326646Z 
2026-01-14T08:12:06.1326650Z 
2026-01-14T08:12:06.1326653Z 
2026-01-14T08:12:06.1326670Z 
2026-01-14T08:12:06.1326674Z 
2026-01-14T08:12:06.1326677Z 
2026-01-14T08:12:06.1326684Z 
2026-01-14T08:12:06.1326688Z 
2026-01-14T08:12:06.1326692Z 
2026-01-14T08:12:06.1327115Z xorg-libxdmcp-1.1.5  | 19 KB     | : 100% 1.0/1 [00:01<00:00,  2.64it/s]             [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1327548Z 
2026-01-14T08:12:06.1327604Z 
2026-01-14T08:12:06.1327608Z 
2026-01-14T08:12:06.1327625Z 
2026-01-14T08:12:06.1327968Z setuptools-80.9.0    | 1.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.11s/it]                 [A[A[A[A
2026-01-14T08:12:06.1328333Z 
2026-01-14T08:12:06.1328337Z 
2026-01-14T08:12:06.1328340Z 
2026-01-14T08:12:06.1328344Z 
2026-01-14T08:12:06.1328643Z setuptools-80.9.0    | 1.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.11s/it][A[A[A[A
2026-01-14T08:12:06.1328966Z 
2026-01-14T08:12:06.1328970Z 
2026-01-14T08:12:06.1328973Z 
2026-01-14T08:12:06.1328977Z 
2026-01-14T08:12:06.1328981Z 
2026-01-14T08:12:06.1328984Z 
2026-01-14T08:12:06.1328988Z 
2026-01-14T08:12:06.1328991Z 
2026-01-14T08:12:06.1328995Z 
2026-01-14T08:12:06.1328998Z 
2026-01-14T08:12:06.1329006Z 
2026-01-14T08:12:06.1329009Z 
2026-01-14T08:12:06.1329449Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:01<00:00,  1.23s/it]                [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1329880Z 
2026-01-14T08:12:06.1329884Z 
2026-01-14T08:12:06.1329891Z 
2026-01-14T08:12:06.1329894Z 
2026-01-14T08:12:06.1329898Z 
2026-01-14T08:12:06.1329901Z 
2026-01-14T08:12:06.1329905Z 
2026-01-14T08:12:06.1329908Z 
2026-01-14T08:12:06.1329912Z 
2026-01-14T08:12:06.1329915Z 
2026-01-14T08:12:06.1329918Z 
2026-01-14T08:12:06.1329922Z 
2026-01-14T08:12:06.1330313Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:01<00:00,  1.23s/it][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1330713Z 
2026-01-14T08:12:06.1330716Z 
2026-01-14T08:12:06.1330720Z 
2026-01-14T08:12:06.1330724Z 
2026-01-14T08:12:06.1330727Z 
2026-01-14T08:12:06.1330730Z 
2026-01-14T08:12:06.1330734Z 
2026-01-14T08:12:06.1330737Z 
2026-01-14T08:12:06.1330741Z 
2026-01-14T08:12:06.1330756Z 
2026-01-14T08:12:06.1331171Z xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:01<00:00,  1.24s/it]                 [A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1331550Z 
2026-01-14T08:12:06.1331554Z 
2026-01-14T08:12:06.1331557Z 
2026-01-14T08:12:06.1331561Z 
2026-01-14T08:12:06.1331568Z 
2026-01-14T08:12:06.1331571Z 
2026-01-14T08:12:06.1331575Z 
2026-01-14T08:12:06.1331578Z 
2026-01-14T08:12:06.1331582Z 
2026-01-14T08:12:06.1331598Z 
2026-01-14T08:12:06.1332015Z xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:01<00:00,  1.24s/it][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1332358Z 
2026-01-14T08:12:06.1332361Z 
2026-01-14T08:12:06.1332365Z 
2026-01-14T08:12:06.1332368Z 
2026-01-14T08:12:06.1332372Z 
2026-01-14T08:12:06.1332375Z 
2026-01-14T08:12:06.1332379Z 
2026-01-14T08:12:06.1332382Z 
2026-01-14T08:12:06.1332398Z 
2026-01-14T08:12:06.1332401Z 
2026-01-14T08:12:06.1332405Z 
2026-01-14T08:12:06.1332408Z 
2026-01-14T08:12:06.1332412Z 
2026-01-14T08:12:06.1332415Z 
2026-01-14T08:12:06.1332418Z 
2026-01-14T08:12:06.1332838Z libnsl-2.0.0         | 31 KB     | : 100% 1.0/1 [00:01<00:00,  1.46s/it]              [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1333252Z 
2026-01-14T08:12:06.1333255Z 
2026-01-14T08:12:06.1333271Z 
2026-01-14T08:12:06.1333275Z 
2026-01-14T08:12:06.1333282Z 
2026-01-14T08:12:06.1333285Z 
2026-01-14T08:12:06.1333289Z 
2026-01-14T08:12:06.1333292Z 
2026-01-14T08:12:06.1333296Z 
2026-01-14T08:12:06.1333299Z 
2026-01-14T08:12:06.1333303Z 
2026-01-14T08:12:06.1333306Z 
2026-01-14T08:12:06.1333310Z 
2026-01-14T08:12:06.1333313Z 
2026-01-14T08:12:06.1333317Z 
2026-01-14T08:12:06.1333689Z libnsl-2.0.0         | 31 KB     | : 100% 1.0/1 [00:01<00:00,  1.46s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1334090Z 
2026-01-14T08:12:06.1334094Z 
2026-01-14T08:12:06.1334097Z 
2026-01-14T08:12:06.1334101Z 
2026-01-14T08:12:06.1334104Z 
2026-01-14T08:12:06.1334108Z 
2026-01-14T08:12:06.1334111Z 
2026-01-14T08:12:06.1334115Z 
2026-01-14T08:12:06.1334119Z 
2026-01-14T08:12:06.1334126Z 
2026-01-14T08:12:06.1334129Z 
2026-01-14T08:12:06.1334132Z 
2026-01-14T08:12:06.1334136Z 
2026-01-14T08:12:06.1334139Z 
2026-01-14T08:12:06.1334143Z 
2026-01-14T08:12:06.1334146Z 
2026-01-14T08:12:06.1334627Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:01<00:00,  2.63it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1335052Z 
2026-01-14T08:12:06.1335055Z 
2026-01-14T08:12:06.1335059Z 
2026-01-14T08:12:06.1335062Z 
2026-01-14T08:12:06.1335066Z 
2026-01-14T08:12:06.1335069Z 
2026-01-14T08:12:06.1335073Z 
2026-01-14T08:12:06.1335077Z 
2026-01-14T08:12:06.1335080Z 
2026-01-14T08:12:06.1335084Z 
2026-01-14T08:12:06.1335087Z 
2026-01-14T08:12:06.1335090Z 
2026-01-14T08:12:06.1335094Z 
2026-01-14T08:12:06.1335097Z 
2026-01-14T08:12:06.1335113Z 
2026-01-14T08:12:06.1335117Z 
2026-01-14T08:12:06.1335120Z 
2026-01-14T08:12:06.1335576Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1336032Z 
2026-01-14T08:12:06.1336035Z 
2026-01-14T08:12:06.1336039Z 
2026-01-14T08:12:06.1336043Z 
2026-01-14T08:12:06.1336046Z 
2026-01-14T08:12:06.1336050Z 
2026-01-14T08:12:06.1336066Z 
2026-01-14T08:12:06.1336069Z 
2026-01-14T08:12:06.1336076Z 
2026-01-14T08:12:06.1336080Z 
2026-01-14T08:12:06.1336083Z 
2026-01-14T08:12:06.1336087Z 
2026-01-14T08:12:06.1336090Z 
2026-01-14T08:12:06.1336094Z 
2026-01-14T08:12:06.1336097Z 
2026-01-14T08:12:06.1336101Z 
2026-01-14T08:12:06.1336104Z 
2026-01-14T08:12:06.1336519Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1336956Z 
2026-01-14T08:12:06.1336960Z 
2026-01-14T08:12:06.1336963Z 
2026-01-14T08:12:06.1336967Z 
2026-01-14T08:12:06.1336970Z 
2026-01-14T08:12:06.1336973Z 
2026-01-14T08:12:06.1336977Z 
2026-01-14T08:12:06.1336980Z 
2026-01-14T08:12:06.1336984Z 
2026-01-14T08:12:06.1336987Z 
2026-01-14T08:12:06.1336991Z 
2026-01-14T08:12:06.1336995Z 
2026-01-14T08:12:06.1337045Z 
2026-01-14T08:12:06.1337049Z 
2026-01-14T08:12:06.1337052Z 
2026-01-14T08:12:06.1337056Z 
2026-01-14T08:12:06.1337059Z 
2026-01-14T08:12:06.1337062Z 
2026-01-14T08:12:06.1337518Z bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:01<00:00,  1.36s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1337957Z 
2026-01-14T08:12:06.1337961Z 
2026-01-14T08:12:06.1337965Z 
2026-01-14T08:12:06.1337968Z 
2026-01-14T08:12:06.1337972Z 
2026-01-14T08:12:06.1337975Z 
2026-01-14T08:12:06.1337978Z 
2026-01-14T08:12:06.1337982Z 
2026-01-14T08:12:06.1337986Z 
2026-01-14T08:12:06.1337989Z 
2026-01-14T08:12:06.1337992Z 
2026-01-14T08:12:06.1337996Z 
2026-01-14T08:12:06.1337999Z 
2026-01-14T08:12:06.1338016Z 
2026-01-14T08:12:06.1338020Z 
2026-01-14T08:12:06.1338023Z 
2026-01-14T08:12:06.1338027Z 
2026-01-14T08:12:06.1338030Z 
2026-01-14T08:12:06.1338429Z bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:01<00:00,  1.36s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1338844Z 
2026-01-14T08:12:06.1338848Z 
2026-01-14T08:12:06.1338852Z 
2026-01-14T08:12:06.1338855Z 
2026-01-14T08:12:06.1338873Z 
2026-01-14T08:12:06.1338876Z 
2026-01-14T08:12:06.1338880Z 
2026-01-14T08:12:06.1338883Z 
2026-01-14T08:12:06.1338890Z 
2026-01-14T08:12:06.1338894Z 
2026-01-14T08:12:06.1338897Z 
2026-01-14T08:12:06.1339304Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.41s/it]                 [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1339718Z 
2026-01-14T08:12:06.1339722Z 
2026-01-14T08:12:06.1339738Z 
2026-01-14T08:12:06.1339741Z 
2026-01-14T08:12:06.1339745Z 
2026-01-14T08:12:06.1339748Z 
2026-01-14T08:12:06.1339751Z 
2026-01-14T08:12:06.1339755Z 
2026-01-14T08:12:06.1339758Z 
2026-01-14T08:12:06.1339762Z 
2026-01-14T08:12:06.1339765Z 
2026-01-14T08:12:06.1340120Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.41s/it][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1340511Z 
2026-01-14T08:12:06.1340519Z 
2026-01-14T08:12:06.1340523Z 
2026-01-14T08:12:06.1340526Z 
2026-01-14T08:12:06.1340530Z 
2026-01-14T08:12:06.1340533Z 
2026-01-14T08:12:06.1340537Z 
2026-01-14T08:12:06.1340540Z 
2026-01-14T08:12:06.1340543Z 
2026-01-14T08:12:06.1340547Z 
2026-01-14T08:12:06.1340599Z 
2026-01-14T08:12:06.1340604Z 
2026-01-14T08:12:06.1340607Z 
2026-01-14T08:12:06.1340611Z 
2026-01-14T08:12:06.1340614Z 
2026-01-14T08:12:06.1340617Z 
2026-01-14T08:12:06.1340621Z 
2026-01-14T08:12:06.1340624Z 
2026-01-14T08:12:06.1340628Z 
2026-01-14T08:12:06.1340895Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1341204Z 
2026-01-14T08:12:06.1341208Z 
2026-01-14T08:12:06.1341212Z 
2026-01-14T08:12:06.1341215Z 
2026-01-14T08:12:06.1341219Z 
2026-01-14T08:12:06.1341222Z 
2026-01-14T08:12:06.1341226Z 
2026-01-14T08:12:06.1341229Z 
2026-01-14T08:12:06.1341233Z 
2026-01-14T08:12:06.1341236Z 
2026-01-14T08:12:06.1341240Z 
2026-01-14T08:12:06.1341243Z 
2026-01-14T08:12:06.1341247Z 
2026-01-14T08:12:06.1341254Z 
2026-01-14T08:12:06.1341258Z 
2026-01-14T08:12:06.1341273Z 
2026-01-14T08:12:06.1341276Z 
2026-01-14T08:12:06.1341280Z 
2026-01-14T08:12:06.1341284Z 
2026-01-14T08:12:06.1341533Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1341835Z 
2026-01-14T08:12:06.1341839Z 
2026-01-14T08:12:06.1341843Z 
2026-01-14T08:12:06.1341846Z 
2026-01-14T08:12:06.1341850Z 
2026-01-14T08:12:06.1341853Z 
2026-01-14T08:12:06.1342207Z ncurses-6.5          | 1.1 MB    | : 100% 1.0/1 [00:02<00:00,  2.25s/it]                 [A[A[A[A[A[A
2026-01-14T08:12:06.1342572Z 
2026-01-14T08:12:06.1342576Z 
2026-01-14T08:12:06.1342579Z 
2026-01-14T08:12:06.1342583Z 
2026-01-14T08:12:06.1342586Z 
2026-01-14T08:12:06.1342590Z 
2026-01-14T08:12:06.1342892Z ncurses-6.5          | 1.1 MB    | : 100% 1.0/1 [00:02<00:00,  2.25s/it][A[A[A[A[A[A
2026-01-14T08:12:06.1343214Z 
2026-01-14T08:12:06.1343218Z 
2026-01-14T08:12:06.1343221Z 
2026-01-14T08:12:06.1343225Z 
2026-01-14T08:12:06.1343290Z 
2026-01-14T08:12:06.1343293Z 
2026-01-14T08:12:06.1343297Z 
2026-01-14T08:12:06.1343300Z 
2026-01-14T08:12:06.1343303Z 
2026-01-14T08:12:06.1343307Z 
2026-01-14T08:12:06.1343310Z 
2026-01-14T08:12:06.1343313Z 
2026-01-14T08:12:06.1343317Z 
2026-01-14T08:12:06.1343736Z python-3.10.19       | 24.5 MB   | : 100% 1.0/1 [00:02<00:00,  1.48it/s]               [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:06.1344148Z 
2026-01-14T08:12:06.1344152Z 
2026-01-14T08:12:06.1344155Z 
2026-01-14T08:12:06.1344158Z 
2026-01-14T08:12:06.1344162Z 
2026-01-14T08:12:06.1344165Z 
2026-01-14T08:12:06.1344169Z 
2026-01-14T08:12:06.1344173Z 
2026-01-14T08:12:06.1344176Z 
2026-01-14T08:12:06.1344180Z 
2026-01-14T08:12:06.1344195Z 
2026-01-14T08:12:06.1344198Z 
2026-01-14T08:12:06.1344202Z 
2026-01-14T08:12:06.1344205Z 
2026-01-14T08:12:06.1344209Z 
2026-01-14T08:12:06.1344212Z 
2026-01-14T08:12:06.1344216Z 
2026-01-14T08:12:06.1344219Z 
2026-01-14T08:12:06.1344223Z 
2026-01-14T08:12:06.1344307Z                       
2026-01-14T08:12:06.1344644Z [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5005188Z                                                                         
2026-01-14T08:12:13.5005552Z 
2026-01-14T08:12:13.5005585Z 
2026-01-14T08:12:13.5006045Z                                                                         [A
2026-01-14T08:12:13.5006306Z 
2026-01-14T08:12:13.5006310Z 
2026-01-14T08:12:13.5006531Z                                                                         [A[A
2026-01-14T08:12:13.5006870Z 
2026-01-14T08:12:13.5006874Z 
2026-01-14T08:12:13.5006879Z 
2026-01-14T08:12:13.5007091Z                                                                         [A[A[A
2026-01-14T08:12:13.5007349Z 
2026-01-14T08:12:13.5007366Z 
2026-01-14T08:12:13.5007370Z 
2026-01-14T08:12:13.5007374Z 
2026-01-14T08:12:13.5007658Z                                                                         [A[A[A[A
2026-01-14T08:12:13.5007919Z 
2026-01-14T08:12:13.5007937Z 
2026-01-14T08:12:13.5007940Z 
2026-01-14T08:12:13.5007944Z 
2026-01-14T08:12:13.5007947Z 
2026-01-14T08:12:13.5008180Z                                                                         [A[A[A[A[A
2026-01-14T08:12:13.5008518Z 
2026-01-14T08:12:13.5008720Z 
2026-01-14T08:12:13.5008725Z 
2026-01-14T08:12:13.5008728Z 
2026-01-14T08:12:13.5008732Z 
2026-01-14T08:12:13.5008735Z 
2026-01-14T08:12:13.5008983Z                                                                         [A[A[A[A[A[A
2026-01-14T08:12:13.5009332Z 
2026-01-14T08:12:13.5009336Z 
2026-01-14T08:12:13.5009339Z 
2026-01-14T08:12:13.5009343Z 
2026-01-14T08:12:13.5009346Z 
2026-01-14T08:12:13.5009350Z 
2026-01-14T08:12:13.5009353Z 
2026-01-14T08:12:13.5009592Z                                                                         [A[A[A[A[A[A[A
2026-01-14T08:12:13.5009905Z 
2026-01-14T08:12:13.5009912Z 
2026-01-14T08:12:13.5009918Z 
2026-01-14T08:12:13.5009924Z 
2026-01-14T08:12:13.5009930Z 
2026-01-14T08:12:13.5009947Z 
2026-01-14T08:12:13.5009953Z 
2026-01-14T08:12:13.5009959Z 
2026-01-14T08:12:13.5010212Z                                                                         [A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5010509Z 
2026-01-14T08:12:13.5010513Z 
2026-01-14T08:12:13.5010520Z 
2026-01-14T08:12:13.5010524Z 
2026-01-14T08:12:13.5010527Z 
2026-01-14T08:12:13.5010531Z 
2026-01-14T08:12:13.5010535Z 
2026-01-14T08:12:13.5010538Z 
2026-01-14T08:12:13.5010541Z 
2026-01-14T08:12:13.5010857Z                                                                         [A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5011157Z 
2026-01-14T08:12:13.5011161Z 
2026-01-14T08:12:13.5011164Z 
2026-01-14T08:12:13.5011168Z 
2026-01-14T08:12:13.5011171Z 
2026-01-14T08:12:13.5011175Z 
2026-01-14T08:12:13.5011179Z 
2026-01-14T08:12:13.5011182Z 
2026-01-14T08:12:13.5011186Z 
2026-01-14T08:12:13.5011189Z 
2026-01-14T08:12:13.5011445Z                                                                         [A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5011967Z 
2026-01-14T08:12:13.5011971Z 
2026-01-14T08:12:13.5011975Z 
2026-01-14T08:12:13.5011978Z 
2026-01-14T08:12:13.5011982Z 
2026-01-14T08:12:13.5011985Z 
2026-01-14T08:12:13.5011988Z 
2026-01-14T08:12:13.5011992Z 
2026-01-14T08:12:13.5012000Z 
2026-01-14T08:12:13.5012004Z 
2026-01-14T08:12:13.5012008Z 
2026-01-14T08:12:13.5012295Z                                                                         [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5012652Z 
2026-01-14T08:12:13.5012655Z 
2026-01-14T08:12:13.5012659Z 
2026-01-14T08:12:13.5012662Z 
2026-01-14T08:12:13.5012666Z 
2026-01-14T08:12:13.5012670Z 
2026-01-14T08:12:13.5012673Z 
2026-01-14T08:12:13.5012677Z 
2026-01-14T08:12:13.5012680Z 
2026-01-14T08:12:13.5012684Z 
2026-01-14T08:12:13.5012687Z 
2026-01-14T08:12:13.5012690Z 
2026-01-14T08:12:13.5012958Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5013349Z 
2026-01-14T08:12:13.5013353Z 
2026-01-14T08:12:13.5013360Z 
2026-01-14T08:12:13.5013363Z 
2026-01-14T08:12:13.5013367Z 
2026-01-14T08:12:13.5013370Z 
2026-01-14T08:12:13.5013374Z 
2026-01-14T08:12:13.5013378Z 
2026-01-14T08:12:13.5013381Z 
2026-01-14T08:12:13.5013384Z 
2026-01-14T08:12:13.5013391Z 
2026-01-14T08:12:13.5013395Z 
2026-01-14T08:12:13.5013398Z 
2026-01-14T08:12:13.5013691Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5014065Z 
2026-01-14T08:12:13.5014068Z 
2026-01-14T08:12:13.5014072Z 
2026-01-14T08:12:13.5014075Z 
2026-01-14T08:12:13.5014079Z 
2026-01-14T08:12:13.5014082Z 
2026-01-14T08:12:13.5014086Z 
2026-01-14T08:12:13.5014089Z 
2026-01-14T08:12:13.5014093Z 
2026-01-14T08:12:13.5014096Z 
2026-01-14T08:12:13.5014100Z 
2026-01-14T08:12:13.5014104Z 
2026-01-14T08:12:13.5014108Z 
2026-01-14T08:12:13.5014124Z 
2026-01-14T08:12:13.5014409Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5014760Z 
2026-01-14T08:12:13.5014766Z 
2026-01-14T08:12:13.5014773Z 
2026-01-14T08:12:13.5014779Z 
2026-01-14T08:12:13.5014785Z 
2026-01-14T08:12:13.5014791Z 
2026-01-14T08:12:13.5014798Z 
2026-01-14T08:12:13.5014805Z 
2026-01-14T08:12:13.5014893Z 
2026-01-14T08:12:13.5014898Z 
2026-01-14T08:12:13.5014901Z 
2026-01-14T08:12:13.5014905Z 
2026-01-14T08:12:13.5014908Z 
2026-01-14T08:12:13.5014912Z 
2026-01-14T08:12:13.5014915Z 
2026-01-14T08:12:13.5015209Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5015573Z 
2026-01-14T08:12:13.5015579Z 
2026-01-14T08:12:13.5015585Z 
2026-01-14T08:12:13.5015605Z 
2026-01-14T08:12:13.5015611Z 
2026-01-14T08:12:13.5015618Z 
2026-01-14T08:12:13.5015623Z 
2026-01-14T08:12:13.5015627Z 
2026-01-14T08:12:13.5015631Z 
2026-01-14T08:12:13.5015634Z 
2026-01-14T08:12:13.5015638Z 
2026-01-14T08:12:13.5015641Z 
2026-01-14T08:12:13.5015645Z 
2026-01-14T08:12:13.5015652Z 
2026-01-14T08:12:13.5015656Z 
2026-01-14T08:12:13.5015659Z 
2026-01-14T08:12:13.5015976Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5016334Z 
2026-01-14T08:12:13.5016346Z 
2026-01-14T08:12:13.5016353Z 
2026-01-14T08:12:13.5016359Z 
2026-01-14T08:12:13.5016365Z 
2026-01-14T08:12:13.5016372Z 
2026-01-14T08:12:13.5016378Z 
2026-01-14T08:12:13.5016384Z 
2026-01-14T08:12:13.5016390Z 
2026-01-14T08:12:13.5016396Z 
2026-01-14T08:12:13.5016403Z 
2026-01-14T08:12:13.5016409Z 
2026-01-14T08:12:13.5016416Z 
2026-01-14T08:12:13.5016421Z 
2026-01-14T08:12:13.5016425Z 
2026-01-14T08:12:13.5016429Z 
2026-01-14T08:12:13.5016432Z 
2026-01-14T08:12:13.5016794Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5017155Z 
2026-01-14T08:12:13.5017162Z 
2026-01-14T08:12:13.5017169Z 
2026-01-14T08:12:13.5017176Z 
2026-01-14T08:12:13.5017182Z 
2026-01-14T08:12:13.5017268Z 
2026-01-14T08:12:13.5017272Z 
2026-01-14T08:12:13.5017275Z 
2026-01-14T08:12:13.5017279Z 
2026-01-14T08:12:13.5017282Z 
2026-01-14T08:12:13.5017286Z 
2026-01-14T08:12:13.5017289Z 
2026-01-14T08:12:13.5017293Z 
2026-01-14T08:12:13.5017300Z 
2026-01-14T08:12:13.5017303Z 
2026-01-14T08:12:13.5017307Z 
2026-01-14T08:12:13.5017310Z 
2026-01-14T08:12:13.5017313Z 
2026-01-14T08:12:13.5017661Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:12:13.5018064Z 
2026-01-14T08:12:13.5018068Z 
2026-01-14T08:12:13.5018071Z 
2026-01-14T08:12:13.5018173Z [A
2026-01-14T08:12:13.5018291Z 
2026-01-14T08:12:13.5018295Z 
2026-01-14T08:12:13.5018393Z [A[A
2026-01-14T08:12:13.5018501Z 
2026-01-14T08:12:13.5018669Z Preparing transaction: | / done
2026-01-14T08:12:13.5019235Z Verifying transaction: \ | / - \ | / - \ | / - \ | / - done
2026-01-14T08:12:13.5019981Z Executing transaction: | / - \ | / - \ | / - \ | / - \ | / - \ | done
2026-01-14T08:12:13.5020485Z #
2026-01-14T08:12:13.5020698Z # To activate this environment, use
2026-01-14T08:12:13.5020966Z #
2026-01-14T08:12:13.5021210Z #     $ conda activate venv
2026-01-14T08:12:13.5021483Z #
2026-01-14T08:12:13.5021691Z # To deactivate an active environment, use
2026-01-14T08:12:13.5022043Z #
2026-01-14T08:12:13.5022231Z #     $ conda deactivate
2026-01-14T08:12:13.5022387Z 
2026-01-14T08:12:13.5022484Z + conda activate venv
2026-01-14T08:12:13.5022708Z + local cmd=activate
2026-01-14T08:12:13.5022998Z + case "$cmd" in
2026-01-14T08:12:13.5023217Z + __conda_activate activate venv
2026-01-14T08:12:13.5023492Z + '[' -n '' ']'
2026-01-14T08:12:13.5023756Z + local ask_conda
2026-01-14T08:12:13.5023976Z ++ PS1='(base) '
2026-01-14T08:12:13.5024204Z ++ __conda_exe shell.posix activate venv
2026-01-14T08:12:13.5024618Z ++ /opt/conda/bin/conda shell.posix activate venv
2026-01-14T08:12:13.5024970Z + ask_conda='PS1='\''(venv) '\''
2026-01-14T08:12:13.5025831Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:12:13.5026894Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:12:13.5027230Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:12:13.5027513Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:12:13.5027899Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:12:13.5028236Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:12:13.5028633Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:12:13.5028941Z export _CE_M='\'''\''
2026-01-14T08:12:13.5029221Z export _CE_CONDA='\'''\''
2026-01-14T08:12:13.5029552Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:12:13.5029909Z + eval 'PS1='\''(venv) '\''
2026-01-14T08:12:13.5030756Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:12:13.5031750Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:12:13.5032078Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:12:13.5032375Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:12:13.5032755Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:12:13.5033078Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:12:13.5033476Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:12:13.5033783Z export _CE_M='\'''\''
2026-01-14T08:12:13.5034087Z export _CE_CONDA='\'''\''
2026-01-14T08:12:13.5034396Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:12:13.5034741Z ++ PS1='(venv) '
2026-01-14T08:12:13.5035525Z ++ export PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:12:13.5036952Z ++ PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:12:13.5037904Z ++ export CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:12:13.5038290Z ++ CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:12:13.5038596Z ++ export CONDA_SHLVL=2
2026-01-14T08:12:13.5038886Z ++ CONDA_SHLVL=2
2026-01-14T08:12:13.5039128Z ++ export CONDA_DEFAULT_ENV=venv
2026-01-14T08:12:13.5039396Z ++ CONDA_DEFAULT_ENV=venv
2026-01-14T08:12:13.5039739Z ++ export 'CONDA_PROMPT_MODIFIER=(venv) '
2026-01-14T08:12:13.5040109Z ++ CONDA_PROMPT_MODIFIER='(venv) '
2026-01-14T08:12:13.5040414Z ++ export CONDA_PREFIX_1=/opt/conda
2026-01-14T08:12:13.5040775Z ++ CONDA_PREFIX_1=/opt/conda
2026-01-14T08:12:13.5041045Z ++ export CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:12:13.5041416Z ++ CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:12:13.5041678Z ++ export _CE_M=
2026-01-14T08:12:13.5041888Z ++ _CE_M=
2026-01-14T08:12:13.5042119Z ++ export _CE_CONDA=
2026-01-14T08:12:13.5042370Z ++ _CE_CONDA=
2026-01-14T08:12:13.5042607Z ++ export CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:12:13.5043018Z ++ CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:12:13.5043307Z + __conda_hashr
2026-01-14T08:12:13.5043518Z + '[' -n '' ']'
2026-01-14T08:12:13.5043732Z + '[' -n '' ']'
2026-01-14T08:12:13.5043982Z + hash -r
2026-01-14T08:12:13.5044209Z + python -m pip install --upgrade pip
2026-01-14T08:12:13.5044717Z Requirement already satisfied: pip in /opt/conda/envs/venv/lib/python3.10/site-packages (25.3)
2026-01-14T08:12:13.5047022Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:12:13.5049004Z [0m+ pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
2026-01-14T08:12:13.5049713Z Looking in indexes: https://download.pytorch.org/whl/cpu
2026-01-14T08:12:13.5050097Z Collecting torch==2.7.1
2026-01-14T08:12:13.5050829Z   Downloading https://download.pytorch.org/whl/cpu/torch-2.7.1%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (27 kB)
2026-01-14T08:12:13.5051578Z Collecting filelock (from torch==2.7.1)
2026-01-14T08:12:13.5052060Z   Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)
2026-01-14T08:12:13.5052541Z Collecting typing-extensions>=4.10.0 (from torch==2.7.1)
2026-01-14T08:12:13.5053198Z   Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:12:13.5053807Z Collecting sympy>=1.13.3 (from torch==2.7.1)
2026-01-14T08:12:13.5054216Z   Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:12:13.5054609Z Collecting networkx (from torch==2.7.1)
2026-01-14T08:12:13.5055019Z   Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:12:13.5055433Z Collecting jinja2 (from torch==2.7.1)
2026-01-14T08:12:13.5055957Z   Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
2026-01-14T08:12:13.5056512Z Collecting fsspec (from torch==2.7.1)
2026-01-14T08:12:13.5056905Z   Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:12:13.5057399Z Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.1)
2026-01-14T08:12:13.5057876Z   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
2026-01-14T08:12:13.5058363Z Collecting MarkupSafe>=2.0 (from jinja2->torch==2.7.1)
2026-01-14T08:12:13.5059123Z   Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)
2026-01-14T08:12:13.5060123Z Downloading https://download.pytorch.org/whl/cpu/torch-2.7.1%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl (175.9 MB)
2026-01-14T08:12:13.5061411Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/175.9 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:13.5062467Z [2K   [91m━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m44.3/175.9 MB[0m [31m221.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:12:13.5063431Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m163.1/175.9 MB[0m [31m406.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:12:13.5064332Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m175.9/175.9 MB[0m [31m416.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:12:13.5065216Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m175.9/175.9 MB[0m [31m416.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:12:13.5066058Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m175.9/175.9 MB[0m [31m205.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:13.5066677Z [?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)
2026-01-14T08:12:20.6510040Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:20.6510927Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.3/6.3 MB[0m [31m138.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:20.6511566Z [?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)
2026-01-14T08:12:20.6512225Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/536.2 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:20.6513014Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m536.2/536.2 kB[0m [31m51.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:20.6513860Z [?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
2026-01-14T08:12:20.6514493Z Downloading filelock-3.20.0-py3-none-any.whl (16 kB)
2026-01-14T08:12:20.6514906Z Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)
2026-01-14T08:12:20.6515451Z Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
2026-01-14T08:12:20.6515993Z Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)
2026-01-14T08:12:20.6516648Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:20.6517629Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m154.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:20.6518565Z [?25hInstalling collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch
2026-01-14T08:12:20.6519234Z [?25l
2026-01-14T08:12:20.6519608Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0/9[0m [mpmath]
2026-01-14T08:12:20.6520236Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6520895Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6521530Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6522364Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6522999Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6523669Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6524317Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6524954Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6525606Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6526244Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6526891Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6527539Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6528197Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6528941Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6529579Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6530226Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6530871Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6531507Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6532262Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6532897Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6533567Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6534234Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6534869Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6535514Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6536148Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2/9[0m [sympy]
2026-01-14T08:12:20.6536809Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3/9[0m [networkx]
2026-01-14T08:12:20.6537472Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3/9[0m [networkx]
2026-01-14T08:12:20.6538251Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3/9[0m [networkx]
2026-01-14T08:12:20.6539026Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3/9[0m [networkx]
2026-01-14T08:12:20.6539702Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3/9[0m [networkx]
2026-01-14T08:12:20.6540382Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m4/9[0m [MarkupSafe]
2026-01-14T08:12:20.6541041Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m7/9[0m [jinja2]
2026-01-14T08:12:20.6541683Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:20.6542320Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:20.6542948Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2598608Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2599470Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2600379Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2601038Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2601677Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2604146Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2604788Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2605410Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2606045Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2606878Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2607515Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2608181Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2608810Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2609444Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2610064Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2610697Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2611330Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2612045Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2612685Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2613397Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2614034Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2614669Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2615291Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2615949Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2616569Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2617207Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2617870Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2618531Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2619154Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2619792Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2620415Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2621049Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2621682Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2622306Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2623027Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2623667Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2624304Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2624925Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2625565Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2626208Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2626831Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2627467Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2628113Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2628829Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2629465Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m8/9[0m [torch]
2026-01-14T08:12:28.2630047Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m9/9[0m [torch]
2026-01-14T08:12:28.2630436Z [?25h
2026-01-14T08:12:32.6354683Z [1A[2KSuccessfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.7.1+cpu typing-extensions-4.15.0
2026-01-14T08:12:32.6357240Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:12:32.6359279Z [0m+ sed -i '' dev-requirements.txt
2026-01-14T08:12:32.6359610Z + pip install -r dev-requirements.txt
2026-01-14T08:12:32.6360019Z Collecting pytest==8.4.2 (from -r dev-requirements.txt (line 2))
2026-01-14T08:12:32.6360514Z   Downloading pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)
2026-01-14T08:12:32.6361059Z Collecting unittest-xml-reporting (from -r dev-requirements.txt (line 3))
2026-01-14T08:12:32.6361673Z   Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl.metadata (11 kB)
2026-01-14T08:12:32.6362263Z Collecting parameterized (from -r dev-requirements.txt (line 4))
2026-01-14T08:12:32.6362817Z   Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)
2026-01-14T08:12:32.6363346Z Collecting packaging (from -r dev-requirements.txt (line 5))
2026-01-14T08:12:32.6363841Z   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:12:32.6364339Z Collecting transformers (from -r dev-requirements.txt (line 6))
2026-01-14T08:12:32.6364867Z   Downloading transformers-4.57.5-py3-none-any.whl.metadata (43 kB)
2026-01-14T08:12:32.6365379Z Collecting hypothesis (from -r dev-requirements.txt (line 7))
2026-01-14T08:12:32.6365889Z   Downloading hypothesis-6.150.2-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:12:32.6366412Z Collecting sentencepiece (from -r dev-requirements.txt (line 8))
2026-01-14T08:12:32.6367096Z   Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)
2026-01-14T08:12:32.6367786Z Collecting expecttest (from -r dev-requirements.txt (line 9))
2026-01-14T08:12:32.6368280Z   Downloading expecttest-0.3.0-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:12:32.6368774Z Collecting pyyaml (from -r dev-requirements.txt (line 10))
2026-01-14T08:12:32.6369480Z   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
2026-01-14T08:12:32.6370234Z Collecting bitsandbytes (from -r dev-requirements.txt (line 13))
2026-01-14T08:12:32.6370815Z   Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)
2026-01-14T08:12:32.6371533Z Collecting matplotlib (from -r dev-requirements.txt (line 14))
2026-01-14T08:12:32.6372312Z   Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)
2026-01-14T08:12:32.6372989Z Collecting pandas (from -r dev-requirements.txt (line 15))
2026-01-14T08:12:32.6373609Z   Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)
2026-01-14T08:12:32.6374244Z Collecting fire (from -r dev-requirements.txt (line 16))
2026-01-14T08:12:32.6374689Z   Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)
2026-01-14T08:12:32.6375167Z Collecting tabulate (from -r dev-requirements.txt (line 17))
2026-01-14T08:12:32.6375654Z   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
2026-01-14T08:12:32.6376136Z Collecting tiktoken (from -r dev-requirements.txt (line 18))
2026-01-14T08:12:32.6376692Z   Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.7 kB)
2026-01-14T08:12:32.6377254Z Collecting blobfile (from -r dev-requirements.txt (line 19))
2026-01-14T08:12:32.6377741Z   Downloading blobfile-3.1.0-py3-none-any.whl.metadata (15 kB)
2026-01-14T08:12:32.6378214Z Collecting lm_eval (from -r dev-requirements.txt (line 20))
2026-01-14T08:12:32.6378690Z   Downloading lm_eval-0.4.9.2-py3-none-any.whl.metadata (53 kB)
2026-01-14T08:12:32.6379180Z Collecting diskcache (from -r dev-requirements.txt (line 22))
2026-01-14T08:12:32.6379661Z   Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
2026-01-14T08:12:32.6380165Z Collecting pycocotools (from -r dev-requirements.txt (line 23))
2026-01-14T08:12:32.6380926Z   Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.3 kB)
2026-01-14T08:12:32.6381749Z Collecting tqdm (from -r dev-requirements.txt (line 24))
2026-01-14T08:12:32.6382191Z   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
2026-01-14T08:12:32.6382707Z Collecting importlib_metadata (from -r dev-requirements.txt (line 25))
2026-01-14T08:12:32.6383290Z   Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:12:32.6383807Z Collecting ninja (from -r dev-requirements.txt (line 28))
2026-01-14T08:12:32.6384423Z   Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)
2026-01-14T08:12:32.6385083Z Collecting cmake<4.0.0,>=3.19.0 (from -r dev-requirements.txt (line 31))
2026-01-14T08:12:32.6385744Z   Downloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:12:32.6386380Z Collecting ruff==0.11.6 (from -r dev-requirements.txt (line 34))
2026-01-14T08:12:32.6387000Z   Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)
2026-01-14T08:12:32.6387641Z Collecting pre-commit (from -r dev-requirements.txt (line 35))
2026-01-14T08:12:32.6388150Z   Downloading pre_commit-4.5.1-py2.py3-none-any.whl.metadata (1.2 kB)
2026-01-14T08:12:32.6388762Z Collecting exceptiongroup>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:12:32.6389365Z   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)
2026-01-14T08:12:32.6389947Z Collecting iniconfig>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:12:32.6390494Z   Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:12:32.6391044Z Collecting pluggy<2,>=1.5 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:12:32.6391594Z   Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)
2026-01-14T08:12:32.6392127Z Collecting pygments>=2.7.2 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:12:32.6392692Z   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:12:32.6393219Z Collecting tomli>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:12:32.6393738Z   Downloading tomli-2.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:12:32.6394379Z Collecting lxml (from unittest-xml-reporting->-r dev-requirements.txt (line 3))
2026-01-14T08:12:32.6395080Z   Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)
2026-01-14T08:12:32.6396103Z Requirement already satisfied: filelock in /opt/conda/envs/venv/lib/python3.10/site-packages (from transformers->-r dev-requirements.txt (line 6)) (3.20.0)
2026-01-14T08:12:32.6397069Z Collecting huggingface-hub<1.0,>=0.34.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:32.6397707Z   Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:12:32.6398259Z Collecting numpy>=1.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:32.6398939Z   Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
2026-01-14T08:12:32.6399648Z Collecting regex!=2019.12.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:32.6400452Z   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
2026-01-14T08:12:32.6401238Z Collecting requests (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:32.6401776Z   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
2026-01-14T08:12:32.6402367Z Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:32.6403126Z   Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
2026-01-14T08:12:32.6403858Z Collecting safetensors>=0.4.3 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:32.6404602Z   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
2026-01-14T08:12:32.6405840Z Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (2025.12.0)
2026-01-14T08:12:32.6407418Z Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (4.15.0)
2026-01-14T08:12:32.6408636Z Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:32.6409437Z   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
2026-01-14T08:12:32.6410181Z Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis->-r dev-requirements.txt (line 7))
2026-01-14T08:12:32.6410850Z   Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)
2026-01-14T08:12:32.6411800Z Requirement already satisfied: torch<3,>=2.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from bitsandbytes->-r dev-requirements.txt (line 13)) (2.7.1+cpu)
2026-01-14T08:12:32.6413233Z Requirement already satisfied: sympy>=1.13.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.14.0)
2026-01-14T08:12:32.6414565Z Requirement already satisfied: networkx in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.4.2)
2026-01-14T08:12:32.6415882Z Requirement already satisfied: jinja2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.1.6)
2026-01-14T08:12:32.6416845Z Collecting contourpy>=1.0.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:12:32.6417566Z   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)
2026-01-14T08:12:32.6418290Z Collecting cycler>=0.10 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:12:39.5355896Z   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:12:39.5356978Z Collecting fonttools>=4.22.0 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:12:39.5357739Z   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)
2026-01-14T08:12:39.5358482Z Collecting kiwisolver>=1.3.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:12:39.5359219Z   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:12:39.5359920Z Collecting pillow>=8 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:12:39.5360610Z   Downloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)
2026-01-14T08:12:39.5361314Z Collecting pyparsing>=3 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:12:39.5361874Z   Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:12:39.5362459Z Collecting python-dateutil>=2.7 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:12:39.5363111Z   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:12:39.5363721Z Collecting pytz>=2020.1 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:12:39.5364256Z   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
2026-01-14T08:12:39.5364780Z Collecting tzdata>=2022.7 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:12:39.5365332Z   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)
2026-01-14T08:12:39.5365850Z Collecting termcolor (from fire->-r dev-requirements.txt (line 16))
2026-01-14T08:12:39.5366376Z   Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)
2026-01-14T08:12:39.5366930Z Collecting pycryptodomex>=3.8 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:12:39.5367820Z   Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)
2026-01-14T08:12:39.5368558Z Collecting urllib3<3,>=1.25.3 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:12:39.5369102Z   Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)
2026-01-14T08:12:39.5369652Z Collecting accelerate>=0.26.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5370221Z   Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:12:39.5370742Z Collecting evaluate (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5371271Z   Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)
2026-01-14T08:12:39.5371797Z Collecting datasets>=2.16.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5372452Z   Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:12:39.5372961Z Collecting jsonlines (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5373506Z   Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)
2026-01-14T08:12:39.5374036Z Collecting numexpr (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5374706Z   Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)
2026-01-14T08:12:39.5375394Z Collecting peft>=0.2.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5375890Z   Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:12:39.5376407Z Collecting pybind11>=2.6.2 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5376950Z   Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)
2026-01-14T08:12:39.5377484Z Collecting pytablewriter (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5378054Z   Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)
2026-01-14T08:12:39.5378613Z Collecting rouge-score>=0.0.4 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5379103Z   Downloading rouge_score-0.1.2.tar.gz (17 kB)
2026-01-14T08:12:39.5379713Z   Installing build dependencies ... [?25l- \ | done
2026-01-14T08:12:39.5380220Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:12:39.5380799Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:12:39.5381420Z [?25hCollecting sacrebleu>=1.5.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5381995Z   Downloading sacrebleu-2.6.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:12:39.5382546Z Collecting scikit-learn>=0.24.1 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5383305Z   Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
2026-01-14T08:12:39.5384005Z Collecting sqlitedict (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5384475Z   Downloading sqlitedict-2.1.0.tar.gz (21 kB)
2026-01-14T08:12:39.5384902Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:12:39.5385402Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:12:39.5385925Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:12:39.5386545Z [?25hCollecting tqdm-multiprocess (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5387183Z   Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)
2026-01-14T08:12:39.5387749Z Collecting zstandard (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5388520Z   Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)
2026-01-14T08:12:39.5389259Z Collecting dill (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5389749Z   Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:12:39.5390263Z Collecting word2number (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5390715Z   Downloading word2number-1.1.zip (9.7 kB)
2026-01-14T08:12:39.5391234Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:12:39.5391712Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:12:39.5392234Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:12:39.5392828Z [?25hCollecting more_itertools (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5393422Z   Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:12:39.5394008Z Collecting zipp>=3.20 (from importlib_metadata->-r dev-requirements.txt (line 25))
2026-01-14T08:12:39.5394551Z   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)
2026-01-14T08:12:39.5395071Z Collecting cfgv>=2.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:12:39.5395601Z   Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)
2026-01-14T08:12:39.5396149Z Collecting identify>=1.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:12:39.5396718Z   Downloading identify-2.6.16-py2.py3-none-any.whl.metadata (4.4 kB)
2026-01-14T08:12:39.5397284Z Collecting nodeenv>=0.11.1 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:12:39.5397855Z   Downloading nodeenv-1.10.0-py2.py3-none-any.whl.metadata (24 kB)
2026-01-14T08:12:39.5398418Z Collecting virtualenv>=20.10.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:12:39.5399009Z   Downloading virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:12:39.5399595Z Collecting psutil (from accelerate>=0.26.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5400416Z   Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)
2026-01-14T08:12:39.5401246Z Collecting pyarrow>=21.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5401915Z   Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)
2026-01-14T08:12:39.5402580Z Collecting httpx<1.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5403154Z   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
2026-01-14T08:12:39.5403821Z Collecting xxhash (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5404624Z   Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:12:39.5405497Z Collecting multiprocess<0.70.19 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5406174Z   Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)
2026-01-14T08:12:39.5406873Z Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:39.5407554Z   Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:12:39.5408298Z Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5409307Z   Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
2026-01-14T08:12:39.5410173Z Collecting anyio (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5410769Z   Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:12:39.5411375Z Collecting certifi (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5412108Z   Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:12:39.5412755Z Collecting httpcore==1.* (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5413405Z   Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
2026-01-14T08:12:39.5413995Z Collecting idna (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5414653Z   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:12:39.5415290Z Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5415953Z   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
2026-01-14T08:12:39.5416777Z Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5417688Z   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
2026-01-14T08:12:39.5418553Z Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:39.5419369Z   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:12:41.8577530Z Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8578556Z   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)
2026-01-14T08:12:41.8579396Z Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8580203Z   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:12:41.8580999Z Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8582064Z   Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)
2026-01-14T08:12:41.8583127Z Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8584191Z   Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)
2026-01-14T08:12:41.8585457Z Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8586540Z   Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:12:41.8587637Z Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8588842Z   Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)
2026-01-14T08:12:41.8589714Z Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:12:41.8590371Z   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
2026-01-14T08:12:41.8591047Z Collecting charset_normalizer<4,>=2 (from requests->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:41.8592035Z   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
2026-01-14T08:12:41.8592954Z Collecting absl-py (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8593570Z   Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:12:41.8594176Z Collecting nltk (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8594777Z   Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)
2026-01-14T08:12:41.8595336Z Collecting portalocker (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8595963Z   Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)
2026-01-14T08:12:41.8596585Z Collecting colorama (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8597360Z   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
2026-01-14T08:12:41.8598005Z Collecting scipy>=1.8.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8598806Z   Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
2026-01-14T08:12:41.8599561Z Collecting joblib>=1.2.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8600227Z   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)
2026-01-14T08:12:41.8600859Z Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8601590Z   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
2026-01-14T08:12:41.8602679Z Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.3.0)
2026-01-14T08:12:41.8603870Z Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:12:41.8604547Z   Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)
2026-01-14T08:12:41.8605149Z Collecting filelock (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:12:41.8605742Z   Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)
2026-01-14T08:12:41.8606393Z Collecting platformdirs<5,>=3.9.1 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:12:41.8607107Z   Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:12:41.8608159Z Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (2.1.5)
2026-01-14T08:12:41.8609275Z Collecting click (from nltk->rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8609879Z   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
2026-01-14T08:12:41.8610929Z Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20)) (80.9.0)
2026-01-14T08:12:41.8612150Z Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8612803Z   Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)
2026-01-14T08:12:41.8613446Z Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8614136Z   Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:12:41.8614769Z Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8615428Z   Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:12:41.8616045Z Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8616683Z   Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:12:41.8617284Z Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8617904Z   Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:12:41.8618601Z Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8619292Z   Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)
2026-01-14T08:12:41.8619975Z Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:12:41.8620656Z   Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)
2026-01-14T08:12:41.8621108Z Downloading pytest-8.4.2-py3-none-any.whl (365 kB)
2026-01-14T08:12:41.8621652Z Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)
2026-01-14T08:12:41.8622740Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/11.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:41.8623544Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m11.5/11.5 MB[0m [31m191.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:41.8624341Z [?25hDownloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)
2026-01-14T08:12:41.8625156Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/27.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:41.8625932Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27.8/27.8 MB[0m [31m272.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:41.8626530Z [?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)
2026-01-14T08:12:41.8627019Z Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:12:41.8627541Z Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:12:41.8628012Z Downloading packaging-25.0-py3-none-any.whl (66 kB)
2026-01-14T08:12:41.8628440Z Downloading transformers-4.57.5-py3-none-any.whl (12.0 MB)
2026-01-14T08:12:41.8629123Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:41.8629897Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.0/12.0 MB[0m [31m225.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:41.8630549Z [?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
2026-01-14T08:12:41.8631243Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/566.1 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:41.8632008Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m566.1/566.1 kB[0m [31m61.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:41.8632809Z [?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:12:41.8633606Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:41.8634369Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m251.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6640682Z [?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:12:42.6641649Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6642414Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m239.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6643067Z [?25hDownloading hypothesis-6.150.2-py3-none-any.whl (542 kB)
2026-01-14T08:12:42.6643738Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/542.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6644520Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m542.7/542.7 kB[0m [31m60.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6645347Z [?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
2026-01-14T08:12:42.6646026Z Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)
2026-01-14T08:12:42.6646886Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.4 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6647632Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.4/1.4 MB[0m [31m110.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6648263Z [?25hDownloading expecttest-0.3.0-py3-none-any.whl (8.2 kB)
2026-01-14T08:12:42.6648939Z Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)
2026-01-14T08:12:42.6650006Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/770.3 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6650799Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m770.3/770.3 kB[0m [31m99.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6651550Z [?25hDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)
2026-01-14T08:12:42.6652399Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/59.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6653244Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m58.2/59.1 MB[0m [31m290.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:12:42.6654077Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m59.1/59.1 MB[0m [31m209.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6654928Z [?25hDownloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)
2026-01-14T08:12:42.6655757Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6656511Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.7/8.7 MB[0m [31m243.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6657326Z [?25hDownloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)
2026-01-14T08:12:42.6658153Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6659043Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.8/12.8 MB[0m [31m264.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6659670Z [?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)
2026-01-14T08:12:42.6660085Z Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)
2026-01-14T08:12:42.6660579Z Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.2 MB)
2026-01-14T08:12:42.6661291Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6662052Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m137.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6662652Z [?25hDownloading blobfile-3.1.0-py3-none-any.whl (75 kB)
2026-01-14T08:12:42.6663073Z Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)
2026-01-14T08:12:42.6663570Z Downloading lm_eval-0.4.9.2-py3-none-any.whl (8.2 MB)
2026-01-14T08:12:42.6664205Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6664965Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.2/8.2 MB[0m [31m232.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6665567Z [?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)
2026-01-14T08:12:42.6666278Z Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (472 kB)
2026-01-14T08:12:42.6666946Z Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
2026-01-14T08:12:42.6667387Z Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)
2026-01-14T08:12:42.6667973Z Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)
2026-01-14T08:12:42.6668553Z Downloading pre_commit-4.5.1-py2.py3-none-any.whl (226 kB)
2026-01-14T08:12:42.6669014Z Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)
2026-01-14T08:12:42.6669425Z Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)
2026-01-14T08:12:42.6670004Z Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
2026-01-14T08:12:42.6670578Z Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
2026-01-14T08:12:42.6671008Z Downloading datasets-4.4.2-py3-none-any.whl (512 kB)
2026-01-14T08:12:42.6671522Z Downloading dill-0.4.0-py3-none-any.whl (119 kB)
2026-01-14T08:12:42.6671914Z Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)
2026-01-14T08:12:42.6672319Z Downloading httpx-0.28.1-py3-none-any.whl (73 kB)
2026-01-14T08:12:42.6672703Z Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)
2026-01-14T08:12:42.6673150Z Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)
2026-01-14T08:12:42.6673843Z Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)
2026-01-14T08:12:42.6674768Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6675615Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m191.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6676245Z [?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)
2026-01-14T08:12:42.6676968Z Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)
2026-01-14T08:12:42.6677888Z Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)
2026-01-14T08:12:42.6678575Z Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
2026-01-14T08:12:42.6679038Z Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:12:42.6679450Z Downloading attrs-25.4.0-py3-none-any.whl (67 kB)
2026-01-14T08:12:42.6679835Z Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)
2026-01-14T08:12:42.6680276Z Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)
2026-01-14T08:12:42.6680935Z Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)
2026-01-14T08:12:42.6681814Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/4.9 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:42.6682571Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m4.9/4.9 MB[0m [31m213.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:42.6683490Z [?25hDownloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)
2026-01-14T08:12:42.6684163Z Downloading h11-0.16.0-py3-none-any.whl (37 kB)
2026-01-14T08:12:42.6684567Z Downloading identify-2.6.16-py2.py3-none-any.whl (99 kB)
2026-01-14T08:12:42.6684984Z Downloading idna-3.11-py3-none-any.whl (71 kB)
2026-01-14T08:12:42.6685369Z Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:12:42.6685968Z Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
2026-01-14T08:12:42.6686869Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6531106Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m151.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6532056Z [?25hDownloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)
2026-01-14T08:12:43.6532889Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6533644Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.3/5.3 MB[0m [31m291.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6534284Z [?25hDownloading nodeenv-1.10.0-py2.py3-none-any.whl (23 kB)
2026-01-14T08:12:43.6534885Z Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)
2026-01-14T08:12:43.6535675Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/16.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6536468Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m16.8/16.8 MB[0m [31m304.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6537288Z [?25hDownloading peft-0.18.1-py3-none-any.whl (556 kB)
2026-01-14T08:12:43.6537938Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/557.0 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6538728Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m557.0/557.0 kB[0m [31m70.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6539545Z [?25hDownloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)
2026-01-14T08:12:43.6540367Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/7.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6541115Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m7.0/7.0 MB[0m [31m194.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6542072Z [?25hDownloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)
2026-01-14T08:12:43.6542874Z Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)
2026-01-14T08:12:43.6543601Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/47.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6544434Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m47.4/47.6 MB[0m [31m249.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:12:43.6545261Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m47.6/47.6 MB[0m [31m184.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6545875Z [?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)
2026-01-14T08:12:43.6546493Z Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)
2026-01-14T08:12:43.6547311Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/2.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6548179Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2.3/2.3 MB[0m [31m179.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6548802Z [?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)
2026-01-14T08:12:43.6549460Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6550389Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m112.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6550997Z [?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)
2026-01-14T08:12:43.6551519Z Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
2026-01-14T08:12:43.6552008Z Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)
2026-01-14T08:12:43.6552683Z Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)
2026-01-14T08:12:43.6553593Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/791.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6554380Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m791.7/791.7 kB[0m [31m60.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6555108Z [?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)
2026-01-14T08:12:43.6555828Z Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)
2026-01-14T08:12:43.6556569Z Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)
2026-01-14T08:12:43.6557002Z Downloading sacrebleu-2.6.0-py3-none-any.whl (100 kB)
2026-01-14T08:12:43.6557580Z Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)
2026-01-14T08:12:43.6558350Z Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)
2026-01-14T08:12:43.6559166Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/9.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6559942Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m9.7/9.7 MB[0m [31m218.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6560547Z [?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)
2026-01-14T08:12:43.6561118Z Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)
2026-01-14T08:12:43.6561917Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/37.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6562726Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m37.5/37.7 MB[0m [31m244.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:12:43.6563552Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m37.7/37.7 MB[0m [31m182.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6564167Z [?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)
2026-01-14T08:12:43.6564602Z Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
2026-01-14T08:12:43.6565023Z Downloading tomli-2.4.0-py3-none-any.whl (14 kB)
2026-01-14T08:12:43.6565509Z Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)
2026-01-14T08:12:43.6565946Z Downloading virtualenv-20.36.1-py3-none-any.whl (6.0 MB)
2026-01-14T08:12:43.6566599Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6567360Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.0/6.0 MB[0m [31m277.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6568002Z [?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)
2026-01-14T08:12:43.6568437Z Downloading filelock-3.20.3-py3-none-any.whl (16 kB)
2026-01-14T08:12:43.6568869Z Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)
2026-01-14T08:12:43.6569273Z Downloading zipp-3.23.0-py3-none-any.whl (10 kB)
2026-01-14T08:12:43.6569661Z Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)
2026-01-14T08:12:43.6570039Z Downloading anyio-4.12.1-py3-none-any.whl (113 kB)
2026-01-14T08:12:43.6570455Z Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
2026-01-14T08:12:43.6570882Z Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)
2026-01-14T08:12:43.6571321Z Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)
2026-01-14T08:12:43.6571749Z Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)
2026-01-14T08:12:43.6572456Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:43.6573217Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.5/1.5 MB[0m [31m182.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:43.6573802Z [?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)
2026-01-14T08:12:43.6574384Z Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (440 kB)
2026-01-14T08:12:43.6574995Z Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)
2026-01-14T08:12:43.6575643Z Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)
2026-01-14T08:12:50.6295904Z Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)
2026-01-14T08:12:50.6296417Z Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)
2026-01-14T08:12:50.6296864Z Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)
2026-01-14T08:12:50.6297541Z Downloading chardet-5.2.0-py3-none-any.whl (199 kB)
2026-01-14T08:12:50.6297965Z Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)
2026-01-14T08:12:50.6298394Z Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)
2026-01-14T08:12:50.6298800Z Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)
2026-01-14T08:12:50.6299210Z Downloading typepy-1.3.4-py3-none-any.whl (31 kB)
2026-01-14T08:12:50.6299621Z Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)
2026-01-14T08:12:50.6300068Z Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)
2026-01-14T08:12:50.6300771Z Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)
2026-01-14T08:12:50.6301600Z Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)
2026-01-14T08:12:50.6302777Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:12:50.6303570Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.6/5.6 MB[0m [31m236.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:12:50.6304291Z [?25hBuilding wheels for collected packages: rouge-score, sqlitedict, word2number
2026-01-14T08:12:50.6304948Z   Building wheel for rouge-score (pyproject.toml) ... [?25l- done
2026-01-14T08:12:50.6306002Z [?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=91751886b0fa48fcb355cd9b32da0765352076294552e6d1f627ea6c527ecb47
2026-01-14T08:12:50.6307068Z   Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4
2026-01-14T08:12:50.6307807Z   Building wheel for sqlitedict (pyproject.toml) ... [?25l- done
2026-01-14T08:12:50.6308846Z [?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16957 sha256=887578a858557a0156db5b1fdb8fd32ab6af975605b22c5ef3ea944dae2e016f
2026-01-14T08:12:50.6309924Z   Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd
2026-01-14T08:12:50.6310650Z   Building wheel for word2number (pyproject.toml) ... [?25l- done
2026-01-14T08:12:50.6311698Z [?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5659 sha256=1e01522eaf1a0fd4998c3e4eca291359aa7184b39953d6b7e972fc4d0db8ff92
2026-01-14T08:12:50.6312758Z   Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b
2026-01-14T08:12:50.6313382Z Successfully built rouge-score sqlitedict word2number
2026-01-14T08:12:50.6318700Z Installing collected packages: word2number, sqlitedict, sortedcontainers, pytz, distlib, zstandard, zipp, xxhash, urllib3, tzdata, tqdm, tomli, threadpoolctl, termcolor, tcolorpy, tabulate, six, sentencepiece, safetensors, ruff, regex, pyyaml, pyparsing, pygments, pycryptodomex, pybind11, pyarrow, psutil, propcache, portalocker, pluggy, platformdirs, pillow, pathvalidate, parameterized, packaging, numpy, nodeenv, ninja, multidict, more_itertools, lxml, kiwisolver, joblib, iniconfig, idna, identify, hf-xet, h11, fsspec, frozenlist, fonttools, filelock, expecttest, exceptiongroup, diskcache, dill, cycler, colorama, cmake, click, charset_normalizer, chardet, cfgv, certifi, attrs, async-timeout, aiohappyeyeballs, absl-py, yarl, virtualenv, unittest-xml-reporting, tqdm-multiprocess, scipy, sacrebleu, requests, python-dateutil, pytest, pycocotools, numexpr, nltk, multiprocess, mbstrdecoder, jsonlines, importlib_metadata, hypothesis, httpcore, fire, contourpy, blobfile, anyio, aiosignal, typepy, tiktoken, scikit-learn, rouge-score, pre-commit, pandas, matplotlib, huggingface-hub, httpx, bitsandbytes, aiohttp, tokenizers, accelerate, transformers, datasets, DataProperty, tabledata, peft, evaluate, pytablewriter, lm_eval
2026-01-14T08:12:50.6324154Z [?25l
2026-01-14T08:12:50.6324633Z [2K   [91m━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  4/113[0m [distlib]
2026-01-14T08:12:50.6325328Z [2K   [91m━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  8/113[0m [urllib3]
2026-01-14T08:12:50.6326006Z [2K   [91m━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 10/113[0m [tqdm]
2026-01-14T08:12:50.6326662Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 19/113[0m [ruff]
2026-01-14T08:12:50.6327332Z [2K   [91m━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 20/113[0m [regex]
2026-01-14T08:12:50.6328023Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/113[0m [pygments]
2026-01-14T08:12:50.6328709Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/113[0m [pygments]
2026-01-14T08:12:50.6329397Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/113[0m [pygments]
2026-01-14T08:12:50.6330180Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/113[0m [pycryptodomex]
2026-01-14T08:12:50.6330934Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/113[0m [pycryptodomex]
2026-01-14T08:12:50.6331665Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/113[0m [pycryptodomex]
2026-01-14T08:12:50.6332476Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/113[0m [pyarrow]
2026-01-14T08:12:50.6333163Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/113[0m [pyarrow]
2026-01-14T08:12:50.6333835Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/113[0m [pyarrow]
2026-01-14T08:12:50.6334516Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/113[0m [pyarrow]
2026-01-14T08:12:50.6335222Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/113[0m [pyarrow]
2026-01-14T08:12:50.6335891Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/113[0m [pyarrow]
2026-01-14T08:12:50.6336650Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 27/113[0m [psutil]
2026-01-14T08:12:50.6337322Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/113[0m [pillow]
2026-01-14T08:12:50.6338001Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/113[0m [pillow]
2026-01-14T08:12:50.6338674Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:50.6339341Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:50.6340011Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:50.6340753Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:50.6341425Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:56.5487539Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:56.5488285Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:56.5488955Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:56.5489629Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:56.5490289Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/113[0m [numpy]
2026-01-14T08:12:56.5490958Z [2K   [91m━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 41/113[0m [lxml]
2026-01-14T08:12:56.5491649Z [2K   [91m━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 43/113[0m [joblib]
2026-01-14T08:12:56.5492416Z [2K   [91m━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 47/113[0m [hf-xet]
2026-01-14T08:12:56.5492942Z [2K  Attempting uninstall: fsspec
2026-01-14T08:12:56.5493456Z    [91m━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 47/113[0m [hf-xet]
2026-01-14T08:12:56.5494003Z [2K    Found existing installation: fsspec 2025.12.0
2026-01-14T08:12:56.5494576Z    [91m━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 47/113[0m [hf-xet]
2026-01-14T08:12:56.5495075Z [2K    Uninstalling fsspec-2025.12.0:
2026-01-14T08:12:56.5495605Z    [91m━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 47/113[0m [hf-xet]
2026-01-14T08:12:56.5496119Z [2K      Successfully uninstalled fsspec-2025.12.0
2026-01-14T08:12:56.5496687Z    [91m━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 47/113[0m [hf-xet]
2026-01-14T08:12:56.5497365Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m 49/113[0m [fsspec]
2026-01-14T08:12:56.5498263Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/113[0m [fonttools]
2026-01-14T08:12:56.5498958Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/113[0m [fonttools]
2026-01-14T08:12:56.5499651Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/113[0m [fonttools]
2026-01-14T08:12:56.5500344Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/113[0m [fonttools]
2026-01-14T08:12:56.5500837Z [2K  Attempting uninstall: filelock
2026-01-14T08:12:56.5501380Z    [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/113[0m [fonttools]
2026-01-14T08:12:56.5501917Z [2K    Found existing installation: filelock 3.20.0
2026-01-14T08:12:56.5502508Z    [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/113[0m [fonttools]
2026-01-14T08:12:56.5503137Z [2K    Uninstalling filelock-3.20.0:
2026-01-14T08:12:56.5503690Z    [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/113[0m [fonttools]
2026-01-14T08:12:56.5504229Z [2K      Successfully uninstalled filelock-3.20.0
2026-01-14T08:12:56.5504818Z    [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/113[0m [fonttools]
2026-01-14T08:12:56.5505505Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/113[0m [colorama]
2026-01-14T08:12:56.5506193Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 59/113[0m [cmake]
2026-01-14T08:12:56.5506853Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 59/113[0m [cmake]
2026-01-14T08:12:56.5507523Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 59/113[0m [cmake]
2026-01-14T08:12:56.5508199Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 59/113[0m [cmake]
2026-01-14T08:12:56.5508866Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 59/113[0m [cmake]
2026-01-14T08:12:56.5509654Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m 61/113[0m [charset_normalizer]
2026-01-14T08:12:56.5510351Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m 63/113[0m [cfgv]
2026-01-14T08:12:56.5511039Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━[0m [32m 70/113[0m [virtualenv]
2026-01-14T08:12:56.5511707Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5512372Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5513035Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5513712Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5514392Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5515068Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5515740Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5516411Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5517072Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5517741Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5518400Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5519144Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:12:56.5519839Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:13:04.0093566Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:13:04.0094322Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:13:04.0094992Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:13:04.0095667Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:13:04.0096321Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:13:04.0096988Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 73/113[0m [scipy]
2026-01-14T08:13:04.0097717Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━[0m [32m 74/113[0m [sacrebleu]
2026-01-14T08:13:04.0098661Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━[0m [32m 75/113[0m [requests]
2026-01-14T08:13:04.0099360Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m 77/113[0m [pytest]
2026-01-14T08:13:04.0100029Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m 77/113[0m [pytest]
2026-01-14T08:13:04.0100711Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━[0m [32m 79/113[0m [numexpr]
2026-01-14T08:13:04.0101372Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 80/113[0m [nltk]
2026-01-14T08:13:04.0102038Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 80/113[0m [nltk]
2026-01-14T08:13:04.0102701Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 80/113[0m [nltk]
2026-01-14T08:13:04.0103489Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 80/113[0m [nltk]
2026-01-14T08:13:04.0104204Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━[0m [32m 81/113[0m [multiprocess]
2026-01-14T08:13:04.0104932Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m 85/113[0m [hypothesis]
2026-01-14T08:13:04.0105622Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m 85/113[0m [hypothesis]
2026-01-14T08:13:04.0106317Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m 88/113[0m [contourpy]
2026-01-14T08:13:04.0106991Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━[0m [32m 92/113[0m [typepy]
2026-01-14T08:13:04.0107693Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 94/113[0m [scikit-learn]
2026-01-14T08:13:04.0108406Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 94/113[0m [scikit-learn]
2026-01-14T08:13:04.0109128Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 94/113[0m [scikit-learn]
2026-01-14T08:13:04.0109937Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 94/113[0m [scikit-learn]
2026-01-14T08:13:04.0110642Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 94/113[0m [scikit-learn]
2026-01-14T08:13:04.0111349Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 94/113[0m [scikit-learn]
2026-01-14T08:13:04.0112059Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 94/113[0m [scikit-learn]
2026-01-14T08:13:04.0112758Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 94/113[0m [scikit-learn]
2026-01-14T08:13:04.0113471Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 94/113[0m [scikit-learn]
2026-01-14T08:13:04.0114192Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m 96/113[0m [pre-commit]
2026-01-14T08:13:04.0114903Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0115575Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0116233Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0116901Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0117556Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0118221Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0118889Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0119622Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0120315Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0120970Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0121640Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0122307Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0122960Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:04.0123628Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:11.5169709Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:11.5170488Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:11.5171692Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:11.5172449Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:11.5173131Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:11.5173806Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 97/113[0m [pandas]
2026-01-14T08:13:11.5174489Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 98/113[0m [matplotlib]
2026-01-14T08:13:11.5175246Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 98/113[0m [matplotlib]
2026-01-14T08:13:11.5175974Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 98/113[0m [matplotlib]
2026-01-14T08:13:11.5176815Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 98/113[0m [matplotlib]
2026-01-14T08:13:11.5177538Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 98/113[0m [matplotlib]
2026-01-14T08:13:11.5178227Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 98/113[0m [matplotlib]
2026-01-14T08:13:11.5178956Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m 99/113[0m [huggingface-hub]
2026-01-14T08:13:11.5179675Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m101/113[0m [bitsandbytes]
2026-01-14T08:13:11.5180390Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m101/113[0m [bitsandbytes]
2026-01-14T08:13:11.5181104Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m101/113[0m [bitsandbytes]
2026-01-14T08:13:11.5181829Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m101/113[0m [bitsandbytes]
2026-01-14T08:13:11.5182611Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m101/113[0m [bitsandbytes]
2026-01-14T08:13:11.5183301Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/113[0m [aiohttp]
2026-01-14T08:13:11.5183996Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m103/113[0m [tokenizers]
2026-01-14T08:13:11.5184693Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m104/113[0m [accelerate]
2026-01-14T08:13:11.5185381Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5186108Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5186816Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5187533Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5188259Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5188954Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5189661Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5190368Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5191066Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5191777Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5192547Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5193259Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5193991Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5194690Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5195402Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5196099Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5196804Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5207433Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5208218Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5209091Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5209818Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5210523Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:11.5211233Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:23.4057646Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:23.4058447Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:23.4059163Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:23.4060142Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:23.4060883Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:23.4061584Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:23.4062299Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:23.4062996Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m105/113[0m [transformers]
2026-01-14T08:13:23.4063694Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m106/113[0m [datasets]
2026-01-14T08:13:23.4064508Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m107/113[0m [DataProperty]
2026-01-14T08:13:23.4065219Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m109/113[0m [peft]
2026-01-14T08:13:23.4066002Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m111/113[0m [pytablewriter]
2026-01-14T08:13:23.4066673Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4067286Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4067911Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4068523Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4069147Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4069753Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4070399Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4071019Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4071642Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4072266Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4072899Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4073500Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4074111Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4074712Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4075328Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4076011Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m112/113[0m [lm_eval]
2026-01-14T08:13:23.4076628Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m113/113[0m [lm_eval]
2026-01-14T08:13:23.4077032Z [?25h
2026-01-14T08:13:23.4085873Z [1A[2KSuccessfully installed DataProperty-1.1.0 absl-py-2.3.1 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 anyio-4.12.1 async-timeout-5.0.1 attrs-25.4.0 bitsandbytes-0.49.1 blobfile-3.1.0 certifi-2026.1.4 cfgv-3.5.0 chardet-5.2.0 charset_normalizer-3.4.4 click-8.3.1 cmake-3.31.10 colorama-0.4.6 contourpy-1.3.2 cycler-0.12.1 datasets-4.4.2 dill-0.4.0 diskcache-5.6.3 distlib-0.4.0 evaluate-0.4.6 exceptiongroup-1.3.1 expecttest-0.3.0 filelock-3.20.3 fire-0.7.1 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 hypothesis-6.150.2 identify-2.6.16 idna-3.11 importlib_metadata-8.7.1 iniconfig-2.3.0 joblib-1.5.3 jsonlines-4.0.0 kiwisolver-1.4.9 lm_eval-0.4.9.2 lxml-6.0.2 matplotlib-3.10.8 mbstrdecoder-1.1.4 more_itertools-10.8.0 multidict-6.7.0 multiprocess-0.70.18 ninja-1.13.0 nltk-3.9.2 nodeenv-1.10.0 numexpr-2.14.1 numpy-2.2.6 packaging-25.0 pandas-2.3.3 parameterized-0.9.0 pathvalidate-3.3.1 peft-0.18.1 pillow-12.1.0 platformdirs-4.5.1 pluggy-1.6.0 portalocker-3.2.0 pre-commit-4.5.1 propcache-0.4.1 psutil-7.2.1 pyarrow-22.0.0 pybind11-3.0.1 pycocotools-2.0.11 pycryptodomex-3.23.0 pygments-2.19.2 pyparsing-3.3.1 pytablewriter-1.2.1 pytest-8.4.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 rouge-score-0.1.2 ruff-0.11.6 sacrebleu-2.6.0 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentencepiece-0.2.1 six-1.17.0 sortedcontainers-2.4.0 sqlitedict-2.1.0 tabledata-1.3.4 tabulate-0.9.0 tcolorpy-0.1.7 termcolor-3.3.0 threadpoolctl-3.6.0 tiktoken-0.12.0 tokenizers-0.22.2 tomli-2.4.0 tqdm-4.67.1 tqdm-multiprocess-0.0.11 transformers-4.57.5 typepy-1.3.4 tzdata-2025.3 unittest-xml-reporting-4.0.0 urllib3-2.6.3 virtualenv-20.36.1 word2number-1.1 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0 zstandard-0.25.0
2026-01-14T08:13:23.4095326Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:13:23.4097050Z [0m+ pip install . --no-build-isolation
2026-01-14T08:13:23.4097369Z Processing /pytorch/ao
2026-01-14T08:13:23.4097738Z   Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:13:23.4098212Z [?25hBuilding wheels for collected packages: torchao
2026-01-14T08:13:23.4098748Z   Building wheel for torchao (pyproject.toml) ... [?25l- \ | / done
2026-01-14T08:13:23.4099874Z [?25h  Created wheel for torchao: filename=torchao-0.16.0+gitb34f898-py3-none-any.whl size=1131604 sha256=a8749ae56994ff95fcf41b96623e9c846591749078b3bbdc4e50a4af12712c85
2026-01-14T08:13:23.4101123Z   Stored in directory: /tmp/pip-ephem-wheel-cache-f09vwhsw/wheels/d2/8b/29/aa26bc7679794c5ecae292c3b064b585980cbedb836e694414
2026-01-14T08:13:23.4101803Z Successfully built torchao
2026-01-14T08:13:23.4102092Z Installing collected packages: torchao
2026-01-14T08:13:23.4102431Z Successfully installed torchao-0.16.0+gitb34f898
2026-01-14T08:13:38.3655980Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:13:38.3657732Z [0m++++ which conda
2026-01-14T08:13:38.3657982Z +++ dirname /opt/conda/condabin/conda
2026-01-14T08:13:38.3658322Z ++ dirname /opt/conda/condabin
2026-01-14T08:13:38.3658605Z + export CONDA=/opt/conda
2026-01-14T08:13:38.3658898Z + CONDA=/opt/conda
2026-01-14T08:13:38.3659441Z + export LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:13:38.3660281Z + LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:13:38.3660846Z + pytest test --verbose -s
2026-01-14T08:13:38.3661268Z [1m============================= test session starts ==============================[0m
2026-01-14T08:13:38.3661987Z platform linux -- Python 3.10.19, pytest-8.4.2, pluggy-1.6.0 -- /opt/conda/envs/venv/bin/python3.10
2026-01-14T08:13:38.3662509Z cachedir: .pytest_cache
2026-01-14T08:13:38.3663130Z hypothesis profile 'ci' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=(HealthCheck.too_slow,)
2026-01-14T08:13:38.3663814Z rootdir: /pytorch/ao
2026-01-14T08:13:38.3664063Z configfile: pyproject.toml
2026-01-14T08:13:38.3664354Z plugins: hypothesis-6.150.2, anyio-4.12.1
2026-01-14T08:13:38.3664700Z [1mcollecting ... [0m[1m
2026-01-14T08:13:38.3665409Z collecting 0 items                                                             [0m[1m
2026-01-14T08:13:38.3666011Z collecting 28 items                                                            [0m[1m
2026-01-14T08:13:38.3666736Z collecting 104 items                                                           [0m[1m
2026-01-14T08:13:38.3667330Z collecting 175 items                                                           [0m[1m
2026-01-14T08:13:38.3667939Z collecting 870 items / 3 skipped                                               [0m[1m
2026-01-14T08:13:38.3668578Z collecting 885 items / 7 skipped                                               [0m[1m
2026-01-14T08:13:38.3669304Z collecting 954 items / 26 skipped                                              [0m[1m
2026-01-14T08:13:38.3669964Z collecting 2543 items / 26 skipped                                             [0m[1m
2026-01-14T08:13:38.3670615Z collecting 4224 items / 26 skipped                                             [0m[1m
2026-01-14T08:13:38.3671250Z collected 5850 items / 26 skipped                                              [0m
2026-01-14T08:13:38.3671595Z 
2026-01-14T08:13:38.3672009Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config0] [32mPASSED[0m
2026-01-14T08:13:38.3672793Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config1] [32mPASSED[0m
2026-01-14T08:13:38.3673581Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config2] [32mPASSED[0m
2026-01-14T08:13:38.3674505Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config3] [32mPASSED[0m
2026-01-14T08:13:38.3675283Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config4] [32mPASSED[0m
2026-01-14T08:13:38.3676085Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config5] [32mPASSED[0m
2026-01-14T08:13:38.3677110Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config6] [32mPASSED[0m
2026-01-14T08:13:38.3677894Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7] [32mPASSED[0m
2026-01-14T08:13:38.3678682Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config8] [32mPASSED[0m
2026-01-14T08:13:38.3679460Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config9] [32mPASSED[0m
2026-01-14T08:13:38.3680257Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config10] [32mPASSED[0m
2026-01-14T08:13:38.3681053Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config11] [32mPASSED[0m
2026-01-14T08:13:38.3681968Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config12] [32mPASSED[0m
2026-01-14T08:13:38.3682761Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config13] [32mPASSED[0m
2026-01-14T08:13:38.3683546Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14] [32mPASSED[0m
2026-01-14T08:13:38.3684396Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config15] [32mPASSED[0m
2026-01-14T08:13:38.3685180Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config16] [32mPASSED[0m
2026-01-14T08:13:38.3685970Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config17] [32mPASSED[0m
2026-01-14T08:13:38.3686761Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config18] [32mPASSED[0m
2026-01-14T08:13:38.3687543Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config19] [32mPASSED[0m
2026-01-14T08:13:38.3688333Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config20] [32mPASSED[0m
2026-01-14T08:13:38.3689205Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config21] [32mPASSED[0m
2026-01-14T08:13:38.3689989Z test/core/test_config.py::test_granularity_serialization[granularity0] [33mSKIPPED[0m
2026-01-14T08:13:38.3690741Z test/core/test_config.py::test_granularity_serialization[granularity1] [33mSKIPPED[0m
2026-01-14T08:13:38.3691673Z test/core/test_config.py::test_granularity_serialization[granularity2] [33mSKIPPED[0m
2026-01-14T08:13:38.3692484Z test/core/test_config.py::test_disallowed_modules [32mPASSED[0m
2026-01-14T08:13:38.3693027Z test/core/test_config.py::test_version_mismatch [32mPASSED[0m
2026-01-14T08:13:38.3693571Z test/core/test_config.py::test_default_version [32mPASSED[0m
2026-01-14T08:13:38.3694369Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant0 [33mSKIPPED[0m
2026-01-14T08:13:38.3696803Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant1 [33mSKIPPED[0m
2026-01-14T08:13:38.3697851Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant2 [33mSKIPPED[0m
2026-01-14T08:13:38.3698943Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant3 [33mSKIPPED[0m
2026-01-14T08:13:38.3699977Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant4 [33mSKIPPED[0m
2026-01-14T08:13:38.3700943Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_print_quantized_module [33mSKIPPED[0m
2026-01-14T08:13:38.3701945Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_register_new_dispatch [33mSKIPPED[0m
2026-01-14T08:13:38.3702882Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_tensor_core_layout_transpose [33mSKIPPED[0m
2026-01-14T08:13:38.3703832Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant0 [33mSKIPPED[0m
2026-01-14T08:13:38.3704803Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant1 [33mSKIPPED[0m
2026-01-14T08:13:38.3705873Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant2 [33mSKIPPED[0m
2026-01-14T08:13:38.3706993Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant3 [33mSKIPPED[0m
2026-01-14T08:13:38.3707964Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant4 [33mSKIPPED[0m
2026-01-14T08:13:38.3709019Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_affine_quantized_intx_static [32mPASSED[0m
2026-01-14T08:13:38.3709960Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant0 [33mSKIPPED[0m
2026-01-14T08:13:38.3710870Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant1 [33mSKIPPED[0m
2026-01-14T08:13:38.3711766Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant2 [33mSKIPPED[0m
2026-01-14T08:13:38.3712673Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant3 [33mSKIPPED[0m
2026-01-14T08:13:38.3713526Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_weights_only [33mSKIPPED[0m
2026-01-14T08:13:38.3714574Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_alias_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:13:38.3715618Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:13:38.3716724Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_matmul_device0_bfloat16 [32mPASSED[0m
2026-01-14T08:13:38.3717707Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_mm_int4wo_device0_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:38.3718745Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_and_copy_int4wo_device0_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:38.3719810Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_device0_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:38.3720835Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_device0_float16 [33mSKIPPED[0m
2026-01-14T08:13:38.3722051Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_int4wo_device0_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:38.3723261Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:38.3724688Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_float32 [33mSKIPPED[0m
2026-01-14T08:13:38.3726018Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:39.2640823Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_float32 [33mSKIPPED[0m
2026-01-14T08:13:39.2642252Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size0 [33mSKIPPED[0m
2026-01-14T08:13:39.2643707Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size1 [33mSKIPPED[0m
2026-01-14T08:13:39.2645141Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size2 [33mSKIPPED[0m
2026-01-14T08:13:39.2646551Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size3 [33mSKIPPED[0m
2026-01-14T08:13:39.2647976Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size0 [33mSKIPPED[0m
2026-01-14T08:13:39.2649393Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size1 [33mSKIPPED[0m
2026-01-14T08:13:39.2651175Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size2 [33mSKIPPED[0m
2026-01-14T08:13:39.2652671Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size3 [33mSKIPPED[0m
2026-01-14T08:13:39.2654099Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size0 [33mSKIPPED[0m
2026-01-14T08:13:39.2655495Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size1 [33mSKIPPED[0m
2026-01-14T08:13:39.2656912Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size2 [33mSKIPPED[0m
2026-01-14T08:13:39.2658314Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size3 [33mSKIPPED[0m
2026-01-14T08:13:39.2659831Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size0 [33mSKIPPED[0m
2026-01-14T08:13:39.2661252Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size1 [33mSKIPPED[0m
2026-01-14T08:13:39.2662646Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size2 [33mSKIPPED[0m
2026-01-14T08:13:39.2664130Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size3 [33mSKIPPED[0m
2026-01-14T08:13:39.2665491Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_scale_broadcasting [33mSKIPPED[0m
2026-01-14T08:13:39.2666871Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity0 [33mSKIPPED[0m
2026-01-14T08:13:39.2668115Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity1 [33mSKIPPED[0m
2026-01-14T08:13:39.2669617Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:13:39.2671174Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:13:39.2672813Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:13:39.2674389Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:13:39.2675943Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:13:39.2677594Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:13:39.2679161Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:13:39.2680782Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:13:39.2682433Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:13:39.2683986Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:13:39.2685608Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:13:39.2687160Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:13:39.2688795Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:13:39.2690333Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:13:39.2691884Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:13:39.2693610Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:13:39.2694912Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_invalid_granularity [32mPASSED[0m
2026-01-14T08:13:39.2696005Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_mismatched_granularity [32mPASSED[0m
2026-01-14T08:13:39.2697163Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_per_row_with_float32 [33mSKIPPED[0m
2026-01-14T08:13:39.2698290Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_preprocess_scale_3d_reshape [32mPASSED[0m
2026-01-14T08:13:39.2699596Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:13:39.2700479Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:13:39.2700895Z inductor [('extern_calls', 4), ('fxgraph_cache_miss', 2)]
2026-01-14T08:13:39.2701429Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:13:39.2701986Z graph_break []
2026-01-14T08:13:39.2702192Z aten_mm_info []
2026-01-14T08:13:39.2702444Z [32mPASSED[0m
2026-01-14T08:13:39.2703213Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:13:39.2704098Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:13:39.2704645Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:13:39.2705232Z inductor [('extern_calls', 4), ('fxgraph_cache_miss', 2)]
2026-01-14T08:13:39.2705592Z graph_break []
2026-01-14T08:13:39.2705794Z aten_mm_info []
2026-01-14T08:13:39.2706040Z [32mPASSED[0m
2026-01-14T08:13:39.2706785Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:13:39.2707673Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:13:39.2708189Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:13:39.2708751Z inductor [('extern_calls', 4), ('fxgraph_cache_miss', 2)]
2026-01-14T08:13:39.2709099Z graph_break []
2026-01-14T08:13:39.2709316Z aten_mm_info []
2026-01-14T08:13:39.2709659Z [32mPASSED[0m
2026-01-14T08:13:39.2710499Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:13:39.2711373Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:13:39.2711894Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:13:39.2712437Z inductor [('extern_calls', 4), ('fxgraph_cache_miss', 2)]
2026-01-14T08:13:39.2712794Z graph_break []
2026-01-14T08:13:39.2713006Z aten_mm_info []
2026-01-14T08:13:39.2713239Z [32mPASSED[0m
2026-01-14T08:13:39.3961791Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_serialization_mode_static [33mSKIPPED[0m
2026-01-14T08:13:39.3962981Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_unsupported_granularity [32mPASSED[0m
2026-01-14T08:13:39.3964136Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:39.3965508Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float16 [33mSKIPPED[0m
2026-01-14T08:13:39.3966726Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float32 [33mSKIPPED[0m
2026-01-14T08:13:39.3968036Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt4woAffineQuantizedTensorParallel::test_tp_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:39.3969188Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestGemliteLayoutTensorParallel::test_tp_gemlite_float16 [33mSKIPPED[0m
2026-01-14T08:13:39.3970352Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8dqAffineQuantizedTensorParallel::test_tp_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:39.3971181Z test/dtypes/test_bitpacking.py::test_CPU[0-1] [32mPASSED[0m
2026-01-14T08:13:39.3971719Z test/dtypes/test_bitpacking.py::test_CPU[0-2] [32mPASSED[0m
2026-01-14T08:13:39.3972470Z test/dtypes/test_bitpacking.py::test_CPU[0-3] [32mPASSED[0m
2026-01-14T08:13:39.3972985Z test/dtypes/test_bitpacking.py::test_CPU[0-4] [32mPASSED[0m
2026-01-14T08:13:39.3973754Z test/dtypes/test_bitpacking.py::test_CPU[0-5] [32mPASSED[0m
2026-01-14T08:13:39.3974274Z test/dtypes/test_bitpacking.py::test_CPU[0-6] [32mPASSED[0m
2026-01-14T08:13:39.3974870Z test/dtypes/test_bitpacking.py::test_CPU[0-7] [32mPASSED[0m
2026-01-14T08:13:39.3975396Z test/dtypes/test_bitpacking.py::test_CPU[-1-1] [32mPASSED[0m
2026-01-14T08:13:39.3975935Z test/dtypes/test_bitpacking.py::test_CPU[-1-2] [32mPASSED[0m
2026-01-14T08:13:39.3976457Z test/dtypes/test_bitpacking.py::test_CPU[-1-3] [32mPASSED[0m
2026-01-14T08:13:39.3976993Z test/dtypes/test_bitpacking.py::test_CPU[-1-4] [32mPASSED[0m
2026-01-14T08:13:39.3977528Z test/dtypes/test_bitpacking.py::test_CPU[-1-5] [32mPASSED[0m
2026-01-14T08:13:39.3978052Z test/dtypes/test_bitpacking.py::test_CPU[-1-6] [32mPASSED[0m
2026-01-14T08:13:39.3978595Z test/dtypes/test_bitpacking.py::test_CPU[-1-7] [32mPASSED[0m
2026-01-14T08:13:39.3979113Z test/dtypes/test_bitpacking.py::test_CPU[1-1] [32mPASSED[0m
2026-01-14T08:13:39.3979715Z test/dtypes/test_bitpacking.py::test_CPU[1-2] [32mPASSED[0m
2026-01-14T08:13:39.3980234Z test/dtypes/test_bitpacking.py::test_CPU[1-3] [32mPASSED[0m
2026-01-14T08:13:39.3980759Z test/dtypes/test_bitpacking.py::test_CPU[1-4] [32mPASSED[0m
2026-01-14T08:13:39.3981281Z test/dtypes/test_bitpacking.py::test_CPU[1-5] [32mPASSED[0m
2026-01-14T08:13:39.3981791Z test/dtypes/test_bitpacking.py::test_CPU[1-6] [32mPASSED[0m
2026-01-14T08:13:39.3982313Z test/dtypes/test_bitpacking.py::test_CPU[1-7] [32mPASSED[0m
2026-01-14T08:13:39.3982924Z test/dtypes/test_bitpacking.py::test_GPU[0-1] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3983627Z test/dtypes/test_bitpacking.py::test_GPU[0-2] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3984377Z test/dtypes/test_bitpacking.py::test_GPU[0-3] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3985211Z test/dtypes/test_bitpacking.py::test_GPU[0-4] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3985913Z test/dtypes/test_bitpacking.py::test_GPU[0-5] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3986595Z test/dtypes/test_bitpacking.py::test_GPU[0-6] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3987284Z test/dtypes/test_bitpacking.py::test_GPU[0-7] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3987962Z test/dtypes/test_bitpacking.py::test_GPU[-1-1] [33mSKIPPED[0m (GPU not avai...)
2026-01-14T08:13:39.3988650Z test/dtypes/test_bitpacking.py::test_GPU[-1-2] [33mSKIPPED[0m (GPU not avai...)
2026-01-14T08:13:39.3989343Z test/dtypes/test_bitpacking.py::test_GPU[-1-3] [33mSKIPPED[0m (GPU not avai...)
2026-01-14T08:13:39.3990022Z test/dtypes/test_bitpacking.py::test_GPU[-1-4] [33mSKIPPED[0m (GPU not avai...)
2026-01-14T08:13:39.3990705Z test/dtypes/test_bitpacking.py::test_GPU[-1-5] [33mSKIPPED[0m (GPU not avai...)
2026-01-14T08:13:39.3991382Z test/dtypes/test_bitpacking.py::test_GPU[-1-6] [33mSKIPPED[0m (GPU not avai...)
2026-01-14T08:13:39.3992065Z test/dtypes/test_bitpacking.py::test_GPU[-1-7] [33mSKIPPED[0m (GPU not avai...)
2026-01-14T08:13:39.3992742Z test/dtypes/test_bitpacking.py::test_GPU[1-1] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3993429Z test/dtypes/test_bitpacking.py::test_GPU[1-2] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3994249Z test/dtypes/test_bitpacking.py::test_GPU[1-3] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3995158Z test/dtypes/test_bitpacking.py::test_GPU[1-4] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3996076Z test/dtypes/test_bitpacking.py::test_GPU[1-5] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3996989Z test/dtypes/test_bitpacking.py::test_GPU[1-6] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3997902Z test/dtypes/test_bitpacking.py::test_GPU[1-7] [33mSKIPPED[0m (GPU not avail...)
2026-01-14T08:13:39.3998830Z test/dtypes/test_bitpacking.py::test_compile[0-1] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.3999745Z test/dtypes/test_bitpacking.py::test_compile[0-2] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4000751Z test/dtypes/test_bitpacking.py::test_compile[0-3] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4001669Z test/dtypes/test_bitpacking.py::test_compile[0-4] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4002599Z test/dtypes/test_bitpacking.py::test_compile[0-5] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4003504Z test/dtypes/test_bitpacking.py::test_compile[0-6] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4004432Z test/dtypes/test_bitpacking.py::test_compile[0-7] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4005361Z test/dtypes/test_bitpacking.py::test_compile[-1-1] [33mSKIPPED[0m (unsuppor...)
2026-01-14T08:13:39.4006271Z test/dtypes/test_bitpacking.py::test_compile[-1-2] [33mSKIPPED[0m (unsuppor...)
2026-01-14T08:13:39.4007198Z test/dtypes/test_bitpacking.py::test_compile[-1-3] [33mSKIPPED[0m (unsuppor...)
2026-01-14T08:13:39.4008098Z test/dtypes/test_bitpacking.py::test_compile[-1-4] [33mSKIPPED[0m (unsuppor...)
2026-01-14T08:13:39.4009016Z test/dtypes/test_bitpacking.py::test_compile[-1-5] [33mSKIPPED[0m (unsuppor...)
2026-01-14T08:13:39.4009928Z test/dtypes/test_bitpacking.py::test_compile[-1-6] [33mSKIPPED[0m (unsuppor...)
2026-01-14T08:13:39.4010831Z test/dtypes/test_bitpacking.py::test_compile[-1-7] [33mSKIPPED[0m (unsuppor...)
2026-01-14T08:13:39.4011753Z test/dtypes/test_bitpacking.py::test_compile[1-1] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4012737Z test/dtypes/test_bitpacking.py::test_compile[1-2] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4013657Z test/dtypes/test_bitpacking.py::test_compile[1-3] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4014561Z test/dtypes/test_bitpacking.py::test_compile[1-4] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4015483Z test/dtypes/test_bitpacking.py::test_compile[1-5] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4016476Z test/dtypes/test_bitpacking.py::test_compile[1-6] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4017393Z test/dtypes/test_bitpacking.py::test_compile[1-7] [33mSKIPPED[0m (unsupport...)
2026-01-14T08:13:39.4018316Z test/dtypes/test_bitpacking.py::test_pack_example [33mSKIPPED[0m (GPU not a...)
2026-01-14T08:13:39.4019395Z test/dtypes/test_bitpacking.py::test_pack_example_CPU tensor([  0, 105, 151,  37], dtype=torch.uint8) tensor([ 39, 146], dtype=torch.uint8)
2026-01-14T08:13:39.4020303Z [32mPASSED[0m
2026-01-14T08:13:39.4020975Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:13:39.4021990Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:13:39.4022999Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:13:39.4024169Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_16 [33mSKIPPED[0m
2026-01-14T08:13:39.4025489Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_32 [33mSKIPPED[0m
2026-01-14T08:13:39.4026806Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_8 [33mSKIPPED[0m
2026-01-14T08:13:39.4028100Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_16 [33mSKIPPED[0m
2026-01-14T08:13:39.4029408Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_32 [33mSKIPPED[0m
2026-01-14T08:13:39.4030691Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_8 [33mSKIPPED[0m
2026-01-14T08:13:39.4031991Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_16 [33mSKIPPED[0m
2026-01-14T08:13:39.4033295Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_32 [33mSKIPPED[0m
2026-01-14T08:13:39.4034582Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_8 [33mSKIPPED[0m
2026-01-14T08:13:39.4035960Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_16 [33mSKIPPED[0m
2026-01-14T08:13:39.4037251Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_32 [33mSKIPPED[0m
2026-01-14T08:13:39.4038538Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_8 [33mSKIPPED[0m
2026-01-14T08:13:39.4039826Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_16 [33mSKIPPED[0m
2026-01-14T08:13:39.4041106Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_32 [33mSKIPPED[0m
2026-01-14T08:13:39.4042405Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_8 [33mSKIPPED[0m
2026-01-14T08:13:39.4043694Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_16 [33mSKIPPED[0m
2026-01-14T08:13:45.5369081Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_32 [33mSKIPPED[0m
2026-01-14T08:13:45.5371043Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_8 [33mSKIPPED[0m
2026-01-14T08:13:45.5372768Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size0 [33mSKIPPED[0m
2026-01-14T08:13:45.5374104Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size1 [33mSKIPPED[0m
2026-01-14T08:13:45.5375496Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:13:45.5376961Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float16 [32mPASSED[0m
2026-01-14T08:13:45.5378408Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float32 [32mPASSED[0m
2026-01-14T08:13:45.5380173Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:13:45.5381655Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float16 [32mPASSED[0m
2026-01-14T08:13:45.5383094Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float32 [32mPASSED[0m
2026-01-14T08:13:45.5384525Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:45.5385975Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float16 [33mSKIPPED[0m
2026-01-14T08:13:45.5387424Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float32 [33mSKIPPED[0m
2026-01-14T08:13:45.5388832Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:45.5390146Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float16 [33mSKIPPED[0m
2026-01-14T08:13:45.5391469Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float32 [33mSKIPPED[0m
2026-01-14T08:13:45.5392836Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:13:45.5394242Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:13:45.5395603Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:13:45.5396985Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_False [33mSKIPPED[0m
2026-01-14T08:13:45.5398379Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_True [33mSKIPPED[0m
2026-01-14T08:13:45.5399868Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:45.5401438Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float16 [33mSKIPPED[0m
2026-01-14T08:13:45.5402968Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float32 [33mSKIPPED[0m
2026-01-14T08:13:45.5404473Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_bfloat16 [32mPASSED[0m
2026-01-14T08:13:45.5406119Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float16 [32mPASSED[0m
2026-01-14T08:13:45.5407579Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float32 [32mPASSED[0m
2026-01-14T08:13:45.5408952Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:45.5410389Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_bfloat16 [33mSKIPPED[0m
2026-01-14T08:13:45.5411895Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float16 [33mSKIPPED[0m
2026-01-14T08:13:45.5413496Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float32 [33mSKIPPED[0m
2026-01-14T08:13:45.5414936Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float16 [33mSKIPPED[0m
2026-01-14T08:13:45.5416296Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float32 [33mSKIPPED[0m
2026-01-14T08:13:45.5417969Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16 [32mPASSED[0m
2026-01-14T08:13:45.5419262Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_device [33mSKIPPED[0m
2026-01-14T08:13:45.5420212Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16 [32mPASSED[0m
2026-01-14T08:13:45.5421171Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32 [32mPASSED[0m
2026-01-14T08:13:45.5422172Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_bfloat16 [32mPASSED[0m
2026-01-14T08:13:45.5423145Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float16 [32mPASSED[0m
2026-01-14T08:13:45.5424254Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float32 [32mPASSED[0m
2026-01-14T08:13:45.5425529Z test/dtypes/test_nf4.py::TestFSDPOps::test_pin_memory [33mSKIPPED[0m (Need ...)
2026-01-14T08:13:45.5426859Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_2d_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:13:45.5428495Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:13:45.5429996Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:13:45.5431489Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size1 [32mPASSED[0m
2026-01-14T08:13:45.5432964Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size2 [32mPASSED[0m
2026-01-14T08:13:45.5434507Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:13:45.5435968Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size1 [33mSKIPPED[0m
2026-01-14T08:13:45.5437349Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size2 [33mSKIPPED[0m
2026-01-14T08:13:45.5438786Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size_262144 [33mSKIPPED[0m
2026-01-14T08:13:45.5440279Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:13:45.5441802Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size2 [32mPASSED[0m
2026-01-14T08:13:45.5443326Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size_262144 [32mPASSED[0m
2026-01-14T08:13:45.5444849Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size1 [32mPASSED[0m
2026-01-14T08:13:45.5446327Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size2 [32mPASSED[0m
2026-01-14T08:13:45.5447845Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:13:45.5449254Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_1d_invalid [32mPASSED[0m
2026-01-14T08:13:45.5450728Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_2d_invalid [32mPASSED[0m
2026-01-14T08:13:45.5452173Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size1 [32mPASSED[0m
2026-01-14T08:13:45.5453596Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size2 [32mPASSED[0m
2026-01-14T08:13:45.5455228Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:13:45.5456700Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:13:45.5458066Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:13:45.5459449Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size1 [32mPASSED[0m
2026-01-14T08:13:45.5460784Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cpu [33mSKIPPED[0m (Need GPU ...)
2026-01-14T08:13:45.5462040Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cuda [33mSKIPPED[0m (Need GPU...)
2026-01-14T08:13:45.5463305Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_module [33mSKIPPED[0m (Need G...)
2026-01-14T08:13:45.5464673Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_3d_input_size0 [32mPASSED[0m
2026-01-14T08:13:45.5466183Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size1 [32mPASSED[0m
2026-01-14T08:13:45.5467714Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size2 [32mPASSED[0m
2026-01-14T08:13:45.5469288Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size_261632 [32mPASSED[0m
2026-01-14T08:13:45.5470805Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size1 [32mPASSED[0m
2026-01-14T08:13:45.5472172Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size2 [32mPASSED[0m
2026-01-14T08:13:45.5473608Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:13:45.5475473Z test/dtypes/test_nf4.py::TestQLoRA::test_qlora_fsdp2 WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work
2026-01-14T08:13:45.5477682Z WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work
2026-01-14T08:13:45.5478766Z dist init r=0, world=2
2026-01-14T08:13:45.5479175Z dist init r=1, world=2
2026-01-14T08:13:45.5479744Z [33mSKIPPED[0m (Need a...)
2026-01-14T08:13:45.5480646Z test/dtypes/test_nf4.py::TestComm::test_comm [33mSKIPPED[0m (Need GPU avail...)
2026-01-14T08:13:45.5482027Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5483546Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5485016Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5486520Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5487999Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5489504Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5491012Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5492590Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5494085Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5495564Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5864574Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5866156Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5867663Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5869153Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5870924Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5872456Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5873970Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5875450Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5876959Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5878471Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5879955Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5881487Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5882964Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5884588Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5886066Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5887506Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5889005Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5890448Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5892031Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5893733Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5895194Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5896687Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5898145Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5899619Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5901081Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5902575Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5904058Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5905523Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5907014Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5908513Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5909992Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5911476Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5912950Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-32-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5914499Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-32-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5916000Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-32-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5917460Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-32-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5918942Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-32-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5920591Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-32-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5922075Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-32-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5923605Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-64-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5925065Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-64-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5926549Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-64-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5928045Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-64-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5929514Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-64-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5931011Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-64-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5932600Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-64-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5934096Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-128-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5935605Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-128-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5937091Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-128-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5938579Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-128-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5940057Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-128-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5941542Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-128-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5943224Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[None-128-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5944635Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5946015Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5947368Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5948757Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5950296Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5951675Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5953013Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5954373Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5955764Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5957134Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5958508Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5959871Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5961217Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5962581Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5963939Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5965318Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5966700Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5968085Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5969664Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5971048Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5972545Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5973916Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-32-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5975303Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-32-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5976692Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-32-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5978055Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-32-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5979443Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-32-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5980829Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-32-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5982200Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-32-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:45.5983589Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-64-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:45.5984948Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-64-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:45.5986304Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-64-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:45.5987688Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-64-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:45.5989036Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-64-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:45.5990419Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-64-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:45.5992014Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-64-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:46.7093439Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-128-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:46.7094965Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-128-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:46.7096381Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-128-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:46.7097808Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-128-dtype3] [33mSKIPPED[0m
2026-01-14T08:13:46.7099204Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-128-dtype4] [33mSKIPPED[0m
2026-01-14T08:13:46.7100586Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-128-dtype5] [33mSKIPPED[0m
2026-01-14T08:13:46.7101991Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[None-128-dtype6] [33mSKIPPED[0m
2026-01-14T08:13:46.7103501Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype0] [33mSKIPPED[0m (...)
2026-01-14T08:13:46.7104799Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype1] [33mSKIPPED[0m (...)
2026-01-14T08:13:46.7106069Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype2] [33mSKIPPED[0m (...)
2026-01-14T08:13:46.7107394Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype3] [33mSKIPPED[0m (...)
2026-01-14T08:13:46.7108706Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype4] [33mSKIPPED[0m (...)
2026-01-14T08:13:46.7109992Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype5] [33mSKIPPED[0m (...)
2026-01-14T08:13:46.7111249Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype6] [33mSKIPPED[0m (...)
2026-01-14T08:13:46.7112551Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype0] [33mSKIPPED[0m
2026-01-14T08:13:46.7113882Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype1] [33mSKIPPED[0m
2026-01-14T08:13:46.7115157Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype2] [33mSKIPPED[0m
2026-01-14T08:13:46.7116496Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype3] [33mSKIPPED[0m
2026-01-14T08:13:46.7118097Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype4] [33mSKIPPED[0m
2026-01-14T08:13:46.7119471Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype5] [33mSKIPPED[0m
2026-01-14T08:13:46.7120791Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype6] [33mSKIPPED[0m
2026-01-14T08:13:46.7122152Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype0] [33mSKIPPED[0m (Ne...)
2026-01-14T08:13:46.7123473Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype1] [33mSKIPPED[0m (Ne...)
2026-01-14T08:13:46.7124723Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype2] [33mSKIPPED[0m (Ne...)
2026-01-14T08:13:46.7126001Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype3] [33mSKIPPED[0m (Ne...)
2026-01-14T08:13:46.7127266Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype4] [33mSKIPPED[0m (Ne...)
2026-01-14T08:13:46.7128555Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype5] [33mSKIPPED[0m (Ne...)
2026-01-14T08:13:46.7129815Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype6] [33mSKIPPED[0m (Ne...)
2026-01-14T08:13:46.7131021Z test/dtypes/test_uintx.py::test_uintx_api_deprecation [32mPASSED[0m
2026-01-14T08:13:46.7132784Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims0-valid.layer-filter_fqns0-True] [32mPASSED[0m
2026-01-14T08:13:46.7134961Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims1-skip_layer.linear-filter_fqns1-False] [32mPASSED[0m
2026-01-14T08:13:46.7137282Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims2-valid.layer-filter_fqns2-False] [32mPASSED[0m
2026-01-14T08:13:46.7139438Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims3-valid.layer-filter_fqns3-True] [32mPASSED[0m
2026-01-14T08:13:46.7141585Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims4-skip_layer.linear-filter_fqns4-False] [32mPASSED[0m
2026-01-14T08:13:46.7143992Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims5-valid.layer-filter_fqns5-False] [32mPASSED[0m
2026-01-14T08:13:46.7145734Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_rowwise [32mPASSED[0m
2026-01-14T08:13:46.7147127Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_tensorwise [32mPASSED[0m
2026-01-14T08:13:46.7148441Z test/float8/test_auto_filter.py::test_partial_fqn_matching [32mPASSED[0m
2026-01-14T08:13:46.7150103Z test/float8/test_base.py::TestFloat8TrainingTensor::test_preserves_dtype [32mPASSED[0m
2026-01-14T08:13:46.7151698Z test/float8/test_base.py::TestFloat8TrainingTensor::test_differentiable_casts [32mPASSED[0m
2026-01-14T08:13:46.7153176Z test/float8/test_base.py::TestFloat8TrainingTensor::test_split_cat [32mPASSED[0m
2026-01-14T08:13:46.7154506Z test/float8/test_base.py::TestFloat8TrainingTensor::test_index_put [32mPASSED[0m
2026-01-14T08:13:46.7155815Z test/float8/test_base.py::TestFloat8TrainingTensor::test_copy_ [32mPASSED[0m
2026-01-14T08:13:46.7157117Z test/float8/test_base.py::TestFloat8TrainingTensor::test_transpose [32mPASSED[0m
2026-01-14T08:13:46.7158680Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape0] [32mPASSED[0m
2026-01-14T08:13:46.7160503Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape1] [32mPASSED[0m
2026-01-14T08:13:46.7162298Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape2] [32mPASSED[0m
2026-01-14T08:13:46.7164095Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape0] [32mPASSED[0m
2026-01-14T08:13:46.7165984Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape1] [32mPASSED[0m
2026-01-14T08:13:46.7167868Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape2] [32mPASSED[0m
2026-01-14T08:13:46.7169697Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape0] [32mPASSED[0m
2026-01-14T08:13:46.7171737Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape1] [32mPASSED[0m
2026-01-14T08:13:46.7173715Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape2] [32mPASSED[0m
2026-01-14T08:13:46.7175548Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape0] [32mPASSED[0m
2026-01-14T08:13:46.7177350Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape1] [32mPASSED[0m
2026-01-14T08:13:46.7179185Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape2] [32mPASSED[0m
2026-01-14T08:13:46.7180897Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_reshape [32mPASSED[0m
2026-01-14T08:13:46.7183201Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:13:46.7185979Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:13:46.7188753Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:13:46.7191560Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:13:46.7194371Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:13:46.7197278Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:13:46.7200377Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:13:46.7203208Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:13:46.7206027Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:13:46.7208084Z test/float8/test_base.py::TestFloat8TrainingTensor::test_fp8_dtype [33mSKIPPED[0m
2026-01-14T08:13:46.7210588Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7214327Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7217831Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7221350Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7224820Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7228454Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7577093Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7580683Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7584155Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7587696Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7591198Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7594706Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7598158Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7601728Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7605197Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7608894Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7612540Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7616136Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7619543Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7622977Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7626491Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7629936Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7633388Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7636886Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.7639859Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7642568Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7645143Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7647767Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7650555Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7653227Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7655824Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7658423Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7661056Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7663670Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7666261Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7668834Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7671707Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7674320Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7676890Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7679435Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7682068Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7684668Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7687221Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7689825Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7692496Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7695171Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7697810Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7700388Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7703172Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7705745Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7708364Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7710958Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7713529Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.7716079Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.7718720Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.8247307Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.8250161Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.8252837Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.8255419Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.8258224Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.8260739Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8263115Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8265439Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8267726Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8269972Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8272308Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8274703Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype0-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8277131Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype1-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8279585Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype2-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8281339Z test/float8/test_base.py::TestFloat8Linear::test_repr [32mPASSED[0m
2026-01-14T08:13:46.8282538Z test/float8/test_base.py::TestFloat8Linear::test_inference_mode [33mSKIPPED[0m
2026-01-14T08:13:46.8283834Z test/float8/test_base.py::TestFloat8Linear::test_quantize [33mSKIPPED[0m (C...)
2026-01-14T08:13:46.8285279Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:13:46.8287058Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:13:46.8288678Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:13:46.8290279Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:13:46.8292007Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:13:46.8293618Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:13:46.8295079Z test/float8/test_base.py::TestScaledMM::test_different_configs_error [33mSKIPPED[0m
2026-01-14T08:13:46.8296480Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:13:46.8297983Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:13:46.8299457Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:13:46.8300910Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:13:46.8302416Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:13:46.8303896Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:13:46.8305379Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype0] [33mSKIPPED[0m
2026-01-14T08:13:46.8306874Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype1] [33mSKIPPED[0m
2026-01-14T08:13:46.8308377Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype2] [33mSKIPPED[0m
2026-01-14T08:13:46.8310004Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype3] [33mSKIPPED[0m
2026-01-14T08:13:46.8311488Z test/float8/test_base.py::TestFloat8LinearUtils::test_fp8_tensor_statistics [32mPASSED[0m
2026-01-14T08:13:46.8313005Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_linears_with_filters [32mPASSED[0m
2026-01-14T08:13:46.8314469Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear [32mPASSED[0m
2026-01-14T08:13:46.8316052Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear_with_children_raises [32mPASSED[0m
2026-01-14T08:13:46.8317646Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears [32mPASSED[0m
2026-01-14T08:13:46.8319231Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears_with_skip [32mPASSED[0m
2026-01-14T08:13:46.8321363Z test/float8/test_compile.py::test_eager_only[dtype0-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8323975Z test/float8/test_compile.py::test_eager_only[dtype1-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8326507Z test/float8/test_compile.py::test_aot_eager[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8329047Z test/float8/test_compile.py::test_aot_eager[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8331748Z test/float8/test_compile.py::test_inductor_from_config_params[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8334848Z test/float8/test_compile.py::test_inductor_from_config_params[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:13:46.8337103Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:46.8338904Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:46.8340653Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_input [33mSKIPPED[0m
2026-01-14T08:13:46.8342071Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_output [33mSKIPPED[0m
2026-01-14T08:13:46.8343620Z test/float8/test_compile.py::TestGraphBreaks::test_float8_with_graph_break_in_the_middle [33mSKIPPED[0m
2026-01-14T08:13:46.8345183Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:46.8346660Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:46.8348120Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:46.8349780Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype0] [33mSKIPPED[0m
2026-01-14T08:13:46.8351273Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype1] [33mSKIPPED[0m
2026-01-14T08:13:46.8352776Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype2] [33mSKIPPED[0m
2026-01-14T08:13:46.8354342Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case0] [33mSKIPPED[0m
2026-01-14T08:13:46.8356108Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case1] [33mSKIPPED[0m
2026-01-14T08:13:46.8357860Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case2] [33mSKIPPED[0m
2026-01-14T08:13:46.8359602Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case3] [33mSKIPPED[0m
2026-01-14T08:13:46.8361522Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case4] [33mSKIPPED[0m
2026-01-14T08:13:46.8363282Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case5] [33mSKIPPED[0m
2026-01-14T08:13:46.8365378Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case6] [33mSKIPPED[0m
2026-01-14T08:13:46.8367207Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case7] [33mSKIPPED[0m
2026-01-14T08:13:46.8368770Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype0] [32mPASSED[0m
2026-01-14T08:13:46.8369998Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype1] [32mPASSED[0m
2026-01-14T08:13:46.8371199Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype2] [32mPASSED[0m
2026-01-14T08:13:46.8372784Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype3] [32mPASSED[0m
2026-01-14T08:13:46.8374258Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype4] [32mPASSED[0m
2026-01-14T08:13:46.8375814Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype5] [32mPASSED[0m
2026-01-14T08:13:46.8377383Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype6] [32mPASSED[0m
2026-01-14T08:13:46.8379017Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype7] [32mPASSED[0m
2026-01-14T08:13:51.4927474Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_config_params[ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC] [33mSKIPPED[0m
2026-01-14T08:13:51.4929737Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:13:51.4931789Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:13:51.4933356Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_2bit [33mSKIPPED[0m (N...)
2026-01-14T08:13:51.4934295Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_3bit [33mSKIPPED[0m (N...)
2026-01-14T08:13:51.4935054Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_4bit [33mSKIPPED[0m (N...)
2026-01-14T08:13:51.4936743Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_5bit [33mSKIPPED[0m (N...)
2026-01-14T08:13:51.4937455Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_6bit [33mSKIPPED[0m (N...)
2026-01-14T08:13:51.4938115Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_7bit [33mSKIPPED[0m (N...)
2026-01-14T08:13:51.4938788Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_8bit [33mSKIPPED[0m (N...)
2026-01-14T08:13:51.4939549Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm [33mSKIPPED[0m
2026-01-14T08:13:51.4940560Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm_eager_and_torch_compile_numerics [33mSKIPPED[0m
2026-01-14T08:13:51.4941701Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cpu [32mPASSED[0m
2026-01-14T08:13:51.4942836Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cuda [33mSKIPPED[0m
2026-01-14T08:13:51.4943894Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cpu [32mPASSED[0m
2026-01-14T08:13:51.4944861Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cuda [33mSKIPPED[0m
2026-01-14T08:13:51.4945846Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cpu [32mPASSED[0m
2026-01-14T08:13:51.4946842Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cuda [33mSKIPPED[0m
2026-01-14T08:13:51.4947898Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4949023Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4950490Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4951606Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:13:51.4952691Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:13:51.4953764Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:13:51.4954882Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4956024Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4957186Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4958332Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:13:51.4959439Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:13:51.4960551Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:13:51.4961682Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4963385Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4964972Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4966515Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:13:51.4968197Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:13:51.4969754Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:13:51.4971037Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4972425Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4973713Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4974984Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:13:51.4976251Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:13:51.4978354Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:13:51.4980038Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4981601Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4983197Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4984730Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_3 [33mSKIPPED[0m
2026-01-14T08:13:51.4986235Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_4 [33mSKIPPED[0m
2026-01-14T08:13:51.4987742Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_5 [33mSKIPPED[0m
2026-01-14T08:13:51.4989453Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4991011Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4992405Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4993729Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_3 [33mSKIPPED[0m
2026-01-14T08:13:51.4995050Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_4 [33mSKIPPED[0m
2026-01-14T08:13:51.4996363Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_5 [33mSKIPPED[0m
2026-01-14T08:13:51.4997670Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.4999003Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.5000328Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.5001636Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:13:51.5002921Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:13:51.5004195Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:13:51.5005470Z test/integration/test_integration.py::TestSubclass::test_autoquantizable_flatten_unflatten [32mPASSED[0m
2026-01-14T08:13:51.5006631Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_0_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.5007741Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_1_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.5008909Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_2_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.5009977Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_3 [33mSKIPPED[0m
2026-01-14T08:13:51.5011036Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_4 [33mSKIPPED[0m
2026-01-14T08:13:51.5012151Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_5 [33mSKIPPED[0m
2026-01-14T08:13:51.5013402Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.5014808Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:13:51.5016187Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:13:51.5017566Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:14:27.2911614Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:14:27.2912685Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_5 [33mSKIPPED[0m
2026-01-14T08:14:27.2913709Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2914705Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2915703Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:14:27.2916675Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:14:27.2917886Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:14:27.2918868Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_5 [33mSKIPPED[0m
2026-01-14T08:14:27.2919896Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2920986Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2922055Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_2_cpu [32mPASSED[0m
2026-01-14T08:14:27.2923730Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_3 [33mSKIPPED[0m
2026-01-14T08:14:27.2925345Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_4 [33mSKIPPED[0m
2026-01-14T08:14:27.2926979Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_5 [33mSKIPPED[0m
2026-01-14T08:14:27.2928550Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_00_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2930076Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_01_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2931578Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_02_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2933162Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_03_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2934630Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_04_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2935950Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_05_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2937260Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_06 [33mSKIPPED[0m
2026-01-14T08:14:27.2938650Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_07 [33mSKIPPED[0m
2026-01-14T08:14:27.2939934Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_08 [33mSKIPPED[0m
2026-01-14T08:14:27.2941183Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_09 [33mSKIPPED[0m
2026-01-14T08:14:27.2942441Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_10 [33mSKIPPED[0m
2026-01-14T08:14:27.2943702Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_11 [33mSKIPPED[0m
2026-01-14T08:14:27.2944984Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_0_cpu [32mPASSED[0m
2026-01-14T08:14:27.2946329Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_1_cpu [32mPASSED[0m
2026-01-14T08:14:27.2947650Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:14:27.2948963Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:14:27.2950436Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:14:27.2951719Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_5 [33mSKIPPED[0m
2026-01-14T08:14:27.2953057Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_0_cpu AUTOTUNE packed_linear(32x64, 1982689x1, 32x64)
2026-01-14T08:14:27.2954053Z   cpp_CppMicroGemmFP32Vec_0 0.0043 ms 100.0% 
2026-01-14T08:14:27.2954481Z   _mkl_linear 0.0184 ms 23.2% 
2026-01-14T08:14:27.2955291Z SingleProcess AUTOTUNE benchmarking takes 0.2485 seconds and 2.4513 seconds precompiling for 2 choices
2026-01-14T08:14:27.2956061Z AUTOTUNE packed_linear(32x32, 1982689x1, 32x32)
2026-01-14T08:14:27.2956531Z   cpp_CppMicroGemmFP32Vec_1 0.0040 ms 100.0% 
2026-01-14T08:14:27.2956979Z   _mkl_linear 0.0178 ms 22.2% 
2026-01-14T08:14:27.2957653Z SingleProcess AUTOTUNE benchmarking takes 0.2475 seconds and 2.4262 seconds precompiling for 2 choices
2026-01-14T08:14:27.2958426Z [32mPASSED[0m
2026-01-14T08:14:27.2959152Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_1_cpu AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:14:27.2960038Z   cpp_CppMicroGemmFP32Vec_2 0.0039 ms 100.0% 
2026-01-14T08:14:27.2960438Z   mm 0.0279 ms 14.0% 
2026-01-14T08:14:27.2961075Z SingleProcess AUTOTUNE benchmarking takes 0.2474 seconds and 2.5467 seconds precompiling for 2 choices
2026-01-14T08:14:27.2961803Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:14:27.2962173Z   cpp_CppMicroGemmFP32Vec_3 0.0035 ms 100.0% 
2026-01-14T08:14:27.2962576Z   mm 0.0250 ms 14.0% 
2026-01-14T08:14:27.2963212Z SingleProcess AUTOTUNE benchmarking takes 0.2477 seconds and 2.5317 seconds precompiling for 2 choices
2026-01-14T08:14:27.2963980Z [32mPASSED[0m
2026-01-14T08:14:27.2964822Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_2_cpu AUTOTUNE _weight_int8pack_mm(32x64, 32x64, 32)
2026-01-14T08:14:27.2965820Z   cpp_CppMicroGemmFP32Vec_4 0.0037 ms 100.0% 
2026-01-14T08:14:27.2966244Z   _weight_int8pack_mm 0.0166 ms 22.2% 
2026-01-14T08:14:27.2966957Z SingleProcess AUTOTUNE benchmarking takes 0.2488 seconds and 2.5407 seconds precompiling for 2 choices
2026-01-14T08:14:27.2967722Z AUTOTUNE _weight_int8pack_mm(32x32, 32x32, 32)
2026-01-14T08:14:27.2968188Z   cpp_CppMicroGemmFP32Vec_5 0.0035 ms 100.0% 
2026-01-14T08:14:27.2968618Z   _weight_int8pack_mm 0.0166 ms 21.3% 
2026-01-14T08:14:27.2969320Z SingleProcess AUTOTUNE benchmarking takes 0.2483 seconds and 2.5445 seconds precompiling for 2 choices
2026-01-14T08:14:27.2970091Z [32mPASSED[0m
2026-01-14T08:14:27.2970885Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_3 [33mSKIPPED[0m
2026-01-14T08:14:27.2972379Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_4 [33mSKIPPED[0m
2026-01-14T08:14:27.2973520Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_5 [33mSKIPPED[0m
2026-01-14T08:14:27.2985001Z test/integration/test_integration.py::TestDynamicQuant::test_dynamic_quant [32mPASSED[0m
2026-01-14T08:14:27.2985992Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_embedding_quant [32mPASSED[0m
2026-01-14T08:14:27.2987055Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_quant [32mPASSED[0m
2026-01-14T08:14:27.2988017Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant [32mPASSED[0m
2026-01-14T08:14:27.2989040Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2990161Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2991251Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2992337Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_3 [33mSKIPPED[0m
2026-01-14T08:14:27.2993402Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_4 [33mSKIPPED[0m
2026-01-14T08:14:27.2994450Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_5 [33mSKIPPED[0m
2026-01-14T08:14:27.2995528Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2996769Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2997848Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.2998919Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_3 [33mSKIPPED[0m
2026-01-14T08:14:27.2999949Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_4 [33mSKIPPED[0m
2026-01-14T08:14:27.3000993Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_5 [33mSKIPPED[0m
2026-01-14T08:14:27.3001975Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.3002880Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.3003800Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_2_cpu [33mSKIPPED[0m
2026-01-14T08:14:27.3004694Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_3 [33mSKIPPED[0m
2026-01-14T08:14:27.3005575Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_4 [33mSKIPPED[0m
2026-01-14T08:14:27.3006453Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_5 [33mSKIPPED[0m
2026-01-14T08:14:35.6901225Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6902244Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6903206Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_2_cpu [32mPASSED[0m
2026-01-14T08:14:35.6904172Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_3 [33mSKIPPED[0m
2026-01-14T08:14:35.6905121Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_4 [33mSKIPPED[0m
2026-01-14T08:14:35.6906273Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_5 [33mSKIPPED[0m
2026-01-14T08:14:35.6907213Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_0_cpu [32mPASSED[0m
2026-01-14T08:14:35.6908145Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_1_cpu [32mPASSED[0m
2026-01-14T08:14:35.6909086Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_2_cpu [32mPASSED[0m
2026-01-14T08:14:35.6910007Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_3 [33mSKIPPED[0m
2026-01-14T08:14:35.6910928Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_4 [33mSKIPPED[0m
2026-01-14T08:14:35.6911859Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_5 [33mSKIPPED[0m
2026-01-14T08:14:35.6912683Z test/integration/test_integration.py::UtilsUnitTest::test_shape_logger [32mPASSED[0m
2026-01-14T08:14:35.6913512Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_00_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6914376Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_01_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6915249Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_02_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6916123Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_03_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6916986Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_04_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6917857Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_05_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6918827Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_06_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6919696Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_07_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6920568Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_08_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6921409Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_09 [33mSKIPPED[0m
2026-01-14T08:14:35.6922248Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_10 [33mSKIPPED[0m
2026-01-14T08:14:35.6923073Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_11 [33mSKIPPED[0m
2026-01-14T08:14:35.6923907Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_12 [33mSKIPPED[0m
2026-01-14T08:14:35.6924737Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_13 [33mSKIPPED[0m
2026-01-14T08:14:35.6925562Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_14 [33mSKIPPED[0m
2026-01-14T08:14:35.6926396Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_15 [33mSKIPPED[0m
2026-01-14T08:14:35.6927218Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_16 [33mSKIPPED[0m
2026-01-14T08:14:35.6928052Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_17 [33mSKIPPED[0m
2026-01-14T08:14:35.6928930Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6929835Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6930752Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_2_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6931637Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_3 [33mSKIPPED[0m
2026-01-14T08:14:35.6932634Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_4 [33mSKIPPED[0m
2026-01-14T08:14:35.6933505Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_5 [33mSKIPPED[0m
2026-01-14T08:14:35.6934445Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6935301Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6936137Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_2_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6936973Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_3 [33mSKIPPED[0m
2026-01-14T08:14:35.6937781Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_4 [33mSKIPPED[0m
2026-01-14T08:14:35.6938594Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_5 [33mSKIPPED[0m
2026-01-14T08:14:35.6939414Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_hp_float [33mSKIPPED[0m
2026-01-14T08:14:35.6940236Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6941094Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6941933Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_2_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6942763Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_3 [33mSKIPPED[0m
2026-01-14T08:14:35.6943579Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_4 [33mSKIPPED[0m
2026-01-14T08:14:35.6944377Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_5 [33mSKIPPED[0m
2026-01-14T08:14:35.6945211Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_00_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6946062Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_01_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6946987Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_02_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6947849Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_03_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6948699Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_04_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6949758Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_05_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6950616Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_06_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6951477Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_07_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6952335Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_08_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6953168Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_09 [33mSKIPPED[0m
2026-01-14T08:14:35.6953994Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_10 [33mSKIPPED[0m
2026-01-14T08:14:35.6954807Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_11 [33mSKIPPED[0m
2026-01-14T08:14:35.6955632Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_12 [33mSKIPPED[0m
2026-01-14T08:14:35.6956456Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_13 [33mSKIPPED[0m
2026-01-14T08:14:35.6957267Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_14 [33mSKIPPED[0m
2026-01-14T08:14:35.6958091Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_15 [33mSKIPPED[0m
2026-01-14T08:14:35.6958901Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_16 [33mSKIPPED[0m
2026-01-14T08:14:35.6959724Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_17 [33mSKIPPED[0m
2026-01-14T08:14:35.6960553Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6961505Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6962365Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_2_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6963185Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_3 [33mSKIPPED[0m
2026-01-14T08:14:35.6964000Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_4 [33mSKIPPED[0m
2026-01-14T08:14:35.6964806Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_5 [33mSKIPPED[0m
2026-01-14T08:14:35.6965625Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_0_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6966455Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_1_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6967273Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_2_cpu [33mSKIPPED[0m
2026-01-14T08:14:35.6968083Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_3 [33mSKIPPED[0m
2026-01-14T08:14:35.6968865Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_4 [33mSKIPPED[0m
2026-01-14T08:14:35.6969658Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_5 [33mSKIPPED[0m
2026-01-14T08:14:35.6970468Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_0 [33mSKIPPED[0m
2026-01-14T08:14:35.6971287Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_1 [33mSKIPPED[0m
2026-01-14T08:14:35.6972216Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_2 [33mSKIPPED[0m
2026-01-14T08:14:35.7488539Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_00_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:14:35.7489416Z [33mSKIPPED[0m
2026-01-14T08:14:35.7489941Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_01_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:14:35.7490546Z [33mSKIPPED[0m
2026-01-14T08:14:35.7491063Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_02_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:14:35.7491659Z [33mSKIPPED[0m
2026-01-14T08:14:35.7492241Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_03_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:14:35.7492861Z [33mSKIPPED[0m
2026-01-14T08:14:35.7493353Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_04_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:14:35.7493957Z [33mSKIPPED[0m
2026-01-14T08:14:35.7494448Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_05_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:14:35.7495054Z [33mSKIPPED[0m
2026-01-14T08:14:35.7495547Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_06_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:14:35.7496161Z [33mSKIPPED[0m
2026-01-14T08:14:35.7496667Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_07_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:14:35.7497259Z [33mSKIPPED[0m
2026-01-14T08:14:35.7497761Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_08_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:14:35.7498347Z [33mSKIPPED[0m
2026-01-14T08:14:35.7498848Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_09_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:14:35.7499438Z [33mSKIPPED[0m
2026-01-14T08:14:35.7499933Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_10_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:14:35.7500521Z [33mSKIPPED[0m
2026-01-14T08:14:35.7501020Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_11_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:14:35.7501627Z [33mSKIPPED[0m
2026-01-14T08:14:35.7502115Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_12_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:14:35.7502717Z [33mSKIPPED[0m
2026-01-14T08:14:35.7503303Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_13_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:14:35.7503912Z [33mSKIPPED[0m
2026-01-14T08:14:35.7504395Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_14_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:14:35.7504999Z [33mSKIPPED[0m
2026-01-14T08:14:35.7505484Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_15 (m, k, n):  (16, 128, 128)
2026-01-14T08:14:35.7506058Z [33mSKIPPED[0m
2026-01-14T08:14:35.7506547Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_16 (m, k, n):  (64, 128, 128)
2026-01-14T08:14:35.7507124Z [33mSKIPPED[0m
2026-01-14T08:14:35.7507606Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_17 (m, k, n):  (16, 128, 256)
2026-01-14T08:14:35.7508189Z [33mSKIPPED[0m
2026-01-14T08:14:35.7508699Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_18 (m, k, n):  (16, 256, 128)
2026-01-14T08:14:35.7509288Z [33mSKIPPED[0m
2026-01-14T08:14:35.7509757Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_19 (m, k, n):  (64, 256, 128)
2026-01-14T08:14:35.7510343Z [33mSKIPPED[0m
2026-01-14T08:14:35.7510831Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_20 (m, k, n):  (16, 128, 128)
2026-01-14T08:14:35.7511412Z [33mSKIPPED[0m
2026-01-14T08:14:35.7511900Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_21 (m, k, n):  (64, 128, 128)
2026-01-14T08:14:35.7512475Z [33mSKIPPED[0m
2026-01-14T08:14:35.7512960Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_22 (m, k, n):  (16, 128, 256)
2026-01-14T08:14:35.7513613Z [33mSKIPPED[0m
2026-01-14T08:14:35.7514099Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_23 (m, k, n):  (16, 256, 128)
2026-01-14T08:14:35.7514687Z [33mSKIPPED[0m
2026-01-14T08:14:35.7515163Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_24 (m, k, n):  (64, 256, 128)
2026-01-14T08:14:35.7515752Z [33mSKIPPED[0m
2026-01-14T08:14:35.7516225Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_25 (m, k, n):  (16, 128, 128)
2026-01-14T08:14:35.7516816Z [33mSKIPPED[0m
2026-01-14T08:14:35.7517308Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_26 (m, k, n):  (64, 128, 128)
2026-01-14T08:14:35.7517974Z [33mSKIPPED[0m
2026-01-14T08:14:35.7518461Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_27 (m, k, n):  (16, 128, 256)
2026-01-14T08:14:35.7519037Z [33mSKIPPED[0m
2026-01-14T08:14:35.7519517Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_28 (m, k, n):  (16, 256, 128)
2026-01-14T08:14:35.7520096Z [33mSKIPPED[0m
2026-01-14T08:14:35.7520576Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_29 (m, k, n):  (64, 256, 128)
2026-01-14T08:14:35.7521155Z [33mSKIPPED[0m
2026-01-14T08:14:35.7521608Z test/integration/test_integration.py::TestAOTI::test_aoti_00 [33mSKIPPED[0m
2026-01-14T08:14:35.7522277Z test/integration/test_integration.py::TestAOTI::test_aoti_01 [33mSKIPPED[0m
2026-01-14T08:14:35.7522951Z test/integration/test_integration.py::TestAOTI::test_aoti_02 [33mSKIPPED[0m
2026-01-14T08:14:35.7523623Z test/integration/test_integration.py::TestAOTI::test_aoti_03 [33mSKIPPED[0m
2026-01-14T08:14:35.7524280Z test/integration/test_integration.py::TestAOTI::test_aoti_04 [33mSKIPPED[0m
2026-01-14T08:14:35.7524951Z test/integration/test_integration.py::TestAOTI::test_aoti_05 [33mSKIPPED[0m
2026-01-14T08:14:35.7525609Z test/integration/test_integration.py::TestAOTI::test_aoti_06 [33mSKIPPED[0m
2026-01-14T08:14:35.7526282Z test/integration/test_integration.py::TestAOTI::test_aoti_07 [33mSKIPPED[0m
2026-01-14T08:14:35.7526951Z test/integration/test_integration.py::TestAOTI::test_aoti_08 [33mSKIPPED[0m
2026-01-14T08:14:35.7527680Z test/integration/test_integration.py::TestAOTI::test_aoti_09 [33mSKIPPED[0m
2026-01-14T08:14:35.7528353Z test/integration/test_integration.py::TestAOTI::test_aoti_10 [33mSKIPPED[0m
2026-01-14T08:14:35.7529011Z test/integration/test_integration.py::TestAOTI::test_aoti_11 [33mSKIPPED[0m
2026-01-14T08:14:35.7529680Z test/integration/test_integration.py::TestAOTI::test_aoti_12 [33mSKIPPED[0m
2026-01-14T08:14:35.7530340Z test/integration/test_integration.py::TestAOTI::test_aoti_13 [33mSKIPPED[0m
2026-01-14T08:14:35.7531009Z test/integration/test_integration.py::TestAOTI::test_aoti_14 [33mSKIPPED[0m
2026-01-14T08:14:35.7531679Z test/integration/test_integration.py::TestAOTI::test_aoti_15 [33mSKIPPED[0m
2026-01-14T08:14:35.7532448Z test/integration/test_integration.py::TestAOTI::test_aoti_16 [33mSKIPPED[0m
2026-01-14T08:14:35.7533132Z test/integration/test_integration.py::TestAOTI::test_aoti_17 [33mSKIPPED[0m
2026-01-14T08:14:35.7533829Z test/integration/test_integration.py::TestExport::test_export_00 [33mSKIPPED[0m
2026-01-14T08:14:35.7534549Z test/integration/test_integration.py::TestExport::test_export_01 [33mSKIPPED[0m
2026-01-14T08:14:35.7535267Z test/integration/test_integration.py::TestExport::test_export_02 [33mSKIPPED[0m
2026-01-14T08:14:35.7535965Z test/integration/test_integration.py::TestExport::test_export_03 [33mSKIPPED[0m
2026-01-14T08:14:35.7536674Z test/integration/test_integration.py::TestExport::test_export_04 [33mSKIPPED[0m
2026-01-14T08:14:35.7537375Z test/integration/test_integration.py::TestExport::test_export_05 [33mSKIPPED[0m
2026-01-14T08:14:35.7538085Z test/integration/test_integration.py::TestExport::test_export_06 [33mSKIPPED[0m
2026-01-14T08:14:35.7538783Z test/integration/test_integration.py::TestExport::test_export_07 [33mSKIPPED[0m
2026-01-14T08:14:35.7539562Z test/integration/test_integration.py::TestExport::test_export_08 [33mSKIPPED[0m
2026-01-14T08:14:35.7540270Z test/integration/test_integration.py::TestExport::test_export_09 [33mSKIPPED[0m
2026-01-14T08:14:35.7540972Z test/integration/test_integration.py::TestExport::test_export_10 [33mSKIPPED[0m
2026-01-14T08:14:35.7541684Z test/integration/test_integration.py::TestExport::test_export_11 [33mSKIPPED[0m
2026-01-14T08:14:35.7542387Z test/integration/test_integration.py::TestExport::test_export_12 [33mSKIPPED[0m
2026-01-14T08:14:35.7543104Z test/integration/test_integration.py::TestExport::test_export_13 [33mSKIPPED[0m
2026-01-14T08:14:35.7543803Z test/integration/test_integration.py::TestExport::test_export_14 [33mSKIPPED[0m
2026-01-14T08:14:35.7544512Z test/integration/test_integration.py::TestExport::test_export_15 [33mSKIPPED[0m
2026-01-14T08:14:35.7545220Z test/integration/test_integration.py::TestExport::test_export_16 [33mSKIPPED[0m
2026-01-14T08:14:35.7545922Z test/integration/test_integration.py::TestExport::test_export_17 [33mSKIPPED[0m
2026-01-14T08:14:35.7546637Z test/integration/test_integration.py::TestExport::test_export_18 [33mSKIPPED[0m
2026-01-14T08:14:35.7547337Z test/integration/test_integration.py::TestExport::test_export_19 [33mSKIPPED[0m
2026-01-14T08:14:35.7548050Z test/integration/test_integration.py::TestExport::test_export_20 [33mSKIPPED[0m
2026-01-14T08:14:35.7548765Z test/integration/test_integration.py::TestExport::test_export_21 [33mSKIPPED[0m
2026-01-14T08:14:35.7549650Z test/integration/test_integration.py::TestExport::test_export_22 [33mSKIPPED[0m
2026-01-14T08:14:35.7550432Z test/integration/test_integration.py::TestExport::test_export_23 [33mSKIPPED[0m
2026-01-14T08:14:35.7551158Z test/integration/test_integration.py::TestExport::test_export_float8 [33mSKIPPED[0m
2026-01-14T08:14:35.7551940Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_00 [33mSKIPPED[0m
2026-01-14T08:14:35.7552745Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_01 [33mSKIPPED[0m
2026-01-14T08:14:35.7553532Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_02 [33mSKIPPED[0m
2026-01-14T08:14:35.7554434Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_03 [33mSKIPPED[0m
2026-01-14T08:14:35.7555218Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_04 [33mSKIPPED[0m
2026-01-14T08:14:35.7556016Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_05 [33mSKIPPED[0m
2026-01-14T08:14:35.7556814Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_06 [33mSKIPPED[0m
2026-01-14T08:14:35.7557594Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_07 [33mSKIPPED[0m
2026-01-14T08:14:35.7558393Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_08 [33mSKIPPED[0m
2026-01-14T08:14:36.3541505Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_09 [33mSKIPPED[0m
2026-01-14T08:14:36.3542683Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_10 [33mSKIPPED[0m
2026-01-14T08:14:36.3543755Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_11 [33mSKIPPED[0m
2026-01-14T08:14:36.3544823Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_12 [33mSKIPPED[0m
2026-01-14T08:14:36.3545869Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_13 [33mSKIPPED[0m
2026-01-14T08:14:36.3546931Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_14 [33mSKIPPED[0m
2026-01-14T08:14:36.3547990Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_15 [33mSKIPPED[0m
2026-01-14T08:14:36.3549035Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_16 [33mSKIPPED[0m
2026-01-14T08:14:36.3550250Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_17 [33mSKIPPED[0m
2026-01-14T08:14:36.3551683Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cpu [32mPASSED[0m
2026-01-14T08:14:36.3552872Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cuda [33mSKIPPED[0m
2026-01-14T08:14:36.3554236Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_hf_models_model_info0 [33mSKIPPED[0m
2026-01-14T08:14:36.3555434Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:14:36.3556593Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:14:36.3557687Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info1 [33mSKIPPED[0m
2026-01-14T08:14:36.3558785Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info2 [33mSKIPPED[0m
2026-01-14T08:14:36.3559890Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info3 [33mSKIPPED[0m
2026-01-14T08:14:36.3560981Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info4 [33mSKIPPED[0m
2026-01-14T08:14:36.3561894Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_0_cuda [33mSKIPPED[0m
2026-01-14T08:14:36.3562599Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_1_cuda [33mSKIPPED[0m
2026-01-14T08:14:36.3563321Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_0_cuda [33mSKIPPED[0m
2026-01-14T08:14:36.3564080Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_1_cuda [33mSKIPPED[0m
2026-01-14T08:14:36.3564825Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_0_cuda [33mSKIPPED[0m
2026-01-14T08:14:36.3565572Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu [32mPASSED[0m
2026-01-14T08:14:36.3566326Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_2_cuda [33mSKIPPED[0m
2026-01-14T08:14:36.3567056Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu [32mPASSED[0m
2026-01-14T08:14:36.3568095Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_fp8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:14:36.3569180Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_int8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:14:36.3570282Z test/prototype/module_swap_quantization/test_kmeans_codebook.py::TestKmeansCodebook::test_kmeans_codebook [33mSKIPPED[0m
2026-01-14T08:14:36.3571367Z test/prototype/module_swap_quantization/test_llm_ptq_data_getter.py::TestPTQDataGetter::test_data_getter [33mSKIPPED[0m
2026-01-14T08:14:36.3572519Z test/prototype/module_swap_quantization/test_module_swap.py::TestEmbeddingSwap::test_embedding_swap [32mPASSED[0m
2026-01-14T08:14:36.3573731Z test/prototype/module_swap_quantization/test_module_swap_quantization_utils.py::TestQuantizedModuleUtils::test_set_bit_widths_by_name [32mPASSED[0m
2026-01-14T08:14:36.3574958Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic [32mPASSED[0m
2026-01-14T08:14:36.3576142Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic_vectorized [32mPASSED[0m
2026-01-14T08:14:36.3577316Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear [32mPASSED[0m
2026-01-14T08:14:36.3578446Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_init [32mPASSED[0m
2026-01-14T08:14:36.3579669Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients [32mPASSED[0m
2026-01-14T08:14:36.3581035Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_activation_scale [32mPASSED[0m
2026-01-14T08:14:36.3582552Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_weight_scale [32mPASSED[0m
2026-01-14T08:14:36.3583942Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_all_options [32mPASSED[0m
2026-01-14T08:14:36.3585274Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_correct [32mPASSED[0m
2026-01-14T08:14:36.3586525Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedEmbedding::test_quantized_embedding [32mPASSED[0m
2026-01-14T08:14:36.3587614Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_qmin_qmax [32mPASSED[0m
2026-01-14T08:14:36.3588648Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max [32mPASSED[0m
2026-01-14T08:14:36.3589779Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max_vectorized [32mPASSED[0m
2026-01-14T08:14:36.3590921Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_asymmetric [32mPASSED[0m
2026-01-14T08:14:36.3592054Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max [32mPASSED[0m
2026-01-14T08:14:36.3593237Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max_tensorized [32mPASSED[0m
2026-01-14T08:14:36.3594400Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_symmetric [32mPASSED[0m
2026-01-14T08:14:36.3595480Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_param_size [32mPASSED[0m
2026-01-14T08:14:36.3596524Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward [32mPASSED[0m
2026-01-14T08:14:36.3597690Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_asymmetric_clipping [32mPASSED[0m
2026-01-14T08:14:36.3598855Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric [32mPASSED[0m
2026-01-14T08:14:36.3600002Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric_clipping [32mPASSED[0m
2026-01-14T08:14:36.3601153Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_codebook_quantizer [32mPASSED[0m
2026-01-14T08:14:36.3602243Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_vector_quantizer [32mPASSED[0m
2026-01-14T08:14:36.3603362Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max [32mPASSED[0m
2026-01-14T08:14:36.3604580Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max_grouped [32mPASSED[0m
2026-01-14T08:14:36.3605743Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse [32mPASSED[0m
2026-01-14T08:14:36.3606880Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse_grouped [32mPASSED[0m
2026-01-14T08:14:36.3608211Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss [32mPASSED[0m
2026-01-14T08:14:36.3609708Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss_progressive [32mPASSED[0m
2026-01-14T08:14:36.3611197Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting [32mPASSED[0m
2026-01-14T08:14:36.3612847Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting_no_input [32mPASSED[0m
2026-01-14T08:14:36.3614254Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales [32mPASSED[0m
2026-01-14T08:14:36.3615683Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales_dont_change_per_channel [32mPASSED[0m
2026-01-14T08:14:36.3617046Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9775814Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9777093Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:14:42.9778325Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9779534Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9780729Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9781930Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9783292Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9784485Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9786695Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9788004Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9789283Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:14:42.9790553Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9791819Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9793103Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9794383Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9795638Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9796907Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:14:42.9798042Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_metadata_torchao [33mSKIPPED[0m
2026-01-14T08:14:42.9799147Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata0 [33mSKIPPED[0m
2026-01-14T08:14:42.9800300Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata1 [33mSKIPPED[0m
2026-01-14T08:14:42.9801563Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata2 [33mSKIPPED[0m
2026-01-14T08:14:42.9802717Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata3 [33mSKIPPED[0m
2026-01-14T08:14:42.9803868Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata4 [33mSKIPPED[0m
2026-01-14T08:14:42.9805005Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata5 [33mSKIPPED[0m
2026-01-14T08:14:42.9806160Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata6 [33mSKIPPED[0m
2026-01-14T08:14:42.9807292Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata7 [33mSKIPPED[0m
2026-01-14T08:14:42.9808440Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata8 [33mSKIPPED[0m
2026-01-14T08:14:42.9809591Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata9 [33mSKIPPED[0m
2026-01-14T08:14:42.9810440Z test/prototype/test_awq.py::TestAWQ::test_awq_config [32mPASSED[0m
2026-01-14T08:14:42.9811175Z test/prototype/test_awq.py::TestAWQ::test_awq_functionality_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:14:42.9812082Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:14:42.9812935Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_vllm_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:14:42.9813862Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook [33mSKIPPED[0m
2026-01-14T08:14:42.9814915Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook_row_grouping [33mSKIPPED[0m
2026-01-14T08:14:42.9816030Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [33mSKIPPED[0m
2026-01-14T08:14:42.9817196Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [33mSKIPPED[0m
2026-01-14T08:14:42.9818393Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float_row_grouping [33mSKIPPED[0m
2026-01-14T08:14:42.9819416Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_export [33mSKIPPED[0m
2026-01-14T08:14:42.9820272Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_quantize_api [33mSKIPPED[0m
2026-01-14T08:14:42.9821229Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook [32mPASSED[0m
2026-01-14T08:14:42.9822268Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:14:42.9823356Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [32mPASSED[0m
2026-01-14T08:14:42.9824341Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:14:42.9825157Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_accuracy [33mSKIPPED[0m
2026-01-14T08:14:42.9826007Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T08:14:42.9827524Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:42.9829518Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:42.9831582Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:42.9833578Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:42.9835555Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:42.9837529Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:42.9839523Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:42.9841501Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:42.9843474Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:42.9845510Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:42.9847787Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:42.9995358Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:42.9997487Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:42.9999567Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0001644Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0003717Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0005786Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0007853Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0010083Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0012243Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0014322Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0016390Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0018470Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0020525Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0022570Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0024629Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0026795Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0029198Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0031822Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0034463Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0037087Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0039711Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0042314Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0045000Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0047613Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0050379Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0053051Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0055666Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0058266Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0060961Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0063553Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0066154Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0182045Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0184658Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0187252Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0190027Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0192745Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0195448Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0198146Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0200838Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0203521Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0206274Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0208957Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0211647Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0214456Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0217162Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0219835Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0222579Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0225263Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0227941Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0230614Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0233303Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0235973Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0238677Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0241418Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0244119Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0246813Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0249633Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0252408Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0379216Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0382052Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0384745Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0387492Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0390183Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0392885Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0395568Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0398338Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0401017Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0403693Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0406370Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0409032Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0411688Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0414453Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0417067Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0419669Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0422298Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0424915Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0427525Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0430179Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0432787Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0435390Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0437984Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0440601Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0443200Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0445785Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0448411Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0565629Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0568256Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0570865Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0573599Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0576283Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0579094Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0581803Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0584501Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0587194Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0589901Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0592604Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0595374Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0598077Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0600772Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0603459Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0606143Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0608831Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0611566Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0614325Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0616992Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0619680Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0622378Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0625086Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0627763Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0630520Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0633212Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0635900Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0757795Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0760500Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0763190Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0765994Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0768684Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0771364Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0774157Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0776838Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0779513Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0782265Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0784944Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0787618Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0790253Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0792874Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0795507Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0798193Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0800787Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0803402Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0806025Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0808639Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0811236Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0813975Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0816582Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0819194Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0821797Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0824399Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0826987Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0950534Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0953227Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0955843Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0958507Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0961239Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0963935Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0966645Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0969416Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0972182Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0974875Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0977592Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0980279Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0982976Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0985706Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0988397Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0991086Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.0993779Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.0996447Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.0999145Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1001897Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1004575Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1007258Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1009950Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1012734Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1015441Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1018162Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1020839Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1141785Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1144507Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1147183Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1149999Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1152703Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1155501Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1158185Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1160864Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1163541Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1166228Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1168894Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1171637Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1174359Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1176983Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1179598Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1182216Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1184841Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1187513Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1190109Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1192736Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1195360Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1197962Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1200575Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1203244Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1205845Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1208426Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1211033Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1327943Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1330549Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1333242Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1335999Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1338710Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1341416Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1344129Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1346814Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1349668Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1352479Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1355187Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1357858Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1360563Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1363255Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1365941Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1368703Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1371389Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1374145Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1376834Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1379502Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1382174Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1384932Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1387625Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1390312Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1393011Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1395690Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1398359Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1520574Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1523281Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1525977Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1528657Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1531343Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1534100Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1536886Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1539574Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1542236Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1544923Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1547598Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1550405Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1553041Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1555739Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1558376Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1560994Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1563592Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1566202Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1568819Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1571489Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1574167Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1576788Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1579402Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1581991Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1584597Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1587264Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1589853Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1711899Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1714544Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1717147Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1719804Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1722601Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1725320Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1728022Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1730719Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1733479Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1736175Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1738872Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1741639Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1744319Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1747010Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1749823Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1752508Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1755173Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1757927Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1760610Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1763296Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1765967Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1768661Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1771351Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1774206Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1776894Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1779574Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1782271Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1901607Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1904291Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1907064Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1909747Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1912447Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1915127Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1917811Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1920489Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1923235Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1925891Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1928570Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1931246Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1933988Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1936596Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1939276Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1941905Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1944510Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1947103Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1949844Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1952461Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1955080Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1957764Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1960363Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1962969Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.1965583Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.1968166Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.1970763Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2103273Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2106026Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2108632Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2111305Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2114011Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2116713Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2119539Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2122218Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2124902Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2127608Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2130290Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2133075Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2135839Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2138549Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2141240Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2143915Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2146601Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2149271Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2152096Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2154850Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2157533Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2160218Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2162925Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2165604Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2168294Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2171053Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2173837Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2303412Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2306142Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2308827Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2311514Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2314306Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2316992Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2319678Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2322377Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2325033Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2327716Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2331092Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2333887Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2336520Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2339148Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2341783Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2344508Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2347267Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2350060Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2352761Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2355386Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2358054Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2360736Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2363350Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2366124Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2368792Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2371466Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2374231Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2504374Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2507117Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2510003Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2512673Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2515508Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2518336Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2521153Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2523985Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2526763Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2529604Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2532509Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2535221Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2538053Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2540862Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2543754Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2546578Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2549264Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2552228Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2555053Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2557843Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2560748Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2563452Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2566283Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2569113Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2571816Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2574698Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2577539Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2706381Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2709212Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2712030Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2714746Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2717566Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2720390Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2723296Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2726111Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2728802Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2731601Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2734498Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2737176Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2740131Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2742813Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2745558Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2748325Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2751064Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2753817Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2756652Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2759387Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2762138Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2764768Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2767506Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2770243Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2772937Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2775772Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2778506Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2906275Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2909045Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2911765Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2914422Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2917371Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2920212Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2923009Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2925840Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2928548Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2931366Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2934378Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2937078Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2939889Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2942718Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2945521Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2948340Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2951312Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2954148Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2956958Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2959778Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2962596Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2965289Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2968211Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2971033Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.2973940Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.2976777Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.2979456Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3119785Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.3122765Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.3125615Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3128289Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.3131105Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.3134015Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3136826Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.3139620Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.3142402Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3145220Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:14:43.3148016Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:14:43.3150809Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3153391Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3155732Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3158093Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3160477Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3162879Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3165148Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3167516Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3169847Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3172190Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3174714Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3177116Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3179382Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3181737Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3184056Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3186304Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3188717Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3191118Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3364758Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3367031Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3369373Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3385599Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3388176Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3390437Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3392788Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3395256Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3397445Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3399681Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3402027Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3404355Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3406599Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3408879Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3411204Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3413514Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3415781Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3418051Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3420394Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3422673Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3424858Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3427219Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3429538Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3431803Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3434058Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3436366Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3438627Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3440855Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3443270Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3445628Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3447907Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:14:43.3449419Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_shared_embedding [33mSKIPPED[0m
2026-01-14T08:14:43.3450944Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3729627Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.3731232Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.3733012Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.3734573Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.3736249Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3737952Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.3739496Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.3741190Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.3742851Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.3744409Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3745951Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.3747611Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.3749164Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.3750973Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.3752528Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3754174Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.3755843Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.3757398Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.3759070Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.3760608Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3762152Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.3763838Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.3765498Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.3767053Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.3768680Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3770343Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.3771883Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.3773638Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.3775156Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.3776685Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3778350Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.3779995Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.3781534Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.3783062Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.3784642Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3786319Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.3787972Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.3789519Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.3791055Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.3792701Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3794251Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.3795783Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.3797427Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.3798968Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.3800558Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.3802207Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4080751Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4082305Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4083828Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4085506Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4087185Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4088716Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4090256Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4091914Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4093583Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4095383Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4096930Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4098451Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4100132Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4101804Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4103339Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4104869Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4106527Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4108060Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4109838Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4111385Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4112909Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4114517Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4116049Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4117666Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4119210Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4120732Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4122342Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4123947Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4125473Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4127060Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4128646Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4130162Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4131744Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4133366Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4134888Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4136483Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4138015Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4139598Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4141195Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4142725Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4144308Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4145899Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4147429Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4148933Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4150664Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4152181Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4427754Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4429297Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4430875Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4432540Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4434076Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4435653Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4437185Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4438724Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4440306Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4441873Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4443494Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4445029Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4446656Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4448281Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4449970Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4451598Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4453235Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4454765Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4456390Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4457943Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4459537Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4461074Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4462713Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4464325Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4465941Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4467495Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4469032Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4470657Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4472200Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4473826Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4475372Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4476910Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4478608Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4480201Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4481738Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4483267Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4484859Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4486393Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4487990Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4489522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4491040Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4492710Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4494338Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4495946Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4497482Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4499022Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4776311Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4777896Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4779491Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4781013Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4782604Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4784136Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4785790Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4787388Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4788917Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4790501Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4792034Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4793571Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4795157Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4796693Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4798228Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4799814Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4801423Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4802956Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4804557Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4806161Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4807693Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4809234Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4810783Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4812451Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4814052Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4815596Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4817193Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4818797Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4820341Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4821941Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4823485Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4825043Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4826640Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4828245Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4829788Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4831317Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4832952Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4834483Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4836069Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4837591Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4839095Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.4840689Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.4842217Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.4843793Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.4845318Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.4846842Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5140456Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5141988Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5143507Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5145100Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5146683Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5148221Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5149888Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5151485Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5153016Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5154597Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5156302Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5157835Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5159414Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5160940Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5162464Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5163990Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5165406Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5166816Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5168259Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5169668Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5171225Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5172728Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5174126Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5175512Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5176982Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5178434Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5179826Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5181219Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5182610Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5184058Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5185456Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5186924Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5188397Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5189799Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5191247Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5192649Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5194113Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5195506Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:14:43.5196904Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:14:43.5198435Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5199966Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5201570Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5203177Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5204699Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5206302Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5207907Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5209432Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5210981Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5488686Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5490218Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5491747Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5493361Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5495033Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5496597Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5498141Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5499668Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5501215Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5502758Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5504290Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5505853Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5507390Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5508911Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5510539Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5512072Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5513593Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5515111Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5516624Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5518144Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5519665Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5521174Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5522694Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5524217Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5525786Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5527310Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5528832Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5530345Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5531867Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5533509Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5535016Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5536537Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5538064Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5539571Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5541156Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5542674Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5544188Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5545712Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5547234Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5548750Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5550415Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5551931Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5553456Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5554986Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5556594Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5558125Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5836921Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5838449Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5839977Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5841517Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5843031Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5844577Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5846092Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5847616Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5849291Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5850943Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5852563Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5854097Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5855693Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5857240Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5858948Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5860464Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5862004Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5863610Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5865300Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5866850Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5868364Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5869906Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5871475Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5873047Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5874571Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5876084Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5877655Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5879179Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5880848Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5882354Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5883864Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5885369Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5886924Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5888441Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5890017Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5891522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5893113Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5894695Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5896270Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5897854Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5899358Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.5900879Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.5902459Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.5903973Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.5905559Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.5907092Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6190093Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6191675Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6193555Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6195104Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6196759Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6198298Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6199832Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6201508Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6203161Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6204696Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6206232Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6207885Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6209517Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6211196Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6212838Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6214366Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6216030Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6217579Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6219239Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6220774Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6222310Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6223966Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6225707Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6227252Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6228768Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6230418Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6231951Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6233602Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6235129Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6236632Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6238280Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6239920Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6241507Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6243036Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6244677Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6246195Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6247847Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6249383Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6251046Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6252635Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6254230Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6255807Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6257608Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6259138Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6260646Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6262301Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6537884Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6539447Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6541035Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6542572Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6544155Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6545687Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6547337Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6548934Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6550621Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6552226Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6553742Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6555279Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6556883Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6558464Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6560005Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6561521Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6563164Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6564757Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6566345Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6567881Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6569411Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6571001Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6572602Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6574206Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6575729Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6577262Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6578942Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6580458Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6582057Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6583562Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6585059Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6586650Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6588226Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6589739Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6591247Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6592800Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6594393Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6595972Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6597471Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6598984Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6600553Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6602060Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6603643Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6605163Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6606665Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6608244Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6884495Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6886085Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6887600Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6889107Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6890695Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6892367Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6893930Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6895444Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6896994Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6898605Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6900305Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6901859Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6903399Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6904989Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6906533Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6908146Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6909668Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6911203Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6912805Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6914328Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6916015Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6917553Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6919076Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6920689Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6922272Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6923812Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6925348Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6926941Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6928486Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6930093Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6931684Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6933329Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6934925Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6936437Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6938032Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6939567Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6941084Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6942676Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6944259Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6945776Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6947362Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.6948926Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.6950617Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.6952227Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.6953807Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.6955340Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7235948Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7237484Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7238998Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7240595Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7242336Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7243860Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7245386Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7246960Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7248506Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7250225Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7251747Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7253389Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7254930Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7256486Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7258163Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7259776Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7261298Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7262833Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7264430Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7265963Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7267569Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7269102Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7270623Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7272214Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7273827Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7275414Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7276945Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7278472Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7280053Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7281648Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7283188Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7284699Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7286283Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7287821Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7289454Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7290993Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7292587Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7294177Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7295695Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7297268Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7298780Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7300287Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7301855Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7303369Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7305064Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7306566Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7585437Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7586991Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7588486Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7590066Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7591599Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7593149Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7594666Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7596181Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7597735Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7599412Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7600993Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7602498Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7604028Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7605597Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7607154Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7608684Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7610219Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7611745Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7613511Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7615101Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7616631Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7618174Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7619699Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7621231Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7622821Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7624395Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7625939Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7627480Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7629007Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7630645Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7632239Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7633771Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7635315Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7637119Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7638665Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7640274Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7641810Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7643329Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7645027Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7646576Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7648169Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7649823Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7651329Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7653018Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7654550Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7656143Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7936826Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7938366Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7939918Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7941697Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7943297Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7944830Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7946342Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7947945Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7949468Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7951211Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7952738Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7954251Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7955962Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7957501Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7959095Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7960617Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7962146Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7963740Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7965283Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7966884Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7968406Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7969938Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7971557Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7973318Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7974857Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7976390Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7977977Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7979510Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7981110Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7982614Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7984137Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7985647Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7987318Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7988852Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7990440Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7991971Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.7993500Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.7995095Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.7996631Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.7998229Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.7999737Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.8001259Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.8002861Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.8004431Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.8006044Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.8007568Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.8356273Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.8357843Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.8359486Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.8360991Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.8362619Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.8364127Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.8365898Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.8367422Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.8369047Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.8370545Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.8372232Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.8373765Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.8375383Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.8376901Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.8378513Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.8380021Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.8381639Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.8383245Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.8384861Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:14:43.8386385Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:14:43.8387991Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:14:43.8389508Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:14:43.8391045Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:14:43.8392343Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_bfloat16 [33mSKIPPED[0m
2026-01-14T08:14:43.8393327Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float16 [33mSKIPPED[0m
2026-01-14T08:14:43.8394408Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float32 [33mSKIPPED[0m
2026-01-14T08:14:43.8395316Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_choose_qparams_gguf [32mPASSED[0m
2026-01-14T08:14:43.8396237Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_gguf_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:14:43.8397162Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:14:43.8398238Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_00 [33mSKIPPED[0m
2026-01-14T08:14:43.8399524Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_01 [33mSKIPPED[0m
2026-01-14T08:14:43.8400796Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_02 [33mSKIPPED[0m
2026-01-14T08:14:43.8402076Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_03 [33mSKIPPED[0m
2026-01-14T08:14:43.8403347Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_04 [33mSKIPPED[0m
2026-01-14T08:14:43.8404630Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_05 [33mSKIPPED[0m
2026-01-14T08:14:43.8405914Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_06 [33mSKIPPED[0m
2026-01-14T08:14:43.8407185Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_07 [33mSKIPPED[0m
2026-01-14T08:14:43.8408691Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_08 [33mSKIPPED[0m
2026-01-14T08:14:43.8410438Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_09 [33mSKIPPED[0m
2026-01-14T08:14:43.8412220Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_10 [33mSKIPPED[0m
2026-01-14T08:14:43.8413945Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_11 [33mSKIPPED[0m
2026-01-14T08:14:43.8415732Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_12 [33mSKIPPED[0m
2026-01-14T08:14:43.8417459Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_13 [33mSKIPPED[0m
2026-01-14T08:14:43.8419176Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_14 [33mSKIPPED[0m
2026-01-14T08:14:43.8420893Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_15 [33mSKIPPED[0m
2026-01-14T08:14:43.8422589Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_00 [33mSKIPPED[0m
2026-01-14T08:14:43.8424254Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_01 [33mSKIPPED[0m
2026-01-14T08:14:43.8425898Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_02 [33mSKIPPED[0m
2026-01-14T08:14:43.8427556Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_03 [33mSKIPPED[0m
2026-01-14T08:14:43.8429199Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_04 [33mSKIPPED[0m
2026-01-14T08:14:43.8430857Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_05 [33mSKIPPED[0m
2026-01-14T08:14:43.8432508Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_06 [33mSKIPPED[0m
2026-01-14T08:14:43.8434217Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_07 [33mSKIPPED[0m
2026-01-14T08:14:43.8435879Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_08 [33mSKIPPED[0m
2026-01-14T08:15:15.6790312Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_09 [33mSKIPPED[0m
2026-01-14T08:15:15.6792031Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_10 [33mSKIPPED[0m
2026-01-14T08:15:15.6793712Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_11 [33mSKIPPED[0m
2026-01-14T08:15:15.6795360Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_12 [33mSKIPPED[0m
2026-01-14T08:15:15.6797042Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_13 [33mSKIPPED[0m
2026-01-14T08:15:15.6798717Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_14 [33mSKIPPED[0m
2026-01-14T08:15:15.6800372Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_15 [33mSKIPPED[0m
2026-01-14T08:15:15.6801959Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6803399Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6804918Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6806807Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6809678Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6812738Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6815064Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6817164Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6819477Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6821826Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6823671Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6825513Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6827351Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6829047Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6830644Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6832232Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6834107Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6835690Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6837257Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6838838Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6840419Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6842154Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6844653Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6846804Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6848931Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6851362Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6853783Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6855628Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6857450Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6859555Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6861312Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6862894Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6864493Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6866093Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6867687Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6869281Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6870861Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6872451Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6874055Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6875654Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6877256Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6878962Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6880592Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6882179Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6883805Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6886244Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6888550Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6890946Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6893195Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6895292Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6897592Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:15.6899808Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:15.6901632Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:20.5359148Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:20.5360678Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:20.5371537Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:20.5372996Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:20.5374063Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:20.5375106Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:20.5376154Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:20.5377201Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_False [32mPASSED[0m
2026-01-14T08:15:20.5378248Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_True [32mPASSED[0m
2026-01-14T08:15:20.5379252Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5380212Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5381173Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5382120Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5383107Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5384277Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5385228Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5386191Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5387154Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5388098Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5389058Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5390007Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5390971Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5391930Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5392877Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5393835Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5394780Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5395725Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5396685Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5397644Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5398590Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5399615Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5400567Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5401526Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5402533Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5403477Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5404431Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5405378Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5406339Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5407293Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5408234Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5409188Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5410091Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5410972Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5411978Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5412850Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5413728Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5414591Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5415466Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5416344Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5417203Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5418077Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5418944Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5419823Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5420695Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5421550Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5422416Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5423275Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5424151Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5425022Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5425887Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5426814Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5427675Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5428547Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5429427Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5430289Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5431160Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5432023Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5432904Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5433780Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5434644Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5435520Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5436377Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:15:20.5437250Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:15:20.5438182Z test/prototype/test_mixed_precision.py::TestWeightOnlyQuantNaive::test_quantization_intNwo [32mPASSED[0m
2026-01-14T08:15:20.5439043Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace [32mPASSED[0m
2026-01-14T08:15:21.0574499Z test/prototype/test_parametrization.py::TestFakeSparsity::test_masking_logic [32mPASSED[0m
2026-01-14T08:15:21.0575784Z test/prototype/test_parametrization.py::TestFakeSparsity::test_state_dict_preserved [32mPASSED[0m
2026-01-14T08:15:21.0576976Z test/prototype/test_parametrization.py::TestFakeSparsity::test_weights_parametrized [32mPASSED[0m
2026-01-14T08:15:21.0578066Z test/prototype/test_paretoq.py::TestParetoQ::test_quantize_functions [32mPASSED[0m
2026-01-14T08:15:21.0579032Z test/prototype/test_paretoq.py::TestParetoQ::test_quantized_linear [32mPASSED[0m
2026-01-14T08:15:21.0580436Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0582174Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0583906Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0585630Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0587357Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0589066Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0590784Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0592544Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0594267Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0596292Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0598016Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0599727Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0601445Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0603138Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0604861Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0606560Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0608252Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0609963Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0611669Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0613475Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0615450Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0617167Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0618874Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0620577Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0622278Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0624011Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0625723Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0627440Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0629154Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0630853Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0632552Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:15:21.0634256Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:15:21.0635732Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_e2e [33mSKIPPED[0m
2026-01-14T08:15:21.0636977Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_256 [33mSKIPPED[0m
2026-01-14T08:15:21.0638241Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_32 [33mSKIPPED[0m
2026-01-14T08:15:21.0639529Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.0640835Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_512 [32mPASSED[0m
2026-01-14T08:15:21.0642122Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.0643432Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_512 [32mPASSED[0m
2026-01-14T08:15:21.0644723Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.0646022Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_512 [32mPASSED[0m
2026-01-14T08:15:21.0647322Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.0648613Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_512 [32mPASSED[0m
2026-01-14T08:15:21.0650063Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_2 [32mPASSED[0m
2026-01-14T08:15:21.0651258Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_3 [32mPASSED[0m
2026-01-14T08:15:21.0652537Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_4 [32mPASSED[0m
2026-01-14T08:15:21.0653861Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_8 [32mPASSED[0m
2026-01-14T08:15:21.0655069Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only [32mPASSED[0m
2026-01-14T08:15:21.0656330Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_e2e [32mPASSED[0m
2026-01-14T08:15:21.0657680Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_parq_equivalent [32mPASSED[0m
2026-01-14T08:15:21.0659121Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_tied_embed_linear [32mPASSED[0m
2026-01-14T08:15:21.0660820Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.0662691Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.0664569Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.0666433Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.0668282Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.0670143Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2889101Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.2890726Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2892491Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.2893896Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2895424Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.2896819Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2898369Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.2899753Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2901288Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.2902800Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2904198Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.2905580Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2906957Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.2908476Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2909866Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.2911469Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2914317Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:15:21.2916899Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:15:21.2918843Z test/prototype/test_parq.py::TestTorchAoConfigIntegration::test_tied_weights_quantization [32mPASSED[0m
2026-01-14T08:15:21.2920468Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity0 [33mSKIPPED[0m
2026-01-14T08:15:21.2922652Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity1 [33mSKIPPED[0m
2026-01-14T08:15:21.2924799Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:15:21.2927116Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:15:21.2929426Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:15:21.2931554Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:15:21.2933911Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:15:21.2935876Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:15:21.2937854Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:15:21.2939808Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:15:21.2941792Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:15:21.2943781Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:15:21.2945736Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:15:21.2947703Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:15:21.2949845Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:15:21.2951813Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:15:21.2953954Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:15:21.2955916Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:15:21.2957731Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity0 [33mSKIPPED[0m
2026-01-14T08:15:21.2959456Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity1 [33mSKIPPED[0m
2026-01-14T08:15:21.2960995Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_False [33mSKIPPED[0m
2026-01-14T08:15:21.2962395Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_True [33mSKIPPED[0m
2026-01-14T08:15:21.2964059Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_False [33mSKIPPED[0m
2026-01-14T08:15:21.2965930Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_True [33mSKIPPED[0m
2026-01-14T08:15:21.2967811Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_False [33mSKIPPED[0m
2026-01-14T08:15:21.2969541Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_True [33mSKIPPED[0m
2026-01-14T08:15:21.2970932Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_False [33mSKIPPED[0m
2026-01-14T08:15:21.2972404Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_True [33mSKIPPED[0m
2026-01-14T08:15:21.2973924Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_False [33mSKIPPED[0m
2026-01-14T08:15:21.2975318Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_True [33mSKIPPED[0m
2026-01-14T08:15:21.2976712Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_False [33mSKIPPED[0m
2026-01-14T08:15:21.2978086Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_True [33mSKIPPED[0m
2026-01-14T08:15:21.2979474Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_False [33mSKIPPED[0m
2026-01-14T08:15:21.2980873Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_True [33mSKIPPED[0m
2026-01-14T08:16:04.3596532Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_False [33mSKIPPED[0m
2026-01-14T08:16:04.3597981Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_True [33mSKIPPED[0m
2026-01-14T08:16:04.3599387Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_False [33mSKIPPED[0m
2026-01-14T08:16:04.3600773Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_True [33mSKIPPED[0m
2026-01-14T08:16:04.3602322Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_stochastic_rounding_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3603546Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3604831Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3606133Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3607433Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3608720Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3610019Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3611352Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3612764Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3614101Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3615440Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3616771Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3618225Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3619493Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_False_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3620740Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_True_device_cpu [32mPASSED[0m
2026-01-14T08:16:04.3621764Z test/prototype/test_quantized_training.py::TestFSDP2::test_fsdp2_correctness [33mSKIPPED[0m
2026-01-14T08:16:04.3622601Z test/prototype/test_quantized_training.py::TestFSDP2::test_precompute_bitnet_scale [33mSKIPPED[0m
2026-01-14T08:16:04.3623399Z test/prototype/test_scheduler.py::TestScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:16:04.3624134Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler [32mPASSED[0m
2026-01-14T08:16:04.3624867Z test/prototype/test_scheduler.py::TestScheduler::test_order_of_steps [32mPASSED[0m
2026-01-14T08:16:04.3625563Z test/prototype/test_scheduler.py::TestScheduler::test_step [32mPASSED[0m
2026-01-14T08:16:04.3626260Z test/prototype/test_scheduler.py::TestCubicScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:16:04.3626989Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step [32mPASSED[0m
2026-01-14T08:16:04.3627814Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_observer_insertion_base_config0 [32mPASSED[0m
2026-01-14T08:16:04.3628738Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_prepare_for_loading_base_config0 [32mPASSED[0m
2026-01-14T08:16:04.3629827Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_5_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:16:04.3631036Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_75_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:16:04.3632079Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:16:04.3632843Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_convert [32mPASSED[0m
2026-01-14T08:16:04.3633586Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:16:04.3634422Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params1 [32mPASSED[0m
2026-01-14T08:16:04.3635297Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params2 [32mPASSED[0m
2026-01-14T08:16:04.3636185Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params3 [32mPASSED[0m
2026-01-14T08:16:04.3637011Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_prepare_config [32mPASSED[0m
2026-01-14T08:16:04.3637787Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_state_dict [32mPASSED[0m
2026-01-14T08:16:04.3638524Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_step [32mPASSED[0m
2026-01-14T08:16:04.3639300Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:16:04.3640135Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:16:04.3640938Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:16:04.3641781Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:16:04.3642594Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step [32mPASSED[0m
2026-01-14T08:16:04.3643389Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step_2_of_4 [32mPASSED[0m
2026-01-14T08:16:04.3644246Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:16:04.3645116Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:16:04.3645975Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:16:04.3646922Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:16:04.3647772Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_step [32mPASSED[0m
2026-01-14T08:16:04.3648631Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module [32mPASSED[0m
2026-01-14T08:16:04.3649826Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_fail [32mPASSED[0m
2026-01-14T08:16:04.3650814Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_for_tensors [32mPASSED[0m
2026-01-14T08:16:04.3651908Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn [32mPASSED[0m
2026-01-14T08:16:04.3652971Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn_fail [32mPASSED[0m
2026-01-14T08:16:04.3653954Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn [32mPASSED[0m
2026-01-14T08:16:04.3654864Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_fail [32mPASSED[0m
2026-01-14T08:16:04.3655804Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_root [32mPASSED[0m
2026-01-14T08:16:04.3656812Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_lstm_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:16:04.3657840Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:16:04.3658852Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_complex_conv2d [32mPASSED[0m
2026-01-14T08:16:04.3659981Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:16:04.3660988Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_conv2d [32mPASSED[0m
2026-01-14T08:16:04.3662015Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_linear [32mPASSED[0m
2026-01-14T08:16:04.3663110Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_activation_conv2d [32mPASSED[0m
2026-01-14T08:16:04.3664241Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_bias_conv2d [32mPASSED[0m
2026-01-14T08:16:04.3665311Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_conv2d [32mPASSED[0m
2026-01-14T08:16:04.3666407Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_padding_conv2d [32mPASSED[0m
2026-01-14T08:16:04.3667527Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_pool_conv2d [32mPASSED[0m
2026-01-14T08:16:04.3668654Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_activation_linear [32mPASSED[0m
2026-01-14T08:16:04.5658447Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_bias_linear [32mPASSED[0m
2026-01-14T08:16:04.5659595Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_linear [32mPASSED[0m
2026-01-14T08:16:04.5660799Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:16:04.5662062Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_single_layer [32mPASSED[0m
2026-01-14T08:16:04.5663273Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:16:04.5664451Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_single_layer [32mPASSED[0m
2026-01-14T08:16:04.5665788Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_conv2d [32mPASSED[0m
2026-01-14T08:16:04.5666785Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_linear [32mPASSED[0m
2026-01-14T08:16:04.5667701Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_compute_distance [32mPASSED[0m
2026-01-14T08:16:04.5668639Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_update_mask [32mPASSED[0m
2026-01-14T08:16:04.5669655Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5670737Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5671843Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5672852Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5673865Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5674872Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5675883Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5676894Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5677895Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5679046Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5680051Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5681063Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5682140Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5683219Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5684234Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5685343Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5686388Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5687414Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5688416Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5689427Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5690425Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5691440Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5692542Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5693553Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5694644Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5695652Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5696754Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5697842Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5698900Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5699993Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5701009Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5702018Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5703036Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5704035Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5705048Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5706057Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5707061Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5708068Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5709140Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5710160Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5711179Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5712238Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5713334Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5714371Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5715473Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5716496Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5717504Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:16:04.5718517Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:16:04.5719388Z test/prototype/test_tensor_conversion.py::test_int4_tensor_conversion [33mSKIPPED[0m
2026-01-14T08:16:04.5720337Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_attention_block [33mSKIPPED[0m
2026-01-14T08:16:04.5721388Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d [33mSKIPPED[0m
2026-01-14T08:16:04.5722420Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:16:04.5723509Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:16:04.5724680Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:16:04.5725882Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_filter_linear_recipe [33mSKIPPED[0m
2026-01-14T08:16:04.5727029Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear [33mSKIPPED[0m
2026-01-14T08:16:04.5728050Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary [33mSKIPPED[0m
2026-01-14T08:16:04.5729291Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic [33mSKIPPED[0m
2026-01-14T08:16:04.5730454Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic_qat [33mSKIPPED[0m
2026-01-14T08:16:04.5731584Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_qat [33mSKIPPED[0m
2026-01-14T08:16:20.5371168Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d [33mSKIPPED[0m
2026-01-14T08:16:20.5372421Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:16:20.5373552Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:16:20.5374696Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:16:20.5375941Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case1 [33mSKIPPED[0m
2026-01-14T08:16:20.5377515Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case2 [33mSKIPPED[0m
2026-01-14T08:16:20.5378871Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:16:20.5380146Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig [33mSKIPPED[0m
2026-01-14T08:16:20.5381617Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_for_dynamic_quant [33mSKIPPED[0m
2026-01-14T08:16:20.5382940Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_with_underscores [33mSKIPPED[0m
2026-01-14T08:16:20.5384230Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:16:20.5385380Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_avgpool_use_different_qconfig [32mPASSED[0m
2026-01-14T08:16:20.5386403Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_add_quant_duplicate_dq [32mPASSED[0m
2026-01-14T08:16:20.5387381Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_need_for_duplicate_dq [32mPASSED[0m
2026-01-14T08:16:20.5388348Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_simple_duplicate_dq [32mPASSED[0m
2026-01-14T08:16:20.5389242Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu [32mPASSED[0m
2026-01-14T08:16:20.5390443Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu W0114 08:16:07.341000 520 site-packages/torch/fx/experimental/symbolic_shapes.py:2704] Failed to reduce inequalities: 1/2
2026-01-14T08:16:20.5391433Z [32mPASSED[0m
2026-01-14T08:16:20.5392392Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict W0114 08:16:07.449000 520 site-packages/torch/fx/experimental/symbolic_shapes.py:2704] Failed to reduce inequalities: 1/2
2026-01-14T08:16:20.5393574Z [32mPASSED[0m
2026-01-14T08:16:20.5394254Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_calculate_qparams [32mPASSED[0m
2026-01-14T08:16:20.5395383Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_disable_range_learning [32mPASSED[0m
2026-01-14T08:16:20.5396514Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_observer [32mPASSED[0m
2026-01-14T08:16:20.5397611Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_range_learning [32mPASSED[0m
2026-01-14T08:16:20.5398717Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_error_conditions [32mPASSED[0m
2026-01-14T08:16:20.5399881Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_and_observer_control [32mPASSED[0m
2026-01-14T08:16:20.5401029Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_control [32mPASSED[0m
2026-01-14T08:16:20.5402179Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_fake_quant_disabled [32mPASSED[0m
2026-01-14T08:16:20.5403346Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_learning_enabled [32mPASSED[0m
2026-01-14T08:16:20.5404490Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_observer_enabled [32mPASSED[0m
2026-01-14T08:16:20.5405613Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_gradient_scaling [32mPASSED[0m
2026-01-14T08:16:20.5406731Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_channel [32mPASSED[0m
2026-01-14T08:16:20.5407975Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_tensor [32mPASSED[0m
2026-01-14T08:16:20.5409159Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_backward_per_tensor [32mPASSED[0m
2026-01-14T08:16:20.5410337Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_forward_per_tensor [32mPASSED[0m
2026-01-14T08:16:20.5411503Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_per_channel_quantization [32mPASSED[0m
2026-01-14T08:16:20.5412709Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_state_persistence [32mPASSED[0m
2026-01-14T08:16:20.5413823Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_symmetric_quantization [32mPASSED[0m
2026-01-14T08:16:20.5415032Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_device_compatibility [32mPASSED[0m
2026-01-14T08:16:20.5416312Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_integration_with_linear_layer [32mPASSED[0m
2026-01-14T08:16:20.5417631Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_multiple_fake_quant_modules [32mPASSED[0m
2026-01-14T08:16:20.5418997Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_optimizer_updates_scale_and_zero_point [32mPASSED[0m
2026-01-14T08:16:20.5420324Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_training_mode_switching [32mPASSED[0m
2026-01-14T08:16:20.5421645Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_numerical_consistency_per_tensor [32mPASSED[0m
2026-01-14T08:16:20.5422891Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_serialization [32mPASSED[0m
2026-01-14T08:16:20.5424622Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq [33mSKIPPED[0m
2026-01-14T08:16:20.5425724Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq_no_static_q [32mPASSED[0m
2026-01-14T08:16:20.5426794Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_two_dq [32mPASSED[0m
2026-01-14T08:16:20.5427917Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_with_no_quant_inbetween [32mPASSED[0m
2026-01-14T08:16:20.5428987Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting [32mPASSED[0m
2026-01-14T08:16:20.5430053Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting_through_unknown_ops [32mPASSED[0m
2026-01-14T08:16:20.5431137Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_simple_metadata_porting [32mPASSED[0m
2026-01-14T08:16:20.5432192Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_added_node_gets_unique_id [33mSKIPPED[0m
2026-01-14T08:16:20.5433229Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_control_flow [33mSKIPPED[0m
2026-01-14T08:16:20.5434248Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_copy_preserve_handle [33mSKIPPED[0m
2026-01-14T08:16:20.5435315Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_deepcopy_preserve_handle [33mSKIPPED[0m
2026-01-14T08:16:20.5436457Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_prepare_for_propagation_comparison [33mSKIPPED[0m
2026-01-14T08:16:20.5437586Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_re_export_preserve_handle [33mSKIPPED[0m
2026-01-14T08:16:20.5438843Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_map_handle_to_new_nodes [33mSKIPPED[0m
2026-01-14T08:16:20.5440059Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_same_handle_id [33mSKIPPED[0m
2026-01-14T08:16:20.5441090Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_simple [33mSKIPPED[0m
2026-01-14T08:16:20.5442078Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval [32mPASSED[0m
2026-01-14T08:16:20.5443146Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval_idempotent [32mPASSED[0m
2026-01-14T08:16:20.5444176Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing [32mPASSED[0m
2026-01-14T08:16:34.0333630Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing_with_shared_input_edge [32mPASSED[0m
2026-01-14T08:16:34.0334756Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_chunked_bn_fusion [32mPASSED[0m
2026-01-14T08:16:34.0336908Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_linear_conv [W114 08:16:20.940628349 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0339929Z [W114 08:16:20.940652875 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0342742Z [W114 08:16:20.940664752 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0345303Z [W114 08:16:20.940672163 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0347846Z [W114 08:16:20.940687360 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0350565Z [W114 08:16:20.940698553 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0353106Z [W114 08:16:20.940713653 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0355648Z [W114 08:16:20.940725066 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0358294Z [W114 08:16:20.940766230 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0360843Z [W114 08:16:20.940775618 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0363390Z [W114 08:16:20.940783759 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0365946Z [W114 08:16:20.940790956 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0368486Z [W114 08:16:20.940808005 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0371104Z [W114 08:16:20.940819352 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0373753Z [W114 08:16:20.940855985 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0376286Z [W114 08:16:20.940865459 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:16:34.0377759Z [32mPASSED[0m
2026-01-14T08:16:34.0378391Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_throw [32mPASSED[0m
2026-01-14T08:16:34.0379473Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_transform_for_annotation [32mPASSED[0m
2026-01-14T08:16:34.0380521Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_folding_pass [32mPASSED[0m
2026-01-14T08:16:34.0381498Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_prop_preserve_metadata [32mPASSED[0m
2026-01-14T08:16:34.0382451Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv3d_bn_relu [32mPASSED[0m
2026-01-14T08:16:34.0383358Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_padding_bn_relu [32mPASSED[0m
2026-01-14T08:16:34.0384294Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose3d_bn_relu [32mPASSED[0m
2026-01-14T08:16:34.0385311Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:16:34.0386202Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec [32mPASSED[0m
2026-01-14T08:16:34.0387126Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec_per_channel [32mPASSED[0m
2026-01-14T08:16:34.0388069Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_disallow_eval_train [32mPASSED[0m
2026-01-14T08:16:34.0388994Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_dont_fold_other_constant [32mPASSED[0m
2026-01-14T08:16:34.0390009Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_conv_linear_quantization [32mPASSED[0m
2026-01-14T08:16:34.0390976Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_quantizer [32mPASSED[0m
2026-01-14T08:16:34.0391966Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_observer_dedup [32mPASSED[0m
2026-01-14T08:16:34.0392967Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_ptq [32mPASSED[0m
2026-01-14T08:16:34.0393907Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_qat [32mPASSED[0m
2026-01-14T08:16:34.0394883Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_all_ops_before_quantize [32mPASSED[0m
2026-01-14T08:16:34.0395794Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize [32mPASSED[0m
2026-01-14T08:16:34.0396712Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize_per_channel [32mPASSED[0m
2026-01-14T08:16:34.0397694Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_groupwise_per_channel_quant [32mPASSED[0m
2026-01-14T08:16:34.0398651Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_input_edge_sanity_check [32mPASSED[0m
2026-01-14T08:16:34.0399593Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_max_pool2d_quantizer [32mPASSED[0m
2026-01-14T08:16:46.8019365Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported [32mPASSED[0m
2026-01-14T08:16:46.8020470Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_bn_device_cpu [32mPASSED[0m
2026-01-14T08:16:46.8021531Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout [32mPASSED[0m
2026-01-14T08:16:46.8022683Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout_inplace [32mPASSED[0m
2026-01-14T08:16:46.8023744Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_multi_users_without_output_observer [32mPASSED[0m
2026-01-14T08:16:46.8024839Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_observer_callback [32mPASSED[0m
2026-01-14T08:16:46.8025801Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_prepare_obs_or_fq_callback [32mPASSED[0m
2026-01-14T08:16:46.8026777Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_preserve_nn_module_stack [32mPASSED[0m
2026-01-14T08:16:46.8027816Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:16:46.8028920Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e5m2 [32mPASSED[0m
2026-01-14T08:16:46.8030114Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_int16 [32mPASSED[0m
2026-01-14T08:16:46.8031189Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:16:46.8032410Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e5m2 [32mPASSED[0m
2026-01-14T08:16:46.8033606Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_int16 [32mPASSED[0m
2026-01-14T08:16:46.8034523Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantize_in_place_ops input_act1 is a node
2026-01-14T08:16:46.8035132Z [32mPASSED[0m
2026-01-14T08:16:46.8035673Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant [32mPASSED[0m
2026-01-14T08:16:46.8036503Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_save_load [32mPASSED[0m
2026-01-14T08:16:46.8037334Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec [32mPASSED[0m
2026-01-14T08:16:46.8038253Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity [32mPASSED[0m
2026-01-14T08:16:46.8039245Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity_case_2 [32mPASSED[0m
2026-01-14T08:16:46.8040344Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_simple_quantizer [32mPASSED[0m
2026-01-14T08:16:46.8041197Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_speed [32mPASSED[0m
2026-01-14T08:16:46.8042093Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_transform_for_annotation [32mPASSED[0m
2026-01-14T08:16:46.8043233Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_wo_annotate_conv_output_quantizer [32mPASSED[0m
2026-01-14T08:16:46.8044295Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_channel_group_quantization prepared model: GraphModule(
2026-01-14T08:16:46.8045052Z   (linear): Module()
2026-01-14T08:16:46.8045399Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:16:46.8045881Z   (activation_post_process_0): AffineQuantizedMinMaxObserver()
2026-01-14T08:16:46.8046259Z )
2026-01-14T08:16:46.8046364Z 
2026-01-14T08:16:46.8046368Z 
2026-01-14T08:16:46.8046377Z 
2026-01-14T08:16:46.8046467Z def forward(self, x):
2026-01-14T08:16:46.8046780Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:16:46.8047149Z     linear_weight = self.linear.weight
2026-01-14T08:16:46.8047769Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:16:46.8048461Z     linear_bias = self.linear.bias
2026-01-14T08:16:46.8048877Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:16:46.8050067Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:16:46.8051147Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:16:46.8051511Z     
2026-01-14T08:16:46.8051821Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:16:46.8052333Z quantized model GraphModule(
2026-01-14T08:16:46.8052621Z   (linear): Module()
2026-01-14T08:16:46.8052838Z )
2026-01-14T08:16:46.8052942Z 
2026-01-14T08:16:46.8052947Z 
2026-01-14T08:16:46.8052969Z 
2026-01-14T08:16:46.8053061Z def forward(self, x):
2026-01-14T08:16:46.8053366Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:16:46.8053737Z     _scale0 = self._scale0
2026-01-14T08:16:46.8053992Z     _zero_point0 = self._zero_point0
2026-01-14T08:16:46.8054306Z     quantize_affine = self._frozen_param0
2026-01-14T08:16:46.8055265Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:16:46.8056218Z     linear_bias = self.linear.bias
2026-01-14T08:16:46.8056626Z     _scale1 = self._scale1
2026-01-14T08:16:46.8056881Z     _zero_point1 = self._zero_point1
2026-01-14T08:16:46.8057478Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255);  x = None
2026-01-14T08:16:46.8058902Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine_1 = _scale1 = _zero_point1 = None
2026-01-14T08:16:46.8060460Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:16:46.8061311Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:16:46.8061654Z     
2026-01-14T08:16:46.8061963Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:16:46.8062430Z [32mPASSED[0m
2026-01-14T08:16:46.8063233Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_affine_act_per_channel_weights [32mPASSED[0m
2026-01-14T08:16:46.8064568Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_per_tok_act_per_group_weights prepared model: GraphModule(
2026-01-14T08:16:46.8065367Z   (linear): Module()
2026-01-14T08:16:46.8065705Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:16:46.8066214Z   (activation_post_process_0): AffineQuantizedPlaceholderObserver()
2026-01-14T08:16:46.8066620Z )
2026-01-14T08:16:46.8066722Z 
2026-01-14T08:16:46.8066727Z 
2026-01-14T08:16:46.8066731Z 
2026-01-14T08:16:46.8066830Z def forward(self, x):
2026-01-14T08:16:46.8067184Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:16:46.8067633Z     linear_weight = self.linear.weight
2026-01-14T08:16:46.8068151Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:16:46.8068696Z     linear_bias = self.linear.bias
2026-01-14T08:16:46.8069102Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:16:46.8070122Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:16:46.8071091Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:16:46.8071553Z     
2026-01-14T08:16:46.8071867Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:16:46.8072275Z quantized model GraphModule(
2026-01-14T08:16:46.8072673Z   (linear): Module()
2026-01-14T08:16:46.8072891Z )
2026-01-14T08:16:46.8073007Z 
2026-01-14T08:16:46.8073011Z 
2026-01-14T08:16:46.8073015Z 
2026-01-14T08:16:46.8073105Z def forward(self, x):
2026-01-14T08:16:46.8073415Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:16:46.8073768Z     _scale0 = self._scale0
2026-01-14T08:16:46.8074045Z     _zero_point0 = self._zero_point0
2026-01-14T08:16:46.8074357Z     quantize_affine = self._frozen_param0
2026-01-14T08:16:46.8075445Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.int8, -127, 127, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:16:46.8076425Z     linear_bias = self.linear.bias
2026-01-14T08:16:46.8077061Z     choose_qparams_affine = torch.ops.torchao.choose_qparams_affine(x, 'SYMMETRIC', (1, 128), torch.int8, -128, 127, None, None, None)
2026-01-14T08:16:46.8077740Z     getitem = choose_qparams_affine[0]
2026-01-14T08:16:46.8078151Z     getitem_1 = choose_qparams_affine[1];  choose_qparams_affine = None
2026-01-14T08:16:46.8078858Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), getitem, getitem_1, torch.int8, -128, 127);  x = None
2026-01-14T08:16:46.8080130Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), getitem, getitem_1, torch.int8, -128, 127, output_dtype = torch.float32);  quantize_affine_1 = getitem = getitem_1 = None
2026-01-14T08:16:46.8081688Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:16:46.8082604Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:16:46.8082977Z     
2026-01-14T08:16:46.8083390Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:16:46.8083848Z [32mPASSED[0m
2026-01-14T08:16:46.8084549Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_fold_bn_erases_bn_node [33mSKIPPED[0m
2026-01-14T08:16:46.8085726Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_bias_derived_qspec [33mSKIPPED[0m
2026-01-14T08:16:46.8086868Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion [33mSKIPPED[0m
2026-01-14T08:16:46.8087966Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:16:46.8089281Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_literal_args [33mSKIPPED[0m
2026-01-14T08:16:46.8090473Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:17:14.3791394Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_per_channel_weight_bias [33mSKIPPED[0m
2026-01-14T08:17:14.3793448Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion [33mSKIPPED[0m
2026-01-14T08:17:14.3795205Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:17:14.3797130Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:17:14.3798882Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_no_bias [33mSKIPPED[0m
2026-01-14T08:17:14.3801845Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn [33mSKIPPED[0m
2026-01-14T08:17:14.3803611Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn_relu [33mSKIPPED[0m
2026-01-14T08:17:14.3805355Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_inplace_add_relu [33mSKIPPED[0m
2026-01-14T08:17:14.3807157Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_per_channel_weight_custom_dtype [33mSKIPPED[0m
2026-01-14T08:17:14.3808986Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_preserve_source_fn_stack [33mSKIPPED[0m
2026-01-14T08:17:14.3810967Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_update_shared_qspec [33mSKIPPED[0m
2026-01-14T08:17:14.3813046Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T08:17:14.3814761Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T08:17:14.3816376Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T08:17:14.3817520Z   (conv): Module()
2026-01-14T08:17:14.3817883Z   (bn): Module()
2026-01-14T08:17:14.3818401Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:14.3820207Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:14.3822496Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:17:14.3823784Z   )
2026-01-14T08:17:14.3824269Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:14.3826165Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:17:14.3828912Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1771, -0.1539, -0.3202]), max_val=tensor([0.2503, 0.2984, 0.3244]))
2026-01-14T08:17:14.3830242Z   )
2026-01-14T08:17:14.3830743Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:14.3832772Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0103]), zero_point=tensor([-10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:14.3835178Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.20903742313385, max_val=1.4062939882278442)
2026-01-14T08:17:14.3836202Z   )
2026-01-14T08:17:14.3836553Z )
2026-01-14T08:17:14.3836723Z 
2026-01-14T08:17:14.3836731Z 
2026-01-14T08:17:14.3836737Z 
2026-01-14T08:17:14.3836893Z def forward(self, x):
2026-01-14T08:17:14.3837431Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:14.3838112Z     conv_weight = self.conv.weight
2026-01-14T08:17:14.3838614Z     conv_bias = self.conv.bias
2026-01-14T08:17:14.3839061Z     bn_weight = self.bn.weight
2026-01-14T08:17:14.3839499Z     bn_bias = self.bn.bias
2026-01-14T08:17:14.3839970Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:17:14.3840511Z     bn_running_var = self.bn.running_var
2026-01-14T08:17:14.3841099Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:14.3841961Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:14.3843222Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:14.3844536Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:17:14.3845238Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:17:14.3846041Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:17:14.3846807Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:17:14.3847777Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:17:14.3848906Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:17:14.3850391Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:17:14.3852640Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:17:14.3854523Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:17:14.3855582Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:17:14.3856810Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:17:14.3857947Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:17:14.3859801Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:17:14.3861897Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:17:14.3863112Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:17:14.3864168Z     
2026-01-14T08:17:14.3864696Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:14.3865435Z model fx: GraphModule(
2026-01-14T08:17:14.3865999Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:14.3867982Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:14.3870356Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:17:14.3871382Z   )
2026-01-14T08:17:14.3871699Z   (conv): ConvBn1d(
2026-01-14T08:17:14.3872092Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:17:14.3872853Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:17:14.3873701Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:14.3875801Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:17:14.3878636Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1771, -0.1539, -0.3202]), max_val=tensor([0.2503, 0.2984, 0.3244]))
2026-01-14T08:17:14.3879949Z     )
2026-01-14T08:17:14.3880265Z   )
2026-01-14T08:17:14.3880750Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:14.3882698Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0103]), zero_point=tensor([-10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:14.3884942Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.20903742313385, max_val=1.4062939882278442)
2026-01-14T08:17:14.3885999Z   )
2026-01-14T08:17:14.3886307Z )
2026-01-14T08:17:14.3886467Z 
2026-01-14T08:17:14.3886473Z 
2026-01-14T08:17:14.3886478Z 
2026-01-14T08:17:14.3886627Z def forward(self, x):
2026-01-14T08:17:14.3887470Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:14.3888497Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:17:14.3889592Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:17:14.3890390Z     return activation_post_process_1
2026-01-14T08:17:14.3890869Z     
2026-01-14T08:17:14.3891416Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:14.3892230Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:17:14.3892658Z          [0., 0., 0.],
2026-01-14T08:17:14.3893064Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:17:14.3893662Z converted model pt2e: GraphModule(
2026-01-14T08:17:14.3894155Z   (conv): Module()
2026-01-14T08:17:14.3894528Z   (bn): Module()
2026-01-14T08:17:14.3894863Z )
2026-01-14T08:17:14.3895039Z 
2026-01-14T08:17:14.3895044Z 
2026-01-14T08:17:14.3895049Z 
2026-01-14T08:17:14.3895194Z def forward(self, x):
2026-01-14T08:17:14.3895721Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:14.3896357Z     conv_bias = self.conv.bias
2026-01-14T08:17:14.3896925Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:14.3898293Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:17:14.3900834Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:14.3903046Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:14.3904148Z     _scale_0 = self._scale_0
2026-01-14T08:17:14.3904644Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:17:14.3905198Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:17:22.4011301Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:17:22.4013996Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:17:22.4016187Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010256201960146427, -10, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:17:22.4018610Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010256201960146427, -10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:17:22.4020670Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:17:22.4021498Z     
2026-01-14T08:17:22.4021993Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:22.4022656Z onverted model fx: GraphModule(
2026-01-14T08:17:22.4023290Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:17:22.4023953Z )
2026-01-14T08:17:22.4024138Z 
2026-01-14T08:17:22.4024145Z 
2026-01-14T08:17:22.4024151Z 
2026-01-14T08:17:22.4024283Z def forward(self, x):
2026-01-14T08:17:22.4025405Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:17:22.4027840Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:22.4029836Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:17:22.4031858Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010256201960146427, -10, -128, 127, torch.int8);  conv = None
2026-01-14T08:17:22.4034500Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010256201960146427, -10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:17:22.4036347Z     return dequantize_per_tensor_default_1
2026-01-14T08:17:22.4036834Z     
2026-01-14T08:17:22.4037353Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:22.4038013Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:17:22.4038459Z          [0., 0., 0.],
2026-01-14T08:17:22.4038828Z          [0., 0., 0.]]])
2026-01-14T08:17:22.4039272Z model pt2e: GraphModule(
2026-01-14T08:17:22.4039659Z   (conv): Module()
2026-01-14T08:17:22.4040006Z   (bn): Module()
2026-01-14T08:17:22.4040528Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:22.4042385Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:22.4044760Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:17:22.4045774Z   )
2026-01-14T08:17:22.4046307Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:22.4048331Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:17:22.4051229Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3201889097690582, max_val=0.3243715763092041)
2026-01-14T08:17:22.4052327Z   )
2026-01-14T08:17:22.4052857Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:22.4054841Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0103]), zero_point=tensor([-10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:22.4057255Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.20903742313385, max_val=1.4068148136138916)
2026-01-14T08:17:22.4058249Z   )
2026-01-14T08:17:22.4058575Z )
2026-01-14T08:17:22.4058759Z 
2026-01-14T08:17:22.4058824Z 
2026-01-14T08:17:22.4058830Z 
2026-01-14T08:17:22.4058980Z def forward(self, x):
2026-01-14T08:17:22.4059507Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:22.4060210Z     conv_weight = self.conv.weight
2026-01-14T08:17:22.4060715Z     conv_bias = self.conv.bias
2026-01-14T08:17:22.4061186Z     bn_weight = self.bn.weight
2026-01-14T08:17:22.4061679Z     bn_bias = self.bn.bias
2026-01-14T08:17:22.4062134Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:17:22.4062675Z     bn_running_var = self.bn.running_var
2026-01-14T08:17:22.4063285Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:22.4064104Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:22.4065266Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:22.4066385Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:17:22.4067194Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:17:22.4067953Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:17:22.4068747Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:17:22.4069744Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:17:22.4070820Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:17:22.4072381Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:17:22.4074419Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:17:22.4076314Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:17:22.4077423Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:17:22.4078657Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:17:22.4079760Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:17:22.4081615Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:17:22.4083517Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:17:22.4084639Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:17:22.4085380Z     
2026-01-14T08:17:22.4085935Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:22.4086684Z model fx: GraphModule(
2026-01-14T08:17:22.4087286Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:22.4089239Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:22.4091828Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:17:22.4092980Z   )
2026-01-14T08:17:22.4093306Z   (conv): ConvBn1d(
2026-01-14T08:17:22.4093728Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:17:22.4094521Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:17:22.4095404Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:22.4097299Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:17:22.4099605Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3201889097690582, max_val=0.3243715763092041)
2026-01-14T08:17:22.4100638Z     )
2026-01-14T08:17:22.4100929Z   )
2026-01-14T08:17:22.4101434Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:22.4103439Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0103]), zero_point=tensor([-10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:22.4105771Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.20903742313385, max_val=1.4068148136138916)
2026-01-14T08:17:22.4106736Z   )
2026-01-14T08:17:22.4107029Z )
2026-01-14T08:17:22.4107203Z 
2026-01-14T08:17:22.4107209Z 
2026-01-14T08:17:22.4107215Z 
2026-01-14T08:17:22.4107378Z def forward(self, x):
2026-01-14T08:17:22.4108014Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:22.4109011Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:17:22.4110020Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:17:22.4110881Z     return activation_post_process_1
2026-01-14T08:17:22.4111370Z     
2026-01-14T08:17:22.4111851Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:22.4112539Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:17:22.4113134Z          [0., 0., 0.],
2026-01-14T08:17:22.4113575Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:17:22.4114140Z converted model pt2e: GraphModule(
2026-01-14T08:17:22.4114623Z   (conv): Module()
2026-01-14T08:17:22.4114963Z   (bn): Module()
2026-01-14T08:17:22.4115302Z )
2026-01-14T08:17:22.4115466Z 
2026-01-14T08:17:22.4115474Z 
2026-01-14T08:17:22.4115480Z 
2026-01-14T08:17:22.4115639Z def forward(self, x):
2026-01-14T08:17:22.4116144Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:22.4116814Z     conv_bias = self.conv.bias
2026-01-14T08:17:22.4117366Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:22.4118817Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:17:22.4121389Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:22.4123515Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:22.4124535Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:17:33.7240856Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002554106991738081, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:17:33.7242900Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:17:33.7244759Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010258244350552559, -10, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:17:33.7247106Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010258244350552559, -10, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:17:33.7248641Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:17:33.7249248Z     
2026-01-14T08:17:33.7249792Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:33.7250343Z onverted model fx: GraphModule(
2026-01-14T08:17:33.7250869Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:17:33.7251398Z )
2026-01-14T08:17:33.7251532Z 
2026-01-14T08:17:33.7251538Z 
2026-01-14T08:17:33.7251543Z 
2026-01-14T08:17:33.7251675Z def forward(self, x):
2026-01-14T08:17:33.7252626Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:17:33.7254526Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:33.7256069Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:17:33.7257347Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010258244350552559, -10, -128, 127, torch.int8);  conv = None
2026-01-14T08:17:33.7259317Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010258244350552559, -10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:17:33.7260668Z     return dequantize_per_tensor_default_1
2026-01-14T08:17:33.7261053Z     
2026-01-14T08:17:33.7261451Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:33.7261975Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:17:33.7262307Z          [0., 0., 0.],
2026-01-14T08:17:33.7262729Z          [0., 0., 0.]]])
2026-01-14T08:17:33.7263285Z [32mPASSED[0m
2026-01-14T08:17:33.7264213Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:17:33.7265657Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T08:17:33.7266609Z   (conv): Module()
2026-01-14T08:17:33.7266884Z   (bn): Module()
2026-01-14T08:17:33.7267300Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:33.7268751Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:33.7270604Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.276310682296753, max_val=1.8198994398117065)
2026-01-14T08:17:33.7271378Z   )
2026-01-14T08:17:33.7271753Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:33.7273311Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:17:33.7275352Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3263, -0.3276, -0.3045]), max_val=tensor([0.2760, 0.3011, 0.3298]))
2026-01-14T08:17:33.7276322Z   )
2026-01-14T08:17:33.7276717Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:33.7278161Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0152]), zero_point=tensor([-12], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:33.7279581Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7719206809997559, max_val=2.111994981765747)
2026-01-14T08:17:33.7280164Z   )
2026-01-14T08:17:33.7280340Z )
2026-01-14T08:17:33.7280439Z 
2026-01-14T08:17:33.7280443Z 
2026-01-14T08:17:33.7280447Z 
2026-01-14T08:17:33.7280554Z def forward(self, x):
2026-01-14T08:17:33.7280859Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:33.7281238Z     conv_weight = self.conv.weight
2026-01-14T08:17:33.7281519Z     conv_bias = self.conv.bias
2026-01-14T08:17:33.7292503Z     bn_weight = self.bn.weight
2026-01-14T08:17:33.7292888Z     bn_bias = self.bn.bias
2026-01-14T08:17:33.7293186Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:17:33.7293509Z     bn_running_var = self.bn.running_var
2026-01-14T08:17:33.7293898Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:33.7294385Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:33.7295066Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:33.7295678Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:17:33.7296098Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:17:33.7296554Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:17:33.7297027Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:17:33.7297581Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:17:33.7298207Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:17:33.7298907Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:17:33.7300063Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:17:33.7301225Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:17:33.7301835Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:17:33.7302471Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:17:33.7303097Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:17:33.7304149Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:17:33.7305252Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:17:33.7305930Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:17:33.7306359Z     
2026-01-14T08:17:33.7306674Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:33.7307086Z model fx: GraphModule(
2026-01-14T08:17:33.7307416Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:33.7308529Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:33.7309833Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.276310682296753, max_val=1.8198994398117065)
2026-01-14T08:17:33.7310396Z   )
2026-01-14T08:17:33.7310591Z   (conv): ConvBn1d(
2026-01-14T08:17:33.7310857Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:17:33.7311418Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:17:33.7311947Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:33.7313099Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:17:33.7314646Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3263, -0.3276, -0.3045]), max_val=tensor([0.2760, 0.3011, 0.3298]))
2026-01-14T08:17:33.7315372Z     )
2026-01-14T08:17:33.7315565Z   )
2026-01-14T08:17:33.7315863Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:33.7316960Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0152]), zero_point=tensor([-12], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:33.7318267Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7719206809997559, max_val=2.111994981765747)
2026-01-14T08:17:33.7318838Z   )
2026-01-14T08:17:33.7319027Z )
2026-01-14T08:17:33.7319129Z 
2026-01-14T08:17:33.7319133Z 
2026-01-14T08:17:33.7319137Z 
2026-01-14T08:17:33.7319238Z def forward(self, x):
2026-01-14T08:17:33.7319609Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:33.7320205Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:17:33.7320805Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:17:33.7321283Z     return activation_post_process_1
2026-01-14T08:17:33.7321557Z     
2026-01-14T08:17:33.7321860Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:33.7322273Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:17:33.7322556Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:17:33.7322871Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:17:33.7323212Z converted model pt2e: GraphModule(
2026-01-14T08:17:33.7323496Z   (conv): Module()
2026-01-14T08:17:33.7323760Z   (bn): Module()
2026-01-14T08:17:33.7323971Z )
2026-01-14T08:17:33.7324071Z 
2026-01-14T08:17:33.7324075Z 
2026-01-14T08:17:33.7324079Z 
2026-01-14T08:17:33.7324166Z def forward(self, x):
2026-01-14T08:17:33.7324476Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:33.7324852Z     conv_bias = self.conv.bias
2026-01-14T08:17:33.7325170Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:42.4913235Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016063569113612175, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:17:42.4915228Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016063569113612175, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:42.4916860Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:42.4917567Z     _scale_0 = self._scale_0
2026-01-14T08:17:42.4917932Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:17:42.4918346Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:17:42.4919699Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:17:42.4921826Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:17:42.4923686Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.015231042169034481, -12, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:17:42.4926702Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.015231042169034481, -12, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:17:42.4928241Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:17:42.4928840Z     
2026-01-14T08:17:42.4929237Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:42.4929772Z onverted model fx: GraphModule(
2026-01-14T08:17:42.4930358Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:17:42.4930959Z )
2026-01-14T08:17:42.4931104Z 
2026-01-14T08:17:42.4931110Z 
2026-01-14T08:17:42.4931115Z 
2026-01-14T08:17:42.4931234Z def forward(self, x):
2026-01-14T08:17:42.4932220Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016063569113612175, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:17:42.4934128Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016063569113612175, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:42.4935670Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:17:42.4936963Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.015231042169034481, -12, -128, 127, torch.int8);  conv = None
2026-01-14T08:17:42.4938909Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.015231042169034481, -12, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:17:42.4940263Z     return dequantize_per_tensor_default_1
2026-01-14T08:17:42.4940643Z     
2026-01-14T08:17:42.4941042Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:42.4941569Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:17:42.4941950Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:17:42.4942419Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:17:42.4942779Z model pt2e: GraphModule(
2026-01-14T08:17:42.4943122Z   (conv): Module()
2026-01-14T08:17:42.4943400Z   (bn): Module()
2026-01-14T08:17:42.4943819Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:42.4945269Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:42.4947013Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.276310682296753, max_val=1.8198994398117065)
2026-01-14T08:17:42.4947778Z   )
2026-01-14T08:17:42.4948149Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:42.4949779Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:17:42.4951392Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:17:42.4951979Z   )
2026-01-14T08:17:42.4952277Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:42.4953361Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0152]), zero_point=tensor([-12], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:42.4954656Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7719206809997559, max_val=2.113234519958496)
2026-01-14T08:17:42.4955217Z   )
2026-01-14T08:17:42.4955503Z )
2026-01-14T08:17:42.4955601Z 
2026-01-14T08:17:42.4955606Z 
2026-01-14T08:17:42.4955609Z 
2026-01-14T08:17:42.4955712Z def forward(self, x):
2026-01-14T08:17:42.4956016Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:42.4956395Z     conv_weight = self.conv.weight
2026-01-14T08:17:42.4956679Z     conv_bias = self.conv.bias
2026-01-14T08:17:42.4956956Z     bn_weight = self.bn.weight
2026-01-14T08:17:42.4957217Z     bn_bias = self.bn.bias
2026-01-14T08:17:42.4957494Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:17:42.4957808Z     bn_running_var = self.bn.running_var
2026-01-14T08:17:42.4958168Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:42.4958652Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:42.4959309Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:42.4959914Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:17:42.4960334Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:17:42.4960785Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:17:42.4961262Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:17:42.4961817Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:17:42.4962448Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:17:42.4963128Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:17:42.4964277Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:17:42.4965297Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:17:42.4965895Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:17:42.4966546Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:17:42.4967246Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:17:42.4968291Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:17:42.4969394Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:17:42.4970065Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:17:42.4970504Z     
2026-01-14T08:17:42.4970799Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:42.4971210Z model fx: GraphModule(
2026-01-14T08:17:42.4971546Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:42.4972745Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:42.4974038Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.276310682296753, max_val=1.8198994398117065)
2026-01-14T08:17:42.4974618Z   )
2026-01-14T08:17:42.4974816Z   (conv): ConvBn1d(
2026-01-14T08:17:42.4975081Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:17:42.4975570Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:17:42.4976084Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:42.4977167Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:17:42.4978551Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:17:42.4979129Z     )
2026-01-14T08:17:42.4979328Z   )
2026-01-14T08:17:42.4979615Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:42.4980724Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0152]), zero_point=tensor([-12], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:42.4982024Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7719206809997559, max_val=2.113234519958496)
2026-01-14T08:17:42.4982588Z   )
2026-01-14T08:17:42.4982773Z )
2026-01-14T08:17:42.4982874Z 
2026-01-14T08:17:42.4982878Z 
2026-01-14T08:17:42.4982882Z 
2026-01-14T08:17:42.4982975Z def forward(self, x):
2026-01-14T08:17:42.4983354Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:42.4983937Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:17:42.4984546Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:17:42.4985020Z     return activation_post_process_1
2026-01-14T08:17:42.4985293Z     
2026-01-14T08:17:42.4985596Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:42.4985994Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:17:42.4986290Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:17:42.4986597Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:17:42.4986957Z converted model pt2e: GraphModule(
2026-01-14T08:17:42.4987232Z   (conv): Module()
2026-01-14T08:17:42.4987454Z   (bn): Module()
2026-01-14T08:17:42.4987652Z )
2026-01-14T08:17:42.4987766Z 
2026-01-14T08:17:42.4987769Z 
2026-01-14T08:17:42.4987773Z 
2026-01-14T08:17:46.3430581Z def forward(self, x):
2026-01-14T08:17:46.3431109Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:46.3431618Z     conv_bias = self.conv.bias
2026-01-14T08:17:46.3432033Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:46.3433099Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016063569113612175, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:17:46.3434548Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016063569113612175, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:46.3435742Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:46.3436308Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:17:46.3437206Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002597068203613162, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:17:46.3438679Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:17:46.3440074Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.0152359027415514, -12, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:17:46.3441573Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0152359027415514, -12, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:17:46.3442716Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:17:46.3443176Z     
2026-01-14T08:17:46.3443469Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:46.3443885Z onverted model fx: GraphModule(
2026-01-14T08:17:46.3444437Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:17:46.3444903Z )
2026-01-14T08:17:46.3445008Z 
2026-01-14T08:17:46.3445012Z 
2026-01-14T08:17:46.3445020Z 
2026-01-14T08:17:46.3445121Z def forward(self, x):
2026-01-14T08:17:46.3445849Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016063569113612175, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:17:46.3447262Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016063569113612175, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:46.3448418Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:17:46.3449373Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0152359027415514, -12, -128, 127, torch.int8);  conv = None
2026-01-14T08:17:46.3451015Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0152359027415514, -12, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:17:46.3452104Z     return dequantize_per_tensor_default_1
2026-01-14T08:17:46.3452401Z     
2026-01-14T08:17:46.3452710Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:46.3453110Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:17:46.3453406Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:17:46.3453663Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:17:46.3454135Z [32mPASSED[0m
2026-01-14T08:17:46.3454805Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:17:46.3455509Z   (conv): Module()
2026-01-14T08:17:46.3455732Z   (bn): Module()
2026-01-14T08:17:46.3456052Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:46.3457275Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0188]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:46.3458599Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5603605508804321, max_val=3.2356624603271484)
2026-01-14T08:17:46.3459181Z   )
2026-01-14T08:17:46.3459468Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:46.3460649Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0026, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:17:46.3462171Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2639, -0.2941, -0.2608]), max_val=tensor([0.2795, 0.3227, 0.2891]))
2026-01-14T08:17:46.3462909Z   )
2026-01-14T08:17:46.3463207Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:46.3464297Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0169]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:46.3465592Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9445278644561768, max_val=2.3592891693115234)
2026-01-14T08:17:46.3466164Z   )
2026-01-14T08:17:46.3466350Z )
2026-01-14T08:17:46.3466449Z 
2026-01-14T08:17:46.3466454Z 
2026-01-14T08:17:46.3466458Z 
2026-01-14T08:17:46.3466562Z def forward(self, x):
2026-01-14T08:17:46.3466863Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:46.3467240Z     conv_weight = self.conv.weight
2026-01-14T08:17:46.3467528Z     bn_weight = self.bn.weight
2026-01-14T08:17:46.3467891Z     bn_bias = self.bn.bias
2026-01-14T08:17:46.3468155Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:17:46.3468481Z     bn_running_var = self.bn.running_var
2026-01-14T08:17:46.3468830Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:46.3469325Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:46.3469996Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:46.3470594Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:17:46.3471023Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:17:46.3471462Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:17:46.3471945Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:17:46.3472498Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:17:46.3473116Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:17:46.3474112Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:17:46.3475114Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:17:46.3475712Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:17:46.3476784Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:17:46.3477883Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:17:46.3478547Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:17:46.3478970Z     
2026-01-14T08:17:46.3479275Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:46.3479671Z model fx: GraphModule(
2026-01-14T08:17:46.3480017Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:46.3481189Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0188]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:46.3482479Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5603605508804321, max_val=3.2356624603271484)
2026-01-14T08:17:46.3483061Z   )
2026-01-14T08:17:46.3483240Z   (conv): ConvBn1d(
2026-01-14T08:17:46.3483502Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:17:46.3483970Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:17:46.3484502Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:46.3485653Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0026, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:17:46.3487191Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2639, -0.2941, -0.2608]), max_val=tensor([0.2795, 0.3227, 0.2891]))
2026-01-14T08:17:46.3487935Z     )
2026-01-14T08:17:46.3488112Z   )
2026-01-14T08:17:46.3488416Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:46.3489533Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0169]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:46.3490821Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9445278644561768, max_val=2.3592891693115234)
2026-01-14T08:17:46.3491506Z   )
2026-01-14T08:17:46.3491679Z )
2026-01-14T08:17:46.3491791Z 
2026-01-14T08:17:46.3491795Z 
2026-01-14T08:17:46.3491799Z 
2026-01-14T08:17:46.3491887Z def forward(self, x):
2026-01-14T08:17:46.3492353Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:46.3492938Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:17:46.3493545Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:17:46.3494010Z     return activation_post_process_1
2026-01-14T08:17:46.3494293Z     
2026-01-14T08:17:46.3494585Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:46.3494997Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:17:46.3495251Z          [0., 0., 0.],
2026-01-14T08:17:46.3495467Z          [0., 0., 0.]],
2026-01-14T08:17:46.3495608Z 
2026-01-14T08:17:46.3495699Z         [[0., 0., 0.],
2026-01-14T08:17:46.3495912Z          [0., 0., 0.],
2026-01-14T08:17:46.3496139Z          [0., 0., 0.]],
2026-01-14T08:17:46.3496280Z 
2026-01-14T08:17:46.3496358Z         [[0., 0., 0.],
2026-01-14T08:17:46.3496580Z          [0., 0., 0.],
2026-01-14T08:17:55.0592408Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:17:55.0592966Z converted model pt2e: GraphModule(
2026-01-14T08:17:55.0593389Z   (conv): Module()
2026-01-14T08:17:55.0593664Z   (bn): Module()
2026-01-14T08:17:55.0593940Z )
2026-01-14T08:17:55.0594076Z 
2026-01-14T08:17:55.0594081Z 
2026-01-14T08:17:55.0594085Z 
2026-01-14T08:17:55.0594222Z def forward(self, x):
2026-01-14T08:17:55.0594619Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:55.0595178Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:55.0596242Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01880793273448944, -45, -128, 127, torch.int8);  x = None
2026-01-14T08:17:55.0598142Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01880793273448944, -45, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:55.0600062Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:55.0600768Z     _scale_0 = self._scale_0
2026-01-14T08:17:55.0601139Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:17:55.0601558Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:17:55.0602774Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:17:55.0603789Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:17:55.0604746Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:17:55.0606211Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.016877712681889534, -13, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:17:55.0607719Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016877712681889534, -13, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:17:55.0608877Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:17:55.0609340Z     
2026-01-14T08:17:55.0609631Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:55.0610044Z onverted model fx: GraphModule(
2026-01-14T08:17:55.0610437Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:17:55.0610844Z )
2026-01-14T08:17:55.0610945Z 
2026-01-14T08:17:55.0610949Z 
2026-01-14T08:17:55.0610953Z 
2026-01-14T08:17:55.0611154Z def forward(self, x):
2026-01-14T08:17:55.0611853Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01880793273448944, -45, -128, 127, torch.int8);  x = None
2026-01-14T08:17:55.0613372Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01880793273448944, -45, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:17:55.0614518Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:17:55.0615487Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016877712681889534, -13, -128, 127, torch.int8);  conv = None
2026-01-14T08:17:55.0616969Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016877712681889534, -13, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:17:55.0617986Z     return dequantize_per_tensor_default_1
2026-01-14T08:17:55.0618285Z     
2026-01-14T08:17:55.0618583Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:55.0618998Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:17:55.0619243Z          [0., 0., 0.],
2026-01-14T08:17:55.0619472Z          [0., 0., 0.]],
2026-01-14T08:17:55.0619614Z 
2026-01-14T08:17:55.0619710Z         [[0., 0., 0.],
2026-01-14T08:17:55.0619922Z          [0., 0., 0.],
2026-01-14T08:17:55.0620146Z          [0., 0., 0.]],
2026-01-14T08:17:55.0620285Z 
2026-01-14T08:17:55.0620362Z         [[0., 0., 0.],
2026-01-14T08:17:55.0620584Z          [0., 0., 0.],
2026-01-14T08:17:55.0620794Z          [0., 0., 0.]]])
2026-01-14T08:17:55.0621042Z model pt2e: GraphModule(
2026-01-14T08:17:55.0621277Z   (conv): Module()
2026-01-14T08:17:55.0621496Z   (bn): Module()
2026-01-14T08:17:55.0621806Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:55.0622915Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0188]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:55.0624324Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5603605508804321, max_val=3.2356624603271484)
2026-01-14T08:17:55.0624904Z   )
2026-01-14T08:17:55.0625208Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:55.0626304Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:17:55.0627618Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2940981984138489, max_val=0.32268622517585754)
2026-01-14T08:17:55.0628206Z   )
2026-01-14T08:17:55.0628490Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:55.0629591Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0169]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:55.0630875Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9461743831634521, max_val=2.3577661514282227)
2026-01-14T08:17:55.0631453Z   )
2026-01-14T08:17:55.0631638Z )
2026-01-14T08:17:55.0631738Z 
2026-01-14T08:17:55.0631742Z 
2026-01-14T08:17:55.0631746Z 
2026-01-14T08:17:55.0631834Z def forward(self, x):
2026-01-14T08:17:55.0632148Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:17:55.0632514Z     conv_weight = self.conv.weight
2026-01-14T08:17:55.0632810Z     bn_weight = self.bn.weight
2026-01-14T08:17:55.0633073Z     bn_bias = self.bn.bias
2026-01-14T08:17:55.0633348Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:17:55.0633675Z     bn_running_var = self.bn.running_var
2026-01-14T08:17:55.0634090Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:17:55.0634581Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:55.0635238Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:17:55.0635844Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:17:55.0636263Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:17:55.0636714Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:17:55.0637194Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:17:55.0637735Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:17:55.0638365Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:17:55.0639313Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:17:55.0640255Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:17:55.0640854Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:17:55.0641911Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:17:55.0643020Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:17:55.0643676Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:17:55.0644111Z     
2026-01-14T08:17:55.0644403Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:55.0644808Z model fx: GraphModule(
2026-01-14T08:17:55.0645160Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:55.0646323Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0188]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:55.0647631Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5603605508804321, max_val=3.2356624603271484)
2026-01-14T08:17:55.0648202Z   )
2026-01-14T08:17:55.0648404Z   (conv): ConvBn1d(
2026-01-14T08:17:55.0648667Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:17:55.0649138Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:17:55.0649961Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:55.0651055Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:17:55.0652467Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2940981984138489, max_val=0.32268622517585754)
2026-01-14T08:17:55.0653051Z     )
2026-01-14T08:17:55.0653251Z   )
2026-01-14T08:17:55.0653554Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:17:55.0654648Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0169]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:17:55.0655958Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9461743831634521, max_val=2.3577661514282227)
2026-01-14T08:17:55.0656532Z   )
2026-01-14T08:17:55.0656721Z )
2026-01-14T08:17:55.0656824Z 
2026-01-14T08:17:55.0656829Z 
2026-01-14T08:17:55.0656832Z 
2026-01-14T08:17:55.0656937Z def forward(self, x):
2026-01-14T08:17:55.0657309Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:17:55.0658030Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:17:55.0658634Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:17:55.0659113Z     return activation_post_process_1
2026-01-14T08:17:55.0659391Z     
2026-01-14T08:17:55.0659702Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:17:55.0660113Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:17:55.0660361Z          [0., 0., 0.],
2026-01-14T08:17:55.0660588Z          [0., 0., 0.]],
2026-01-14T08:17:55.0660733Z 
2026-01-14T08:17:55.0660813Z         [[0., 0., 0.],
2026-01-14T08:17:55.0661035Z          [0., 0., 0.],
2026-01-14T08:17:55.0661246Z          [0., 0., 0.]],
2026-01-14T08:17:55.0661398Z 
2026-01-14T08:18:03.8851291Z         [[0., 0., 0.],
2026-01-14T08:18:03.8851682Z          [0., 0., 0.],
2026-01-14T08:18:03.8852084Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:18:03.8852560Z converted model pt2e: GraphModule(
2026-01-14T08:18:03.8852939Z   (conv): Module()
2026-01-14T08:18:03.8853214Z   (bn): Module()
2026-01-14T08:18:03.8853490Z )
2026-01-14T08:18:03.8853626Z 
2026-01-14T08:18:03.8853645Z 
2026-01-14T08:18:03.8853650Z 
2026-01-14T08:18:03.8853769Z def forward(self, x):
2026-01-14T08:18:03.8854177Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:03.8854732Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:18:03.8855815Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01880793273448944, -45, -128, 127, torch.int8);  x = None
2026-01-14T08:18:03.8857710Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01880793273448944, -45, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:03.8858972Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:18:03.8859528Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:18:03.8860697Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0025408363435417414, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:18:03.8861617Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:18:03.8862556Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:18:03.8864000Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.016878198832273483, -13, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:18:03.8865498Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.016878198832273483, -13, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:18:03.8866679Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:18:03.8867137Z     
2026-01-14T08:18:03.8867440Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:03.8867856Z onverted model fx: GraphModule(
2026-01-14T08:18:03.8868249Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:18:03.8868662Z )
2026-01-14T08:18:03.8868764Z 
2026-01-14T08:18:03.8868768Z 
2026-01-14T08:18:03.8868772Z 
2026-01-14T08:18:03.8868873Z def forward(self, x):
2026-01-14T08:18:03.8869557Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01880793273448944, -45, -128, 127, torch.int8);  x = None
2026-01-14T08:18:03.8870976Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01880793273448944, -45, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:03.8872257Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:18:03.8873235Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016878198832273483, -13, -128, 127, torch.int8);  conv = None
2026-01-14T08:18:03.8874711Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016878198832273483, -13, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:18:03.8875716Z     return dequantize_per_tensor_default_1
2026-01-14T08:18:03.8876015Z     
2026-01-14T08:18:03.8876304Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:03.8876715Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:18:03.8876972Z          [0., 0., 0.],
2026-01-14T08:18:03.8877185Z          [0., 0., 0.]],
2026-01-14T08:18:03.8877335Z 
2026-01-14T08:18:03.8877429Z         [[0., 0., 0.],
2026-01-14T08:18:03.8877640Z          [0., 0., 0.],
2026-01-14T08:18:03.8877866Z          [0., 0., 0.]],
2026-01-14T08:18:03.8878008Z 
2026-01-14T08:18:03.8878086Z         [[0., 0., 0.],
2026-01-14T08:18:03.8878312Z          [0., 0., 0.],
2026-01-14T08:18:03.8878524Z          [0., 0., 0.]]])
2026-01-14T08:18:03.8878774Z model pt2e: GraphModule(
2026-01-14T08:18:03.8879012Z   (conv1): Module()
2026-01-14T08:18:03.8879230Z   (bn1): Module()
2026-01-14T08:18:03.8879448Z   (conv2): Module()
2026-01-14T08:18:03.8879651Z   (bn2): Module()
2026-01-14T08:18:03.8879969Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:03.8881063Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0188]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:03.8882393Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5603605508804321, max_val=3.2356624603271484)
2026-01-14T08:18:03.8882968Z   )
2026-01-14T08:18:03.8883266Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:03.8884507Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:18:03.8886033Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2563, -0.2799]), max_val=tensor([0.3101, 0.1970, 0.1855]))
2026-01-14T08:18:03.8886770Z   )
2026-01-14T08:18:03.8887058Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:03.8888241Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:18:03.8889773Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3263, -0.3276, -0.3045]), max_val=tensor([0.1376, 0.2760, 0.3298]))
2026-01-14T08:18:03.8890498Z   )
2026-01-14T08:18:03.8890790Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:03.8891875Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0132]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:03.8893271Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6533392667770386, max_val=1.7188055515289307)
2026-01-14T08:18:03.8893859Z   )
2026-01-14T08:18:03.8894144Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:03.8895240Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:03.8896601Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.403315544128418, max_val=1.3918161392211914)
2026-01-14T08:18:03.8897165Z   )
2026-01-14T08:18:03.8897351Z )
2026-01-14T08:18:03.8897453Z 
2026-01-14T08:18:03.8897458Z 
2026-01-14T08:18:03.8897462Z 
2026-01-14T08:18:03.8897551Z def forward(self, x):
2026-01-14T08:18:03.8897868Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:03.8898236Z     conv1_weight = self.conv1.weight
2026-01-14T08:18:03.8898546Z     bn1_weight = self.bn1.weight
2026-01-14T08:18:03.8898818Z     bn1_bias = self.bn1.bias
2026-01-14T08:18:03.8899098Z     conv2_weight = self.conv2.weight
2026-01-14T08:18:03.8899401Z     conv2_bias = self.conv2.bias
2026-01-14T08:18:03.8899670Z     bn2_weight = self.bn2.weight
2026-01-14T08:18:03.8899948Z     bn2_bias = self.bn2.bias
2026-01-14T08:18:03.8900227Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:18:03.8900557Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:18:03.8900915Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:18:03.8901298Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:18:03.8901612Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:18:03.8901976Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:18:03.8902465Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:03.8903124Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:18:03.8903904Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:18:03.8904511Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:18:03.8904951Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:18:03.8905403Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:18:03.8905894Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:18:03.8906525Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:18:03.8907156Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:18:03.8907857Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:18:03.8908473Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:18:03.8908927Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:18:03.8909416Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:18:03.8909916Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T08:18:03.8910508Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:18:03.8911170Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:18:03.8912142Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:18:03.8913090Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T08:18:03.8913690Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T08:18:03.8914793Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:18:03.8915928Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:18:03.8917029Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:18:10.6211931Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:18:10.6212722Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T08:18:10.6213388Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T08:18:10.6214005Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:18:10.6215125Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:18:10.6216276Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:18:10.6216944Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:18:10.6217386Z     
2026-01-14T08:18:10.6217695Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:10.6218095Z model fx: GraphModule(
2026-01-14T08:18:10.6218445Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:10.6219543Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0188]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:10.6220873Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5603605508804321, max_val=3.2356624603271484)
2026-01-14T08:18:10.6221455Z   )
2026-01-14T08:18:10.6221634Z   (conv1): ConvBn1d(
2026-01-14T08:18:10.6221903Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:18:10.6222374Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:18:10.6222907Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:10.6224292Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:18:10.6225832Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3263, -0.3276, -0.3045]), max_val=tensor([0.1376, 0.2760, 0.3298]))
2026-01-14T08:18:10.6226572Z     )
2026-01-14T08:18:10.6226747Z   )
2026-01-14T08:18:10.6227046Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:10.6228154Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0132]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:10.6229451Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6533392667770386, max_val=1.7188055515289307)
2026-01-14T08:18:10.6230040Z   )
2026-01-14T08:18:10.6230224Z   (conv2): ConvBn1d(
2026-01-14T08:18:10.6230471Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:18:10.6230915Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:18:10.6231445Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:10.6232605Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:18:10.6234130Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2563, -0.2799]), max_val=tensor([0.3101, 0.1970, 0.1855]))
2026-01-14T08:18:10.6234861Z     )
2026-01-14T08:18:10.6235035Z   )
2026-01-14T08:18:10.6235438Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:10.6236547Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:10.6237834Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.403315544128418, max_val=1.3918161392211914)
2026-01-14T08:18:10.6238412Z   )
2026-01-14T08:18:10.6238586Z )
2026-01-14T08:18:10.6238700Z 
2026-01-14T08:18:10.6238705Z 
2026-01-14T08:18:10.6238709Z 
2026-01-14T08:18:10.6238797Z def forward(self, x):
2026-01-14T08:18:10.6239184Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:10.6239772Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:18:10.6240397Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:18:10.6241008Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:18:10.6241623Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:18:10.6242097Z     return activation_post_process_2
2026-01-14T08:18:10.6242382Z     
2026-01-14T08:18:10.6242685Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:10.6243074Z diff: tensor([[[0.],
2026-01-14T08:18:10.6243305Z          [0.],
2026-01-14T08:18:10.6243494Z          [0.]],
2026-01-14T08:18:10.6243616Z 
2026-01-14T08:18:10.6243704Z         [[0.],
2026-01-14T08:18:10.6243891Z          [0.],
2026-01-14T08:18:10.6244087Z          [0.]],
2026-01-14T08:18:10.6244203Z 
2026-01-14T08:18:10.6244299Z         [[0.],
2026-01-14T08:18:10.6244503Z          [0.],
2026-01-14T08:18:10.6244719Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:18:10.6245039Z converted model pt2e: GraphModule(
2026-01-14T08:18:10.6245314Z   (conv1): Module()
2026-01-14T08:18:10.6245542Z   (bn1): Module()
2026-01-14T08:18:10.6245749Z   (conv2): Module()
2026-01-14T08:18:10.6245969Z   (bn2): Module()
2026-01-14T08:18:10.6246167Z )
2026-01-14T08:18:10.6246283Z 
2026-01-14T08:18:10.6246287Z 
2026-01-14T08:18:10.6246360Z 
2026-01-14T08:18:10.6246452Z def forward(self, x):
2026-01-14T08:18:10.6246772Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:10.6247139Z     conv2_bias = self.conv2.bias
2026-01-14T08:18:10.6247490Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:18:10.6247901Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:18:10.6248721Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01880793273448944, -45, -128, 127, torch.int8);  x = None
2026-01-14T08:18:10.6250341Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01880793273448944, -45, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:10.6251573Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:18:10.6252445Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:18:10.6252985Z     _scale_0 = self._scale_0
2026-01-14T08:18:10.6253268Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:18:10.6253556Z     _scale_1 = self._scale_1
2026-01-14T08:18:10.6253829Z     _zero_point_1 = self._zero_point_1
2026-01-14T08:18:10.6254151Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T08:18:10.6255210Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T08:18:10.6256262Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:18:10.6257235Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T08:18:10.6258843Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.013224096968770027, -3, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T08:18:10.6260351Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.013224096968770027, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:18:10.6261361Z     quantize_per_channel = self._frozen_param1
2026-01-14T08:18:10.6262378Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:18:10.6263971Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T08:18:10.6265382Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.010961300693452358, 0, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T08:18:10.6266880Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010961300693452358, 0, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:18:10.6268039Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:18:10.6268488Z     
2026-01-14T08:18:10.6268798Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:10.6269207Z onverted model fx: GraphModule(
2026-01-14T08:18:10.6269618Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:18:10.6270160Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:18:10.6270579Z )
2026-01-14T08:18:10.6270680Z 
2026-01-14T08:18:10.6270684Z 
2026-01-14T08:18:10.6270688Z 
2026-01-14T08:18:10.6270870Z def forward(self, x):
2026-01-14T08:18:10.6271561Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01880793273448944, -45, -128, 127, torch.int8);  x = None
2026-01-14T08:18:10.6272985Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01880793273448944, -45, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:10.6274145Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:18:10.6275135Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.013224096968770027, -3, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:18:10.6276620Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.013224096968770027, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:18:12.7460175Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:18:12.7461728Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.010961300693452358, 0, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:18:12.7463209Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010961300693452358, 0, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:18:12.7464234Z     return dequantize_per_tensor_default_2
2026-01-14T08:18:12.7464526Z     
2026-01-14T08:18:12.7464842Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:12.7465521Z diff: tensor([[[0.],
2026-01-14T08:18:12.7465739Z          [0.],
2026-01-14T08:18:12.7465947Z          [0.]],
2026-01-14T08:18:12.7466070Z 
2026-01-14T08:18:12.7466147Z         [[0.],
2026-01-14T08:18:12.7466349Z          [0.],
2026-01-14T08:18:12.7466543Z          [0.]],
2026-01-14T08:18:12.7466676Z 
2026-01-14T08:18:12.7466753Z         [[0.],
2026-01-14T08:18:12.7466940Z          [0.],
2026-01-14T08:18:12.7467140Z          [0.]]])
2026-01-14T08:18:12.7467354Z model pt2e: GraphModule(
2026-01-14T08:18:12.7467635Z   (conv1): Module()
2026-01-14T08:18:12.7467854Z   (bn1): Module()
2026-01-14T08:18:12.7468059Z   (conv2): Module()
2026-01-14T08:18:12.7468276Z   (bn2): Module()
2026-01-14T08:18:12.7468584Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:12.7469691Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0188]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:12.7471020Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5603605508804321, max_val=3.2356624603271484)
2026-01-14T08:18:12.7471593Z   )
2026-01-14T08:18:12.7471894Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:12.7473086Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:18:12.7474407Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.31014329195022583)
2026-01-14T08:18:12.7474998Z   )
2026-01-14T08:18:12.7475283Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:12.7476400Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:18:12.7477711Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:18:12.7478441Z   )
2026-01-14T08:18:12.7478739Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:12.7479826Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0132]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:12.7481114Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.652099370956421, max_val=1.720017671585083)
2026-01-14T08:18:12.7481674Z   )
2026-01-14T08:18:12.7481971Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:12.7483063Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:12.7484349Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4020289182662964, max_val=1.3896838426589966)
2026-01-14T08:18:12.7484930Z   )
2026-01-14T08:18:12.7485100Z )
2026-01-14T08:18:12.7485210Z 
2026-01-14T08:18:12.7485215Z 
2026-01-14T08:18:12.7485219Z 
2026-01-14T08:18:12.7485305Z def forward(self, x):
2026-01-14T08:18:12.7485620Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:12.7485985Z     conv1_weight = self.conv1.weight
2026-01-14T08:18:12.7486287Z     bn1_weight = self.bn1.weight
2026-01-14T08:18:12.7486560Z     bn1_bias = self.bn1.bias
2026-01-14T08:18:12.7486836Z     conv2_weight = self.conv2.weight
2026-01-14T08:18:12.7487124Z     conv2_bias = self.conv2.bias
2026-01-14T08:18:12.7487408Z     bn2_weight = self.bn2.weight
2026-01-14T08:18:12.7487668Z     bn2_bias = self.bn2.bias
2026-01-14T08:18:12.7488020Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:18:12.7488339Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:18:12.7488711Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:18:12.7489104Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:18:12.7489420Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:18:12.7489789Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:18:12.7490267Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:12.7490944Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:18:12.7491712Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:18:12.7492437Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:18:12.7492874Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:18:12.7493324Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:18:12.7493813Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:18:12.7494365Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:18:12.7495005Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:18:12.7495693Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:18:12.7496327Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:18:12.7496783Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:18:12.7497259Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:18:12.7497770Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T08:18:12.7498350Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:18:12.7499022Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:18:12.7500069Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:18:12.7501010Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T08:18:12.7501617Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T08:18:12.7502715Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:18:12.7503869Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:18:12.7504976Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:18:12.7505989Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:18:12.7506592Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T08:18:12.7507231Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T08:18:12.7507858Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:18:12.7508926Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:18:12.7510063Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:18:12.7510724Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:18:12.7511204Z     
2026-01-14T08:18:12.7511512Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:12.7511915Z model fx: GraphModule(
2026-01-14T08:18:12.7512248Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:12.7513362Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0188]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:12.7514660Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5603605508804321, max_val=3.2356624603271484)
2026-01-14T08:18:12.7515239Z   )
2026-01-14T08:18:12.7515429Z   (conv1): ConvBn1d(
2026-01-14T08:18:12.7515684Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:18:12.7516169Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:18:12.7516688Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:12.7517777Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:18:12.7519083Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:18:12.7519675Z     )
2026-01-14T08:18:12.7519865Z   )
2026-01-14T08:18:12.7520150Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:12.7521255Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0132]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:12.7522535Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.652099370956421, max_val=1.720017671585083)
2026-01-14T08:18:12.7523115Z   )
2026-01-14T08:18:12.7523308Z   (conv2): ConvBn1d(
2026-01-14T08:18:12.7523546Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:18:12.7524058Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:18:12.7524578Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:31.4891470Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:18:31.4893373Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.31014329195022583)
2026-01-14T08:18:31.4894167Z     )
2026-01-14T08:18:31.4894403Z   )
2026-01-14T08:18:31.4894793Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:31.4896244Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:31.4898009Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4020289182662964, max_val=1.3896838426589966)
2026-01-14T08:18:31.4898768Z   )
2026-01-14T08:18:31.4899011Z )
2026-01-14T08:18:31.4899147Z 
2026-01-14T08:18:31.4899152Z 
2026-01-14T08:18:31.4899157Z 
2026-01-14T08:18:31.4899290Z def forward(self, x):
2026-01-14T08:18:31.4899775Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:31.4900559Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:18:31.4901367Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:18:31.4902181Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:18:31.4902991Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:18:31.4903947Z     return activation_post_process_2
2026-01-14T08:18:31.4904318Z     
2026-01-14T08:18:31.4904707Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:31.4905234Z diff: tensor([[[0.],
2026-01-14T08:18:31.4905517Z          [0.],
2026-01-14T08:18:31.4905783Z          [0.]],
2026-01-14T08:18:31.4905939Z 
2026-01-14T08:18:31.4906041Z         [[0.],
2026-01-14T08:18:31.4906301Z          [0.],
2026-01-14T08:18:31.4906550Z          [0.]],
2026-01-14T08:18:31.4906719Z 
2026-01-14T08:18:31.4906820Z         [[0.],
2026-01-14T08:18:31.4907078Z          [0.],
2026-01-14T08:18:31.4907370Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:18:31.4907779Z converted model pt2e: GraphModule(
2026-01-14T08:18:31.4908140Z   (conv1): Module()
2026-01-14T08:18:31.4908431Z   (bn1): Module()
2026-01-14T08:18:31.4908700Z   (conv2): Module()
2026-01-14T08:18:31.4908987Z   (bn2): Module()
2026-01-14T08:18:31.4909255Z )
2026-01-14T08:18:31.4909392Z 
2026-01-14T08:18:31.4909414Z 
2026-01-14T08:18:31.4909419Z 
2026-01-14T08:18:31.4909543Z def forward(self, x):
2026-01-14T08:18:31.4909880Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:31.4910297Z     conv2_bias = self.conv2.bias
2026-01-14T08:18:31.4910647Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:18:31.4911062Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:18:31.4911889Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01880793273448944, -45, -128, 127, torch.int8);  x = None
2026-01-14T08:18:31.4913333Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01880793273448944, -45, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:31.4914539Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:18:31.4915328Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:18:31.4915906Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T08:18:31.4916939Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.002597068203613162, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T08:18:31.4917878Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:18:31.4918849Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T08:18:31.4920316Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.013223988004028797, -3, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T08:18:31.4921824Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.013223988004028797, -3, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:18:31.4922842Z     quantize_per_tensor = self._frozen_param1
2026-01-14T08:18:31.4923741Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0024561204481869936, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:18:31.4925193Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T08:18:31.4926589Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.010947893373668194, 0, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T08:18:31.4928077Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.010947893373668194, 0, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T08:18:31.4929283Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T08:18:31.4929745Z     
2026-01-14T08:18:31.4930051Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:31.4930456Z onverted model fx: GraphModule(
2026-01-14T08:18:31.4930865Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:18:31.4931403Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:18:31.4931816Z )
2026-01-14T08:18:31.4931917Z 
2026-01-14T08:18:31.4931921Z 
2026-01-14T08:18:31.4931925Z 
2026-01-14T08:18:31.4932016Z def forward(self, x):
2026-01-14T08:18:31.4932806Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01880793273448944, -45, -128, 127, torch.int8);  x = None
2026-01-14T08:18:31.4934237Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01880793273448944, -45, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:31.4935400Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:18:31.4936385Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.013223988004028797, -3, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:18:31.4937864Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.013223988004028797, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:18:31.4939053Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:18:31.4940046Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.010947893373668194, 0, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:18:31.4941581Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010947893373668194, 0, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:18:31.4942582Z     return dequantize_per_tensor_default_2
2026-01-14T08:18:31.4942883Z     
2026-01-14T08:18:31.4943175Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:31.4943576Z diff: tensor([[[0.],
2026-01-14T08:18:31.4943793Z          [0.],
2026-01-14T08:18:31.4944002Z          [0.]],
2026-01-14T08:18:31.4944125Z 
2026-01-14T08:18:31.4944203Z         [[0.],
2026-01-14T08:18:31.4944409Z          [0.],
2026-01-14T08:18:31.4944598Z          [0.]],
2026-01-14T08:18:31.4944729Z 
2026-01-14T08:18:31.4944805Z         [[0.],
2026-01-14T08:18:31.4945008Z          [0.],
2026-01-14T08:18:31.4945198Z          [0.]]])
2026-01-14T08:18:31.4945609Z [32mPASSED[0m
2026-01-14T08:18:31.4946379Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T08:18:31.4947480Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T08:18:31.4948152Z   (conv): Module()
2026-01-14T08:18:31.4948372Z   (bn): Module()
2026-01-14T08:18:31.4948700Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:31.4949964Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:31.4951274Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:18:31.4951842Z   )
2026-01-14T08:18:31.4952141Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:31.4953444Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:18:31.4954960Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2935, -0.3313, -0.3129]), max_val=tensor([0.2532, 0.1628, 0.3013]))
2026-01-14T08:18:31.4955698Z   )
2026-01-14T08:18:31.4955982Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:31.4957085Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:31.4958325Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.410499095916748)
2026-01-14T08:18:31.4958837Z   )
2026-01-14T08:18:31.4959020Z )
2026-01-14T08:18:31.4959119Z 
2026-01-14T08:18:31.4959123Z 
2026-01-14T08:18:31.4959127Z 
2026-01-14T08:18:31.4959216Z def forward(self, x):
2026-01-14T08:18:31.4959532Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:31.4959898Z     conv_weight = self.conv.weight
2026-01-14T08:18:31.4960188Z     conv_bias = self.conv.bias
2026-01-14T08:18:31.4960458Z     bn_weight = self.bn.weight
2026-01-14T08:18:31.4960717Z     bn_bias = self.bn.bias
2026-01-14T08:18:31.4960990Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:18:31.4961303Z     bn_running_var = self.bn.running_var
2026-01-14T08:18:31.4961661Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:18:31.4962132Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:40.3638762Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:18:40.3639645Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:18:40.3640219Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:18:40.3641124Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:18:40.3641759Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:18:40.3642470Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:18:40.3643302Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:18:40.3644203Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:18:40.3645690Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:18:40.3647037Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:18:40.3647823Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:18:40.3648670Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:18:40.3649639Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:18:40.3662605Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:18:40.3663656Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:18:40.3664241Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:18:40.3664851Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:18:40.3665281Z     
2026-01-14T08:18:40.3665593Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:40.3666198Z model fx: GraphModule(
2026-01-14T08:18:40.3666556Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:40.3667671Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:40.3668979Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:18:40.3669558Z   )
2026-01-14T08:18:40.3669749Z   (conv): ConvBnReLU1d(
2026-01-14T08:18:40.3670014Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:18:40.3670498Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:18:40.3671016Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:40.3672174Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:18:40.3673735Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2935, -0.3313, -0.3129]), max_val=tensor([0.2532, 0.1628, 0.3013]))
2026-01-14T08:18:40.3674469Z     )
2026-01-14T08:18:40.3674663Z   )
2026-01-14T08:18:40.3674953Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:40.3676065Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:40.3677309Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.410499095916748)
2026-01-14T08:18:40.3677822Z   )
2026-01-14T08:18:40.3678006Z )
2026-01-14T08:18:40.3678111Z 
2026-01-14T08:18:40.3678115Z 
2026-01-14T08:18:40.3678119Z 
2026-01-14T08:18:40.3678206Z def forward(self, x):
2026-01-14T08:18:40.3678584Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:40.3679260Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:18:40.3679872Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:18:40.3680332Z     return activation_post_process_1
2026-01-14T08:18:40.3680616Z     
2026-01-14T08:18:40.3680908Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:40.3681317Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:18:40.3681557Z          [0., 0., 0.],
2026-01-14T08:18:40.3681819Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:18:40.3682136Z converted model pt2e: GraphModule(
2026-01-14T08:18:40.3682421Z   (conv): Module()
2026-01-14T08:18:40.3682628Z   (bn): Module()
2026-01-14T08:18:40.3682844Z )
2026-01-14T08:18:40.3682945Z 
2026-01-14T08:18:40.3682949Z 
2026-01-14T08:18:40.3682952Z 
2026-01-14T08:18:40.3683055Z def forward(self, x):
2026-01-14T08:18:40.3683357Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:40.3683739Z     conv_bias = self.conv.bias
2026-01-14T08:18:40.3684056Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:18:40.3684857Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:18:40.3686283Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:40.3687473Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:18:40.3688004Z     _scale_0 = self._scale_0
2026-01-14T08:18:40.3688850Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:18:40.3689183Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:18:40.3690196Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:18:40.3691777Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:18:40.3692874Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:18:40.3693752Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005531368777155876, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:18:40.3695246Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005531368777155876, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:18:40.3696422Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:18:40.3696878Z     
2026-01-14T08:18:40.3697188Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:40.3697594Z onverted model fx: GraphModule(
2026-01-14T08:18:40.3697873Z   (conv): ConvReLU1d(
2026-01-14T08:18:40.3698217Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:18:40.3698617Z     (1): ReLU()
2026-01-14T08:18:40.3698821Z   )
2026-01-14T08:18:40.3698991Z )
2026-01-14T08:18:40.3699090Z 
2026-01-14T08:18:40.3699094Z 
2026-01-14T08:18:40.3699098Z 
2026-01-14T08:18:40.3699198Z def forward(self, x):
2026-01-14T08:18:40.3699874Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:18:40.3701292Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:40.3702521Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:18:40.3703485Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005531368777155876, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:18:40.3704976Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005531368777155876, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:18:40.3705992Z     return dequantize_per_tensor_default_1
2026-01-14T08:18:40.3706294Z     
2026-01-14T08:18:40.3706601Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:40.3706999Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:18:40.3707254Z          [0., 0., 0.],
2026-01-14T08:18:40.3707473Z          [0., 0., 0.]]])
2026-01-14T08:18:40.3707718Z model pt2e: GraphModule(
2026-01-14T08:18:40.3707951Z   (conv): Module()
2026-01-14T08:18:40.3708169Z   (bn): Module()
2026-01-14T08:18:40.3708474Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:40.3709568Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:40.3710865Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:18:40.3711430Z   )
2026-01-14T08:18:40.3711724Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:40.3712820Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:18:40.3714214Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3312976360321045, max_val=0.3013271391391754)
2026-01-14T08:18:40.3714796Z   )
2026-01-14T08:18:40.3715080Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:40.3716185Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:40.3717424Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4099854230880737)
2026-01-14T08:18:40.3717952Z   )
2026-01-14T08:18:40.3718139Z )
2026-01-14T08:18:40.3718239Z 
2026-01-14T08:18:40.3718243Z 
2026-01-14T08:18:40.3718246Z 
2026-01-14T08:18:40.3718335Z def forward(self, x):
2026-01-14T08:18:40.3718652Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:40.3719017Z     conv_weight = self.conv.weight
2026-01-14T08:18:40.3719315Z     conv_bias = self.conv.bias
2026-01-14T08:18:40.3719582Z     bn_weight = self.bn.weight
2026-01-14T08:18:50.9973162Z     bn_bias = self.bn.bias
2026-01-14T08:18:50.9973625Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:18:50.9974046Z     bn_running_var = self.bn.running_var
2026-01-14T08:18:50.9974530Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:18:50.9975162Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:50.9976042Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:18:50.9976823Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:18:50.9977388Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:18:50.9977984Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:18:50.9978627Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:18:50.9979357Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:18:50.9980497Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:18:50.9981423Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:18:50.9982903Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:18:50.9984262Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:18:50.9985053Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:18:50.9985894Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:18:50.9986816Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:18:50.9988191Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:18:50.9989535Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:18:50.9990298Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:18:50.9991075Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:18:50.9991647Z     
2026-01-14T08:18:50.9992034Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:50.9992569Z model fx: GraphModule(
2026-01-14T08:18:50.9993010Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:50.9994138Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:50.9995669Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:18:50.9996317Z   )
2026-01-14T08:18:50.9996521Z   (conv): ConvBnReLU1d(
2026-01-14T08:18:50.9996773Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:18:50.9997293Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:18:50.9997821Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:50.9998977Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:18:51.0000307Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3312976360321045, max_val=0.3013271391391754)
2026-01-14T08:18:51.0000883Z     )
2026-01-14T08:18:51.0001070Z   )
2026-01-14T08:18:51.0001359Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:51.0002471Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:51.0003723Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4099854230880737)
2026-01-14T08:18:51.0004236Z   )
2026-01-14T08:18:51.0004423Z )
2026-01-14T08:18:51.0004525Z 
2026-01-14T08:18:51.0004530Z 
2026-01-14T08:18:51.0004534Z 
2026-01-14T08:18:51.0004636Z def forward(self, x):
2026-01-14T08:18:51.0005002Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:51.0005590Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:18:51.0006190Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:18:51.0006667Z     return activation_post_process_1
2026-01-14T08:18:51.0007012Z     
2026-01-14T08:18:51.0007318Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:51.0007716Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:18:51.0007973Z          [0., 0., 0.],
2026-01-14T08:18:51.0008234Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:18:51.0008555Z converted model pt2e: GraphModule(
2026-01-14T08:18:51.0008845Z   (conv): Module()
2026-01-14T08:18:51.0009055Z   (bn): Module()
2026-01-14T08:18:51.0009265Z )
2026-01-14T08:18:51.0009395Z 
2026-01-14T08:18:51.0009399Z 
2026-01-14T08:18:51.0009403Z 
2026-01-14T08:18:51.0009493Z def forward(self, x):
2026-01-14T08:18:51.0009809Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:51.0010185Z     conv_bias = self.conv.bias
2026-01-14T08:18:51.0010514Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:18:51.0011327Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:18:51.0012834Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:51.0014039Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:18:51.0014605Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:18:51.0015493Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002608642913401127, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:18:51.0016954Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:18:51.0018007Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:18:51.0018879Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.00552935479208827, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:18:51.0020363Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.00552935479208827, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:18:51.0021511Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:18:51.0021971Z     
2026-01-14T08:18:51.0022279Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:51.0022680Z onverted model fx: GraphModule(
2026-01-14T08:18:51.0022956Z   (conv): ConvReLU1d(
2026-01-14T08:18:51.0023301Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:18:51.0023703Z     (1): ReLU()
2026-01-14T08:18:51.0023896Z   )
2026-01-14T08:18:51.0024078Z )
2026-01-14T08:18:51.0024176Z 
2026-01-14T08:18:51.0024184Z 
2026-01-14T08:18:51.0024188Z 
2026-01-14T08:18:51.0024276Z def forward(self, x):
2026-01-14T08:18:51.0024963Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:18:51.0026380Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:51.0027528Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:18:51.0028503Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.00552935479208827, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:18:51.0030045Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.00552935479208827, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:18:51.0031051Z     return dequantize_per_tensor_default_1
2026-01-14T08:18:51.0031353Z     
2026-01-14T08:18:51.0031644Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:51.0032050Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:18:51.0032293Z          [0., 0., 0.],
2026-01-14T08:18:51.0032523Z          [0., 0., 0.]]])
2026-01-14T08:18:51.0032938Z [32mPASSED[0m
2026-01-14T08:18:51.0033712Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:18:51.0034837Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:18:51.0035568Z   (conv): Module()
2026-01-14T08:18:51.0035788Z   (bn): Module()
2026-01-14T08:18:51.0036098Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:51.0037202Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:51.0038502Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:18:51.0039067Z   )
2026-01-14T08:18:51.0039363Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:51.0040525Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0026, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:18:51.0042124Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2639, -0.2941, -0.2608]), max_val=tensor([0.2795, 0.3227, 0.2891]))
2026-01-14T08:18:51.0042856Z   )
2026-01-14T08:18:51.0043143Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:59.9935679Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0039]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:59.9937422Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9981018900871277)
2026-01-14T08:18:59.9938128Z   )
2026-01-14T08:18:59.9938364Z )
2026-01-14T08:18:59.9938496Z 
2026-01-14T08:18:59.9938502Z 
2026-01-14T08:18:59.9938523Z 
2026-01-14T08:18:59.9938640Z def forward(self, x):
2026-01-14T08:18:59.9939045Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:59.9939562Z     conv_weight = self.conv.weight
2026-01-14T08:18:59.9939938Z     bn_weight = self.bn.weight
2026-01-14T08:18:59.9940296Z     bn_bias = self.bn.bias
2026-01-14T08:18:59.9940652Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:18:59.9941074Z     bn_running_var = self.bn.running_var
2026-01-14T08:18:59.9941545Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:18:59.9942171Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:59.9943044Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:18:59.9943821Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:18:59.9944388Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:18:59.9944976Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:18:59.9945597Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:18:59.9946332Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:18:59.9947146Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:18:59.9948743Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:18:59.9950260Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:18:59.9951052Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:18:59.9952466Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:18:59.9953840Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:18:59.9954586Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:18:59.9955394Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:18:59.9955951Z     
2026-01-14T08:18:59.9956350Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:59.9956874Z model fx: GraphModule(
2026-01-14T08:18:59.9957325Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:59.9958779Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:59.9960212Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:18:59.9960790Z   )
2026-01-14T08:18:59.9960977Z   (conv): ConvBnReLU1d(
2026-01-14T08:18:59.9961263Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:18:59.9961881Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:18:59.9962397Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:59.9963555Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0026, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:18:59.9965088Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2639, -0.2941, -0.2608]), max_val=tensor([0.2795, 0.3227, 0.2891]))
2026-01-14T08:18:59.9965827Z     )
2026-01-14T08:18:59.9966020Z   )
2026-01-14T08:18:59.9966312Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:18:59.9967430Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0039]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:18:59.9968666Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9981018900871277)
2026-01-14T08:18:59.9969190Z   )
2026-01-14T08:18:59.9969366Z )
2026-01-14T08:18:59.9969478Z 
2026-01-14T08:18:59.9969482Z 
2026-01-14T08:18:59.9969486Z 
2026-01-14T08:18:59.9969575Z def forward(self, x):
2026-01-14T08:18:59.9969954Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:18:59.9970534Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:18:59.9971141Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:18:59.9971599Z     return activation_post_process_1
2026-01-14T08:18:59.9971881Z     
2026-01-14T08:18:59.9972249Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:59.9972670Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:18:59.9972940Z          [0., 0., 0.],
2026-01-14T08:18:59.9973191Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:18:59.9973528Z converted model pt2e: GraphModule(
2026-01-14T08:18:59.9973806Z   (conv): Module()
2026-01-14T08:18:59.9974135Z   (bn): Module()
2026-01-14T08:18:59.9974338Z )
2026-01-14T08:18:59.9974453Z 
2026-01-14T08:18:59.9974457Z 
2026-01-14T08:18:59.9974461Z 
2026-01-14T08:18:59.9974551Z def forward(self, x):
2026-01-14T08:18:59.9974857Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:18:59.9975286Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:18:59.9976091Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:18:59.9977504Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:59.9978705Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:18:59.9979230Z     _scale_0 = self._scale_0
2026-01-14T08:18:59.9979514Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:18:59.9979846Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:18:59.9980853Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:18:59.9981879Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:18:59.9982821Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:18:59.9983860Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:18:59.9984815Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0039141252636909485, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:18:59.9986311Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0039141252636909485, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:18:59.9987483Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:18:59.9987950Z     
2026-01-14T08:18:59.9988250Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:59.9988670Z onverted model fx: GraphModule(
2026-01-14T08:18:59.9988935Z   (conv): ConvReLU1d(
2026-01-14T08:18:59.9989294Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:18:59.9989684Z     (1): ReLU()
2026-01-14T08:18:59.9989887Z   )
2026-01-14T08:18:59.9990058Z )
2026-01-14T08:18:59.9990174Z 
2026-01-14T08:18:59.9990179Z 
2026-01-14T08:18:59.9990183Z 
2026-01-14T08:18:59.9990271Z def forward(self, x):
2026-01-14T08:18:59.9990962Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:18:59.9992363Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:18:59.9993514Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:18:59.9994480Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0039141252636909485, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:18:59.9995985Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0039141252636909485, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:18:59.9997017Z     return dequantize_per_tensor_default_1
2026-01-14T08:18:59.9997306Z     
2026-01-14T08:18:59.9997664Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:18:59.9998061Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:18:59.9998320Z          [0., 0., 0.],
2026-01-14T08:18:59.9998537Z          [0., 0., 0.]]])
2026-01-14T08:18:59.9998787Z model pt2e: GraphModule(
2026-01-14T08:18:59.9999033Z   (conv): Module()
2026-01-14T08:18:59.9999241Z   (bn): Module()
2026-01-14T08:18:59.9999558Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:00.0000646Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:00.0001936Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:00.0002519Z   )
2026-01-14T08:19:00.0002805Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:00.0003926Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:19:00.0005222Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2940981984138489, max_val=0.32268622517585754)
2026-01-14T08:19:00.0005814Z   )
2026-01-14T08:19:00.0006096Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:08.2695233Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0040]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:08.2697368Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.0074307918548584)
2026-01-14T08:19:08.2698070Z   )
2026-01-14T08:19:08.2698301Z )
2026-01-14T08:19:08.2698433Z 
2026-01-14T08:19:08.2698439Z 
2026-01-14T08:19:08.2698443Z 
2026-01-14T08:19:08.2698591Z def forward(self, x):
2026-01-14T08:19:08.2698987Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:08.2699484Z     conv_weight = self.conv.weight
2026-01-14T08:19:08.2699857Z     bn_weight = self.bn.weight
2026-01-14T08:19:08.2700215Z     bn_bias = self.bn.bias
2026-01-14T08:19:08.2700561Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:19:08.2700989Z     bn_running_var = self.bn.running_var
2026-01-14T08:19:08.2701456Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:19:08.2702083Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:08.2702955Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:19:08.2703734Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:19:08.2704294Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:19:08.2704876Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:19:08.2705510Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:19:08.2706235Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:19:08.2707049Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:19:08.2708319Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:19:08.2709607Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:19:08.2710379Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:19:08.2711797Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:19:08.2713283Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:19:08.2714002Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:19:08.2714611Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:19:08.2715033Z     
2026-01-14T08:19:08.2715341Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:08.2715738Z model fx: GraphModule(
2026-01-14T08:19:08.2716084Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:08.2717189Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:08.2718479Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:08.2719057Z   )
2026-01-14T08:19:08.2719244Z   (conv): ConvBnReLU1d(
2026-01-14T08:19:08.2719525Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:19:08.2719993Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:19:08.2720523Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:08.2721608Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:19:08.2722917Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2940981984138489, max_val=0.32268622517585754)
2026-01-14T08:19:08.2723613Z     )
2026-01-14T08:19:08.2723790Z   )
2026-01-14T08:19:08.2724089Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:08.2725202Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0040]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:08.2726436Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.0074307918548584)
2026-01-14T08:19:08.2726962Z   )
2026-01-14T08:19:08.2727133Z )
2026-01-14T08:19:08.2727243Z 
2026-01-14T08:19:08.2727248Z 
2026-01-14T08:19:08.2727251Z 
2026-01-14T08:19:08.2727340Z def forward(self, x):
2026-01-14T08:19:08.2727707Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:08.2728315Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:19:08.2728924Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:19:08.2729403Z     return activation_post_process_1
2026-01-14T08:19:08.2729682Z     
2026-01-14T08:19:08.2729991Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:08.2730397Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:08.2730660Z          [0., 0., 0.],
2026-01-14T08:19:08.2730909Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:19:08.2731245Z converted model pt2e: GraphModule(
2026-01-14T08:19:08.2731520Z   (conv): Module()
2026-01-14T08:19:08.2731746Z   (bn): Module()
2026-01-14T08:19:08.2731946Z )
2026-01-14T08:19:08.2732169Z 
2026-01-14T08:19:08.2732173Z 
2026-01-14T08:19:08.2732177Z 
2026-01-14T08:19:08.2732267Z def forward(self, x):
2026-01-14T08:19:08.2732583Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:08.2732997Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:19:08.2733799Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:08.2735295Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:08.2736504Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:19:08.2737065Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:19:08.2737961Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0025408363435417414, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:19:08.2738882Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:19:08.2739819Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:19:08.2740856Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:19:08.2741741Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003950709011405706, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:19:08.2743222Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003950709011405706, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:19:08.2744394Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:19:08.2744851Z     
2026-01-14T08:19:08.2745142Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:08.2745557Z onverted model fx: GraphModule(
2026-01-14T08:19:08.2745824Z   (conv): ConvReLU1d(
2026-01-14T08:19:08.2746180Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:19:08.2746627Z     (1): ReLU()
2026-01-14T08:19:08.2746831Z   )
2026-01-14T08:19:08.2747005Z )
2026-01-14T08:19:08.2747118Z 
2026-01-14T08:19:08.2747122Z 
2026-01-14T08:19:08.2747126Z 
2026-01-14T08:19:08.2747220Z def forward(self, x):
2026-01-14T08:19:08.2747913Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:08.2749320Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:08.2750697Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:19:08.2751677Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003950709011405706, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:19:08.2753167Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003950709011405706, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:08.2754198Z     return dequantize_per_tensor_default_1
2026-01-14T08:19:08.2754486Z     
2026-01-14T08:19:08.2754788Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:08.2755183Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:08.2755441Z          [0., 0., 0.],
2026-01-14T08:19:08.2755669Z          [0., 0., 0.]]])
2026-01-14T08:19:08.2756087Z [32mPASSED[0m
2026-01-14T08:19:08.2756704Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T08:19:08.2757355Z   (conv): Module()
2026-01-14T08:19:08.2757686Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:08.2758860Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021, 0.0023, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:19:08.2760529Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1720, -0.2918, -0.2941]), max_val=tensor([0.2663, 0.2795, 0.3227]))
2026-01-14T08:19:08.2761278Z   )
2026-01-14T08:19:08.2761566Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:08.2762666Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:08.2763953Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:08.2764537Z   )
2026-01-14T08:19:08.2764836Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.0510561Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0006]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.0512290Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.16202233731746674)
2026-01-14T08:19:09.0512990Z   )
2026-01-14T08:19:09.0513241Z )
2026-01-14T08:19:09.0513373Z 
2026-01-14T08:19:09.0513379Z 
2026-01-14T08:19:09.0513384Z 
2026-01-14T08:19:09.0513516Z def forward(self, x):
2026-01-14T08:19:09.0513908Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:09.0514400Z     conv_weight = self.conv.weight
2026-01-14T08:19:09.0515048Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:19:09.0515904Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:09.0517417Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:19:09.0518555Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:19:09.0519253Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:19:09.0520033Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:19:09.0520595Z     
2026-01-14T08:19:09.0520979Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:09.0521470Z model fx: GraphModule(
2026-01-14T08:19:09.0521816Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.0522903Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.0524214Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:09.0524782Z   )
2026-01-14T08:19:09.0524984Z   (conv): ConvReLU1d(
2026-01-14T08:19:09.0525257Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:19:09.0525656Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.0526846Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021, 0.0023, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:19:09.0528400Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1720, -0.2918, -0.2941]), max_val=tensor([0.2663, 0.2795, 0.3227]))
2026-01-14T08:19:09.0529121Z     )
2026-01-14T08:19:09.0529309Z   )
2026-01-14T08:19:09.0529593Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.0530818Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0006]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.0532157Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.16202233731746674)
2026-01-14T08:19:09.0532678Z   )
2026-01-14T08:19:09.0532868Z )
2026-01-14T08:19:09.0532970Z 
2026-01-14T08:19:09.0532974Z 
2026-01-14T08:19:09.0532978Z 
2026-01-14T08:19:09.0533068Z def forward(self, x):
2026-01-14T08:19:09.0533455Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:09.0534037Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:19:09.0534648Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:19:09.0535126Z     return activation_post_process_1
2026-01-14T08:19:09.0535403Z     
2026-01-14T08:19:09.0535707Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:09.0536105Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:09.0536362Z          [0., 0., 0.],
2026-01-14T08:19:09.0536619Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:19:09.0536951Z converted model pt2e: GraphModule(
2026-01-14T08:19:09.0537224Z   (conv): Module()
2026-01-14T08:19:09.0537441Z )
2026-01-14T08:19:09.0537540Z 
2026-01-14T08:19:09.0537544Z 
2026-01-14T08:19:09.0537548Z 
2026-01-14T08:19:09.0537651Z def forward(self, x):
2026-01-14T08:19:09.0537952Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:09.0538320Z     _scale_0 = self._scale_0
2026-01-14T08:19:09.0538586Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:19:09.0538933Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:19:09.0540071Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:19:09.0541708Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:09.0543128Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:09.0544643Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:19:09.0545583Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:19:09.0546459Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0006353817298077047, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:19:09.0547947Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0006353817298077047, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:09.0549119Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:19:09.0549724Z     
2026-01-14T08:19:09.0550032Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:09.0550449Z onverted model fx: GraphModule(
2026-01-14T08:19:09.0550713Z   (conv): ConvReLU1d(
2026-01-14T08:19:09.0551108Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:19:09.0551540Z     (1): ReLU()
2026-01-14T08:19:09.0551746Z   )
2026-01-14T08:19:09.0551919Z )
2026-01-14T08:19:09.0552038Z 
2026-01-14T08:19:09.0552042Z 
2026-01-14T08:19:09.0552046Z 
2026-01-14T08:19:09.0552136Z def forward(self, x):
2026-01-14T08:19:09.0552836Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:09.0554360Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:09.0555524Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:19:09.0556492Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0006353817298077047, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:19:09.0557996Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0006353817298077047, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:09.0559026Z     return dequantize_per_tensor_default_1
2026-01-14T08:19:09.0559321Z     
2026-01-14T08:19:09.0559628Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:09.0560019Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:09.0560276Z          [0., 0., 0.],
2026-01-14T08:19:09.0560491Z          [0., 0., 0.]]])
2026-01-14T08:19:09.0560740Z model pt2e: GraphModule(
2026-01-14T08:19:09.0560987Z   (conv): Module()
2026-01-14T08:19:09.0561300Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.0562414Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:19:09.0563710Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2940996587276459, max_val=0.3226878345012665)
2026-01-14T08:19:09.0564295Z   )
2026-01-14T08:19:09.0564576Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.0565758Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.0567053Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:09.0567620Z   )
2026-01-14T08:19:09.0567926Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.0569015Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0006]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.0570265Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.1632835566997528)
2026-01-14T08:19:09.0570790Z   )
2026-01-14T08:19:09.0570968Z )
2026-01-14T08:19:09.0571078Z 
2026-01-14T08:19:09.0571082Z 
2026-01-14T08:19:09.0571086Z 
2026-01-14T08:19:09.0571173Z def forward(self, x):
2026-01-14T08:19:09.0571474Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:09.0571852Z     conv_weight = self.conv.weight
2026-01-14T08:19:09.0572465Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:19:09.0573109Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:09.0574021Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:19:09.0574869Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:19:09.0575411Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:19:09.0576012Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:19:09.0576438Z     
2026-01-14T08:19:09.0576742Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:09.0577136Z model fx: GraphModule(
2026-01-14T08:19:09.0577547Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.8210016Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.8211806Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:09.8212589Z   )
2026-01-14T08:19:09.8212796Z   (conv): ConvReLU1d(
2026-01-14T08:19:09.8213143Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:19:09.8213544Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.8214770Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:19:09.8216289Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2940996587276459, max_val=0.3226878345012665)
2026-01-14T08:19:09.8216877Z     )
2026-01-14T08:19:09.8217125Z   )
2026-01-14T08:19:09.8217423Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.8218662Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0006]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.8219995Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.1632835566997528)
2026-01-14T08:19:09.8220598Z   )
2026-01-14T08:19:09.8220769Z )
2026-01-14T08:19:09.8220872Z 
2026-01-14T08:19:09.8220892Z 
2026-01-14T08:19:09.8221196Z 
2026-01-14T08:19:09.8221294Z def forward(self, x):
2026-01-14T08:19:09.8221679Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:09.8222354Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:19:09.8223042Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:19:09.8223579Z     return activation_post_process_1
2026-01-14T08:19:09.8223860Z     
2026-01-14T08:19:09.8224217Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:09.8224640Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:09.8224987Z          [0., 0., 0.],
2026-01-14T08:19:09.8225267Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:19:09.8225592Z converted model pt2e: GraphModule(
2026-01-14T08:19:09.8225949Z   (conv): Module()
2026-01-14T08:19:09.8226154Z )
2026-01-14T08:19:09.8226271Z 
2026-01-14T08:19:09.8226275Z 
2026-01-14T08:19:09.8226279Z 
2026-01-14T08:19:09.8226373Z def forward(self, x):
2026-01-14T08:19:09.8226760Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:09.8227169Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:19:09.8228375Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0025408491492271423, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:09.8229950Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:09.8231545Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:09.8233251Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:19:09.8234273Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:19:09.8235392Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0006403276929631829, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:19:09.8237052Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0006403276929631829, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:19:09.8238289Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:19:09.8238831Z     
2026-01-14T08:19:09.8239127Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:09.8239622Z onverted model fx: GraphModule(
2026-01-14T08:19:09.8239906Z   (conv): ConvReLU1d(
2026-01-14T08:19:09.8240360Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:19:09.8240835Z     (1): ReLU()
2026-01-14T08:19:09.8241076Z   )
2026-01-14T08:19:09.8241262Z )
2026-01-14T08:19:09.8241360Z 
2026-01-14T08:19:09.8241364Z 
2026-01-14T08:19:09.8241372Z 
2026-01-14T08:19:09.8241459Z def forward(self, x):
2026-01-14T08:19:09.8242222Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:09.8243801Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:09.8245096Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:19:09.8246153Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0006403276929631829, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:19:09.8247873Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0006403276929631829, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:09.8249059Z     return dequantize_per_tensor_default_1
2026-01-14T08:19:09.8249359Z     
2026-01-14T08:19:09.8249832Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:09.8250278Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:09.8250522Z          [0., 0., 0.],
2026-01-14T08:19:09.8250751Z          [0., 0., 0.]]])
2026-01-14T08:19:09.8250987Z model pt2e: GraphModule(
2026-01-14T08:19:09.8251305Z   (conv): Module()
2026-01-14T08:19:09.8251621Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.8252886Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:19:09.8254523Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3263, -0.3276, -0.3045]), max_val=tensor([0.1376, 0.2760, 0.3298]))
2026-01-14T08:19:09.8255244Z   )
2026-01-14T08:19:09.8255540Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.8256637Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.8257994Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:09.8258574Z   )
2026-01-14T08:19:09.8258859Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.8259958Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([34], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.8261376Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.284900426864624, max_val=0.7360976338386536)
2026-01-14T08:19:09.8261947Z   )
2026-01-14T08:19:09.8262137Z )
2026-01-14T08:19:09.8262238Z 
2026-01-14T08:19:09.8262242Z 
2026-01-14T08:19:09.8262246Z 
2026-01-14T08:19:09.8262336Z def forward(self, x):
2026-01-14T08:19:09.8262657Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:09.8263024Z     conv_weight = self.conv.weight
2026-01-14T08:19:09.8263529Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:19:09.8264207Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:09.8265157Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:19:09.8266100Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:19:09.8266708Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:19:09.8267138Z     
2026-01-14T08:19:09.8267429Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:09.8267831Z model fx: GraphModule(
2026-01-14T08:19:09.8268171Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.8269252Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.8270541Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:09.8272018Z   )
2026-01-14T08:19:09.8272214Z   (conv): Conv1d(
2026-01-14T08:19:09.8272472Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:19:09.8272854Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.8274016Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:19:09.8275546Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3263, -0.3276, -0.3045]), max_val=tensor([0.1376, 0.2760, 0.3298]))
2026-01-14T08:19:09.8276283Z     )
2026-01-14T08:19:09.8276470Z   )
2026-01-14T08:19:09.8276753Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:09.8277949Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([34], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:09.8279237Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.284900426864624, max_val=0.7360976338386536)
2026-01-14T08:19:09.8279816Z   )
2026-01-14T08:19:09.8279988Z )
2026-01-14T08:19:09.8280097Z 
2026-01-14T08:19:09.8280101Z 
2026-01-14T08:19:09.8280106Z 
2026-01-14T08:19:09.8280193Z def forward(self, x):
2026-01-14T08:19:09.8280576Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:10.7648261Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:19:10.7649110Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:19:10.7649889Z     return activation_post_process_1
2026-01-14T08:19:10.7650257Z     
2026-01-14T08:19:10.7650670Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:10.7651200Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:10.7651563Z          [0., 0., 0.],
2026-01-14T08:19:10.7651882Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:19:10.7652420Z converted model pt2e: GraphModule(
2026-01-14T08:19:10.7652792Z   (conv): Module()
2026-01-14T08:19:10.7653392Z )
2026-01-14T08:19:10.7653531Z 
2026-01-14T08:19:10.7653536Z 
2026-01-14T08:19:10.7653541Z 
2026-01-14T08:19:10.7653676Z def forward(self, x):
2026-01-14T08:19:10.7654067Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:10.7654554Z     _scale_0 = self._scale_0
2026-01-14T08:19:10.7654902Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:19:10.7655361Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:19:10.7656911Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:19:10.7659067Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:10.7660960Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:10.7662988Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:19:10.7664769Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.007925482466816902, 34, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:19:10.7666760Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007925482466816902, 34, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:10.7668409Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:19:10.7669003Z     
2026-01-14T08:19:10.7669406Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:10.7669986Z onverted model fx: GraphModule(
2026-01-14T08:19:10.7670547Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:19:10.7671144Z )
2026-01-14T08:19:10.7671276Z 
2026-01-14T08:19:10.7671281Z 
2026-01-14T08:19:10.7671286Z 
2026-01-14T08:19:10.7671402Z def forward(self, x):
2026-01-14T08:19:10.7672306Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:10.7674188Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:10.7675716Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:19:10.7676995Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007925482466816902, 34, -128, 127, torch.int8);  conv = None
2026-01-14T08:19:10.7678960Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007925482466816902, 34, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:10.7680284Z     return dequantize_per_tensor_default_1
2026-01-14T08:19:10.7680677Z     
2026-01-14T08:19:10.7681061Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:10.7681594Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:10.7681916Z          [0., 0., 0.],
2026-01-14T08:19:10.7682212Z          [0., 0., 0.]]])
2026-01-14T08:19:10.7682521Z model pt2e: GraphModule(
2026-01-14T08:19:10.7682852Z   (conv): Module()
2026-01-14T08:19:10.7683277Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:10.7684814Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:19:10.7686553Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.327648401260376, max_val=0.32982930541038513)
2026-01-14T08:19:10.7687320Z   )
2026-01-14T08:19:10.7687710Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:10.7688915Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:10.7690191Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:10.7690774Z   )
2026-01-14T08:19:10.7691058Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:10.7692241Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([34], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:10.7693549Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.284900426864624, max_val=0.7398542761802673)
2026-01-14T08:19:10.7694113Z   )
2026-01-14T08:19:10.7694300Z )
2026-01-14T08:19:10.7694399Z 
2026-01-14T08:19:10.7694404Z 
2026-01-14T08:19:10.7694407Z 
2026-01-14T08:19:10.7694495Z def forward(self, x):
2026-01-14T08:19:10.7694809Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:10.7695175Z     conv_weight = self.conv.weight
2026-01-14T08:19:10.7695677Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:19:10.7696407Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:10.7697309Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:19:10.7698252Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:19:10.7698856Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:19:10.7699294Z     
2026-01-14T08:19:10.7699598Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:10.7699995Z model fx: GraphModule(
2026-01-14T08:19:10.7700340Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:10.7701431Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:10.7702727Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:19:10.7703304Z   )
2026-01-14T08:19:10.7703487Z   (conv): Conv1d(
2026-01-14T08:19:10.7703745Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:19:10.7704130Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:10.7705212Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:19:10.7706518Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.327648401260376, max_val=0.32982930541038513)
2026-01-14T08:19:10.7707100Z     )
2026-01-14T08:19:10.7707288Z   )
2026-01-14T08:19:10.7707574Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:10.7708738Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([34], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:10.7710035Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.284900426864624, max_val=0.7398542761802673)
2026-01-14T08:19:10.7710609Z   )
2026-01-14T08:19:10.7710779Z )
2026-01-14T08:19:10.7710892Z 
2026-01-14T08:19:10.7710897Z 
2026-01-14T08:19:10.7710901Z 
2026-01-14T08:19:10.7710988Z def forward(self, x):
2026-01-14T08:19:10.7711370Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:10.7711950Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:19:10.7712554Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:19:10.7713016Z     return activation_post_process_1
2026-01-14T08:19:10.7713306Z     
2026-01-14T08:19:10.7713597Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:10.7714007Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:10.7714261Z          [0., 0., 0.],
2026-01-14T08:19:10.7714509Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:19:10.7714839Z converted model pt2e: GraphModule(
2026-01-14T08:19:10.7715111Z   (conv): Module()
2026-01-14T08:19:10.7715325Z )
2026-01-14T08:19:10.7715425Z 
2026-01-14T08:19:10.7715429Z 
2026-01-14T08:19:10.7715433Z 
2026-01-14T08:19:10.7715520Z def forward(self, x):
2026-01-14T08:19:10.7715830Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:10.7716246Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:19:10.7717264Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0025970812421292067, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:10.7718761Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:10.7720188Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:10.7721730Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:19:10.7723086Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.007940215058624744, 34, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:19:44.8548340Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007940215058624744, 34, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:19:44.8549752Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:19:44.8550229Z     
2026-01-14T08:19:44.8550567Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:44.8550980Z onverted model fx: GraphModule(
2026-01-14T08:19:44.8551434Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:19:44.8551882Z )
2026-01-14T08:19:44.8551999Z 
2026-01-14T08:19:44.8552004Z 
2026-01-14T08:19:44.8552008Z 
2026-01-14T08:19:44.8552099Z def forward(self, x):
2026-01-14T08:19:44.8552782Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:19:44.8554209Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:44.8555375Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:19:44.8556585Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007940215058624744, 34, -128, 127, torch.int8);  conv = None
2026-01-14T08:19:44.8558068Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007940215058624744, 34, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:44.8559086Z     return dequantize_per_tensor_default_1
2026-01-14T08:19:44.8559377Z     
2026-01-14T08:19:44.8559683Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:44.8560080Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:19:44.8560337Z          [0., 0., 0.],
2026-01-14T08:19:44.8560552Z          [0., 0., 0.]]])
2026-01-14T08:19:44.8560971Z [32mPASSED[0m
2026-01-14T08:19:44.8561689Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T08:19:44.8562814Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:19:44.8563849Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T08:19:44.8564503Z   (conv): Module()
2026-01-14T08:19:44.8564831Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:44.8565949Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:19:44.8567345Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.5429]), max_val=tensor([-0.5429]))
2026-01-14T08:19:44.8568091Z   )
2026-01-14T08:19:44.8568376Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:44.8569481Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0012]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:44.8570793Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31662631034851074, max_val=-0.1489601731300354)
2026-01-14T08:19:44.8571371Z   )
2026-01-14T08:19:44.8571666Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:44.8572870Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:44.8574177Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.26761165261268616, max_val=0.3586132824420929)
2026-01-14T08:19:44.8574752Z   )
2026-01-14T08:19:44.8575044Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:44.8576150Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0005]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:44.8577445Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.04198697209358215, max_val=0.11820143461227417)
2026-01-14T08:19:44.8578031Z   )
2026-01-14T08:19:44.8578203Z )
2026-01-14T08:19:44.8578315Z 
2026-01-14T08:19:44.8578320Z 
2026-01-14T08:19:44.8578324Z 
2026-01-14T08:19:44.8578412Z def forward(self, x):
2026-01-14T08:19:44.8578728Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:44.8579093Z     conv_weight = self.conv.weight
2026-01-14T08:19:44.8579595Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:19:44.8580115Z     conv_bias = self.conv.bias
2026-01-14T08:19:44.8580519Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:44.8581511Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:19:44.8582431Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:19:44.8583347Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:19:44.8584178Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:19:44.8584707Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:19:44.8585361Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:19:44.8585792Z     
2026-01-14T08:19:44.8586101Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:44.8586507Z model fx: GraphModule(
2026-01-14T08:19:44.8586838Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:44.8587946Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0012]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:44.8589253Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31662631034851074, max_val=-0.1489601731300354)
2026-01-14T08:19:44.8589842Z   )
2026-01-14T08:19:44.8590035Z   (conv): Conv1d(
2026-01-14T08:19:44.8590258Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T08:19:44.8590621Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:44.8591705Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:19:44.8593168Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.5429]), max_val=tensor([-0.5429]))
2026-01-14T08:19:44.8593798Z     )
2026-01-14T08:19:44.8593991Z   )
2026-01-14T08:19:44.8594290Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:44.8595389Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:44.8596693Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.26761165261268616, max_val=0.3586132824420929)
2026-01-14T08:19:44.8597261Z   )
2026-01-14T08:19:44.8597463Z   (relu): ReLU(inplace=True)
2026-01-14T08:19:44.8597816Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:44.8598930Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0005]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:44.8600239Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.04198697209358215, max_val=0.11820143461227417)
2026-01-14T08:19:44.8600813Z   )
2026-01-14T08:19:44.8600997Z )
2026-01-14T08:19:44.8601096Z 
2026-01-14T08:19:44.8601101Z 
2026-01-14T08:19:44.8601104Z 
2026-01-14T08:19:44.8601205Z def forward(self, x):
2026-01-14T08:19:44.8601574Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:44.8602054Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:19:44.8602524Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:19:44.8603307Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:19:44.8603944Z     relu = self.relu(add);  add = None
2026-01-14T08:19:44.8604393Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:19:44.8604922Z     return activation_post_process_2
2026-01-14T08:19:44.8605195Z     
2026-01-14T08:19:44.8605499Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:44.8605944Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:19:44.8606309Z converted model pt2e: GraphModule(
2026-01-14T08:19:44.8606584Z   (conv): Module()
2026-01-14T08:19:44.8606803Z )
2026-01-14T08:19:44.8606904Z 
2026-01-14T08:19:44.8606908Z 
2026-01-14T08:19:44.8606911Z 
2026-01-14T08:19:44.8607000Z def forward(self, x):
2026-01-14T08:19:44.8607319Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:44.8607692Z     _scale_0 = self._scale_0
2026-01-14T08:19:44.8618284Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:19:44.8618709Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:19:44.8619877Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:19:44.8621003Z     conv_bias = self.conv.bias
2026-01-14T08:19:44.8621728Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.0012416718527674675, 127, -128, 127, torch.int8);  x = None
2026-01-14T08:19:44.8623035Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0012416718527674675, 127, -128, 127, torch.int8)
2026-01-14T08:19:45.4701704Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0012416718527674675, 127, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:45.4703626Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T08:19:45.4705102Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0014063265407457948, -128, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:19:45.4706611Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0014063265407457948, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:45.4708152Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T08:19:45.4709069Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:19:45.4709931Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.00046353504876606166, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:19:45.4711441Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.00046353504876606166, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:19:45.4712618Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:19:45.4713068Z     
2026-01-14T08:19:45.4713379Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:45.4713786Z onverted model fx: GraphModule(
2026-01-14T08:19:45.4714199Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T08:19:45.4714627Z   (relu): ReLU(inplace=True)
2026-01-14T08:19:45.4714882Z )
2026-01-14T08:19:45.4714987Z 
2026-01-14T08:19:45.4714991Z 
2026-01-14T08:19:45.4715000Z 
2026-01-14T08:19:45.4715101Z def forward(self, x):
2026-01-14T08:19:45.4715829Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.0012416718527674675, 127, -128, 127, torch.int8);  x = None
2026-01-14T08:19:45.4717361Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0012416718527674675, 127, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:19:45.4718406Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:19:45.4719225Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0014063265407457948, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:19:45.4720721Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0014063265407457948, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:19:45.4722137Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:19:45.4722847Z     relu = self.relu(add);  add = None
2026-01-14T08:19:45.4723645Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.00046353504876606166, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:19:45.4725151Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.00046353504876606166, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:19:45.4726175Z     return dequantize_per_tensor_default_2
2026-01-14T08:19:45.4726478Z     
2026-01-14T08:19:45.4726775Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:45.4727189Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T08:19:45.4727454Z model pt2e: GraphModule(
2026-01-14T08:19:45.4727768Z   (conv): Module()
2026-01-14T08:19:45.4728078Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:45.4729207Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:19:45.4730549Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5428858995437622, max_val=-0.5428858995437622)
2026-01-14T08:19:45.4731129Z   )
2026-01-14T08:19:45.4731424Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:45.4732616Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0012]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:45.4733923Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31662631034851074, max_val=-0.1489601731300354)
2026-01-14T08:19:45.4734514Z   )
2026-01-14T08:19:45.4734794Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:45.4735901Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:45.4737197Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.26761165261268616, max_val=0.3586132824420929)
2026-01-14T08:19:45.4737764Z   )
2026-01-14T08:19:45.4738058Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:45.4739153Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0005]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:45.4740460Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.04198697209358215, max_val=0.11820143461227417)
2026-01-14T08:19:45.4741048Z   )
2026-01-14T08:19:45.4741220Z )
2026-01-14T08:19:45.4741320Z 
2026-01-14T08:19:45.4741325Z 
2026-01-14T08:19:45.4741328Z 
2026-01-14T08:19:45.4741492Z def forward(self, x):
2026-01-14T08:19:45.4741795Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:19:45.4742175Z     conv_weight = self.conv.weight
2026-01-14T08:19:45.4742664Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:19:45.4743193Z     conv_bias = self.conv.bias
2026-01-14T08:19:45.4743584Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:45.4744475Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:19:45.4745399Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:19:45.4746305Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:19:45.4747129Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:19:45.4747653Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:19:45.4748248Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:19:45.4748687Z     
2026-01-14T08:19:45.4748978Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:19:45.4749383Z model fx: GraphModule(
2026-01-14T08:19:45.4749889Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:45.4751005Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0012]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:45.4752921Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31662631034851074, max_val=-0.1489601731300354)
2026-01-14T08:19:45.4753501Z   )
2026-01-14T08:19:45.4753704Z   (conv): Conv1d(
2026-01-14T08:19:45.4753929Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T08:19:45.4754293Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:45.4755373Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:19:45.4756698Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5428858995437622, max_val=-0.5428858995437622)
2026-01-14T08:19:45.4757284Z     )
2026-01-14T08:19:45.4757462Z   )
2026-01-14T08:19:45.4757757Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:45.4758857Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:45.4760167Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.26761165261268616, max_val=0.3586132824420929)
2026-01-14T08:19:45.4760749Z   )
2026-01-14T08:19:45.4760944Z   (relu): ReLU(inplace=True)
2026-01-14T08:19:45.4761307Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:19:45.4762405Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0005]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:19:45.4763724Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.04198697209358215, max_val=0.11820143461227417)
2026-01-14T08:19:45.4764290Z   )
2026-01-14T08:19:45.4764476Z )
2026-01-14T08:19:45.4764576Z 
2026-01-14T08:19:45.4764581Z 
2026-01-14T08:19:45.4764585Z 
2026-01-14T08:19:45.4764685Z def forward(self, x):
2026-01-14T08:19:45.4765139Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:19:45.4765616Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:19:45.4766084Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:20:03.3755306Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:20:03.3756557Z     relu = self.relu(add);  add = None
2026-01-14T08:20:03.3757352Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:20:03.3758152Z     return activation_post_process_2
2026-01-14T08:20:03.3758634Z     
2026-01-14T08:20:03.3759132Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:03.3759989Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:20:03.3760570Z converted model pt2e: GraphModule(
2026-01-14T08:20:03.3761026Z   (conv): Module()
2026-01-14T08:20:03.3761349Z )
2026-01-14T08:20:03.3761526Z 
2026-01-14T08:20:03.3761553Z 
2026-01-14T08:20:03.3761560Z 
2026-01-14T08:20:03.3761704Z def forward(self, x):
2026-01-14T08:20:03.3762224Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:20:03.3762919Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:20:03.3764682Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.004274691920727491, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:20:03.3766472Z     conv_bias = self.conv.bias
2026-01-14T08:20:03.3767758Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.0012416718527674675, 127, -128, 127, torch.int8);  x = None
2026-01-14T08:20:03.3770479Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0012416718527674675, 127, -128, 127, torch.int8)
2026-01-14T08:20:03.3773409Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0012416718527674675, 127, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:20:03.3776332Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T08:20:03.3778849Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0014063265407457948, -128, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:20:03.3781329Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0014063265407457948, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:20:03.3784153Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T08:20:03.3785877Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:20:03.3787508Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.00046353504876606166, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:20:03.3790459Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.00046353504876606166, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:20:03.3792711Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T08:20:03.3793516Z     
2026-01-14T08:20:03.3794073Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:03.3794787Z onverted model fx: GraphModule(
2026-01-14T08:20:03.3795528Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T08:20:03.3796499Z   (relu): ReLU(inplace=True)
2026-01-14T08:20:03.3796974Z )
2026-01-14T08:20:03.3797165Z 
2026-01-14T08:20:03.3797172Z 
2026-01-14T08:20:03.3797179Z 
2026-01-14T08:20:03.3797339Z def forward(self, x):
2026-01-14T08:20:03.3798618Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.0012416718527674675, 127, -128, 127, torch.int8);  x = None
2026-01-14T08:20:03.3801140Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0012416718527674675, 127, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:20:03.3803023Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:20:03.3804590Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0014063265407457948, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:20:03.3807355Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0014063265407457948, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:20:03.3810035Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:20:03.3811285Z     relu = self.relu(add);  add = None
2026-01-14T08:20:03.3812784Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.00046353504876606166, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:20:03.3815657Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.00046353504876606166, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:20:03.3817839Z     return dequantize_per_tensor_default_2
2026-01-14T08:20:03.3818296Z     
2026-01-14T08:20:03.3818816Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:03.3819466Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T08:20:03.3820147Z [32mPASSED[0m
2026-01-14T08:20:03.3821490Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T08:20:03.3823716Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T08:20:03.3825734Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T08:20:03.3826968Z   (conv): Module()
2026-01-14T08:20:03.3827335Z   (bn): Module()
2026-01-14T08:20:03.3827868Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:03.3829793Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:03.3832184Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:20:03.3833215Z   )
2026-01-14T08:20:03.3833720Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:03.3835769Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0016, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:20:03.3838547Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3010, -0.2094, -0.2957]), max_val=tensor([0.2519, 0.1882, 0.3171]))
2026-01-14T08:20:03.3839815Z   )
2026-01-14T08:20:03.3840303Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:03.3842403Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:03.3844738Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.407715082168579, max_val=1.379811406135559)
2026-01-14T08:20:03.3845777Z   )
2026-01-14T08:20:03.3846281Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:03.3848197Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:03.3850788Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.407715082168579, max_val=1.379811406135559)
2026-01-14T08:20:03.3851899Z   )
2026-01-14T08:20:03.3852215Z )
2026-01-14T08:20:03.3852375Z 
2026-01-14T08:20:03.3852382Z 
2026-01-14T08:20:03.3852388Z 
2026-01-14T08:20:03.3852550Z def forward(self, x):
2026-01-14T08:20:03.3853094Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:20:03.3853783Z     conv_weight = self.conv.weight
2026-01-14T08:20:03.3854272Z     conv_bias = self.conv.bias
2026-01-14T08:20:03.3854743Z     bn_weight = self.bn.weight
2026-01-14T08:20:03.3855193Z     bn_bias = self.bn.bias
2026-01-14T08:20:03.3855666Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:20:03.3856226Z     bn_running_var = self.bn.running_var
2026-01-14T08:20:03.3856843Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:20:03.3857699Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:20:03.3858875Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:20:03.3860223Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:20:03.3860992Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:20:03.3861811Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:20:03.3862662Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:20:03.3863625Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:20:03.3864749Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:20:03.3865871Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:20:03.3867812Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:20:03.3869622Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:20:03.3870681Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:20:03.3871830Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:20:12.4365238Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:20:12.4366674Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:20:12.4368164Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:20:12.4369290Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:20:12.4370354Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:20:12.4371219Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:20:12.4371779Z     
2026-01-14T08:20:12.4372259Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:12.4373119Z model fx: GraphModule(
2026-01-14T08:20:12.4373577Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:12.4375043Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:12.4376843Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:20:12.4377617Z   )
2026-01-14T08:20:12.4377872Z   (conv): ConvBn1d(
2026-01-14T08:20:12.4378178Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:20:12.4378778Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:20:12.4379472Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:12.4381011Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0016, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:20:12.4383071Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3010, -0.2094, -0.2957]), max_val=tensor([0.2519, 0.1882, 0.3171]))
2026-01-14T08:20:12.4384060Z     )
2026-01-14T08:20:12.4384311Z   )
2026-01-14T08:20:12.4384631Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:12.4385765Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:12.4387185Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.407715082168579, max_val=1.379811406135559)
2026-01-14T08:20:12.4387751Z   )
2026-01-14T08:20:12.4387995Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:20:12.4388422Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:12.4389516Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:12.4390807Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.407715082168579, max_val=1.379811406135559)
2026-01-14T08:20:12.4391367Z   )
2026-01-14T08:20:12.4391549Z )
2026-01-14T08:20:12.4391652Z 
2026-01-14T08:20:12.4391656Z 
2026-01-14T08:20:12.4391660Z 
2026-01-14T08:20:12.4391747Z def forward(self, x):
2026-01-14T08:20:12.4392123Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:20:12.4392719Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:20:12.4393320Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:20:12.4393960Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:20:12.4394622Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:20:12.4395129Z     return activation_post_process_2
2026-01-14T08:20:12.4395399Z     
2026-01-14T08:20:12.4395698Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:12.4396107Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:20:12.4396348Z          [0., 0., 0.],
2026-01-14T08:20:12.4396602Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:20:12.4396921Z converted model pt2e: GraphModule(
2026-01-14T08:20:12.4397201Z   (conv): Module()
2026-01-14T08:20:12.4397408Z   (bn): Module()
2026-01-14T08:20:12.4397614Z )
2026-01-14T08:20:12.4397713Z 
2026-01-14T08:20:12.4397717Z 
2026-01-14T08:20:12.4397721Z 
2026-01-14T08:20:12.4397807Z def forward(self, x):
2026-01-14T08:20:12.4398187Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:20:12.4398567Z     conv_bias = self.conv.bias
2026-01-14T08:20:12.4398883Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:20:12.4399689Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:20:12.4401101Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:20:12.4402301Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:20:12.4402834Z     _scale_0 = self._scale_0
2026-01-14T08:20:12.4403105Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:20:12.4403433Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:20:12.4404447Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:20:12.4406022Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:20:12.4407411Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010931476950645447, 1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:20:12.4408896Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010931476950645447, 1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:20:12.4410306Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T08:20:12.4411482Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010931476950645447, 1, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:20:12.4413066Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010931476950645447, 1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:20:12.4414223Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:20:12.4414679Z     
2026-01-14T08:20:12.4414992Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:12.4415412Z onverted model fx: GraphModule(
2026-01-14T08:20:12.4415808Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:20:12.4416277Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:20:12.4416581Z )
2026-01-14T08:20:12.4416693Z 
2026-01-14T08:20:12.4416698Z 
2026-01-14T08:20:12.4416702Z 
2026-01-14T08:20:12.4416794Z def forward(self, x):
2026-01-14T08:20:12.4417470Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:20:12.4418888Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:20:12.4420039Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:20:12.4420988Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010931476950645447, 1, -128, 127, torch.int8);  conv = None
2026-01-14T08:20:12.4422446Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010931476950645447, 1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:20:12.4423731Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:20:12.4424771Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010931476950645447, 1, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:20:12.4426271Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010931476950645447, 1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:20:12.4427279Z     return dequantize_per_tensor_default_2
2026-01-14T08:20:12.4427565Z     
2026-01-14T08:20:12.4427871Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:12.4428273Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:20:12.4428533Z          [0., 0., 0.],
2026-01-14T08:20:12.4428751Z          [0., 0., 0.]]])
2026-01-14T08:20:12.4429002Z model pt2e: GraphModule(
2026-01-14T08:20:12.4429241Z   (conv): Module()
2026-01-14T08:20:12.4429460Z   (bn): Module()
2026-01-14T08:20:12.4429766Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:12.4430858Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:12.4432158Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:20:12.4432723Z   )
2026-01-14T08:20:12.4433015Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:12.4434116Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:20:19.2108726Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.30097201466560364, max_val=0.3171221613883972)
2026-01-14T08:20:19.2109555Z   )
2026-01-14T08:20:19.2109953Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:19.2111459Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:19.2113186Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.407715082168579, max_val=1.3807092905044556)
2026-01-14T08:20:19.2113955Z   )
2026-01-14T08:20:19.2114336Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:19.2115809Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:19.2117535Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.407715082168579, max_val=1.3807092905044556)
2026-01-14T08:20:19.2118283Z   )
2026-01-14T08:20:19.2118526Z )
2026-01-14T08:20:19.2118662Z 
2026-01-14T08:20:19.2118667Z 
2026-01-14T08:20:19.2118672Z 
2026-01-14T08:20:19.2118790Z def forward(self, x):
2026-01-14T08:20:19.2119197Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:20:19.2119679Z     conv_weight = self.conv.weight
2026-01-14T08:20:19.2120072Z     conv_bias = self.conv.bias
2026-01-14T08:20:19.2120438Z     bn_weight = self.bn.weight
2026-01-14T08:20:19.2120779Z     bn_bias = self.bn.bias
2026-01-14T08:20:19.2121142Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:20:19.2121553Z     bn_running_var = self.bn.running_var
2026-01-14T08:20:19.2122032Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:20:19.2122653Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:20:19.2123837Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:20:19.2124637Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:20:19.2125187Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:20:19.2125779Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:20:19.2126400Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:20:19.2127132Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:20:19.2127946Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:20:19.2128854Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:20:19.2130348Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:20:19.2131680Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:20:19.2132565Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:20:19.2133402Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:20:19.2134214Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:20:19.2135592Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:20:19.2137049Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:20:19.2138314Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:20:19.2139469Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:20:19.2140310Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:20:19.2140881Z     
2026-01-14T08:20:19.2141266Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:19.2141806Z model fx: GraphModule(
2026-01-14T08:20:19.2142244Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:19.2143706Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:19.2145290Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:20:19.2145859Z   )
2026-01-14T08:20:19.2146055Z   (conv): ConvBn1d(
2026-01-14T08:20:19.2146283Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:20:19.2146739Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:20:19.2147259Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:19.2148348Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:20:19.2149826Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.30097201466560364, max_val=0.3171221613883972)
2026-01-14T08:20:19.2150406Z     )
2026-01-14T08:20:19.2150600Z   )
2026-01-14T08:20:19.2150886Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:19.2152103Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:19.2153407Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.407715082168579, max_val=1.3807092905044556)
2026-01-14T08:20:19.2153978Z   )
2026-01-14T08:20:19.2154220Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:20:19.2154637Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:19.2155730Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0109]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:19.2157001Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.407715082168579, max_val=1.3807092905044556)
2026-01-14T08:20:19.2157580Z   )
2026-01-14T08:20:19.2157766Z )
2026-01-14T08:20:19.2157865Z 
2026-01-14T08:20:19.2157869Z 
2026-01-14T08:20:19.2157873Z 
2026-01-14T08:20:19.2157961Z def forward(self, x):
2026-01-14T08:20:19.2158341Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:20:19.2158918Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:20:19.2159522Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:20:19.2160155Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:20:19.2160846Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:20:19.2161347Z     return activation_post_process_2
2026-01-14T08:20:19.2161634Z     
2026-01-14T08:20:19.2161927Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:19.2162346Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:20:19.2162689Z          [0., 0., 0.],
2026-01-14T08:20:19.2162937Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:20:19.2163272Z converted model pt2e: GraphModule(
2026-01-14T08:20:19.2163546Z   (conv): Module()
2026-01-14T08:20:19.2163774Z   (bn): Module()
2026-01-14T08:20:19.2163974Z )
2026-01-14T08:20:19.2164090Z 
2026-01-14T08:20:19.2164094Z 
2026-01-14T08:20:19.2164098Z 
2026-01-14T08:20:19.2164188Z def forward(self, x):
2026-01-14T08:20:19.2164491Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:20:19.2164869Z     conv_bias = self.conv.bias
2026-01-14T08:20:19.2165199Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:20:19.2165992Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:20:19.2167413Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:20:19.2168609Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:20:19.2169174Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:20:19.2170079Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0024970248341560364, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:20:19.2171520Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:20:19.2172984Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010934998281300068, 1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:20:19.2174483Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010934998281300068, 1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:20:19.2175894Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T08:20:19.2177067Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010934998281300068, 1, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:20:19.2178566Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.010934998281300068, 1, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:20:19.2179703Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T08:20:19.2180167Z     
2026-01-14T08:20:19.2180462Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:19.2180883Z onverted model fx: GraphModule(
2026-01-14T08:20:19.2181273Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:20:19.2181735Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:20:19.2182060Z )
2026-01-14T08:20:19.2182163Z 
2026-01-14T08:20:19.2182167Z 
2026-01-14T08:20:19.2182171Z 
2026-01-14T08:20:19.2182261Z def forward(self, x):
2026-01-14T08:20:47.1690830Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:20:47.1692846Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:20:47.1694445Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:20:47.1695718Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010934998281300068, 1, -128, 127, torch.int8);  conv = None
2026-01-14T08:20:47.1698021Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010934998281300068, 1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:20:47.1699664Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:20:47.1701056Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010934998281300068, 1, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:20:47.1703053Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010934998281300068, 1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:20:47.1704393Z     return dequantize_per_tensor_default_2
2026-01-14T08:20:47.1704796Z     
2026-01-14T08:20:47.1705198Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:47.1705725Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:20:47.1706058Z          [0., 0., 0.],
2026-01-14T08:20:47.1706346Z          [0., 0., 0.]]])
2026-01-14T08:20:47.1706857Z [32mPASSED[0m
2026-01-14T08:20:47.1707786Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T08:20:47.1709315Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T08:20:47.1710706Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T08:20:47.1711576Z   (conv): Module()
2026-01-14T08:20:47.1711871Z   (bn): Module()
2026-01-14T08:20:47.1712279Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:47.1713749Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:47.1715709Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:20:47.1716464Z   )
2026-01-14T08:20:47.1716860Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:47.1718405Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:20:47.1720446Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1822, -0.1883, -0.1585]), max_val=tensor([0.1856, 0.1719, 0.1858]))
2026-01-14T08:20:47.1721428Z   )
2026-01-14T08:20:47.1721811Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:47.1723268Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0139]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:47.1724984Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.628747820854187, max_val=1.9105255603790283)
2026-01-14T08:20:47.1725748Z   )
2026-01-14T08:20:47.1725989Z )
2026-01-14T08:20:47.1726120Z 
2026-01-14T08:20:47.1726125Z 
2026-01-14T08:20:47.1726129Z 
2026-01-14T08:20:47.1726247Z def forward(self, x):
2026-01-14T08:20:47.1726648Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:20:47.1727128Z     conv_weight = self.conv.weight
2026-01-14T08:20:47.1727511Z     conv_bias = self.conv.bias
2026-01-14T08:20:47.1727855Z     bn_weight = self.bn.weight
2026-01-14T08:20:47.1728204Z     bn_bias = self.bn.bias
2026-01-14T08:20:47.1728614Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:20:47.1728929Z     bn_running_var = self.bn.running_var
2026-01-14T08:20:47.1729291Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:20:47.1729765Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:20:47.1730431Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:20:47.1731022Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:20:47.1731450Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:20:47.1731966Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:20:47.1732449Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:20:47.1733011Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:20:47.1733627Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:20:47.1734323Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:20:47.1735435Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:20:47.1736454Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:20:47.1737066Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:20:47.1737713Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:20:47.1738344Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:20:47.1739371Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:20:47.1740489Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:20:47.1741232Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:20:47.1741656Z     
2026-01-14T08:20:47.1741963Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:47.1742357Z model fx: GraphModule(
2026-01-14T08:20:47.1742704Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:47.1743811Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:47.1745113Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:20:47.1745689Z   )
2026-01-14T08:20:47.1745880Z   (conv): ConvBn2d(
2026-01-14T08:20:47.1746130Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:20:47.1746580Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:20:47.1747113Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:47.1748260Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:20:47.1749956Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1822, -0.1883, -0.1585]), max_val=tensor([0.1856, 0.1719, 0.1858]))
2026-01-14T08:20:47.1750700Z     )
2026-01-14T08:20:47.1750880Z   )
2026-01-14T08:20:47.1751185Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:47.1752303Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0139]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:47.1753720Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.628747820854187, max_val=1.9105255603790283)
2026-01-14T08:20:47.1754302Z   )
2026-01-14T08:20:47.1754479Z )
2026-01-14T08:20:47.1754594Z 
2026-01-14T08:20:47.1754598Z 
2026-01-14T08:20:47.1754602Z 
2026-01-14T08:20:47.1754691Z def forward(self, x):
2026-01-14T08:20:47.1755082Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:20:47.1755669Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:20:47.1756277Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:20:47.1756740Z     return activation_post_process_1
2026-01-14T08:20:47.1757021Z     
2026-01-14T08:20:47.1757309Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:47.1757717Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:20:47.1757963Z           [0., 0., 0.],
2026-01-14T08:20:47.1758191Z           [0., 0., 0.]],
2026-01-14T08:20:47.1758340Z 
2026-01-14T08:20:47.1758435Z          [[0., 0., 0.],
2026-01-14T08:20:47.1758651Z           [0., 0., 0.],
2026-01-14T08:20:47.1758879Z           [0., 0., 0.]],
2026-01-14T08:20:47.1759025Z 
2026-01-14T08:20:47.1759103Z          [[0., 0., 0.],
2026-01-14T08:20:47.1759326Z           [0., 0., 0.],
2026-01-14T08:20:47.1759575Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:20:47.1759908Z converted model pt2e: GraphModule(
2026-01-14T08:20:47.1760177Z   (conv): Module()
2026-01-14T08:20:47.1760394Z   (bn): Module()
2026-01-14T08:20:47.1760588Z )
2026-01-14T08:20:47.1760699Z 
2026-01-14T08:20:47.1760703Z 
2026-01-14T08:20:47.1760707Z 
2026-01-14T08:20:47.1760794Z def forward(self, x):
2026-01-14T08:20:47.1761103Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:20:47.1761464Z     conv_bias = self.conv.bias
2026-01-14T08:20:47.1762182Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:20:47.1763686Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:20:47.1764666Z     _scale_0 = self._scale_0
2026-01-14T08:20:47.1764942Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:20:47.1765259Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:20:56.4448924Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:20:56.4451828Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:20:56.4454122Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.0138795031234622, -11, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:20:56.4456515Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0138795031234622, -11, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:20:56.4458490Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:20:56.4459257Z     
2026-01-14T08:20:56.4459750Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:56.4460422Z onverted model fx: GraphModule(
2026-01-14T08:20:56.4461046Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:20:56.4462127Z )
2026-01-14T08:20:56.4462295Z 
2026-01-14T08:20:56.4462301Z 
2026-01-14T08:20:56.4462307Z 
2026-01-14T08:20:56.4462469Z def forward(self, x):
2026-01-14T08:20:56.4463575Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:20:56.4466036Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:20:56.4467943Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:20:56.4469581Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0138795031234622, -11, -128, 127, torch.int8);  conv = None
2026-01-14T08:20:56.4472125Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0138795031234622, -11, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:20:56.4473991Z     return dequantize_per_tensor_default_1
2026-01-14T08:20:56.4474507Z     
2026-01-14T08:20:56.4475040Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:56.4475748Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:20:56.4476174Z           [0., 0., 0.],
2026-01-14T08:20:56.4476551Z           [0., 0., 0.]],
2026-01-14T08:20:56.4476810Z 
2026-01-14T08:20:56.4476962Z          [[0., 0., 0.],
2026-01-14T08:20:56.4477335Z           [0., 0., 0.],
2026-01-14T08:20:56.4477724Z           [0., 0., 0.]],
2026-01-14T08:20:56.4477984Z 
2026-01-14T08:20:56.4478118Z          [[0., 0., 0.],
2026-01-14T08:20:56.4478495Z           [0., 0., 0.],
2026-01-14T08:20:56.4478853Z           [0., 0., 0.]]]])
2026-01-14T08:20:56.4479272Z model pt2e: GraphModule(
2026-01-14T08:20:56.4479661Z   (conv): Module()
2026-01-14T08:20:56.4479999Z   (bn): Module()
2026-01-14T08:20:56.4480657Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:56.4483229Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:56.4485966Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:20:56.4487238Z   )
2026-01-14T08:20:56.4487759Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:56.4489607Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:20:56.4492085Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.18581794202327728)
2026-01-14T08:20:56.4493133Z   )
2026-01-14T08:20:56.4493627Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:56.4495631Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0139]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:56.4497944Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6255242824554443, max_val=1.9112863540649414)
2026-01-14T08:20:56.4498954Z   )
2026-01-14T08:20:56.4499230Z )
2026-01-14T08:20:56.4499393Z 
2026-01-14T08:20:56.4499401Z 
2026-01-14T08:20:56.4499408Z 
2026-01-14T08:20:56.4499564Z def forward(self, x):
2026-01-14T08:20:56.4500111Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:20:56.4500775Z     conv_weight = self.conv.weight
2026-01-14T08:20:56.4501228Z     conv_bias = self.conv.bias
2026-01-14T08:20:56.4501710Z     bn_weight = self.bn.weight
2026-01-14T08:20:56.4502420Z     bn_bias = self.bn.bias
2026-01-14T08:20:56.4502830Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:20:56.4503344Z     bn_running_var = self.bn.running_var
2026-01-14T08:20:56.4503930Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:20:56.4504693Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:20:56.4505707Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:20:56.4506749Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:20:56.4507514Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:20:56.4508347Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:20:56.4509173Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:20:56.4510031Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:20:56.4511049Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:20:56.4512124Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:20:56.4514183Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:20:56.4515968Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:20:56.4517000Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:20:56.4518213Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:20:56.4519301Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:20:56.4521178Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:20:56.4523022Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:20:56.4524285Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:20:56.4525015Z     
2026-01-14T08:20:56.4525505Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:56.4526111Z model fx: GraphModule(
2026-01-14T08:20:56.4526647Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:56.4528575Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:56.4530945Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:20:56.4532032Z   )
2026-01-14T08:20:56.4532343Z   (conv): ConvBn2d(
2026-01-14T08:20:56.4532756Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:20:56.4533567Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:20:56.4534416Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:56.4536235Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:20:56.4538645Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.18581794202327728)
2026-01-14T08:20:56.4539644Z     )
2026-01-14T08:20:56.4539935Z   )
2026-01-14T08:20:56.4540407Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:20:56.4542250Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0139]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:20:56.4544692Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6255242824554443, max_val=1.9112863540649414)
2026-01-14T08:20:56.4545664Z   )
2026-01-14T08:20:56.4545950Z )
2026-01-14T08:20:56.4546107Z 
2026-01-14T08:20:56.4546114Z 
2026-01-14T08:20:56.4546121Z 
2026-01-14T08:20:56.4546280Z def forward(self, x):
2026-01-14T08:20:56.4546913Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:20:56.4547941Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:20:56.4548980Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:20:56.4550007Z     return activation_post_process_1
2026-01-14T08:20:56.4550472Z     
2026-01-14T08:20:56.4550982Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:20:56.4551668Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:20:56.4552057Z           [0., 0., 0.],
2026-01-14T08:20:56.4552417Z           [0., 0., 0.]],
2026-01-14T08:20:56.4552665Z 
2026-01-14T08:20:56.4552809Z          [[0., 0., 0.],
2026-01-14T08:20:56.4553182Z           [0., 0., 0.],
2026-01-14T08:20:56.4553552Z           [0., 0., 0.]],
2026-01-14T08:20:56.4553793Z 
2026-01-14T08:20:56.4553913Z          [[0., 0., 0.],
2026-01-14T08:20:56.4554247Z           [0., 0., 0.],
2026-01-14T08:20:56.4554660Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:20:56.4555230Z converted model pt2e: GraphModule(
2026-01-14T08:20:56.4555661Z   (conv): Module()
2026-01-14T08:20:56.4556005Z   (bn): Module()
2026-01-14T08:20:56.4556304Z )
2026-01-14T08:20:56.4556462Z 
2026-01-14T08:20:56.4556469Z 
2026-01-14T08:20:56.4556476Z 
2026-01-14T08:20:56.4556631Z def forward(self, x):
2026-01-14T08:20:56.4557152Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:20:56.4557781Z     conv_bias = self.conv.bias
2026-01-14T08:20:56.4558968Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:21:00.4015128Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:00.4017202Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:21:00.4018895Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014826410915702581, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:21:00.4021730Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:21:00.4024367Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.013869845308363438, -11, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:21:00.4027224Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.013869845308363438, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:21:00.4029412Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:21:00.4030134Z     
2026-01-14T08:21:00.4030657Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:00.4031389Z onverted model fx: GraphModule(
2026-01-14T08:21:00.4032107Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:21:00.4032860Z )
2026-01-14T08:21:00.4033043Z 
2026-01-14T08:21:00.4033053Z 
2026-01-14T08:21:00.4033059Z 
2026-01-14T08:21:00.4033208Z def forward(self, x):
2026-01-14T08:21:00.4034843Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:21:00.4037491Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:00.4039665Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:21:00.4041401Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.013869845308363438, -11, -128, 127, torch.int8);  conv = None
2026-01-14T08:21:00.4044085Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.013869845308363438, -11, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:21:00.4046078Z     return dequantize_per_tensor_default_1
2026-01-14T08:21:00.4046649Z     
2026-01-14T08:21:00.4047146Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:00.4047809Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:21:00.4048233Z           [0., 0., 0.],
2026-01-14T08:21:00.4048624Z           [0., 0., 0.]],
2026-01-14T08:21:00.4048842Z 
2026-01-14T08:21:00.4048956Z          [[0., 0., 0.],
2026-01-14T08:21:00.4049324Z           [0., 0., 0.],
2026-01-14T08:21:00.4049933Z           [0., 0., 0.]],
2026-01-14T08:21:00.4050192Z 
2026-01-14T08:21:00.4050321Z          [[0., 0., 0.],
2026-01-14T08:21:00.4050696Z           [0., 0., 0.],
2026-01-14T08:21:00.4051061Z           [0., 0., 0.]]]])
2026-01-14T08:21:00.4051717Z [32mPASSED[0m
2026-01-14T08:21:00.4053141Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:21:00.4055217Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T08:21:00.4056563Z   (conv): Module()
2026-01-14T08:21:00.4056922Z   (bn): Module()
2026-01-14T08:21:00.4057485Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:00.4059635Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0147]), zero_point=tensor([-28], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:00.4062065Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4721859693527222, max_val=2.2869999408721924)
2026-01-14T08:21:00.4063127Z   )
2026-01-14T08:21:00.4063647Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:00.4065728Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:21:00.4068505Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1787, -0.1913]), max_val=tensor([0.1870, 0.1478, 0.1740]))
2026-01-14T08:21:00.4069819Z   )
2026-01-14T08:21:00.4070326Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:00.4072205Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0313]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:00.4074579Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.046965599060059, max_val=3.922553539276123)
2026-01-14T08:21:00.4075591Z   )
2026-01-14T08:21:00.4075895Z )
2026-01-14T08:21:00.4076064Z 
2026-01-14T08:21:00.4076072Z 
2026-01-14T08:21:00.4076079Z 
2026-01-14T08:21:00.4076240Z def forward(self, x):
2026-01-14T08:21:00.4076784Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:00.4077657Z     conv_weight = self.conv.weight
2026-01-14T08:21:00.4078170Z     conv_bias = self.conv.bias
2026-01-14T08:21:00.4078645Z     bn_weight = self.bn.weight
2026-01-14T08:21:00.4079112Z     bn_bias = self.bn.bias
2026-01-14T08:21:00.4079591Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:21:00.4080131Z     bn_running_var = self.bn.running_var
2026-01-14T08:21:00.4080758Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:21:00.4081595Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:00.4082816Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:21:00.4083892Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:21:00.4084634Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:21:00.4085429Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:21:00.4086285Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:21:00.4087307Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:21:00.4088458Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:21:00.4089752Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:21:00.4091992Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:21:00.4093856Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:21:00.4094834Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:21:00.4095999Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:21:00.4097097Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:21:00.4099135Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:21:00.4101159Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:21:00.4102349Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:21:00.4103123Z     
2026-01-14T08:21:00.4103674Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:00.4104379Z model fx: GraphModule(
2026-01-14T08:21:00.4104981Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:00.4107006Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0147]), zero_point=tensor([-28], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:00.4109377Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4721859693527222, max_val=2.2869999408721924)
2026-01-14T08:21:00.4110419Z   )
2026-01-14T08:21:00.4110752Z   (conv): ConvBn2d(
2026-01-14T08:21:00.4111259Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T08:21:00.4112132Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:21:00.4113014Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:00.4115042Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:21:00.4117854Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1787, -0.1913]), max_val=tensor([0.1870, 0.1478, 0.1740]))
2026-01-14T08:21:00.4119350Z     )
2026-01-14T08:21:00.4119661Z   )
2026-01-14T08:21:00.4120177Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:00.4122181Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0313]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:00.4124634Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.046965599060059, max_val=3.922553539276123)
2026-01-14T08:21:00.4125688Z   )
2026-01-14T08:21:00.4125985Z )
2026-01-14T08:21:00.4126178Z 
2026-01-14T08:21:00.4126186Z 
2026-01-14T08:21:00.4126192Z 
2026-01-14T08:21:00.4126350Z def forward(self, x):
2026-01-14T08:21:00.4127033Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:00.4128131Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:21:00.4129235Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:21:00.4130044Z     return activation_post_process_1
2026-01-14T08:21:00.4130515Z     
2026-01-14T08:21:00.4131004Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:00.4131775Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:00.4132419Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5746772Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5747413Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5747910Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5748347Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T08:21:08.5748662Z 
2026-01-14T08:21:08.5748801Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5749201Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5749807Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5750236Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5750659Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5751043Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T08:21:08.5751319Z 
2026-01-14T08:21:08.5751455Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5752170Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5752617Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5753080Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5753553Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5754097Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:21:08.5754740Z converted model pt2e: GraphModule(
2026-01-14T08:21:08.5755251Z   (conv): Module()
2026-01-14T08:21:08.5755629Z   (bn): Module()
2026-01-14T08:21:08.5755970Z )
2026-01-14T08:21:08.5756157Z 
2026-01-14T08:21:08.5756165Z 
2026-01-14T08:21:08.5756174Z 
2026-01-14T08:21:08.5756331Z def forward(self, x):
2026-01-14T08:21:08.5756873Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:08.5757573Z     conv_bias = self.conv.bias
2026-01-14T08:21:08.5758957Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01474190503358841, -28, -128, 127, torch.int8);  x = None
2026-01-14T08:21:08.5761725Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01474190503358841, -28, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:08.5763576Z     _scale_0 = self._scale_0
2026-01-14T08:21:08.5764060Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:21:08.5764633Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:21:08.5766485Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:21:08.5769414Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:21:08.5772450Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.031253017485141754, 1, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:21:08.5775275Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.031253017485141754, 1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:21:08.5777403Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:21:08.5778263Z     
2026-01-14T08:21:08.5778760Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:08.5779535Z onverted model fx: GraphModule(
2026-01-14T08:21:08.5780302Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T08:21:08.5781129Z )
2026-01-14T08:21:08.5781316Z 
2026-01-14T08:21:08.5781323Z 
2026-01-14T08:21:08.5781330Z 
2026-01-14T08:21:08.5781495Z def forward(self, x):
2026-01-14T08:21:08.5782695Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01474190503358841, -28, -128, 127, torch.int8);  x = None
2026-01-14T08:21:08.5785457Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01474190503358841, -28, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:08.5787601Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:21:08.5789223Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.031253017485141754, 1, -128, 127, torch.int8);  conv = None
2026-01-14T08:21:08.5791900Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.031253017485141754, 1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:21:08.5793830Z     return dequantize_per_tensor_default_1
2026-01-14T08:21:08.5794393Z     
2026-01-14T08:21:08.5795107Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:08.5795856Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5796328Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5796793Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5797220Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5797650Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5798099Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T08:21:08.5798413Z 
2026-01-14T08:21:08.5798556Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5798999Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5799462Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5799896Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5800336Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5800793Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T08:21:08.5801142Z 
2026-01-14T08:21:08.5801290Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5801725Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5802190Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5802645Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5803097Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:08.5803549Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T08:21:08.5804012Z model pt2e: GraphModule(
2026-01-14T08:21:08.5804440Z   (conv): Module()
2026-01-14T08:21:08.5804790Z   (bn): Module()
2026-01-14T08:21:08.5805311Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:08.5807276Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0147]), zero_point=tensor([-28], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:08.5809794Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4721859693527222, max_val=2.2869999408721924)
2026-01-14T08:21:08.5810828Z   )
2026-01-14T08:21:08.5811322Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:08.5813338Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:21:08.5815739Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T08:21:08.5816804Z   )
2026-01-14T08:21:08.5817288Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:08.5819290Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0312]), zero_point=tensor([2], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:08.5821671Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.046965599060059, max_val=3.9041571617126465)
2026-01-14T08:21:08.5822751Z   )
2026-01-14T08:21:08.5823054Z )
2026-01-14T08:21:08.5823234Z 
2026-01-14T08:21:08.5823241Z 
2026-01-14T08:21:08.5823248Z 
2026-01-14T08:21:08.5823411Z def forward(self, x):
2026-01-14T08:21:08.5823948Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:08.5824602Z     conv_weight = self.conv.weight
2026-01-14T08:21:08.5825106Z     conv_bias = self.conv.bias
2026-01-14T08:21:08.5825578Z     bn_weight = self.bn.weight
2026-01-14T08:21:08.5826039Z     bn_bias = self.bn.bias
2026-01-14T08:21:08.5826499Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:21:08.5827047Z     bn_running_var = self.bn.running_var
2026-01-14T08:21:08.5827674Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:21:08.5828545Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:08.5829789Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:21:08.5830920Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:21:08.5831825Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:21:08.5832628Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:21:08.5833463Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:21:08.5834383Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:21:08.5835457Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:21:08.5836632Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:21:08.5838693Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:21:08.5840607Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:21:08.5841706Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:21:08.5842881Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:21:08.5859558Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:21:08.5861431Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:21:08.5863493Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:21:08.5864762Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:21:08.5865801Z     
2026-01-14T08:21:08.5866346Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:08.5867088Z model fx: GraphModule(
2026-01-14T08:21:08.5867705Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:08.5869774Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0147]), zero_point=tensor([-28], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:08.5872190Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4721859693527222, max_val=2.2869999408721924)
2026-01-14T08:21:08.5873274Z   )
2026-01-14T08:21:08.5873594Z   (conv): ConvBn2d(
2026-01-14T08:21:08.5874062Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T08:21:08.5874956Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:21:08.5875928Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:20.4237886Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:21:20.4240349Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T08:21:20.4241423Z     )
2026-01-14T08:21:20.4241784Z   )
2026-01-14T08:21:20.4242266Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:20.4244167Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0312]), zero_point=tensor([2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:20.4246484Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.046965599060059, max_val=3.9041571617126465)
2026-01-14T08:21:20.4247547Z   )
2026-01-14T08:21:20.4247839Z )
2026-01-14T08:21:20.4248031Z 
2026-01-14T08:21:20.4248041Z 
2026-01-14T08:21:20.4248047Z 
2026-01-14T08:21:20.4248210Z def forward(self, x):
2026-01-14T08:21:20.4249140Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:20.4250369Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:21:20.4251406Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:21:20.4252328Z     return activation_post_process_1
2026-01-14T08:21:20.4252793Z     
2026-01-14T08:21:20.4253243Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:20.4253940Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4254377Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4254794Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4255227Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4255736Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4256224Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T08:21:20.4256557Z 
2026-01-14T08:21:20.4256706Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4257194Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4257653Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4258135Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4258597Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4259040Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T08:21:20.4259326Z 
2026-01-14T08:21:20.4259464Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4259858Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4260276Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4260684Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4261096Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4261536Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:21:20.4262114Z converted model pt2e: GraphModule(
2026-01-14T08:21:20.4262828Z   (conv): Module()
2026-01-14T08:21:20.4263175Z   (bn): Module()
2026-01-14T08:21:20.4263511Z )
2026-01-14T08:21:20.4263695Z 
2026-01-14T08:21:20.4263704Z 
2026-01-14T08:21:20.4263710Z 
2026-01-14T08:21:20.4263889Z def forward(self, x):
2026-01-14T08:21:20.4264432Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:20.4265077Z     conv_bias = self.conv.bias
2026-01-14T08:21:20.4266428Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01474190503358841, -28, -128, 127, torch.int8);  x = None
2026-01-14T08:21:20.4269161Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01474190503358841, -28, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:20.4271083Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:21:20.4272727Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0015061007579788566, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:21:20.4275472Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:21:20.4277933Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.03118087351322174, 2, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:21:20.4280693Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.03118087351322174, 2, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:21:20.4282815Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:21:20.4283645Z     
2026-01-14T08:21:20.4284151Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:20.4284926Z onverted model fx: GraphModule(
2026-01-14T08:21:20.4285725Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T08:21:20.4286620Z )
2026-01-14T08:21:20.4287023Z 
2026-01-14T08:21:20.4287032Z 
2026-01-14T08:21:20.4287038Z 
2026-01-14T08:21:20.4287207Z def forward(self, x):
2026-01-14T08:21:20.4288400Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01474190503358841, -28, -128, 127, torch.int8);  x = None
2026-01-14T08:21:20.4290981Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01474190503358841, -28, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:20.4293339Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:21:20.4295025Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.03118087351322174, 2, -128, 127, torch.int8);  conv = None
2026-01-14T08:21:20.4297535Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.03118087351322174, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:21:20.4299382Z     return dequantize_per_tensor_default_1
2026-01-14T08:21:20.4299936Z     
2026-01-14T08:21:20.4300487Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:20.4301209Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4301754Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4302237Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4302718Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4303185Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4303636Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T08:21:20.4303929Z 
2026-01-14T08:21:20.4304074Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4304709Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4305137Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4305568Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4306025Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4306454Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T08:21:20.4306770Z 
2026-01-14T08:21:20.4306930Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4307364Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4307808Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4308227Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4308675Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T08:21:20.4309143Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T08:21:20.4309841Z [32mPASSED[0m
2026-01-14T08:21:20.4311020Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:21:20.4312274Z   (conv): Module()
2026-01-14T08:21:20.4312639Z   (bn): Module()
2026-01-14T08:21:20.4313166Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:20.4315124Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0195]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:20.4317427Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.247849225997925, max_val=2.7226178646087646)
2026-01-14T08:21:20.4318440Z   )
2026-01-14T08:21:20.4318939Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:20.4320956Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:21:20.4323742Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1720, -0.1912, -0.1684]), max_val=tensor([0.1914, 0.1792, 0.1824]))
2026-01-14T08:21:20.4325061Z   )
2026-01-14T08:21:20.4325576Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:20.4327766Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0200]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:20.4330175Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.5782737731933594, max_val=2.5220179557800293)
2026-01-14T08:21:20.4331212Z   )
2026-01-14T08:21:20.4331527Z )
2026-01-14T08:21:20.4331694Z 
2026-01-14T08:21:20.4331701Z 
2026-01-14T08:21:20.4331708Z 
2026-01-14T08:21:20.4331856Z def forward(self, x):
2026-01-14T08:21:20.4332491Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:20.4333135Z     conv_weight = self.conv.weight
2026-01-14T08:21:20.4333662Z     bn_weight = self.bn.weight
2026-01-14T08:21:20.4334118Z     bn_bias = self.bn.bias
2026-01-14T08:21:20.4334574Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:21:20.4335113Z     bn_running_var = self.bn.running_var
2026-01-14T08:21:20.4335754Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:21:20.4336627Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:20.4337831Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:21:20.4338919Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:21:20.4339660Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:21:20.4340447Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:21:20.4341291Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:21:20.4342206Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:21:20.4343470Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:21:20.4345120Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:21:20.4346806Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:21:20.4347836Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:21:20.4350008Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:21:28.5295792Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:21:28.5296727Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:21:28.5297334Z     
2026-01-14T08:21:28.5297729Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:28.5298262Z model fx: GraphModule(
2026-01-14T08:21:28.5298711Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:28.5300176Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0195]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:28.5301915Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.247849225997925, max_val=2.7226178646087646)
2026-01-14T08:21:28.5302689Z   )
2026-01-14T08:21:28.5302943Z   (conv): ConvBn2d(
2026-01-14T08:21:28.5303288Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:21:28.5303932Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:21:28.5304617Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:28.5306475Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:21:28.5308598Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1720, -0.1912, -0.1684]), max_val=tensor([0.1914, 0.1792, 0.1824]))
2026-01-14T08:21:28.5309585Z     )
2026-01-14T08:21:28.5309821Z   )
2026-01-14T08:21:28.5310213Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:28.5311657Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0200]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:28.5313381Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.5782737731933594, max_val=2.5220179557800293)
2026-01-14T08:21:28.5314160Z   )
2026-01-14T08:21:28.5314387Z )
2026-01-14T08:21:28.5314518Z 
2026-01-14T08:21:28.5314536Z 
2026-01-14T08:21:28.5314541Z 
2026-01-14T08:21:28.5314662Z def forward(self, x):
2026-01-14T08:21:28.5315144Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:28.5315918Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:21:28.5316711Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:21:28.5317323Z     return activation_post_process_1
2026-01-14T08:21:28.5317688Z     
2026-01-14T08:21:28.5318074Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:28.5318484Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:21:28.5318732Z           [0., 0., 0.],
2026-01-14T08:21:28.5318965Z           [0., 0., 0.]],
2026-01-14T08:21:28.5319114Z 
2026-01-14T08:21:28.5319324Z          [[0., 0., 0.],
2026-01-14T08:21:28.5319558Z           [0., 0., 0.],
2026-01-14T08:21:28.5319785Z           [0., 0., 0.]],
2026-01-14T08:21:28.5319929Z 
2026-01-14T08:21:28.5320008Z          [[0., 0., 0.],
2026-01-14T08:21:28.5320238Z           [0., 0., 0.],
2026-01-14T08:21:28.5320454Z           [0., 0., 0.]]],
2026-01-14T08:21:28.5320608Z 
2026-01-14T08:21:28.5320624Z 
2026-01-14T08:21:28.5320703Z         [[[0., 0., 0.],
2026-01-14T08:21:28.5320916Z           [0., 0., 0.],
2026-01-14T08:21:28.5321138Z           [0., 0., 0.]],
2026-01-14T08:21:28.5321281Z 
2026-01-14T08:21:28.5321359Z          [[0., 0., 0.],
2026-01-14T08:21:28.5321585Z           [0., 0., 0.],
2026-01-14T08:21:28.5321807Z           [0., 0., 0.]],
2026-01-14T08:21:28.5321950Z 
2026-01-14T08:21:28.5322028Z          [[0., 0., 0.],
2026-01-14T08:21:28.5322253Z           [0., 0., 0.],
2026-01-14T08:21:28.5322472Z           [0., 0., 0.]]],
2026-01-14T08:21:28.5322631Z 
2026-01-14T08:21:28.5322636Z 
2026-01-14T08:21:28.5322714Z         [[[0., 0., 0.],
2026-01-14T08:21:28.5322929Z           [0., 0., 0.],
2026-01-14T08:21:28.5323153Z           [0., 0., 0.]],
2026-01-14T08:21:28.5323298Z 
2026-01-14T08:21:28.5323376Z          [[0., 0., 0.],
2026-01-14T08:21:28.5323604Z           [0., 0., 0.],
2026-01-14T08:21:28.5323828Z           [0., 0., 0.]],
2026-01-14T08:21:28.5323970Z 
2026-01-14T08:21:28.5324049Z          [[0., 0., 0.],
2026-01-14T08:21:28.5324269Z           [0., 0., 0.],
2026-01-14T08:21:28.5324513Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:21:28.5324850Z converted model pt2e: GraphModule(
2026-01-14T08:21:28.5325121Z   (conv): Module()
2026-01-14T08:21:28.5325342Z   (bn): Module()
2026-01-14T08:21:28.5325537Z )
2026-01-14T08:21:28.5325647Z 
2026-01-14T08:21:28.5325651Z 
2026-01-14T08:21:28.5325655Z 
2026-01-14T08:21:28.5325741Z def forward(self, x):
2026-01-14T08:21:28.5326050Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:28.5326864Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.019492028281092644, -13, -128, 127, torch.int8);  x = None
2026-01-14T08:21:28.5328391Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.019492028281092644, -13, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:28.5329380Z     _scale_0 = self._scale_0
2026-01-14T08:21:28.5329651Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:21:28.5329979Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:21:28.5330994Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:21:28.5332123Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:21:28.5333081Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:21:28.5334529Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.020001143217086792, 1, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:21:28.5336031Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.020001143217086792, 1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:21:28.5337179Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:21:28.5337629Z     
2026-01-14T08:21:28.5337936Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:28.5338342Z onverted model fx: GraphModule(
2026-01-14T08:21:28.5338755Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:21:28.5339166Z )
2026-01-14T08:21:28.5339283Z 
2026-01-14T08:21:28.5339360Z 
2026-01-14T08:21:28.5339363Z 
2026-01-14T08:21:28.5339455Z def forward(self, x):
2026-01-14T08:21:28.5340159Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.019492028281092644, -13, -128, 127, torch.int8);  x = None
2026-01-14T08:21:28.5341574Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.019492028281092644, -13, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:28.5342740Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:21:28.5343705Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.020001143217086792, 1, -128, 127, torch.int8);  conv = None
2026-01-14T08:21:28.5345157Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.020001143217086792, 1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:21:28.5346173Z     return dequantize_per_tensor_default_1
2026-01-14T08:21:28.5346458Z     
2026-01-14T08:21:28.5346766Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:28.5347163Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:21:28.5347421Z           [0., 0., 0.],
2026-01-14T08:21:28.5347648Z           [0., 0., 0.]],
2026-01-14T08:21:28.5347798Z 
2026-01-14T08:21:28.5347877Z          [[0., 0., 0.],
2026-01-14T08:21:28.5348104Z           [0., 0., 0.],
2026-01-14T08:21:28.5348317Z           [0., 0., 0.]],
2026-01-14T08:21:28.5348474Z 
2026-01-14T08:21:28.5348551Z          [[0., 0., 0.],
2026-01-14T08:21:28.5348762Z           [0., 0., 0.],
2026-01-14T08:21:28.5348990Z           [0., 0., 0.]]],
2026-01-14T08:21:28.5349137Z 
2026-01-14T08:21:28.5349142Z 
2026-01-14T08:21:28.5349232Z         [[[0., 0., 0.],
2026-01-14T08:21:28.5349447Z           [0., 0., 0.],
2026-01-14T08:21:28.5349880Z           [0., 0., 0.]],
2026-01-14T08:21:28.5350033Z 
2026-01-14T08:21:28.5350113Z          [[0., 0., 0.],
2026-01-14T08:21:28.5350338Z           [0., 0., 0.],
2026-01-14T08:21:28.5350548Z           [0., 0., 0.]],
2026-01-14T08:21:28.5350706Z 
2026-01-14T08:21:28.5350904Z          [[0., 0., 0.],
2026-01-14T08:21:28.5351118Z           [0., 0., 0.],
2026-01-14T08:21:28.5351343Z           [0., 0., 0.]]],
2026-01-14T08:21:28.5351489Z 
2026-01-14T08:21:28.5351493Z 
2026-01-14T08:21:28.5351583Z         [[[0., 0., 0.],
2026-01-14T08:21:28.5351793Z           [0., 0., 0.],
2026-01-14T08:21:28.5352022Z           [0., 0., 0.]],
2026-01-14T08:21:28.5352165Z 
2026-01-14T08:21:28.5352242Z          [[0., 0., 0.],
2026-01-14T08:21:28.5352466Z           [0., 0., 0.],
2026-01-14T08:21:28.5352682Z           [0., 0., 0.]],
2026-01-14T08:21:28.5352838Z 
2026-01-14T08:21:28.5352916Z          [[0., 0., 0.],
2026-01-14T08:21:28.5353133Z           [0., 0., 0.],
2026-01-14T08:21:28.5353369Z           [0., 0., 0.]]]])
2026-01-14T08:21:28.5353613Z model pt2e: GraphModule(
2026-01-14T08:21:28.5353875Z   (conv): Module()
2026-01-14T08:21:28.5354094Z   (bn): Module()
2026-01-14T08:21:28.5354400Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:28.5355513Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0195]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:28.5356813Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.247849225997925, max_val=2.7226178646087646)
2026-01-14T08:21:28.5357391Z   )
2026-01-14T08:21:28.5357674Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:28.5358791Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:21:28.5360197Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T08:21:28.5360778Z   )
2026-01-14T08:21:28.5361076Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:28.5362162Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0200]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:28.5363447Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.577202320098877, max_val=2.521923303604126)
2026-01-14T08:21:28.5364025Z   )
2026-01-14T08:21:28.5364199Z )
2026-01-14T08:21:28.5364312Z 
2026-01-14T08:21:28.5364316Z 
2026-01-14T08:21:28.5364320Z 
2026-01-14T08:21:28.5364408Z def forward(self, x):
2026-01-14T08:21:28.5364709Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:28.5365089Z     conv_weight = self.conv.weight
2026-01-14T08:21:28.5365391Z     bn_weight = self.bn.weight
2026-01-14T08:21:28.5365653Z     bn_bias = self.bn.bias
2026-01-14T08:21:28.5365927Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:21:28.5366239Z     bn_running_var = self.bn.running_var
2026-01-14T08:21:28.5366603Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:21:28.5367075Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:28.5367738Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:21:28.5368342Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:21:37.8977003Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:21:37.8977648Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:21:37.8978308Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:21:37.8979038Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:21:37.8979909Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:21:37.8981514Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:21:37.8982779Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:21:37.8983582Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:21:37.8984881Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:21:37.8985996Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:21:37.8986669Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:21:37.8987095Z     
2026-01-14T08:21:37.8987402Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:37.8987793Z model fx: GraphModule(
2026-01-14T08:21:37.8988145Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:37.8989257Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0195]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:37.8990569Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.247849225997925, max_val=2.7226178646087646)
2026-01-14T08:21:37.8991148Z   )
2026-01-14T08:21:37.8991331Z   (conv): ConvBn2d(
2026-01-14T08:21:37.8991603Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:21:37.8992086Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:21:37.8992669Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:37.8993864Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:21:37.8995193Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T08:21:37.8995774Z     )
2026-01-14T08:21:37.8995963Z   )
2026-01-14T08:21:37.8996243Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:37.8997343Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0200]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:37.8998633Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.577202320098877, max_val=2.521923303604126)
2026-01-14T08:21:37.8999198Z   )
2026-01-14T08:21:37.8999381Z )
2026-01-14T08:21:37.8999481Z 
2026-01-14T08:21:37.8999485Z 
2026-01-14T08:21:37.8999489Z 
2026-01-14T08:21:37.8999578Z def forward(self, x):
2026-01-14T08:21:37.8999964Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:37.9000554Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:21:37.9001147Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:21:37.9001619Z     return activation_post_process_1
2026-01-14T08:21:37.9001889Z     
2026-01-14T08:21:37.9002189Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:37.9002588Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:21:37.9002848Z           [0., 0., 0.],
2026-01-14T08:21:37.9003080Z           [0., 0., 0.]],
2026-01-14T08:21:37.9003227Z 
2026-01-14T08:21:37.9003307Z          [[0., 0., 0.],
2026-01-14T08:21:37.9003540Z           [0., 0., 0.],
2026-01-14T08:21:37.9003755Z           [0., 0., 0.]],
2026-01-14T08:21:37.9003899Z 
2026-01-14T08:21:37.9003991Z          [[0., 0., 0.],
2026-01-14T08:21:37.9004204Z           [0., 0., 0.],
2026-01-14T08:21:37.9004499Z           [0., 0., 0.]]],
2026-01-14T08:21:37.9004650Z 
2026-01-14T08:21:37.9004654Z 
2026-01-14T08:21:37.9004734Z         [[[0., 0., 0.],
2026-01-14T08:21:37.9004961Z           [0., 0., 0.],
2026-01-14T08:21:37.9005191Z           [0., 0., 0.]],
2026-01-14T08:21:37.9005338Z 
2026-01-14T08:21:37.9005419Z          [[0., 0., 0.],
2026-01-14T08:21:37.9005652Z           [0., 0., 0.],
2026-01-14T08:21:37.9005868Z           [0., 0., 0.]],
2026-01-14T08:21:37.9006013Z 
2026-01-14T08:21:37.9006107Z          [[0., 0., 0.],
2026-01-14T08:21:37.9006320Z           [0., 0., 0.],
2026-01-14T08:21:37.9006547Z           [0., 0., 0.]]],
2026-01-14T08:21:37.9006695Z 
2026-01-14T08:21:37.9006699Z 
2026-01-14T08:21:37.9006777Z         [[[0., 0., 0.],
2026-01-14T08:21:37.9007003Z           [0., 0., 0.],
2026-01-14T08:21:37.9007232Z           [0., 0., 0.]],
2026-01-14T08:21:37.9007374Z 
2026-01-14T08:21:37.9007454Z          [[0., 0., 0.],
2026-01-14T08:21:37.9007678Z           [0., 0., 0.],
2026-01-14T08:21:37.9007888Z           [0., 0., 0.]],
2026-01-14T08:21:37.9008048Z 
2026-01-14T08:21:37.9008127Z          [[0., 0., 0.],
2026-01-14T08:21:37.9008337Z           [0., 0., 0.],
2026-01-14T08:21:37.9008599Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:21:37.9008925Z converted model pt2e: GraphModule(
2026-01-14T08:21:37.9009210Z   (conv): Module()
2026-01-14T08:21:37.9009430Z   (bn): Module()
2026-01-14T08:21:37.9009626Z )
2026-01-14T08:21:37.9009724Z 
2026-01-14T08:21:37.9009728Z 
2026-01-14T08:21:37.9009732Z 
2026-01-14T08:21:37.9009830Z def forward(self, x):
2026-01-14T08:21:37.9010127Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:37.9010960Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.019492028281092644, -13, -128, 127, torch.int8);  x = None
2026-01-14T08:21:37.9012560Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.019492028281092644, -13, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:37.9013577Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:21:37.9014475Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001507229870185256, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:21:37.9015371Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:21:37.9016316Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:21:37.9017745Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01999657228589058, 1, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:21:37.9019230Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01999657228589058, 1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:21:37.9020385Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:21:37.9020834Z     
2026-01-14T08:21:37.9021146Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:37.9021562Z onverted model fx: GraphModule(
2026-01-14T08:21:37.9021964Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:21:37.9022405Z )
2026-01-14T08:21:37.9022507Z 
2026-01-14T08:21:37.9022511Z 
2026-01-14T08:21:37.9022515Z 
2026-01-14T08:21:37.9022604Z def forward(self, x):
2026-01-14T08:21:37.9023306Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.019492028281092644, -13, -128, 127, torch.int8);  x = None
2026-01-14T08:21:37.9024798Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.019492028281092644, -13, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:37.9025962Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:21:37.9026924Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01999657228589058, 1, -128, 127, torch.int8);  conv = None
2026-01-14T08:21:37.9028363Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01999657228589058, 1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:21:37.9029374Z     return dequantize_per_tensor_default_1
2026-01-14T08:21:37.9029679Z     
2026-01-14T08:21:37.9029975Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:37.9030391Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:21:37.9030643Z           [0., 0., 0.],
2026-01-14T08:21:37.9030882Z           [0., 0., 0.]],
2026-01-14T08:21:37.9031032Z 
2026-01-14T08:21:37.9031117Z          [[0., 0., 0.],
2026-01-14T08:21:37.9031353Z           [0., 0., 0.],
2026-01-14T08:21:37.9031572Z           [0., 0., 0.]],
2026-01-14T08:21:37.9031730Z 
2026-01-14T08:21:37.9031811Z          [[0., 0., 0.],
2026-01-14T08:21:37.9032025Z           [0., 0., 0.],
2026-01-14T08:21:37.9032255Z           [0., 0., 0.]]],
2026-01-14T08:21:37.9032400Z 
2026-01-14T08:21:37.9032404Z 
2026-01-14T08:21:37.9032498Z         [[[0., 0., 0.],
2026-01-14T08:21:37.9032708Z           [0., 0., 0.],
2026-01-14T08:21:37.9032932Z           [0., 0., 0.]],
2026-01-14T08:21:37.9033077Z 
2026-01-14T08:21:37.9033155Z          [[0., 0., 0.],
2026-01-14T08:21:37.9033377Z           [0., 0., 0.],
2026-01-14T08:21:37.9033587Z           [0., 0., 0.]],
2026-01-14T08:21:37.9033740Z 
2026-01-14T08:21:37.9033879Z          [[0., 0., 0.],
2026-01-14T08:21:37.9034103Z           [0., 0., 0.],
2026-01-14T08:21:37.9034316Z           [0., 0., 0.]]],
2026-01-14T08:21:37.9034462Z 
2026-01-14T08:21:37.9034466Z 
2026-01-14T08:21:37.9034558Z         [[[0., 0., 0.],
2026-01-14T08:21:37.9034769Z           [0., 0., 0.],
2026-01-14T08:21:37.9034990Z           [0., 0., 0.]],
2026-01-14T08:21:37.9035133Z 
2026-01-14T08:21:37.9035210Z          [[0., 0., 0.],
2026-01-14T08:21:37.9035432Z           [0., 0., 0.],
2026-01-14T08:21:37.9035644Z           [0., 0., 0.]],
2026-01-14T08:21:37.9035802Z 
2026-01-14T08:21:37.9035880Z          [[0., 0., 0.],
2026-01-14T08:21:37.9036105Z           [0., 0., 0.],
2026-01-14T08:21:37.9036321Z           [0., 0., 0.]]]])
2026-01-14T08:21:37.9036575Z model pt2e: GraphModule(
2026-01-14T08:21:37.9036814Z   (conv1): Module()
2026-01-14T08:21:37.9037032Z   (bn1): Module()
2026-01-14T08:21:37.9037236Z   (conv2): Module()
2026-01-14T08:21:37.9037453Z   (bn2): Module()
2026-01-14T08:21:37.9037764Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:37.9038874Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0195]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:37.9040179Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.247849225997925, max_val=2.7226178646087646)
2026-01-14T08:21:37.9040746Z   )
2026-01-14T08:21:37.9041038Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:37.9042199Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0012, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:21:37.9043741Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1469, -0.1921, -0.1853]), max_val=tensor([0.1307, 0.1779, 0.1810]))
2026-01-14T08:21:37.9044482Z   )
2026-01-14T08:21:37.9044770Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:44.6392017Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:21:44.6393888Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1787, -0.1913]), max_val=tensor([0.1870, 0.1478, 0.1740]))
2026-01-14T08:21:44.6394691Z   )
2026-01-14T08:21:44.6394983Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:44.6396203Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0192]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:44.6397601Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.725703001022339, max_val=2.165140390396118)
2026-01-14T08:21:44.6398186Z   )
2026-01-14T08:21:44.6398547Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:44.6399696Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:44.6401110Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3412710428237915, max_val=1.3707175254821777)
2026-01-14T08:21:44.6401738Z   )
2026-01-14T08:21:44.6401922Z )
2026-01-14T08:21:44.6402021Z 
2026-01-14T08:21:44.6402026Z 
2026-01-14T08:21:44.6402030Z 
2026-01-14T08:21:44.6402131Z def forward(self, x):
2026-01-14T08:21:44.6402486Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:44.6402867Z     conv1_weight = self.conv1.weight
2026-01-14T08:21:44.6403349Z     bn1_weight = self.bn1.weight
2026-01-14T08:21:44.6403640Z     bn1_bias = self.bn1.bias
2026-01-14T08:21:44.6403963Z     conv2_weight = self.conv2.weight
2026-01-14T08:21:44.6404273Z     conv2_bias = self.conv2.bias
2026-01-14T08:21:44.6404545Z     bn2_weight = self.bn2.weight
2026-01-14T08:21:44.6404878Z     bn2_bias = self.bn2.bias
2026-01-14T08:21:44.6405151Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:21:44.6405531Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:21:44.6405903Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:21:44.6406324Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:21:44.6406649Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:21:44.6407051Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:21:44.6407544Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:44.6408257Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:21:44.6409098Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:21:44.6409783Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:21:44.6410261Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:21:44.6410715Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:21:44.6411256Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:21:44.6411881Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:21:44.6412657Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:21:44.6413413Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:21:44.6414090Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:21:44.6414543Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:21:44.6415083Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:21:44.6415836Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T08:21:44.6416498Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:21:44.6417199Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:21:44.6418238Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:21:44.6419264Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T08:21:44.6419949Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T08:21:44.6421138Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:21:44.6422364Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:21:44.6423576Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:21:44.6424646Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:21:44.6425309Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T08:21:44.6426023Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T08:21:44.6426719Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:21:44.6427942Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:21:44.6429142Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:21:44.6429816Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:21:44.6430243Z     
2026-01-14T08:21:44.6430558Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:44.6430952Z model fx: GraphModule(
2026-01-14T08:21:44.6431359Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:44.6432470Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0195]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:44.6433770Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.247849225997925, max_val=2.7226178646087646)
2026-01-14T08:21:44.6434350Z   )
2026-01-14T08:21:44.6434535Z   (conv1): ConvBn2d(
2026-01-14T08:21:44.6434820Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:21:44.6435361Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:21:44.6435889Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:44.6437041Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:21:44.6438576Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1787, -0.1913]), max_val=tensor([0.1870, 0.1478, 0.1740]))
2026-01-14T08:21:44.6439309Z     )
2026-01-14T08:21:44.6439488Z   )
2026-01-14T08:21:44.6439780Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:44.6440950Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0192]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:44.6442292Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.725703001022339, max_val=2.165140390396118)
2026-01-14T08:21:44.6442865Z   )
2026-01-14T08:21:44.6443045Z   (conv2): ConvBn2d(
2026-01-14T08:21:44.6443296Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:21:44.6443755Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:21:44.6444269Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:44.6445425Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0012, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:21:44.6446966Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1469, -0.1921, -0.1853]), max_val=tensor([0.1307, 0.1779, 0.1810]))
2026-01-14T08:21:44.6447708Z     )
2026-01-14T08:21:44.6447897Z   )
2026-01-14T08:21:44.6448180Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:44.6449289Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:44.6450750Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3412710428237915, max_val=1.3707175254821777)
2026-01-14T08:21:44.6451332Z   )
2026-01-14T08:21:44.6451507Z )
2026-01-14T08:21:44.6451622Z 
2026-01-14T08:21:44.6451742Z 
2026-01-14T08:21:44.6451746Z 
2026-01-14T08:21:44.6451835Z def forward(self, x):
2026-01-14T08:21:44.6452306Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:44.6452904Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:21:44.6453529Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:21:44.6454132Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:21:44.6454747Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:21:44.6455231Z     return activation_post_process_2
2026-01-14T08:21:44.6455573Z     
2026-01-14T08:21:44.6455879Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:44.6456270Z diff: tensor([[[[0.]],
2026-01-14T08:21:44.6456417Z 
2026-01-14T08:21:44.6456506Z          [[0.]],
2026-01-14T08:21:44.6456630Z 
2026-01-14T08:21:44.6456712Z          [[0.]]],
2026-01-14T08:21:44.6456846Z 
2026-01-14T08:21:44.6456850Z 
2026-01-14T08:21:44.6456927Z         [[[0.]],
2026-01-14T08:21:44.6457049Z 
2026-01-14T08:21:44.6457136Z          [[0.]],
2026-01-14T08:21:44.6457256Z 
2026-01-14T08:21:44.6457336Z          [[0.]]],
2026-01-14T08:21:44.6457458Z 
2026-01-14T08:21:44.6457462Z 
2026-01-14T08:21:44.6457550Z         [[[0.]],
2026-01-14T08:21:44.6457670Z 
2026-01-14T08:21:44.6457746Z          [[0.]],
2026-01-14T08:21:44.6457879Z 
2026-01-14T08:21:44.6457981Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:21:44.6458289Z converted model pt2e: GraphModule(
2026-01-14T08:21:44.6458576Z   (conv1): Module()
2026-01-14T08:21:44.6458798Z   (bn1): Module()
2026-01-14T08:21:45.9831299Z   (conv2): Module()
2026-01-14T08:21:45.9831673Z   (bn2): Module()
2026-01-14T08:21:45.9831943Z )
2026-01-14T08:21:45.9832087Z 
2026-01-14T08:21:45.9832093Z 
2026-01-14T08:21:45.9832098Z 
2026-01-14T08:21:45.9832214Z def forward(self, x):
2026-01-14T08:21:45.9832651Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:45.9833129Z     conv2_bias = self.conv2.bias
2026-01-14T08:21:45.9834436Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.019492028281092644, -13, -128, 127, torch.int8);  x = None
2026-01-14T08:21:45.9836334Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.019492028281092644, -13, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:45.9837646Z     _scale_0 = self._scale_0
2026-01-14T08:21:45.9838006Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:21:45.9838381Z     _scale_1 = self._scale_1
2026-01-14T08:21:45.9838734Z     _zero_point_1 = self._zero_point_1
2026-01-14T08:21:45.9839194Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T08:21:45.9840556Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T08:21:45.9841975Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:21:45.9843270Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T08:21:45.9845232Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.019179778173565865, 14, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T08:21:45.9847226Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.019179778173565865, 14, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:21:45.9848286Z     quantize_per_channel = self._frozen_param1
2026-01-14T08:21:45.9849302Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:21:45.9851279Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T08:21:45.9852758Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.010635248385369778, -2, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T08:21:45.9854271Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010635248385369778, -2, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:21:45.9855427Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:21:45.9855874Z     
2026-01-14T08:21:45.9856187Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:45.9856606Z onverted model fx: GraphModule(
2026-01-14T08:21:45.9857026Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:21:45.9857596Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:21:45.9858023Z )
2026-01-14T08:21:45.9858124Z 
2026-01-14T08:21:45.9858129Z 
2026-01-14T08:21:45.9858133Z 
2026-01-14T08:21:45.9858237Z def forward(self, x):
2026-01-14T08:21:45.9858927Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.019492028281092644, -13, -128, 127, torch.int8);  x = None
2026-01-14T08:21:45.9860365Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.019492028281092644, -13, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:45.9861524Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:21:45.9862517Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.019179778173565865, 14, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:21:45.9864103Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.019179778173565865, 14, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:21:45.9865284Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:21:45.9866284Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.010635248385369778, -2, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:21:45.9867768Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010635248385369778, -2, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:21:45.9868786Z     return dequantize_per_tensor_default_2
2026-01-14T08:21:45.9869096Z     
2026-01-14T08:21:45.9869393Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:45.9869801Z diff: tensor([[[[0.]],
2026-01-14T08:21:45.9869951Z 
2026-01-14T08:21:45.9870044Z          [[0.]],
2026-01-14T08:21:45.9870165Z 
2026-01-14T08:21:45.9870246Z          [[0.]]],
2026-01-14T08:21:45.9870368Z 
2026-01-14T08:21:45.9870372Z 
2026-01-14T08:21:45.9870465Z         [[[0.]],
2026-01-14T08:21:45.9870585Z 
2026-01-14T08:21:45.9870659Z          [[0.]],
2026-01-14T08:21:45.9870788Z 
2026-01-14T08:21:45.9870864Z          [[0.]]],
2026-01-14T08:21:45.9870984Z 
2026-01-14T08:21:45.9870988Z 
2026-01-14T08:21:45.9871063Z         [[[0.]],
2026-01-14T08:21:45.9871190Z 
2026-01-14T08:21:45.9871266Z          [[0.]],
2026-01-14T08:21:45.9871382Z 
2026-01-14T08:21:45.9871469Z          [[0.]]]])
2026-01-14T08:21:45.9871682Z model pt2e: GraphModule(
2026-01-14T08:21:45.9872013Z   (conv1): Module()
2026-01-14T08:21:45.9872220Z   (bn1): Module()
2026-01-14T08:21:45.9872433Z   (conv2): Module()
2026-01-14T08:21:45.9872635Z   (bn2): Module()
2026-01-14T08:21:45.9872957Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:45.9874052Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0195]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:45.9875367Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.247849225997925, max_val=2.7226178646087646)
2026-01-14T08:21:45.9875943Z   )
2026-01-14T08:21:45.9876230Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:45.9877342Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:21:45.9878662Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T08:21:45.9879241Z   )
2026-01-14T08:21:45.9879546Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:45.9880633Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:21:45.9881943Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T08:21:45.9882531Z   )
2026-01-14T08:21:45.9882810Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:45.9883903Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0192]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:45.9885176Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.725703001022339, max_val=2.165140390396118)
2026-01-14T08:21:45.9885806Z   )
2026-01-14T08:21:45.9886089Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:45.9887180Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0107]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:45.9888459Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.349876046180725, max_val=1.373764157295227)
2026-01-14T08:21:45.9889020Z   )
2026-01-14T08:21:45.9889204Z )
2026-01-14T08:21:45.9889302Z 
2026-01-14T08:21:45.9889306Z 
2026-01-14T08:21:45.9889309Z 
2026-01-14T08:21:45.9889397Z def forward(self, x):
2026-01-14T08:21:45.9889713Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:45.9890096Z     conv1_weight = self.conv1.weight
2026-01-14T08:21:45.9890391Z     bn1_weight = self.bn1.weight
2026-01-14T08:21:45.9890670Z     bn1_bias = self.bn1.bias
2026-01-14T08:21:45.9890934Z     conv2_weight = self.conv2.weight
2026-01-14T08:21:45.9891233Z     conv2_bias = self.conv2.bias
2026-01-14T08:21:45.9891501Z     bn2_weight = self.bn2.weight
2026-01-14T08:21:45.9891777Z     bn2_bias = self.bn2.bias
2026-01-14T08:21:45.9892156Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:21:45.9892497Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:21:45.9892872Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:21:45.9893241Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:21:45.9893569Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:21:45.9893923Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:21:45.9894409Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:45.9895169Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:21:45.9895957Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:21:45.9896578Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:21:45.9897001Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:21:45.9897456Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:21:45.9897939Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:21:45.9898505Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:21:45.9899126Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:21:45.9899818Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:21:45.9900458Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:21:45.9900900Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:21:54.0510921Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:21:54.0511618Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T08:21:54.0512283Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:21:54.0513001Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:21:54.0513971Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:21:54.0514927Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T08:21:54.0515551Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T08:21:54.0516942Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:21:54.0518084Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:21:54.0519320Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:21:54.0520386Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:21:54.0521000Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T08:21:54.0521667Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T08:21:54.0522297Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:21:54.0523384Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:21:54.0524648Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:21:54.0525378Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:21:54.0525813Z     
2026-01-14T08:21:54.0526111Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:54.0526519Z model fx: GraphModule(
2026-01-14T08:21:54.0526851Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:54.0527957Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0195]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:54.0529542Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.247849225997925, max_val=2.7226178646087646)
2026-01-14T08:21:54.0530111Z   )
2026-01-14T08:21:54.0530311Z   (conv1): ConvBn2d(
2026-01-14T08:21:54.0530580Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:21:54.0531071Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:21:54.0531627Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:54.0532824Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:21:54.0534139Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T08:21:54.0534731Z     )
2026-01-14T08:21:54.0534908Z   )
2026-01-14T08:21:54.0535210Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:54.0536313Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0192]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:54.0537610Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.725703001022339, max_val=2.165140390396118)
2026-01-14T08:21:54.0538185Z   )
2026-01-14T08:21:54.0538367Z   (conv2): ConvBn2d(
2026-01-14T08:21:54.0538619Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:21:54.0539065Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:21:54.0539592Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:54.0540679Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:21:54.0542071Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T08:21:54.0542666Z     )
2026-01-14T08:21:54.0542844Z   )
2026-01-14T08:21:54.0543146Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:21:54.0544241Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0107]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:21:54.0545542Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.349876046180725, max_val=1.373764157295227)
2026-01-14T08:21:54.0546124Z   )
2026-01-14T08:21:54.0546299Z )
2026-01-14T08:21:54.0546412Z 
2026-01-14T08:21:54.0546417Z 
2026-01-14T08:21:54.0546420Z 
2026-01-14T08:21:54.0546515Z def forward(self, x):
2026-01-14T08:21:54.0546884Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:21:54.0547491Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:21:54.0548110Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:21:54.0548717Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:21:54.0549331Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:21:54.0549985Z     return activation_post_process_2
2026-01-14T08:21:54.0550274Z     
2026-01-14T08:21:54.0550565Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:54.0550969Z diff: tensor([[[[0.]],
2026-01-14T08:21:54.0551116Z 
2026-01-14T08:21:54.0551211Z          [[0.]],
2026-01-14T08:21:54.0551336Z 
2026-01-14T08:21:54.0551417Z          [[0.]]],
2026-01-14T08:21:54.0551659Z 
2026-01-14T08:21:54.0551663Z 
2026-01-14T08:21:54.0551756Z         [[[0.]],
2026-01-14T08:21:54.0551877Z 
2026-01-14T08:21:54.0551957Z          [[0.]],
2026-01-14T08:21:54.0552090Z 
2026-01-14T08:21:54.0552167Z          [[0.]]],
2026-01-14T08:21:54.0552295Z 
2026-01-14T08:21:54.0552299Z 
2026-01-14T08:21:54.0552390Z         [[[0.]],
2026-01-14T08:21:54.0552509Z 
2026-01-14T08:21:54.0552586Z          [[0.]],
2026-01-14T08:21:54.0552707Z 
2026-01-14T08:21:54.0552824Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:21:54.0553131Z converted model pt2e: GraphModule(
2026-01-14T08:21:54.0553413Z   (conv1): Module()
2026-01-14T08:21:54.0553619Z   (bn1): Module()
2026-01-14T08:21:54.0553833Z   (conv2): Module()
2026-01-14T08:21:54.0554040Z   (bn2): Module()
2026-01-14T08:21:54.0554248Z )
2026-01-14T08:21:54.0554347Z 
2026-01-14T08:21:54.0554351Z 
2026-01-14T08:21:54.0554355Z 
2026-01-14T08:21:54.0554453Z def forward(self, x):
2026-01-14T08:21:54.0554754Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:21:54.0555136Z     conv2_bias = self.conv2.bias
2026-01-14T08:21:54.0555868Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.019492028281092644, -13, -128, 127, torch.int8);  x = None
2026-01-14T08:21:54.0557307Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.019492028281092644, -13, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:21:54.0558323Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T08:21:54.0559235Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.0015061007579788566, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T08:21:54.0560173Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:21:54.0561141Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T08:21:54.0562682Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.019179778173565865, 14, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T08:21:54.0564191Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.019179778173565865, 14, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:21:54.0565201Z     quantize_per_tensor = self._frozen_param1
2026-01-14T08:21:54.0566095Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001512790797278285, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:21:54.0567565Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T08:21:54.0568962Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.010680941864848137, -2, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T08:21:54.0570464Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.010680941864848137, -2, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T08:21:54.0571616Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T08:21:54.0572147Z     
2026-01-14T08:21:54.0572458Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:21:54.0572866Z onverted model fx: GraphModule(
2026-01-14T08:21:54.0573290Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:21:54.0573855Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:21:54.0574346Z )
2026-01-14T08:21:54.0574447Z 
2026-01-14T08:21:54.0574451Z 
2026-01-14T08:21:54.0574455Z 
2026-01-14T08:21:54.0574556Z def forward(self, x):
2026-01-14T08:21:54.0575244Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.019492028281092644, -13, -128, 127, torch.int8);  x = None
2026-01-14T08:22:13.3630363Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.019492028281092644, -13, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:13.3631975Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:22:13.3633286Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.019179778173565865, 14, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:22:13.3635278Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.019179778173565865, 14, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:13.3636877Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:22:13.3638210Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.010680941864848137, -2, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:22:13.3640174Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010680941864848137, -2, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:22:13.3641511Z     return dequantize_per_tensor_default_2
2026-01-14T08:22:13.3641907Z     
2026-01-14T08:22:13.3642297Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:13.3642831Z diff: tensor([[[[0.]],
2026-01-14T08:22:13.3643024Z 
2026-01-14T08:22:13.3643144Z          [[0.]],
2026-01-14T08:22:13.3643312Z 
2026-01-14T08:22:13.3643418Z          [[0.]]],
2026-01-14T08:22:13.3643584Z 
2026-01-14T08:22:13.3643603Z 
2026-01-14T08:22:13.3643708Z         [[[0.]],
2026-01-14T08:22:13.3643871Z 
2026-01-14T08:22:13.3643972Z          [[0.]],
2026-01-14T08:22:13.3644465Z 
2026-01-14T08:22:13.3644571Z          [[0.]]],
2026-01-14T08:22:13.3644735Z 
2026-01-14T08:22:13.3644740Z 
2026-01-14T08:22:13.3644856Z         [[[0.]],
2026-01-14T08:22:13.3645014Z 
2026-01-14T08:22:13.3645118Z          [[0.]],
2026-01-14T08:22:13.3645276Z 
2026-01-14T08:22:13.3645393Z          [[0.]]]])
2026-01-14T08:22:13.3645887Z [32mPASSED[0m
2026-01-14T08:22:13.3646910Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T08:22:13.3648351Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T08:22:13.3649255Z   (conv): Module()
2026-01-14T08:22:13.3649905Z   (bn): Module()
2026-01-14T08:22:13.3650321Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:13.3651794Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:13.3653580Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:13.3654344Z   )
2026-01-14T08:22:13.3654734Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:13.3656280Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:22:13.3658356Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1761, -0.1923, -0.1707]), max_val=tensor([0.1830, 0.1717, 0.1892]))
2026-01-14T08:22:13.3659490Z   )
2026-01-14T08:22:13.3659864Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:13.3661333Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0065]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:13.3662989Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.6655889749526978)
2026-01-14T08:22:13.3663670Z   )
2026-01-14T08:22:13.3663912Z )
2026-01-14T08:22:13.3664043Z 
2026-01-14T08:22:13.3664048Z 
2026-01-14T08:22:13.3664053Z 
2026-01-14T08:22:13.3664171Z def forward(self, x):
2026-01-14T08:22:13.3664572Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:13.3665049Z     conv_weight = self.conv.weight
2026-01-14T08:22:13.3665436Z     conv_bias = self.conv.bias
2026-01-14T08:22:13.3665787Z     bn_weight = self.bn.weight
2026-01-14T08:22:13.3666140Z     bn_bias = self.bn.bias
2026-01-14T08:22:13.3666498Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:22:13.3666915Z     bn_running_var = self.bn.running_var
2026-01-14T08:22:13.3667382Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:22:13.3667973Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:13.3668635Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:22:13.3669223Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:22:13.3669650Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:22:13.3670101Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:22:13.3670577Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:22:13.3671137Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:22:13.3671763Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:22:13.3672554Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:22:13.3673670Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:22:13.3674696Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:22:13.3675309Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:22:13.3675962Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:22:13.3676603Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:22:13.3677638Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:22:13.3678669Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:22:13.3679247Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:22:13.3679833Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:22:13.3680266Z     
2026-01-14T08:22:13.3680555Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:13.3680954Z model fx: GraphModule(
2026-01-14T08:22:13.3681284Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:13.3682388Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:13.3683751Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:13.3684311Z   )
2026-01-14T08:22:13.3684518Z   (conv): ConvBnReLU2d(
2026-01-14T08:22:13.3684770Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:22:13.3685231Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:22:13.3685760Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:13.3686895Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:22:13.3688439Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1761, -0.1923, -0.1707]), max_val=tensor([0.1830, 0.1717, 0.1892]))
2026-01-14T08:22:13.3689165Z     )
2026-01-14T08:22:13.3689353Z   )
2026-01-14T08:22:13.3689646Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:13.3690748Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0065]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:13.3692091Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.6655889749526978)
2026-01-14T08:22:13.3692602Z   )
2026-01-14T08:22:13.3692786Z )
2026-01-14T08:22:13.3692887Z 
2026-01-14T08:22:13.3692891Z 
2026-01-14T08:22:13.3692895Z 
2026-01-14T08:22:13.3692996Z def forward(self, x):
2026-01-14T08:22:13.3693362Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:13.3693951Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:22:13.3694545Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:22:13.3695023Z     return activation_post_process_1
2026-01-14T08:22:13.3695296Z     
2026-01-14T08:22:13.3695674Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:13.3696077Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:13.3696338Z           [0., 0., 0.],
2026-01-14T08:22:13.3696570Z           [0., 0., 0.]],
2026-01-14T08:22:13.3696716Z 
2026-01-14T08:22:13.3696795Z          [[0., 0., 0.],
2026-01-14T08:22:13.3697022Z           [0., 0., 0.],
2026-01-14T08:22:13.3697237Z           [0., 0., 0.]],
2026-01-14T08:22:13.3697391Z 
2026-01-14T08:22:13.3697470Z          [[0., 0., 0.],
2026-01-14T08:22:13.3697682Z           [0., 0., 0.],
2026-01-14T08:22:13.3697941Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:22:13.3698269Z converted model pt2e: GraphModule(
2026-01-14T08:22:13.3698556Z   (conv): Module()
2026-01-14T08:22:13.3698773Z   (bn): Module()
2026-01-14T08:22:13.3698977Z )
2026-01-14T08:22:13.3699079Z 
2026-01-14T08:22:13.3699083Z 
2026-01-14T08:22:13.3699087Z 
2026-01-14T08:22:13.3699189Z def forward(self, x):
2026-01-14T08:22:13.3699488Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:13.3699862Z     conv_bias = self.conv.bias
2026-01-14T08:22:13.3715341Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:13.3716787Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:13.3717785Z     _scale_0 = self._scale_0
2026-01-14T08:22:13.3718061Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:22:13.3718396Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:22:21.4648998Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:22:21.4651696Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:22:21.4653163Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T08:22:21.4654326Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006531721446663141, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:22:21.4656318Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006531721446663141, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:21.4657888Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:22:21.4658489Z     
2026-01-14T08:22:21.4658891Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:21.4659435Z onverted model fx: GraphModule(
2026-01-14T08:22:21.4659804Z   (conv): ConvReLU2d(
2026-01-14T08:22:21.4660277Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:22:21.4660830Z     (1): ReLU()
2026-01-14T08:22:21.4661096Z   )
2026-01-14T08:22:21.4661344Z )
2026-01-14T08:22:21.4661474Z 
2026-01-14T08:22:21.4661480Z 
2026-01-14T08:22:21.4661485Z 
2026-01-14T08:22:21.4661613Z def forward(self, x):
2026-01-14T08:22:21.4662513Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:21.4664419Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:21.4665957Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:22:21.4667370Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006531721446663141, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:22:21.4669353Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006531721446663141, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:21.4670698Z     return dequantize_per_tensor_default_1
2026-01-14T08:22:21.4671089Z     
2026-01-14T08:22:21.4671486Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:21.4672011Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:21.4672347Z           [0., 0., 0.],
2026-01-14T08:22:21.4672636Z           [0., 0., 0.]],
2026-01-14T08:22:21.4672831Z 
2026-01-14T08:22:21.4672952Z          [[0., 0., 0.],
2026-01-14T08:22:21.4673243Z           [0., 0., 0.],
2026-01-14T08:22:21.4673537Z           [0., 0., 0.]],
2026-01-14T08:22:21.4673727Z 
2026-01-14T08:22:21.4673834Z          [[0., 0., 0.],
2026-01-14T08:22:21.4674223Z           [0., 0., 0.],
2026-01-14T08:22:21.4674514Z           [0., 0., 0.]]]])
2026-01-14T08:22:21.4674845Z model pt2e: GraphModule(
2026-01-14T08:22:21.4675172Z   (conv): Module()
2026-01-14T08:22:21.4675447Z   (bn): Module()
2026-01-14T08:22:21.4675865Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:21.4677313Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:21.4679052Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:21.4679801Z   )
2026-01-14T08:22:21.4680188Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:21.4681757Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:22:21.4683492Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1923346221446991, max_val=0.18921314179897308)
2026-01-14T08:22:21.4684272Z   )
2026-01-14T08:22:21.4684643Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:21.4686109Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0065]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:21.4687448Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.6606048345565796)
2026-01-14T08:22:21.4687958Z   )
2026-01-14T08:22:21.4688148Z )
2026-01-14T08:22:21.4688247Z 
2026-01-14T08:22:21.4688252Z 
2026-01-14T08:22:21.4688256Z 
2026-01-14T08:22:21.4688345Z def forward(self, x):
2026-01-14T08:22:21.4688656Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:21.4689035Z     conv_weight = self.conv.weight
2026-01-14T08:22:21.4689319Z     conv_bias = self.conv.bias
2026-01-14T08:22:21.4689593Z     bn_weight = self.bn.weight
2026-01-14T08:22:21.4689850Z     bn_bias = self.bn.bias
2026-01-14T08:22:21.4690124Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:22:21.4690435Z     bn_running_var = self.bn.running_var
2026-01-14T08:22:21.4690791Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:22:21.4691260Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:21.4691993Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:22:21.4692601Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:22:21.4693021Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:22:21.4693476Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:22:21.4694035Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:22:21.4694597Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:22:21.4695218Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:22:21.4695915Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:22:21.4697043Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:22:21.4698058Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:22:21.4698669Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:22:21.4699320Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:22:21.4699956Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:22:21.4700998Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:22:21.4701997Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:22:21.4702574Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:22:21.4703165Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:22:21.4703602Z     
2026-01-14T08:22:21.4703906Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:21.4704299Z model fx: GraphModule(
2026-01-14T08:22:21.4705088Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:21.4706187Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:21.4707495Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:21.4708072Z   )
2026-01-14T08:22:21.4708262Z   (conv): ConvBnReLU2d(
2026-01-14T08:22:21.4708523Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:22:21.4708971Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:22:21.4709496Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:21.4710569Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:22:21.4711898Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1923346221446991, max_val=0.18921314179897308)
2026-01-14T08:22:21.4712485Z     )
2026-01-14T08:22:21.4712660Z   )
2026-01-14T08:22:21.4712955Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:21.4714048Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0065]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:21.4715296Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.6606048345565796)
2026-01-14T08:22:21.4715816Z   )
2026-01-14T08:22:21.4715987Z )
2026-01-14T08:22:21.4716087Z 
2026-01-14T08:22:21.4716091Z 
2026-01-14T08:22:21.4716096Z 
2026-01-14T08:22:21.4716194Z def forward(self, x):
2026-01-14T08:22:21.4716567Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:21.4717157Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:22:21.4717841Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:22:21.4718315Z     return activation_post_process_1
2026-01-14T08:22:21.4718601Z     
2026-01-14T08:22:21.4718888Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:21.4719304Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:21.4719549Z           [0., 0., 0.],
2026-01-14T08:22:21.4719778Z           [0., 0., 0.]],
2026-01-14T08:22:21.4719925Z 
2026-01-14T08:22:21.4720004Z          [[0., 0., 0.],
2026-01-14T08:22:21.4720233Z           [0., 0., 0.],
2026-01-14T08:22:21.4720445Z           [0., 0., 0.]],
2026-01-14T08:22:21.4720600Z 
2026-01-14T08:22:21.4720677Z          [[0., 0., 0.],
2026-01-14T08:22:21.4720888Z           [0., 0., 0.],
2026-01-14T08:22:21.4721152Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:22:21.4721490Z converted model pt2e: GraphModule(
2026-01-14T08:22:21.4721761Z   (conv): Module()
2026-01-14T08:22:21.4721979Z   (bn): Module()
2026-01-14T08:22:21.4722177Z )
2026-01-14T08:22:21.4722277Z 
2026-01-14T08:22:21.4722295Z 
2026-01-14T08:22:21.4722299Z 
2026-01-14T08:22:21.4722387Z def forward(self, x):
2026-01-14T08:22:21.4722684Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:21.4723059Z     conv_bias = self.conv.bias
2026-01-14T08:22:26.6578886Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:26.6580352Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:26.6581655Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:22:26.6582576Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0015144458739086986, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:22:26.6584029Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:22:26.6584986Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T08:22:26.6585867Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006512175779789686, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:22:26.6587355Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.006512175779789686, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:22:26.6588518Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:22:26.6588980Z     
2026-01-14T08:22:26.6589277Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:26.6589697Z onverted model fx: GraphModule(
2026-01-14T08:22:26.6589965Z   (conv): ConvReLU2d(
2026-01-14T08:22:26.6590367Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:22:26.6590780Z     (1): ReLU()
2026-01-14T08:22:26.6590973Z   )
2026-01-14T08:22:26.6591157Z )
2026-01-14T08:22:26.6591256Z 
2026-01-14T08:22:26.6591260Z 
2026-01-14T08:22:26.6591264Z 
2026-01-14T08:22:26.6591365Z def forward(self, x):
2026-01-14T08:22:26.6592046Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:26.6593468Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:26.6594614Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:22:26.6595700Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006512175779789686, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:22:26.6597190Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006512175779789686, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:26.6598201Z     return dequantize_per_tensor_default_1
2026-01-14T08:22:26.6598502Z     
2026-01-14T08:22:26.6598794Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:26.6599203Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:26.6599446Z           [0., 0., 0.],
2026-01-14T08:22:26.6599676Z           [0., 0., 0.]],
2026-01-14T08:22:26.6599828Z 
2026-01-14T08:22:26.6599918Z          [[0., 0., 0.],
2026-01-14T08:22:26.6600131Z           [0., 0., 0.],
2026-01-14T08:22:26.6600355Z           [0., 0., 0.]],
2026-01-14T08:22:26.6600499Z 
2026-01-14T08:22:26.6600580Z          [[0., 0., 0.],
2026-01-14T08:22:26.6600803Z           [0., 0., 0.],
2026-01-14T08:22:26.6601018Z           [0., 0., 0.]]]])
2026-01-14T08:22:26.6601444Z [32mPASSED[0m
2026-01-14T08:22:26.6602172Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:22:26.6603284Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:22:26.6604018Z   (conv): Module()
2026-01-14T08:22:26.6604224Z   (bn): Module()
2026-01-14T08:22:26.6604544Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:26.6605637Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:26.6607020Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:26.6607592Z   )
2026-01-14T08:22:26.6607877Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:26.6609057Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:22:26.6610579Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1720, -0.1912, -0.1684]), max_val=tensor([0.1914, 0.1792, 0.1824]))
2026-01-14T08:22:26.6611313Z   )
2026-01-14T08:22:26.6611609Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:26.6612865Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:26.6614117Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9991776943206787)
2026-01-14T08:22:26.6614633Z   )
2026-01-14T08:22:26.6614822Z )
2026-01-14T08:22:26.6614927Z 
2026-01-14T08:22:26.6614931Z 
2026-01-14T08:22:26.6614935Z 
2026-01-14T08:22:26.6615038Z def forward(self, x):
2026-01-14T08:22:26.6615344Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:26.6615719Z     conv_weight = self.conv.weight
2026-01-14T08:22:26.6616002Z     bn_weight = self.bn.weight
2026-01-14T08:22:26.6616273Z     bn_bias = self.bn.bias
2026-01-14T08:22:26.6616538Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:22:26.6616861Z     bn_running_var = self.bn.running_var
2026-01-14T08:22:26.6617213Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:22:26.6617697Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:26.6618437Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:22:26.6619028Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:22:26.6619460Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:22:26.6619902Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:22:26.6620395Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:22:26.6620942Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:22:26.6621575Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:22:26.6622528Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:22:26.6623467Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:22:26.6624082Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:22:26.6625146Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:22:26.6626146Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:22:26.6626723Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:22:26.6627327Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:22:26.6627757Z     
2026-01-14T08:22:26.6628054Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:26.6628520Z model fx: GraphModule(
2026-01-14T08:22:26.6628855Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:26.6629960Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:26.6631251Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:26.6631815Z   )
2026-01-14T08:22:26.6632016Z   (conv): ConvBnReLU2d(
2026-01-14T08:22:26.6632291Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:22:26.6632783Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:22:26.6633298Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:26.6634444Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:22:26.6635989Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1720, -0.1912, -0.1684]), max_val=tensor([0.1914, 0.1792, 0.1824]))
2026-01-14T08:22:26.6636715Z     )
2026-01-14T08:22:26.6636902Z   )
2026-01-14T08:22:26.6637183Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:26.6638295Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:26.6639540Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9991776943206787)
2026-01-14T08:22:26.6640050Z   )
2026-01-14T08:22:26.6640233Z )
2026-01-14T08:22:26.6640337Z 
2026-01-14T08:22:26.6640341Z 
2026-01-14T08:22:26.6640345Z 
2026-01-14T08:22:26.6640433Z def forward(self, x):
2026-01-14T08:22:26.6640810Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:26.6641446Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:22:26.6642054Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:22:26.6642528Z     return activation_post_process_1
2026-01-14T08:22:26.6642798Z     
2026-01-14T08:22:26.6643100Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:26.6643493Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:26.6643754Z           [0., 0., 0.],
2026-01-14T08:22:26.6643972Z           [0., 0., 0.]],
2026-01-14T08:22:26.6644132Z 
2026-01-14T08:22:26.6644210Z          [[0., 0., 0.],
2026-01-14T08:22:26.6644425Z           [0., 0., 0.],
2026-01-14T08:22:34.7886808Z           [0., 0., 0.]],
2026-01-14T08:22:34.7887203Z 
2026-01-14T08:22:34.7887349Z          [[0., 0., 0.],
2026-01-14T08:22:34.7887725Z           [0., 0., 0.],
2026-01-14T08:22:34.7888216Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:22:34.7888869Z converted model pt2e: GraphModule(
2026-01-14T08:22:34.7889375Z   (conv): Module()
2026-01-14T08:22:34.7889754Z   (bn): Module()
2026-01-14T08:22:34.7890122Z )
2026-01-14T08:22:34.7890296Z 
2026-01-14T08:22:34.7890320Z 
2026-01-14T08:22:34.7890327Z 
2026-01-14T08:22:34.7890469Z def forward(self, x):
2026-01-14T08:22:34.7891006Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:34.7892649Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:34.7895433Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:34.7897659Z     _scale_0 = self._scale_0
2026-01-14T08:22:34.7898134Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:22:34.7898710Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:22:34.7900519Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:22:34.7902422Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:22:34.7904031Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:22:34.7905954Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T08:22:34.7907591Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007839912548661232, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:22:34.7910386Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007839912548661232, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:34.7912598Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:22:34.7913363Z     
2026-01-14T08:22:34.7913877Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:34.7914603Z onverted model fx: GraphModule(
2026-01-14T08:22:34.7915055Z   (conv): ConvReLU2d(
2026-01-14T08:22:34.7915668Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:22:34.7916459Z     (1): ReLU()
2026-01-14T08:22:34.7916833Z   )
2026-01-14T08:22:34.7917122Z )
2026-01-14T08:22:34.7917299Z 
2026-01-14T08:22:34.7917306Z 
2026-01-14T08:22:34.7917313Z 
2026-01-14T08:22:34.7917490Z def forward(self, x):
2026-01-14T08:22:34.7918789Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:34.7921658Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:34.7923767Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:22:34.7925563Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007839912548661232, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:22:34.7928449Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007839912548661232, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:34.7930286Z     return dequantize_per_tensor_default_1
2026-01-14T08:22:34.7930806Z     
2026-01-14T08:22:34.7931318Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:34.7932118Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:34.7932580Z           [0., 0., 0.],
2026-01-14T08:22:34.7932942Z           [0., 0., 0.]],
2026-01-14T08:22:34.7933219Z 
2026-01-14T08:22:34.7933349Z          [[0., 0., 0.],
2026-01-14T08:22:34.7933703Z           [0., 0., 0.],
2026-01-14T08:22:34.7934079Z           [0., 0., 0.]],
2026-01-14T08:22:34.7934346Z 
2026-01-14T08:22:34.7934484Z          [[0., 0., 0.],
2026-01-14T08:22:34.7934863Z           [0., 0., 0.],
2026-01-14T08:22:34.7935247Z           [0., 0., 0.]]]])
2026-01-14T08:22:34.7935676Z model pt2e: GraphModule(
2026-01-14T08:22:34.7936096Z   (conv): Module()
2026-01-14T08:22:34.7936445Z   (bn): Module()
2026-01-14T08:22:34.7936982Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:34.7938922Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:34.7941530Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:34.7942542Z   )
2026-01-14T08:22:34.7943028Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:34.7944910Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:22:34.7947300Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T08:22:34.7948359Z   )
2026-01-14T08:22:34.7948861Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:34.7951059Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:34.7953347Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.999093770980835)
2026-01-14T08:22:34.7954278Z   )
2026-01-14T08:22:34.7954578Z )
2026-01-14T08:22:34.7954744Z 
2026-01-14T08:22:34.7954750Z 
2026-01-14T08:22:34.7954757Z 
2026-01-14T08:22:34.7954926Z def forward(self, x):
2026-01-14T08:22:34.7955473Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:34.7956150Z     conv_weight = self.conv.weight
2026-01-14T08:22:34.7956636Z     bn_weight = self.bn.weight
2026-01-14T08:22:34.7957109Z     bn_bias = self.bn.bias
2026-01-14T08:22:34.7957573Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:22:34.7958177Z     bn_running_var = self.bn.running_var
2026-01-14T08:22:34.7958806Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:22:34.7959666Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:34.7961037Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:22:34.7962117Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:22:34.7962910Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:22:34.7963711Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:22:34.7964574Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:22:34.7965590Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:22:34.7966672Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:22:34.7968264Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:22:34.7969928Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:22:34.7970997Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:22:34.7972983Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:22:34.7974803Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:22:34.7975831Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:22:34.7976962Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:22:34.7977712Z     
2026-01-14T08:22:34.7978265Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:34.7978966Z model fx: GraphModule(
2026-01-14T08:22:34.7979806Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:34.7981808Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:34.7984139Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:34.7985207Z   )
2026-01-14T08:22:34.7985526Z   (conv): ConvBnReLU2d(
2026-01-14T08:22:34.7985999Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:22:34.7986804Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:22:34.7987715Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:34.7989616Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:22:34.7992055Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T08:22:34.7993117Z     )
2026-01-14T08:22:34.7993409Z   )
2026-01-14T08:22:34.7993931Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:34.7995935Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:34.7998318Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.999093770980835)
2026-01-14T08:22:34.7999272Z   )
2026-01-14T08:22:34.7999585Z )
2026-01-14T08:22:34.7999764Z 
2026-01-14T08:22:34.7999786Z 
2026-01-14T08:22:34.7999792Z 
2026-01-14T08:22:34.7999946Z def forward(self, x):
2026-01-14T08:22:34.8000639Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:34.8001728Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:22:34.8003036Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:22:34.8003893Z     return activation_post_process_1
2026-01-14T08:22:34.8004385Z     
2026-01-14T08:22:34.8004900Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:34.8005634Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:34.8006074Z           [0., 0., 0.],
2026-01-14T08:22:43.6721859Z           [0., 0., 0.]],
2026-01-14T08:22:43.6722228Z 
2026-01-14T08:22:43.6722340Z          [[0., 0., 0.],
2026-01-14T08:22:43.6722652Z           [0., 0., 0.],
2026-01-14T08:22:43.6722944Z           [0., 0., 0.]],
2026-01-14T08:22:43.6723143Z 
2026-01-14T08:22:43.6723273Z          [[0., 0., 0.],
2026-01-14T08:22:43.6723557Z           [0., 0., 0.],
2026-01-14T08:22:43.6723935Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:22:43.6724396Z converted model pt2e: GraphModule(
2026-01-14T08:22:43.6724776Z   (conv): Module()
2026-01-14T08:22:43.6725049Z   (bn): Module()
2026-01-14T08:22:43.6725338Z )
2026-01-14T08:22:43.6725472Z 
2026-01-14T08:22:43.6725477Z 
2026-01-14T08:22:43.6725482Z 
2026-01-14T08:22:43.6725600Z def forward(self, x):
2026-01-14T08:22:43.6726008Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:43.6727096Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:43.6728999Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:43.6730339Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:22:43.6731863Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001507229870185256, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:22:43.6733155Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:22:43.6734399Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:22:43.6735777Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T08:22:43.6736950Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007839583791792393, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:22:43.6738926Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007839583791792393, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:22:43.6740491Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:22:43.6741111Z     
2026-01-14T08:22:43.6741510Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:43.6742062Z onverted model fx: GraphModule(
2026-01-14T08:22:43.6742415Z   (conv): ConvReLU2d(
2026-01-14T08:22:43.6742894Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:22:43.6743437Z     (1): ReLU()
2026-01-14T08:22:43.6743710Z   )
2026-01-14T08:22:43.6743942Z )
2026-01-14T08:22:43.6744090Z 
2026-01-14T08:22:43.6744095Z 
2026-01-14T08:22:43.6744101Z 
2026-01-14T08:22:43.6744217Z def forward(self, x):
2026-01-14T08:22:43.6745127Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:43.6747011Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:43.6748566Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:22:43.6750206Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007839583791792393, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:22:43.6752203Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007839583791792393, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:43.6753571Z     return dequantize_per_tensor_default_1
2026-01-14T08:22:43.6753951Z     
2026-01-14T08:22:43.6754348Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:43.6754871Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:43.6755211Z           [0., 0., 0.],
2026-01-14T08:22:43.6755522Z           [0., 0., 0.]],
2026-01-14T08:22:43.6755716Z 
2026-01-14T08:22:43.6755822Z          [[0., 0., 0.],
2026-01-14T08:22:43.6756117Z           [0., 0., 0.],
2026-01-14T08:22:43.6756399Z           [0., 0., 0.]],
2026-01-14T08:22:43.6756609Z 
2026-01-14T08:22:43.6756713Z          [[0., 0., 0.],
2026-01-14T08:22:43.6757000Z           [0., 0., 0.],
2026-01-14T08:22:43.6757297Z           [0., 0., 0.]]]])
2026-01-14T08:22:43.6757834Z [32mPASSED[0m
2026-01-14T08:22:43.6758639Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T08:22:43.6759516Z   (conv): Module()
2026-01-14T08:22:43.6759873Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:43.6761067Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:22:43.6762738Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1782, -0.1825, -0.1912]), max_val=tensor([0.1676, 0.1914, 0.1824]))
2026-01-14T08:22:43.6763486Z   )
2026-01-14T08:22:43.6763799Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:43.6764896Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:43.6766194Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:43.6766761Z   )
2026-01-14T08:22:43.6767061Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:43.6768169Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0052]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:43.6769417Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3200514316558838)
2026-01-14T08:22:43.6769949Z   )
2026-01-14T08:22:43.6770122Z )
2026-01-14T08:22:43.6770234Z 
2026-01-14T08:22:43.6770238Z 
2026-01-14T08:22:43.6770242Z 
2026-01-14T08:22:43.6770332Z def forward(self, x):
2026-01-14T08:22:43.6770649Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:43.6771013Z     conv_weight = self.conv.weight
2026-01-14T08:22:43.6771518Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:22:43.6772261Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:43.6773177Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:22:43.6774030Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T08:22:43.6774565Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:22:43.6775260Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:22:43.6775685Z     
2026-01-14T08:22:43.6775994Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:43.6776387Z model fx: GraphModule(
2026-01-14T08:22:43.6776734Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:43.6777830Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:43.6779123Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:43.6779698Z   )
2026-01-14T08:22:43.6779883Z   (conv): ConvReLU2d(
2026-01-14T08:22:43.6780165Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:22:43.6780552Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:43.6781718Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:22:43.6783269Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1782, -0.1825, -0.1912]), max_val=tensor([0.1676, 0.1914, 0.1824]))
2026-01-14T08:22:43.6783992Z     )
2026-01-14T08:22:43.6784181Z   )
2026-01-14T08:22:43.6784463Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:43.6785577Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0052]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:43.6786888Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3200514316558838)
2026-01-14T08:22:43.6787405Z   )
2026-01-14T08:22:43.6787592Z )
2026-01-14T08:22:43.6787691Z 
2026-01-14T08:22:43.6787695Z 
2026-01-14T08:22:43.6787699Z 
2026-01-14T08:22:43.6787791Z def forward(self, x):
2026-01-14T08:22:43.6788175Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:43.6788755Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:22:43.6789369Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:22:43.6789840Z     return activation_post_process_1
2026-01-14T08:22:43.6790110Z     
2026-01-14T08:22:43.6790411Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:43.6790806Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:43.6791067Z           [0., 0., 0.],
2026-01-14T08:22:43.6791285Z           [0., 0., 0.]],
2026-01-14T08:22:43.6791442Z 
2026-01-14T08:22:43.6791522Z          [[0., 0., 0.],
2026-01-14T08:22:43.6791734Z           [0., 0., 0.],
2026-01-14T08:22:43.6791969Z           [0., 0., 0.]],
2026-01-14T08:22:43.6792117Z 
2026-01-14T08:22:43.6792210Z          [[0., 0., 0.],
2026-01-14T08:22:43.6792424Z           [0., 0., 0.],
2026-01-14T08:22:43.6792690Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:22:43.6793021Z converted model pt2e: GraphModule(
2026-01-14T08:22:43.6793310Z   (conv): Module()
2026-01-14T08:22:43.6793512Z )
2026-01-14T08:22:43.6793658Z 
2026-01-14T08:22:43.6793663Z 
2026-01-14T08:22:43.6793667Z 
2026-01-14T08:22:43.6793756Z def forward(self, x):
2026-01-14T08:22:43.6794068Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:43.6794429Z     _scale_0 = self._scale_0
2026-01-14T08:22:43.6794712Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:22:43.6795057Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:22:43.6796298Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:22:43.6797834Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:44.4534422Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:44.4536504Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:22:44.4537767Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T08:22:44.4538946Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005176672246307135, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:22:44.4540934Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005176672246307135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:44.4542494Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:22:44.4543095Z     
2026-01-14T08:22:44.4543504Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:44.4544054Z onverted model fx: GraphModule(
2026-01-14T08:22:44.4544404Z   (conv): ConvReLU2d(
2026-01-14T08:22:44.4544924Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T08:22:44.4545520Z     (1): ReLU()
2026-01-14T08:22:44.4546075Z   )
2026-01-14T08:22:44.4546300Z )
2026-01-14T08:22:44.4546445Z 
2026-01-14T08:22:44.4546450Z 
2026-01-14T08:22:44.4546455Z 
2026-01-14T08:22:44.4546572Z def forward(self, x):
2026-01-14T08:22:44.4547495Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:44.4549376Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:44.4551067Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:22:44.4552344Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005176672246307135, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:22:44.4554325Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005176672246307135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:44.4555694Z     return dequantize_per_tensor_default_1
2026-01-14T08:22:44.4556076Z     
2026-01-14T08:22:44.4556473Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:44.4556995Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:44.4557333Z           [0., 0., 0.],
2026-01-14T08:22:44.4557620Z           [0., 0., 0.]],
2026-01-14T08:22:44.4557825Z 
2026-01-14T08:22:44.4557930Z          [[0., 0., 0.],
2026-01-14T08:22:44.4558225Z           [0., 0., 0.],
2026-01-14T08:22:44.4558505Z           [0., 0., 0.]],
2026-01-14T08:22:44.4558694Z 
2026-01-14T08:22:44.4558811Z          [[0., 0., 0.],
2026-01-14T08:22:44.4559090Z           [0., 0., 0.],
2026-01-14T08:22:44.4559385Z           [0., 0., 0.]]]])
2026-01-14T08:22:44.4559698Z model pt2e: GraphModule(
2026-01-14T08:22:44.4560021Z   (conv): Module()
2026-01-14T08:22:44.4560430Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:44.4562066Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:22:44.4563848Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124378263950348, max_val=0.19141915440559387)
2026-01-14T08:22:44.4564620Z   )
2026-01-14T08:22:44.4565050Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:44.4566504Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:44.4568200Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:44.4568962Z   )
2026-01-14T08:22:44.4569334Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:44.4570801Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0052]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:44.4572417Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3200514316558838)
2026-01-14T08:22:44.4572932Z   )
2026-01-14T08:22:44.4573119Z )
2026-01-14T08:22:44.4573219Z 
2026-01-14T08:22:44.4573223Z 
2026-01-14T08:22:44.4573227Z 
2026-01-14T08:22:44.4573316Z def forward(self, x):
2026-01-14T08:22:44.4573631Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:44.4574006Z     conv_weight = self.conv.weight
2026-01-14T08:22:44.4574495Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:22:44.4575237Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:44.4576145Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:22:44.4577013Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T08:22:44.4577547Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:22:44.4578135Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:22:44.4578564Z     
2026-01-14T08:22:44.4578855Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:44.4579261Z model fx: GraphModule(
2026-01-14T08:22:44.4579592Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:44.4580693Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:44.4581988Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:44.4582550Z   )
2026-01-14T08:22:44.4582746Z   (conv): ConvReLU2d(
2026-01-14T08:22:44.4583020Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:22:44.4583421Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:44.4584494Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:22:44.4585817Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124378263950348, max_val=0.19141915440559387)
2026-01-14T08:22:44.4586408Z     )
2026-01-14T08:22:44.4586583Z   )
2026-01-14T08:22:44.4586886Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:44.4588762Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0052]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:44.4590039Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3200514316558838)
2026-01-14T08:22:44.4590571Z   )
2026-01-14T08:22:44.4590743Z )
2026-01-14T08:22:44.4590844Z 
2026-01-14T08:22:44.4590848Z 
2026-01-14T08:22:44.4590852Z 
2026-01-14T08:22:44.4590954Z def forward(self, x):
2026-01-14T08:22:44.4591324Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:44.4591915Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:22:44.4592507Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:22:44.4592991Z     return activation_post_process_1
2026-01-14T08:22:44.4593285Z     
2026-01-14T08:22:44.4593574Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:44.4593985Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:44.4594242Z           [0., 0., 0.],
2026-01-14T08:22:44.4594477Z           [0., 0., 0.]],
2026-01-14T08:22:44.4594626Z 
2026-01-14T08:22:44.4594707Z          [[0., 0., 0.],
2026-01-14T08:22:44.4594938Z           [0., 0., 0.],
2026-01-14T08:22:44.4595159Z           [0., 0., 0.]],
2026-01-14T08:22:44.4595320Z 
2026-01-14T08:22:44.4595401Z          [[0., 0., 0.],
2026-01-14T08:22:44.4595634Z           [0., 0., 0.],
2026-01-14T08:22:44.4595888Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:22:44.4596231Z converted model pt2e: GraphModule(
2026-01-14T08:22:44.4596506Z   (conv): Module()
2026-01-14T08:22:44.4596721Z )
2026-01-14T08:22:44.4596820Z 
2026-01-14T08:22:44.4596824Z 
2026-01-14T08:22:44.4596828Z 
2026-01-14T08:22:44.4596917Z def forward(self, x):
2026-01-14T08:22:44.4597295Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:44.4597702Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:22:44.4598743Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0015072374371811748, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:44.4600182Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:44.4601618Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:44.4603173Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:22:44.4604118Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T08:22:44.4604978Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005176672246307135, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:22:44.4606469Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005176672246307135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:22:44.4607639Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:22:44.4608088Z     
2026-01-14T08:22:44.4608393Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:44.4608795Z onverted model fx: GraphModule(
2026-01-14T08:22:44.4609069Z   (conv): ConvReLU2d(
2026-01-14T08:22:44.4609461Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T08:22:44.4609926Z     (1): ReLU()
2026-01-14T08:22:44.4610120Z   )
2026-01-14T08:22:44.4610303Z )
2026-01-14T08:22:44.4610400Z 
2026-01-14T08:22:44.4610404Z 
2026-01-14T08:22:44.4610408Z 
2026-01-14T08:22:44.4610565Z def forward(self, x):
2026-01-14T08:22:45.2122689Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:45.2124615Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:45.2126167Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:22:45.2127455Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005176672246307135, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:22:45.2129466Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005176672246307135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:45.2130837Z     return dequantize_per_tensor_default_1
2026-01-14T08:22:45.2131217Z     
2026-01-14T08:22:45.2131615Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:45.2132212Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:45.2132557Z           [0., 0., 0.],
2026-01-14T08:22:45.2132849Z           [0., 0., 0.]],
2026-01-14T08:22:45.2133059Z 
2026-01-14T08:22:45.2133165Z          [[0., 0., 0.],
2026-01-14T08:22:45.2133463Z           [0., 0., 0.],
2026-01-14T08:22:45.2133750Z           [0., 0., 0.]],
2026-01-14T08:22:45.2133942Z 
2026-01-14T08:22:45.2134065Z          [[0., 0., 0.],
2026-01-14T08:22:45.2134344Z           [0., 0., 0.],
2026-01-14T08:22:45.2134644Z           [0., 0., 0.]]]])
2026-01-14T08:22:45.2135004Z model pt2e: GraphModule(
2026-01-14T08:22:45.2135612Z   (conv): Module()
2026-01-14T08:22:45.2136039Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:45.2137591Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:22:45.2139646Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1787, -0.1913]), max_val=tensor([0.1870, 0.1478, 0.1740]))
2026-01-14T08:22:45.2140620Z   )
2026-01-14T08:22:45.2140991Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:45.2142447Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:45.2144156Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:45.2144916Z   )
2026-01-14T08:22:45.2145307Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:45.2146748Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0084]), zero_point=tensor([-20], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:45.2148471Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9077497124671936, max_val=1.2348304986953735)
2026-01-14T08:22:45.2149231Z   )
2026-01-14T08:22:45.2149468Z )
2026-01-14T08:22:45.2149743Z 
2026-01-14T08:22:45.2149748Z 
2026-01-14T08:22:45.2149753Z 
2026-01-14T08:22:45.2149885Z def forward(self, x):
2026-01-14T08:22:45.2150281Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:45.2150773Z     conv_weight = self.conv.weight
2026-01-14T08:22:45.2151429Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:22:45.2152285Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:45.2153610Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:22:45.2154871Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T08:22:45.2155685Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:22:45.2156248Z     
2026-01-14T08:22:45.2156648Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:45.2157162Z model fx: GraphModule(
2026-01-14T08:22:45.2157612Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:45.2158939Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:45.2160246Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:22:45.2160818Z   )
2026-01-14T08:22:45.2160997Z   (conv): Conv2d(
2026-01-14T08:22:45.2161265Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:22:45.2161656Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:45.2162809Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:22:45.2164347Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1787, -0.1913]), max_val=tensor([0.1870, 0.1478, 0.1740]))
2026-01-14T08:22:45.2165182Z     )
2026-01-14T08:22:45.2165373Z   )
2026-01-14T08:22:45.2165660Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:22:45.2166776Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0084]), zero_point=tensor([-20], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:22:45.2168085Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9077497124671936, max_val=1.2348304986953735)
2026-01-14T08:22:45.2168657Z   )
2026-01-14T08:22:45.2168846Z )
2026-01-14T08:22:45.2168947Z 
2026-01-14T08:22:45.2168952Z 
2026-01-14T08:22:45.2168956Z 
2026-01-14T08:22:45.2169045Z def forward(self, x):
2026-01-14T08:22:45.2169427Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:22:45.2170005Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:22:45.2170615Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:22:45.2171088Z     return activation_post_process_1
2026-01-14T08:22:45.2171359Z     
2026-01-14T08:22:45.2171667Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:45.2172145Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:45.2172407Z           [0., 0., 0.],
2026-01-14T08:22:45.2172630Z           [0., 0., 0.]],
2026-01-14T08:22:45.2172792Z 
2026-01-14T08:22:45.2172871Z          [[0., 0., 0.],
2026-01-14T08:22:45.2173088Z           [0., 0., 0.],
2026-01-14T08:22:45.2173322Z           [0., 0., 0.]],
2026-01-14T08:22:45.2173464Z 
2026-01-14T08:22:45.2173558Z          [[0., 0., 0.],
2026-01-14T08:22:45.2173774Z           [0., 0., 0.],
2026-01-14T08:22:45.2174034Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:22:45.2174360Z converted model pt2e: GraphModule(
2026-01-14T08:22:45.2174645Z   (conv): Module()
2026-01-14T08:22:45.2174846Z )
2026-01-14T08:22:45.2174962Z 
2026-01-14T08:22:45.2174966Z 
2026-01-14T08:22:45.2174970Z 
2026-01-14T08:22:45.2175057Z def forward(self, x):
2026-01-14T08:22:45.2175363Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:22:45.2175787Z     _scale_0 = self._scale_0
2026-01-14T08:22:45.2176067Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:22:45.2176402Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:22:45.2177553Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:22:45.2179092Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:45.2180521Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:45.2182050Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:22:45.2183392Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.00840227585285902, -20, -128, 127, torch.int8);  conv2d = None
2026-01-14T08:22:45.2184880Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.00840227585285902, -20, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:45.2186031Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:22:45.2186475Z     
2026-01-14T08:22:45.2186783Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:45.2187249Z onverted model fx: GraphModule(
2026-01-14T08:22:45.2187709Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T08:22:45.2188179Z )
2026-01-14T08:22:45.2188281Z 
2026-01-14T08:22:45.2188285Z 
2026-01-14T08:22:45.2188292Z 
2026-01-14T08:22:45.2188381Z def forward(self, x):
2026-01-14T08:22:45.2189077Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:22:45.2190486Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:22:45.2191639Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:22:45.2192606Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.00840227585285902, -20, -128, 127, torch.int8);  conv = None
2026-01-14T08:22:45.2194067Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.00840227585285902, -20, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:22:45.2195075Z     return dequantize_per_tensor_default_1
2026-01-14T08:22:45.2195360Z     
2026-01-14T08:22:45.2195663Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:22:45.2196070Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:22:45.2196317Z           [0., 0., 0.],
2026-01-14T08:22:45.2196548Z           [0., 0., 0.]],
2026-01-14T08:22:45.2196697Z 
2026-01-14T08:22:45.2196777Z          [[0., 0., 0.],
2026-01-14T08:22:45.2197003Z           [0., 0., 0.],
2026-01-14T08:22:45.2197217Z           [0., 0., 0.]],
2026-01-14T08:22:45.2197374Z 
2026-01-14T08:22:45.2197453Z          [[0., 0., 0.],
2026-01-14T08:23:19.6292239Z           [0., 0., 0.],
2026-01-14T08:23:19.6292568Z           [0., 0., 0.]]]])
2026-01-14T08:23:19.6292863Z model pt2e: GraphModule(
2026-01-14T08:23:19.6293109Z   (conv): Module()
2026-01-14T08:23:19.6293438Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.6294851Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:23:19.6296201Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127574563026428, max_val=0.18703685700893402)
2026-01-14T08:23:19.6296795Z   )
2026-01-14T08:23:19.6297082Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.6298182Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.6299469Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:23:19.6300044Z   )
2026-01-14T08:23:19.6300338Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.6301436Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0084]), zero_point=tensor([-20], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.6302740Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9042347073554993, max_val=1.2348304986953735)
2026-01-14T08:23:19.6303311Z   )
2026-01-14T08:23:19.6303494Z )
2026-01-14T08:23:19.6303595Z 
2026-01-14T08:23:19.6303599Z 
2026-01-14T08:23:19.6303603Z 
2026-01-14T08:23:19.6303706Z def forward(self, x):
2026-01-14T08:23:19.6304009Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:23:19.6304385Z     conv_weight = self.conv.weight
2026-01-14T08:23:19.6305035Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:23:19.6305691Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:23:19.6306592Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:23:19.6307534Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T08:23:19.6308152Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:23:19.6308621Z     
2026-01-14T08:23:19.6308918Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:19.6309327Z model fx: GraphModule(
2026-01-14T08:23:19.6309658Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.6310762Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.6312080Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:23:19.6312654Z   )
2026-01-14T08:23:19.6312839Z   (conv): Conv2d(
2026-01-14T08:23:19.6313115Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T08:23:19.6313509Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.6314607Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:23:19.6315925Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127574563026428, max_val=0.18703685700893402)
2026-01-14T08:23:19.6316520Z     )
2026-01-14T08:23:19.6316718Z   )
2026-01-14T08:23:19.6317009Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.6318180Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0084]), zero_point=tensor([-20], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.6319474Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9042347073554993, max_val=1.2348304986953735)
2026-01-14T08:23:19.6320060Z   )
2026-01-14T08:23:19.6320235Z )
2026-01-14T08:23:19.6320351Z 
2026-01-14T08:23:19.6320355Z 
2026-01-14T08:23:19.6320359Z 
2026-01-14T08:23:19.6320451Z def forward(self, x):
2026-01-14T08:23:19.6320834Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:23:19.6321416Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:23:19.6322025Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:23:19.6322492Z     return activation_post_process_1
2026-01-14T08:23:19.6322775Z     
2026-01-14T08:23:19.6323065Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:19.6323482Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:23:19.6323739Z           [0., 0., 0.],
2026-01-14T08:23:19.6323958Z           [0., 0., 0.]],
2026-01-14T08:23:19.6324107Z 
2026-01-14T08:23:19.6324199Z          [[0., 0., 0.],
2026-01-14T08:23:19.6324412Z           [0., 0., 0.],
2026-01-14T08:23:19.6324634Z           [0., 0., 0.]],
2026-01-14T08:23:19.6324779Z 
2026-01-14T08:23:19.6324860Z          [[0., 0., 0.],
2026-01-14T08:23:19.6325084Z           [0., 0., 0.],
2026-01-14T08:23:19.6325332Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:23:19.6325666Z converted model pt2e: GraphModule(
2026-01-14T08:23:19.6325947Z   (conv): Module()
2026-01-14T08:23:19.6326148Z )
2026-01-14T08:23:19.6326248Z 
2026-01-14T08:23:19.6326253Z 
2026-01-14T08:23:19.6326318Z 
2026-01-14T08:23:19.6326419Z def forward(self, x):
2026-01-14T08:23:19.6326717Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:23:19.6327134Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:23:19.6328162Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0015061082085594535, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:23:19.6329594Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:23:19.6331042Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:23:19.6332712Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:23:19.6334084Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.008388491347432137, -20, -128, 127, torch.int8);  conv2d = None
2026-01-14T08:23:19.6335582Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.008388491347432137, -20, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:23:19.6336726Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:23:19.6337185Z     
2026-01-14T08:23:19.6337478Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:19.6337892Z onverted model fx: GraphModule(
2026-01-14T08:23:19.6338346Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T08:23:19.6338800Z )
2026-01-14T08:23:19.6338903Z 
2026-01-14T08:23:19.6338918Z 
2026-01-14T08:23:19.6338923Z 
2026-01-14T08:23:19.6339009Z def forward(self, x):
2026-01-14T08:23:19.6339758Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:23:19.6341190Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:23:19.6342353Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:23:19.6343314Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008388491347432137, -20, -128, 127, torch.int8);  conv = None
2026-01-14T08:23:19.6344799Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008388491347432137, -20, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:23:19.6345827Z     return dequantize_per_tensor_default_1
2026-01-14T08:23:19.6346116Z     
2026-01-14T08:23:19.6346427Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:19.6346820Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:23:19.6347082Z           [0., 0., 0.],
2026-01-14T08:23:19.6347299Z           [0., 0., 0.]],
2026-01-14T08:23:19.6347462Z 
2026-01-14T08:23:19.6347542Z          [[0., 0., 0.],
2026-01-14T08:23:19.6347758Z           [0., 0., 0.],
2026-01-14T08:23:19.6347983Z           [0., 0., 0.]],
2026-01-14T08:23:19.6348128Z 
2026-01-14T08:23:19.6348222Z          [[0., 0., 0.],
2026-01-14T08:23:19.6348436Z           [0., 0., 0.],
2026-01-14T08:23:19.6348666Z           [0., 0., 0.]]]])
2026-01-14T08:23:19.6349082Z [32mPASSED[0m
2026-01-14T08:23:19.6349974Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T08:23:19.6351210Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:23:19.6352254Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T08:23:19.6352929Z   (conv): Module()
2026-01-14T08:23:19.6353243Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.6354376Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0002]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:23:19.6355751Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.0532]), max_val=tensor([-0.0532]))
2026-01-14T08:23:19.6356385Z   )
2026-01-14T08:23:19.6356681Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.6357769Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([38], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.6359069Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8401848077774048, max_val=0.9828221797943115)
2026-01-14T08:23:19.6359639Z   )
2026-01-14T08:23:19.8029669Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.8030809Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.8032109Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.3858921527862549, max_val=0.5359839200973511)
2026-01-14T08:23:19.8032687Z   )
2026-01-14T08:23:19.8032973Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.8034299Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.8035547Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.372033953666687)
2026-01-14T08:23:19.8036056Z   )
2026-01-14T08:23:19.8036239Z )
2026-01-14T08:23:19.8036339Z 
2026-01-14T08:23:19.8036343Z 
2026-01-14T08:23:19.8036347Z 
2026-01-14T08:23:19.8036435Z def forward(self, x):
2026-01-14T08:23:19.8036752Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:23:19.8037130Z     conv_weight = self.conv.weight
2026-01-14T08:23:19.8037622Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:23:19.8038147Z     conv_bias = self.conv.bias
2026-01-14T08:23:19.8038537Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:23:19.8039427Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:23:19.8040336Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T08:23:19.8041249Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:23:19.8042073Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:23:19.8042589Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:23:19.8043198Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:23:19.8043623Z     
2026-01-14T08:23:19.8057196Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:19.8057927Z model fx: GraphModule(
2026-01-14T08:23:19.8058474Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.8059615Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([38], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.8060920Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8401848077774048, max_val=0.9828221797943115)
2026-01-14T08:23:19.8061502Z   )
2026-01-14T08:23:19.8061687Z   (conv): Conv2d(
2026-01-14T08:23:19.8061934Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T08:23:19.8062295Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.8063398Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0002]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:23:19.8064792Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.0532]), max_val=tensor([-0.0532]))
2026-01-14T08:23:19.8065416Z     )
2026-01-14T08:23:19.8065609Z   )
2026-01-14T08:23:19.8065899Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.8067018Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.8068322Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.3858921527862549, max_val=0.5359839200973511)
2026-01-14T08:23:19.8068885Z   )
2026-01-14T08:23:19.8069096Z   (relu): ReLU(inplace=True)
2026-01-14T08:23:19.8069450Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:19.8070559Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:19.8071892Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.372033953666687)
2026-01-14T08:23:19.8072404Z   )
2026-01-14T08:23:19.8072591Z )
2026-01-14T08:23:19.8072694Z 
2026-01-14T08:23:19.8072699Z 
2026-01-14T08:23:19.8072702Z 
2026-01-14T08:23:19.8072793Z def forward(self, x):
2026-01-14T08:23:19.8073176Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:23:19.8073642Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:23:19.8074110Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:23:19.8074879Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:23:19.8075504Z     relu = self.relu(add);  add = None
2026-01-14T08:23:19.8075935Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:23:19.8076394Z     return activation_post_process_2
2026-01-14T08:23:19.8076653Z     
2026-01-14T08:23:19.8076944Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:19.8077333Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:23:19.8077583Z           [0., 0., 0.],
2026-01-14T08:23:19.8077836Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:23:19.8078176Z converted model pt2e: GraphModule(
2026-01-14T08:23:19.8078466Z   (conv): Module()
2026-01-14T08:23:19.8078668Z )
2026-01-14T08:23:19.8078770Z 
2026-01-14T08:23:19.8078774Z 
2026-01-14T08:23:19.8078778Z 
2026-01-14T08:23:19.8078881Z def forward(self, x):
2026-01-14T08:23:19.8079181Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:23:19.8079553Z     _scale_0 = self._scale_0
2026-01-14T08:23:19.8079815Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:23:19.8080167Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:23:19.8081378Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:23:19.8082479Z     conv_bias = self.conv.bias
2026-01-14T08:23:19.8083187Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.011070616543293, 38, -128, 127, torch.int8);  x = None
2026-01-14T08:23:19.8084441Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.011070616543293, 38, -128, 127, torch.int8)
2026-01-14T08:23:19.8085942Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.011070616543293, 38, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:23:19.8087568Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T08:23:19.8089019Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.0021018977276980877, -128, -128, 127, torch.int8);  conv2d = None
2026-01-14T08:23:19.8090534Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021018977276980877, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:23:19.8092179Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T08:23:19.8093079Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:23:19.8093944Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.005380525253713131, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:23:19.8095519Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005380525253713131, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:23:19.8096682Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:23:19.8097144Z     
2026-01-14T08:23:19.8097437Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:19.8097851Z onverted model fx: GraphModule(
2026-01-14T08:23:19.8098258Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T08:23:19.8098705Z   (relu): ReLU(inplace=True)
2026-01-14T08:23:19.8098959Z )
2026-01-14T08:23:19.8099065Z 
2026-01-14T08:23:19.8099069Z 
2026-01-14T08:23:19.8099073Z 
2026-01-14T08:23:19.8099161Z def forward(self, x):
2026-01-14T08:23:19.8099846Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.011070616543293, 38, -128, 127, torch.int8);  x = None
2026-01-14T08:23:19.8101230Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.011070616543293, 38, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:23:19.8102244Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:23:19.8103073Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021018977276980877, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:23:19.8104561Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021018977276980877, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:23:19.8105980Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:23:19.8106757Z     relu = self.relu(add);  add = None
2026-01-14T08:23:19.8107531Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005380525253713131, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:23:20.5939763Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005380525253713131, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:23:20.5940848Z     return dequantize_per_tensor_default_2
2026-01-14T08:23:20.5941145Z     
2026-01-14T08:23:20.5941459Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:20.5941859Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:23:20.5942124Z           [0., 0., 0.],
2026-01-14T08:23:20.5942346Z           [0., 0., 0.]]]])
2026-01-14T08:23:20.5942604Z model pt2e: GraphModule(
2026-01-14T08:23:20.5942865Z   (conv): Module()
2026-01-14T08:23:20.5943189Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:20.5944326Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0002]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:23:20.5945764Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.05316734313964844, max_val=-0.05316734313964844)
2026-01-14T08:23:20.5946364Z   )
2026-01-14T08:23:20.5946649Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:20.5947754Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([38], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:20.5949049Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8401848077774048, max_val=0.9828221797943115)
2026-01-14T08:23:20.5949767Z   )
2026-01-14T08:23:20.5950149Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:20.5951471Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:20.5952783Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.3858921527862549, max_val=0.5359839200973511)
2026-01-14T08:23:20.5953361Z   )
2026-01-14T08:23:20.5953640Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:20.5954741Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:20.5955985Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.372033953666687)
2026-01-14T08:23:20.5956490Z   )
2026-01-14T08:23:20.5956674Z )
2026-01-14T08:23:20.5956776Z 
2026-01-14T08:23:20.5956781Z 
2026-01-14T08:23:20.5956784Z 
2026-01-14T08:23:20.5956877Z def forward(self, x):
2026-01-14T08:23:20.5957192Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:23:20.5957556Z     conv_weight = self.conv.weight
2026-01-14T08:23:20.5958053Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:23:20.5958581Z     conv_bias = self.conv.bias
2026-01-14T08:23:20.5958975Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:23:20.5959866Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:23:20.5960769Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T08:23:20.5961796Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:23:20.5962614Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:23:20.5963146Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:23:20.5963761Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:23:20.5964185Z     
2026-01-14T08:23:20.5964499Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:20.5964894Z model fx: GraphModule(
2026-01-14T08:23:20.5965242Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:20.5966380Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([38], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:20.5967676Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8401848077774048, max_val=0.9828221797943115)
2026-01-14T08:23:20.5968261Z   )
2026-01-14T08:23:20.5968464Z   (conv): Conv2d(
2026-01-14T08:23:20.5968698Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T08:23:20.5969070Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:20.5970148Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0002]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:23:20.5971499Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.05316734313964844, max_val=-0.05316734313964844)
2026-01-14T08:23:20.5972187Z     )
2026-01-14T08:23:20.5972379Z   )
2026-01-14T08:23:20.5972679Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:20.5973782Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:20.5975169Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.3858921527862549, max_val=0.5359839200973511)
2026-01-14T08:23:20.5975736Z   )
2026-01-14T08:23:20.5975945Z   (relu): ReLU(inplace=True)
2026-01-14T08:23:20.5976296Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:20.5977400Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:20.5978637Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.372033953666687)
2026-01-14T08:23:20.5979141Z   )
2026-01-14T08:23:20.5979330Z )
2026-01-14T08:23:20.5979430Z 
2026-01-14T08:23:20.5979434Z 
2026-01-14T08:23:20.5979438Z 
2026-01-14T08:23:20.5979538Z def forward(self, x):
2026-01-14T08:23:20.5979905Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:23:20.5980382Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:23:20.5980850Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:23:20.5981633Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:23:20.5982263Z     relu = self.relu(add);  add = None
2026-01-14T08:23:20.5982716Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:23:20.5983195Z     return activation_post_process_2
2026-01-14T08:23:20.5983466Z     
2026-01-14T08:23:20.5983774Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:20.5984171Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:23:20.5984493Z           [0., 0., 0.],
2026-01-14T08:23:20.5984743Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:23:20.5985079Z converted model pt2e: GraphModule(
2026-01-14T08:23:20.5985349Z   (conv): Module()
2026-01-14T08:23:20.5985565Z )
2026-01-14T08:23:20.5985666Z 
2026-01-14T08:23:20.5985670Z 
2026-01-14T08:23:20.5985674Z 
2026-01-14T08:23:20.5985774Z def forward(self, x):
2026-01-14T08:23:20.5986074Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:23:20.5986488Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:23:20.5987510Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.00041864049853757024, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:23:20.5988508Z     conv_bias = self.conv.bias
2026-01-14T08:23:20.5989211Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.011070616543293, 38, -128, 127, torch.int8);  x = None
2026-01-14T08:23:20.5990499Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011070616543293, 38, -128, 127, torch.int8)
2026-01-14T08:23:20.5992012Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011070616543293, 38, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:23:20.5993619Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T08:23:20.5995082Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.0021018977276980877, -128, -128, 127, torch.int8);  conv2d = None
2026-01-14T08:23:20.5996601Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0021018977276980877, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:23:20.5998187Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T08:23:20.5999099Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:23:20.5999961Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.005380525253713131, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:23:20.6001444Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.005380525253713131, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:23:20.6002613Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T08:23:20.6003081Z     
2026-01-14T08:23:20.6003374Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:20.6003787Z onverted model fx: GraphModule(
2026-01-14T08:23:20.6004190Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T08:23:20.6004637Z   (relu): ReLU(inplace=True)
2026-01-14T08:23:20.6004877Z )
2026-01-14T08:23:20.6004990Z 
2026-01-14T08:23:20.6004994Z 
2026-01-14T08:23:20.6004998Z 
2026-01-14T08:23:20.6005087Z def forward(self, x):
2026-01-14T08:23:39.5880191Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.011070616543293, 38, -128, 127, torch.int8);  x = None
2026-01-14T08:23:39.5881647Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.011070616543293, 38, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:23:39.5882666Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:23:39.5883760Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021018977276980877, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:23:39.5885278Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021018977276980877, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:23:39.5886681Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:23:39.5887414Z     relu = self.relu(add);  add = None
2026-01-14T08:23:39.5888202Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005380525253713131, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:23:39.5898094Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005380525253713131, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:23:39.5899130Z     return dequantize_per_tensor_default_2
2026-01-14T08:23:39.5899429Z     
2026-01-14T08:23:39.5899731Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:39.5900142Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:23:39.5900389Z           [0., 0., 0.],
2026-01-14T08:23:39.5900621Z           [0., 0., 0.]]]])
2026-01-14T08:23:39.5901034Z [32mPASSED[0m
2026-01-14T08:23:39.5901815Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T08:23:39.5902991Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T08:23:39.5904088Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec [32mPASSED[0m
2026-01-14T08:23:39.5905130Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T08:23:39.5905813Z   (conv): Module()
2026-01-14T08:23:39.5906023Z   (bn): Module()
2026-01-14T08:23:39.5906482Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:39.5907582Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:39.5908896Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:23:39.5909479Z   )
2026-01-14T08:23:39.5909765Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:39.5910937Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0012]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:23:39.5912467Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1911, -0.1747, -0.1488]), max_val=tensor([0.1791, 0.1781, 0.1559]))
2026-01-14T08:23:39.5913205Z   )
2026-01-14T08:23:39.5913499Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:39.5914582Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0168]), zero_point=tensor([19], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:39.5915866Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.466952085494995, max_val=1.815312147140503)
2026-01-14T08:23:39.5916432Z   )
2026-01-14T08:23:39.5916726Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:39.5917827Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0168]), zero_point=tensor([19], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:39.5919168Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.466952085494995, max_val=1.815312147140503)
2026-01-14T08:23:39.5919738Z   )
2026-01-14T08:23:39.5919909Z )
2026-01-14T08:23:39.5920023Z 
2026-01-14T08:23:39.5920028Z 
2026-01-14T08:23:39.5920031Z 
2026-01-14T08:23:39.5920120Z def forward(self, x):
2026-01-14T08:23:39.5920436Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:23:39.5920803Z     conv_weight = self.conv.weight
2026-01-14T08:23:39.5921101Z     conv_bias = self.conv.bias
2026-01-14T08:23:39.5921364Z     bn_weight = self.bn.weight
2026-01-14T08:23:39.5921634Z     bn_bias = self.bn.bias
2026-01-14T08:23:39.5921898Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:23:39.5922225Z     bn_running_var = self.bn.running_var
2026-01-14T08:23:39.5922578Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:23:39.5923064Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:23:39.5923731Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:23:39.5924325Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:23:39.5924752Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:23:39.5925190Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:23:39.5925684Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:23:39.5926236Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:23:39.5926868Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:23:39.5927558Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:23:39.5928679Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:23:39.5929768Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:23:39.5930369Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:23:39.5931023Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:23:39.5931656Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:23:39.5932774Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:23:39.5933895Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:23:39.5934740Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:23:39.5935538Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:23:39.5936176Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:23:39.5936596Z     
2026-01-14T08:23:39.5936900Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:39.5937294Z model fx: GraphModule(
2026-01-14T08:23:39.5937636Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:39.5938742Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:39.5940034Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:23:39.5940680Z   )
2026-01-14T08:23:39.5940865Z   (conv): ConvBn2d(
2026-01-14T08:23:39.5941110Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:23:39.5941557Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:23:39.5942084Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:39.5943237Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0012]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:23:39.5944773Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1911, -0.1747, -0.1488]), max_val=tensor([0.1791, 0.1781, 0.1559]))
2026-01-14T08:23:39.5945515Z     )
2026-01-14T08:23:39.5945694Z   )
2026-01-14T08:23:39.5945998Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:39.5947106Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0168]), zero_point=tensor([19], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:39.5948380Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.466952085494995, max_val=1.815312147140503)
2026-01-14T08:23:39.5948954Z   )
2026-01-14T08:23:39.5949177Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:23:39.5949774Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:39.5950877Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0168]), zero_point=tensor([19], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:39.5952156Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.466952085494995, max_val=1.815312147140503)
2026-01-14T08:23:39.5952732Z   )
2026-01-14T08:23:39.5952907Z )
2026-01-14T08:23:39.5953022Z 
2026-01-14T08:23:39.5953026Z 
2026-01-14T08:23:39.5953030Z 
2026-01-14T08:23:39.5953234Z def forward(self, x):
2026-01-14T08:23:49.1809179Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:23:49.1810018Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:23:49.1810814Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:23:49.1811669Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:23:49.1812615Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:23:49.1813320Z     return activation_post_process_2
2026-01-14T08:23:49.1813697Z     
2026-01-14T08:23:49.1814088Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:49.1814653Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:23:49.1814979Z           [0., 0., 0.],
2026-01-14T08:23:49.1815282Z           [0., 0., 0.]],
2026-01-14T08:23:49.1815477Z 
2026-01-14T08:23:49.1815595Z          [[0., 0., 0.],
2026-01-14T08:23:49.1815895Z           [0., 0., 0.],
2026-01-14T08:23:49.1816192Z           [0., 0., 0.]],
2026-01-14T08:23:49.1816382Z 
2026-01-14T08:23:49.1816487Z          [[0., 0., 0.],
2026-01-14T08:23:49.1816782Z           [0., 0., 0.],
2026-01-14T08:23:49.1817107Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:23:49.1817552Z converted model pt2e: GraphModule(
2026-01-14T08:23:49.1817912Z   (conv): Module()
2026-01-14T08:23:49.1818194Z   (bn): Module()
2026-01-14T08:23:49.1818460Z )
2026-01-14T08:23:49.1818608Z 
2026-01-14T08:23:49.1818613Z 
2026-01-14T08:23:49.1818618Z 
2026-01-14T08:23:49.1818737Z def forward(self, x):
2026-01-14T08:23:49.1819140Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:23:49.1819940Z     conv_bias = self.conv.bias
2026-01-14T08:23:49.1820910Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:23:49.1822806Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:23:49.1824113Z     _scale_0 = self._scale_0
2026-01-14T08:23:49.1824479Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:23:49.1824897Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:23:49.1826244Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:23:49.1828175Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:23:49.1829568Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01679319329559803, 19, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:23:49.1831058Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01679319329559803, 19, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:23:49.1832393Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T08:23:49.1833565Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.01679319329559803, 19, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:23:49.1835064Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01679319329559803, 19, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:23:49.1836205Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:23:49.1836767Z     
2026-01-14T08:23:49.1837066Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:49.1837482Z onverted model fx: GraphModule(
2026-01-14T08:23:49.1837897Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:23:49.1838362Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:23:49.1838685Z )
2026-01-14T08:23:49.1838785Z 
2026-01-14T08:23:49.1838790Z 
2026-01-14T08:23:49.1838794Z 
2026-01-14T08:23:49.1838883Z def forward(self, x):
2026-01-14T08:23:49.1839580Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:23:49.1841002Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:23:49.1842148Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:23:49.1843114Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01679319329559803, 19, -128, 127, torch.int8);  conv = None
2026-01-14T08:23:49.1844563Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01679319329559803, 19, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:23:49.1845782Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:23:49.1846836Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.01679319329559803, 19, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:23:49.1848396Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01679319329559803, 19, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:23:49.1849412Z     return dequantize_per_tensor_default_2
2026-01-14T08:23:49.1849891Z     
2026-01-14T08:23:49.1850188Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:23:49.1850605Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:23:49.1850858Z           [0., 0., 0.],
2026-01-14T08:23:49.1851095Z           [0., 0., 0.]],
2026-01-14T08:23:49.1851245Z 
2026-01-14T08:23:49.1851326Z          [[0., 0., 0.],
2026-01-14T08:23:49.1851553Z           [0., 0., 0.],
2026-01-14T08:23:49.1851770Z           [0., 0., 0.]],
2026-01-14T08:23:49.1852017Z 
2026-01-14T08:23:49.1852099Z          [[0., 0., 0.],
2026-01-14T08:23:49.1852332Z           [0., 0., 0.],
2026-01-14T08:23:49.1852556Z           [0., 0., 0.]]]])
2026-01-14T08:23:49.1852813Z model pt2e: GraphModule(
2026-01-14T08:23:49.1853052Z   (conv): Module()
2026-01-14T08:23:49.1853278Z   (bn): Module()
2026-01-14T08:23:49.1853593Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:49.1854695Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:49.1856011Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:23:49.1856570Z   )
2026-01-14T08:23:49.1856864Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:49.1857959Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:23:49.1859279Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19109377264976501, max_val=0.1791490763425827)
2026-01-14T08:23:49.1859864Z   )
2026-01-14T08:23:49.1860255Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:49.1861353Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0168]), zero_point=tensor([19], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:49.1862634Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.4698235988616943, max_val=1.8196974992752075)
2026-01-14T08:23:49.1863215Z   )
2026-01-14T08:23:49.1863496Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:23:49.1864588Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0168]), zero_point=tensor([19], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:23:49.1865881Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.4698235988616943, max_val=1.8196974992752075)
2026-01-14T08:23:49.1866454Z   )
2026-01-14T08:23:49.1866636Z )
2026-01-14T08:23:49.1866735Z 
2026-01-14T08:23:49.1866739Z 
2026-01-14T08:23:49.1866743Z 
2026-01-14T08:23:49.1866830Z def forward(self, x):
2026-01-14T08:23:49.1867144Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:23:49.1867521Z     conv_weight = self.conv.weight
2026-01-14T08:23:49.1867804Z     conv_bias = self.conv.bias
2026-01-14T08:23:49.1868078Z     bn_weight = self.bn.weight
2026-01-14T08:23:49.1868335Z     bn_bias = self.bn.bias
2026-01-14T08:23:49.1868610Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:23:49.1868925Z     bn_running_var = self.bn.running_var
2026-01-14T08:23:49.1869290Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:23:49.1869842Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:23:49.1870512Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:23:49.1871119Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:23:49.1871540Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:23:49.1871993Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:23:49.1872470Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:23:49.1873026Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:23:49.1873668Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:23:49.1874361Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:23:49.1875473Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:23:49.1876502Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:23:49.1877111Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:23:49.1877778Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:23:49.1878414Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:24:10.7908933Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:24:10.7910092Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:24:10.7910943Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:24:10.7911768Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:24:10.7912691Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:24:10.7913166Z     
2026-01-14T08:24:10.7913467Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:24:10.7913877Z model fx: GraphModule(
2026-01-14T08:24:10.7914225Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:24:10.7915323Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:24:10.7916635Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:24:10.7917200Z   )
2026-01-14T08:24:10.7917397Z   (conv): ConvBn2d(
2026-01-14T08:24:10.7917640Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:24:10.7918089Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:24:10.7918620Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:24:10.7919691Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:24:10.7921014Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19109377264976501, max_val=0.1791490763425827)
2026-01-14T08:24:10.7921600Z     )
2026-01-14T08:24:10.7921776Z   )
2026-01-14T08:24:10.7922075Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:24:10.7923164Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0168]), zero_point=tensor([19], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:24:10.7924573Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.4698235988616943, max_val=1.8196974992752075)
2026-01-14T08:24:10.7925141Z   )
2026-01-14T08:24:10.7925382Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:24:10.7925811Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:24:10.7926906Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0168]), zero_point=tensor([19], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:24:10.7928203Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.4698235988616943, max_val=1.8196974992752075)
2026-01-14T08:24:10.7928771Z   )
2026-01-14T08:24:10.7928957Z )
2026-01-14T08:24:10.7929061Z 
2026-01-14T08:24:10.7929070Z 
2026-01-14T08:24:10.7929074Z 
2026-01-14T08:24:10.7929175Z def forward(self, x):
2026-01-14T08:24:10.7929542Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:24:10.7930192Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:24:10.7930785Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:24:10.7931429Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:24:10.7932205Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:24:10.7932723Z     return activation_post_process_2
2026-01-14T08:24:10.7933012Z     
2026-01-14T08:24:10.7933303Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:24:10.7933717Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:24:10.7933964Z           [0., 0., 0.],
2026-01-14T08:24:10.7934195Z           [0., 0., 0.]],
2026-01-14T08:24:10.7934350Z 
2026-01-14T08:24:10.7934431Z          [[0., 0., 0.],
2026-01-14T08:24:10.7934658Z           [0., 0., 0.],
2026-01-14T08:24:10.7934872Z           [0., 0., 0.]],
2026-01-14T08:24:10.7935029Z 
2026-01-14T08:24:10.7935180Z          [[0., 0., 0.],
2026-01-14T08:24:10.7935409Z           [0., 0., 0.],
2026-01-14T08:24:10.7935658Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:24:10.7936003Z converted model pt2e: GraphModule(
2026-01-14T08:24:10.7936276Z   (conv): Module()
2026-01-14T08:24:10.7936498Z   (bn): Module()
2026-01-14T08:24:10.7936694Z )
2026-01-14T08:24:10.7936807Z 
2026-01-14T08:24:10.7936811Z 
2026-01-14T08:24:10.7936815Z 
2026-01-14T08:24:10.7936903Z def forward(self, x):
2026-01-14T08:24:10.7937201Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:24:10.7937573Z     conv_bias = self.conv.bias
2026-01-14T08:24:10.7938299Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:24:10.7939724Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:24:10.7940730Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:24:10.7941617Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0015046753687784076, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:24:10.7943067Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:24:10.7944441Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01682165265083313, 19, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:24:10.7945992Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01682165265083313, 19, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:24:10.7947342Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T08:24:10.7948510Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.01682165265083313, 19, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:24:10.7950161Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.01682165265083313, 19, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:24:10.7951318Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T08:24:10.7951778Z     
2026-01-14T08:24:10.7952071Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:24:10.7952495Z onverted model fx: GraphModule(
2026-01-14T08:24:10.7952895Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:24:10.7953376Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:24:10.7953685Z )
2026-01-14T08:24:10.7953802Z 
2026-01-14T08:24:10.7953806Z 
2026-01-14T08:24:10.7953811Z 
2026-01-14T08:24:10.7953905Z def forward(self, x):
2026-01-14T08:24:10.7954607Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:24:10.7956026Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:24:10.7957178Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:24:10.7958143Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01682165265083313, 19, -128, 127, torch.int8);  conv = None
2026-01-14T08:24:10.7959723Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01682165265083313, 19, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:24:10.7960949Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:24:10.7961983Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.01682165265083313, 19, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:24:10.7963479Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01682165265083313, 19, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:24:10.7964497Z     return dequantize_per_tensor_default_2
2026-01-14T08:24:10.7964787Z     
2026-01-14T08:24:10.7965097Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:24:10.7965497Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:24:10.7965766Z           [0., 0., 0.],
2026-01-14T08:24:10.7965991Z           [0., 0., 0.]],
2026-01-14T08:24:10.7966154Z 
2026-01-14T08:24:10.7966237Z          [[0., 0., 0.],
2026-01-14T08:24:10.7966468Z           [0., 0., 0.],
2026-01-14T08:24:10.7966685Z           [0., 0., 0.]],
2026-01-14T08:24:10.7966831Z 
2026-01-14T08:24:10.7966927Z          [[0., 0., 0.],
2026-01-14T08:24:10.7967144Z           [0., 0., 0.],
2026-01-14T08:24:10.7967377Z           [0., 0., 0.]]]])
2026-01-14T08:24:10.7967803Z [32mPASSED[0m
2026-01-14T08:24:10.7968482Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_mobilenet_v2 [33mSKIPPED[0m
2026-01-14T08:24:10.7969494Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_resnet18 [33mSKIPPED[0m
2026-01-14T08:24:10.7970582Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizeMixQATAndPTQ::test_mixing_qat_ptq [33mSKIPPED[0m
2026-01-14T08:24:10.7971521Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add [32mPASSED[0m
2026-01-14T08:24:10.7972506Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add_relu [32mPASSED[0m
2026-01-14T08:24:10.7973400Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_conv2d [32mPASSED[0m
2026-01-14T08:24:10.7974321Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_dynamic_linear [32mPASSED[0m
2026-01-14T08:24:10.7975251Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_maxpool2d [32mPASSED[0m
2026-01-14T08:24:21.5389196Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq [32mPASSED[0m
2026-01-14T08:24:21.5390308Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq_per_channel [32mPASSED[0m
2026-01-14T08:24:21.5391391Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_static_linear [32mPASSED[0m
2026-01-14T08:24:21.5393030Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5395123Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5397124Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5399113Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5401316Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5403352Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5405280Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5407217Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5409235Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5411146Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5413153Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5415078Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5417112Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5419046Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5420967Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5422972Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5424890Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5426805Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5428715Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5430617Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5432587Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5434526Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5436440Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5438355Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5440265Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5442157Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5444062Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5445963Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5447924Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5450060Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5452040Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5453948Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5455876Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5457804Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5459713Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5664705Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5666796Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5668733Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5670636Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5672555Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5674475Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5676464Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5678370Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5680270Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5682259Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5684179Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5686088Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5688000Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5689898Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5691806Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5693790Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5695676Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5697595Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5699587Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5701499Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5703493Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5705391Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5707290Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5709183Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5711066Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5712963Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5714966Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5716864Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5718773Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5720681Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5722610Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5724509Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5726432Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5728354Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5730316Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5732323Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5945742Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5947647Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5949691Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5951604Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5953496Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5955499Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5957547Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5959469Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5961366Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5963276Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5965198Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5967088Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5968979Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5970884Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5972954Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5974886Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5976796Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5978685Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5980602Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5982489Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5984372Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5986267Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5988231Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5990140Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5992042Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5993947Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5995861Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.5997759Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.5999657Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6001563Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6003464Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6005491Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6007434Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6009328Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6011226Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6013213Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6015102Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6322231Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6324168Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6326202Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6328096Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6329994Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6331891Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6333882Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6335764Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6337667Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6339560Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6341537Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6343432Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6345333Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6347211Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6349104Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6351366Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6353250Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6355146Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6357176Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T08:24:21.6359048Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T08:24:21.6360471Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6361649Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:21.6362724Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_qat_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6363895Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T08:24:21.6365163Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T08:24:21.6366426Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T08:24:21.6367685Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T08:24:21.6368768Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6369818Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6371037Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:21.6372359Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6373731Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:21.6374891Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6375938Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6377027Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:21.6378213Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T08:24:21.6379361Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6380470Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:21.6381753Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T08:24:21.6382918Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mul_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6383900Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6384976Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:21.6386084Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6387292Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:21.6388401Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_dynamic_fp16 [33mSKIPPED[0m
2026-01-14T08:24:21.6389413Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_relu_dynamic_fp16 [33mSKIPPED[0m
2026-01-14T08:24:21.6390392Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d [33mSKIPPED[0m
2026-01-14T08:24:21.6391334Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add [33mSKIPPED[0m
2026-01-14T08:24:21.6392304Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add_relu [33mSKIPPED[0m
2026-01-14T08:24:21.6793042Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardswish [33mSKIPPED[0m
2026-01-14T08:24:21.6794094Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardtanh [33mSKIPPED[0m
2026-01-14T08:24:21.6795097Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu [33mSKIPPED[0m
2026-01-14T08:24:21.6796076Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu6 [33mSKIPPED[0m
2026-01-14T08:24:21.6797036Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_silu [33mSKIPPED[0m
2026-01-14T08:24:21.6797953Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qcat [33mSKIPPED[0m
2026-01-14T08:24:21.6798867Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv1d_relu_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6799826Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_2 [33mSKIPPED[0m
2026-01-14T08:24:21.6800777Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_3 [33mSKIPPED[0m
2026-01-14T08:24:21.6801955Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_broadcast_shapes_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6803002Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6803972Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6805008Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6806077Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6807101Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6808153Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6809232Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6810319Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6811328Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6812399Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_dequant_promotion_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6813417Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6814408Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6815506Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6816547Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6817655Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6818800Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6819869Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6820887Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6821982Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6823136Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6824212Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:21.6825216Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6826203Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_fp8_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6827195Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6828185Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_fp8_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6829237Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_int8_mixed_bf16_xpu [33mSKIPPED[0m
2026-01-14T08:24:21.6830274Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6831321Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6832381Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6833488Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6834542Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_with_concat_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6835498Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qflatten [33mSKIPPED[0m
2026-01-14T08:24:21.6836643Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:21.6837985Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:21.6839323Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:21.6840641Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:21.6841976Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:21.6843304Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:21.6844617Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:21.6845997Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:21.6847395Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:21.6848829Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:21.6850432Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:21.6851872Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:21.6853395Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:21.6854832Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:21.6856251Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:21.6857670Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:21.6858830Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6859839Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6861125Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:21.6862351Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_dynamic_cpu [33mSKIPPED[0m
2026-01-14T08:24:21.6863494Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:26.0392181Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:26.0393387Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_cpu [33mSKIPPED[0m
2026-01-14T08:24:26.0394402Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:26.0395471Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:26.0396644Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T08:24:26.0397744Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:26.0398828Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:26.0400087Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T08:24:26.0401199Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mul_cpu [33mSKIPPED[0m
2026-01-14T08:24:26.0402173Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_cpu [33mSKIPPED[0m
2026-01-14T08:24:26.0403507Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:26.0404574Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T08:24:26.0405705Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T08:24:26.0406747Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qmaxpool2d [33mSKIPPED[0m
2026-01-14T08:24:26.0408039Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:26.0409611Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:26.0411241Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:26.0413229Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:26.0414887Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:26.0416475Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:26.0418196Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:26.0419939Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:26.0421520Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:26.0423250Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:26.0424890Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:26.0426469Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:26.0428170Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:26.0429836Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:26.0431423Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_False [33mSKIPPED[0m
2026-01-14T08:24:26.0433111Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_True [33mSKIPPED[0m
2026-01-14T08:24:26.0434504Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_q_attention_block [33mSKIPPED[0m
2026-01-14T08:24:26.0435723Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T08:24:26.0437007Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T08:24:26.0438338Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag_with_output_quant [33mSKIPPED[0m
2026-01-14T08:24:26.0439543Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block [33mSKIPPED[0m
2026-01-14T08:24:26.0440737Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qat_bn_conv2d [33mSKIPPED[0m
2026-01-14T08:24:26.0441930Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qconv2d_maxpool2d_linear_dynamic_cpu [33mSKIPPED[0m
2026-01-14T08:24:26.0443221Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_adaptive_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T08:24:26.0444527Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_annotate_mul_tensor [32mPASSED[0m
2026-01-14T08:24:26.0445685Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_attention_block [32mPASSED[0m
2026-01-14T08:24:26.0446852Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T08:24:26.0448061Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe [32mPASSED[0m
2026-01-14T08:24:26.0449210Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_same_inputs [32mPASSED[0m
2026-01-14T08:24:26.0450656Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_single_input [32mPASSED[0m
2026-01-14T08:24:26.0451855Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d [32mPASSED[0m
2026-01-14T08:24:26.0453220Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary [32mPASSED[0m
2026-01-14T08:24:26.0454376Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary2 [32mPASSED[0m
2026-01-14T08:24:26.0455602Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary_unary [32mPASSED[0m
2026-01-14T08:24:26.0456859Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_serials_binary_unary [32mPASSED[0m
2026-01-14T08:24:26.0458051Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_unary [32mPASSED[0m
2026-01-14T08:24:26.0459260Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_dynamic_quant_linear [32mPASSED[0m
2026-01-14T08:24:26.0460483Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe [32mPASSED[0m
2026-01-14T08:24:26.0461660Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_linear_recipe [32mPASSED[0m
2026-01-14T08:24:26.0462947Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_maxpool2d_recipe [32mPASSED[0m
2026-01-14T08:24:26.0464153Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe [32mPASSED[0m
2026-01-14T08:24:26.0465271Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe2 [32mPASSED[0m
2026-01-14T08:24:26.0466438Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear [32mPASSED[0m
2026-01-14T08:24:26.0467560Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary [32mPASSED[0m
2026-01-14T08:24:26.0468775Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary2 [32mPASSED[0m
2026-01-14T08:26:41.9476963Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic [32mPASSED[0m
2026-01-14T08:26:41.9480020Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic_qat [32mPASSED[0m
2026-01-14T08:26:41.9481626Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_qat [32mPASSED[0m
2026-01-14T08:26:41.9482827Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary [32mPASSED[0m
2026-01-14T08:26:41.9484264Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic [32mPASSED[0m
2026-01-14T08:26:41.9485629Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic_qat [32mPASSED[0m
2026-01-14T08:26:41.9496445Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_qat [32mPASSED[0m
2026-01-14T08:26:41.9497786Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_serials [32mPASSED[0m
2026-01-14T08:26:41.9498998Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_dynamic_fp16 [32mPASSED[0m
2026-01-14T08:26:41.9500154Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary [32mPASSED[0m
2026-01-14T08:26:41.9501319Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic [32mPASSED[0m
2026-01-14T08:26:41.9502471Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic_qat [32mPASSED[0m
2026-01-14T08:26:41.9503599Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_qat [32mPASSED[0m
2026-01-14T08:26:41.9505047Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_lowering_to_x86 [33mSKIPPED[0m
2026-01-14T08:26:41.9506313Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_maxpool2d_recipe [32mPASSED[0m
2026-01-14T08:26:41.9507365Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d [32mPASSED[0m
2026-01-14T08:26:41.9508495Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary [32mPASSED[0m
2026-01-14T08:26:41.9509673Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary2 [32mPASSED[0m
2026-01-14T08:26:41.9510806Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary_unary [32mPASSED[0m
2026-01-14T08:26:41.9511929Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_unary [32mPASSED[0m
2026-01-14T08:26:41.9513049Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_dynamic_quant_linear [32mPASSED[0m
2026-01-14T08:26:41.9514422Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case1 [32mPASSED[0m
2026-01-14T08:26:41.9515687Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case2 [32mPASSED[0m
2026-01-14T08:26:41.9517138Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs [32mPASSED[0m
2026-01-14T08:26:41.9518432Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig [32mPASSED[0m
2026-01-14T08:26:41.9519815Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_for_dynamic_quant [32mPASSED[0m
2026-01-14T08:26:41.9521127Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_with_underscores [32mPASSED[0m
2026-01-14T08:26:41.9522542Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_with_mixed_configs [32mPASSED[0m
2026-01-14T08:26:41.9523655Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T08:26:41.9524842Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm_weight_in_bkn_layout [33mSKIPPED[0m
2026-01-14T08:26:41.9526094Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:41.9527283Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:41.9528450Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T08:26:41.9529617Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:41.9530929Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:41.9532198Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T08:26:41.9533390Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-1 [33mSKIPPED[0m
2026-01-14T08:26:41.9534536Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-2 [33mSKIPPED[0m
2026-01-14T08:26:41.9535733Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_create_tensor_out_of_inference_mode [33mSKIPPED[0m
2026-01-14T08:26:41.9537141Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_expected_gpu_kernel_fbgemm [33mSKIPPED[0m
2026-01-14T08:26:41.9538598Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:41.9540194Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:41.9541756Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:41.9543352Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:41.9544870Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:41.9546395Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:41.9548055Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:41.9549718Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:41.9551307Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:41.9552579Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:41.9553849Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes2 [33mSKIPPED[0m
2026-01-14T08:26:41.9555099Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes3 [33mSKIPPED[0m
2026-01-14T08:26:41.9556359Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:41.9557603Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:41.9558864Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes2 [33mSKIPPED[0m
2026-01-14T08:26:41.9560118Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes3 [33mSKIPPED[0m
2026-01-14T08:26:41.9561810Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9563903Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9772319Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9774726Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9777091Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9779180Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9781518Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9783584Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9785839Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9787991Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9790322Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9792526Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9794850Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9797086Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9799236Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9801299Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9803651Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9805957Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9808029Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9810311Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9812582Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9814950Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9817029Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9819264Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9821528Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9823719Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9825888Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9828175Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9830418Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9832545Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9834587Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9836894Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9839218Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9841271Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9843597Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:41.9845743Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:41.9848076Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0075004Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0077113Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0079542Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0081786Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0083908Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0086182Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0088383Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0090608Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0093059Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0095108Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0097344Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0099516Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0101813Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0103996Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0106333Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0108588Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0110713Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0112781Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0115108Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0117416Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0119461Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0121781Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0123911Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0126231Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0128280Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0130526Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T08:26:42.0132849Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T08:26:42.0135084Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0137192Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0139644Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0141958Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0144167Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0146417Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0148699Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0151245Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0361937Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0364215Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0366624Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0368933Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0371131Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0373439Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0375706Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0378092Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0380195Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0382703Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0385048Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0387244Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0389355Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0391759Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0393853Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0396248Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0398354Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0400741Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0403042Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0405290Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0407397Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0409786Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0412221Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0414405Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0416715Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0418994Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0421399Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0423513Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0425850Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0428214Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0430387Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0432456Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0434920Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0437318Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0648318Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0650581Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0653105Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0655408Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0657611Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0659709Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0662240Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0664613Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0666707Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0668993Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0671373Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0673586Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0675684Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0678068Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0680534Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0682652Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0684938Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0687119Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0689504Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0691601Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0693970Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0696159Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0698535Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0700733Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0702839Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0705242Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0707614Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0709706Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0711992Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0714254Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0716662Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0718813Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0721201Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0723542Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0935177Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0937387Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0939820Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0942373Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0944545Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0946896Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0949151Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0951656Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0953814Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0956194Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0958487Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0960801Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0963108Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0965327Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0967728Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0969895Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0972335Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0974665Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0977004Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0979264Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0981530Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0983911Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0986086Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0988372Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0990748Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0992972Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0995205Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.0997589Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.0999755Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1002133Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1004284Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1006603Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1008849Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1011240Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1222264Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1224440Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1226886Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1229286Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1231497Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1233848Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1236062Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1238605Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1240746Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1243175Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1245552Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1247731Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1250205Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1252516Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1254962Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1257236Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1259660Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1262020Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1264270Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1266649Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1268878Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1271323Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1273590Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1275986Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1278325Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1280553Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1282831Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1285138Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1287570Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1289709Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1292301Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1294681Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1296918Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1299180Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1507344Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1509484Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1511748Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1513927Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1516257Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1518369Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1520609Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1522866Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1524977Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1527229Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1529438Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1531715Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1534009Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1536329Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1538588Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1540749Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1542934Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1545156Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1547428Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1549823Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1552104Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1554376Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1556543Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1558654Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1560958Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1563251Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1565338Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1567647Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1569870Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1572215Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1574333Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1576658Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1578877Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1581052Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1801224Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1803476Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1805780Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1807871Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1810153Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1812389Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1814481Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1816854Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1819224Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1821424Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1823710Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1825903Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1828220Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1830319Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1832665Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1834934Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1837193Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1839277Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1841629Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1843975Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1846090Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1848369Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1850758Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1853136Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1855349Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1857708Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1859990Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1862159Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1864297Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1866556Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1868908Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1870995Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1873384Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.1875702Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.1877932Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2087134Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2089281Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2091606Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2094033Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2096249Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2098552Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2100903Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2103296Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2105457Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2107799Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2110026Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2112360Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2114689Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2116819Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2119234Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2121633Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2123783Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2126083Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2128414Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2130702Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2133033Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2135468Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2137884Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2140025Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2142358Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2144591Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2146994Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2149120Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2151730Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2154059Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2156268Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2158523Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2160827Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2163237Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2372590Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2374857Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2377435Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2379774Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2382014Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2384323Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2386524Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2388942Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2391060Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2393578Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2395929Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2398165Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2400420Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2402705Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2405112Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2407234Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2409589Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2411844Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2414030Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2416430Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2418573Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2420902Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2423163Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2425547Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2427764Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2430163Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2432509Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2434727Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2436974Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2439246Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2441644Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2443755Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2446197Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2448531Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2667914Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2670082Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2672523Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2674867Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2677085Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2679357Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T08:26:42.2681768Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T08:26:42.2684155Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2686198Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2688517Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2690787Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2693022Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2695080Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2697420Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2699829Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2701898Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2704163Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2706293Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2708635Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2710682Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2712984Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2715026Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2717361Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2719500Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2721532Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2723856Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2726182Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2728229Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2730411Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2732698Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2735128Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2737213Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2739446Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2741711Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2743965Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2961242Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2963380Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2965901Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2968196Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2970392Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2972721Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2974970Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2977356Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2979446Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2981706Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2984172Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2986381Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2988463Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2990847Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2993219Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2995304Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.2997517Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.2999706Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3002081Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3004160Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3006436Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3008541Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3010669Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3012799Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3014994Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3017024Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3019197Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3021324Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3023356Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3025569Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3027768Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3029818Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3031833Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3034008Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3036258Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3262117Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3264179Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3266427Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3268693Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3270807Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3272847Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3275172Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3277602Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3279661Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3281923Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3284140Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3286455Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3288556Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3290914Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3293322Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3295577Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3297836Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3300004Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3302385Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3304480Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3306821Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3309092Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3311248Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3313411Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3315729Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3317812Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3320159Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3322248Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3324511Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3326799Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3329119Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3331206Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3333669Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3335500Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_has_compatible_shallow_copy_type [33mSKIPPED[0m
2026-01-14T08:26:42.3336749Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_index_select [33mSKIPPED[0m
2026-01-14T08:26:42.3338069Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3722470Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3724031Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3725536Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3727150Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T08:26:42.3728332Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_per_row_config_before_dim [33mSKIPPED[0m
2026-01-14T08:26:42.3729874Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.3731024Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.3732227Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config2 [33mSKIPPED[0m
2026-01-14T08:26:42.3733548Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T08:26:42.3735320Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T08:26:42.3736921Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T08:26:42.3738556Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T08:26:42.3740033Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T08:26:42.3741488Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T08:26:42.3743241Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T08:26:42.3744950Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T08:26:42.3746585Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T08:26:42.3748066Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T08:26:42.3749657Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T08:26:42.3751427Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T08:26:42.3752972Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity0 [33mSKIPPED[0m
2026-01-14T08:26:42.3754490Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity1 [33mSKIPPED[0m
2026-01-14T08:26:42.3755715Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity0 [33mSKIPPED[0m
2026-01-14T08:26:42.3756849Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity1 [33mSKIPPED[0m
2026-01-14T08:26:42.3758128Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity0 [33mSKIPPED[0m
2026-01-14T08:26:42.3759624Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity1 [33mSKIPPED[0m
2026-01-14T08:26:42.3761034Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3762409Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3763757Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T08:26:42.3764986Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3766394Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3767698Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T08:26:42.3768978Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_dtype_layout [33mSKIPPED[0m
2026-01-14T08:26:42.3770212Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_transpose [33mSKIPPED[0m
2026-01-14T08:26:42.3771346Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_conv2d_weight [33mSKIPPED[0m
2026-01-14T08:26:42.3772686Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3774149Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3775633Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.3777076Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.3778745Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T08:26:42.3780256Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T08:26:42.3781810Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T08:26:42.3783611Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T08:26:42.3785125Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.3786552Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.3787835Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_from_int4_tensor [33mSKIPPED[0m
2026-01-14T08:26:42.3789092Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.3790555Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.3791923Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.3793276Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.3794803Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.3796163Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.3797363Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_activation_prescaling [33mSKIPPED[0m
2026-01-14T08:26:42.3798382Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T08:26:42.3799534Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4184053Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4185060Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes2 [33mSKIPPED[0m
2026-01-14T08:26:42.4186031Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_linear [33mSKIPPED[0m
2026-01-14T08:26:42.4187069Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T08:26:42.4188281Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice [33mSKIPPED[0m
2026-01-14T08:26:42.4189438Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_and_copy_similar_to_vllm [33mSKIPPED[0m
2026-01-14T08:26:42.4190718Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_preserves_aliasing [33mSKIPPED[0m
2026-01-14T08:26:42.4191939Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4192986Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4194163Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes2 [33mSKIPPED[0m
2026-01-14T08:26:42.4195448Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4197223Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4198791Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_cant_initialize_in_cpu [33mSKIPPED[0m
2026-01-14T08:26:42.4200428Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_128 [33mSKIPPED[0m
2026-01-14T08:26:42.4201962Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_32 [33mSKIPPED[0m
2026-01-14T08:26:42.4203483Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_64 [33mSKIPPED[0m
2026-01-14T08:26:42.4205218Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_error_conditions [33mSKIPPED[0m
2026-01-14T08:26:42.4206698Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4208264Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4209665Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4211060Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4212819Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4214315Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4215760Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_mm_int4wo_device_cuda_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4217367Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4218822Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4220283Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4221826Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4223537Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4224853Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4226547Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4228117Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4229487Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_to_device [33mSKIPPED[0m
2026-01-14T08:26:42.4230876Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_available_gpu_kernels [33mSKIPPED[0m
2026-01-14T08:26:42.4232098Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4233421Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4234752Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config2 [33mSKIPPED[0m
2026-01-14T08:26:42.4235928Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config3 [33mSKIPPED[0m
2026-01-14T08:26:42.4237109Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4238410Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4239741Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config2 [33mSKIPPED[0m
2026-01-14T08:26:42.4240925Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config3 [33mSKIPPED[0m
2026-01-14T08:26:42.4242247Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4243418Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4244579Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config2 [33mSKIPPED[0m
2026-01-14T08:26:42.4245649Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config3 [33mSKIPPED[0m
2026-01-14T08:26:42.4247119Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4248636Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4250378Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4251851Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4253360Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4254914Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4256483Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4258089Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4259579Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4261112Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4582612Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4584066Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4585478Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4587076Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4588587Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4590201Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4591681Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4593098Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4594510Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4596183Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4597848Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4599429Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4600831Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4602242Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4603828Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4605316Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4606924Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4608395Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4609787Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4611181Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4613022Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes0 [33mSKIPPED[0m
2026-01-14T08:26:42.4614433Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes1 [33mSKIPPED[0m
2026-01-14T08:26:42.4615652Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config0 [33mSKIPPED[0m
2026-01-14T08:26:42.4616874Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config1 [33mSKIPPED[0m
2026-01-14T08:26:42.4618064Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config2 [33mSKIPPED[0m
2026-01-14T08:26:42.4619118Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config3 [33mSKIPPED[0m
2026-01-14T08:26:42.4620240Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device1_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4621410Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device1_float16 [33mSKIPPED[0m
2026-01-14T08:26:42.4622783Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4624060Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_float16 [33mSKIPPED[0m
2026-01-14T08:26:42.4625421Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device1_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4626665Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device1_float16 [33mSKIPPED[0m
2026-01-14T08:26:42.4627848Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4629021Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_float16 [33mSKIPPED[0m
2026-01-14T08:26:42.4630306Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device1_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4631733Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device1_float16 [33mSKIPPED[0m
2026-01-14T08:26:42.4632907Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4634293Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_float16 [33mSKIPPED[0m
2026-01-14T08:26:42.4635548Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device1_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4636713Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device1_float16 [33mSKIPPED[0m
2026-01-14T08:26:42.4637898Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4639265Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_float16 [33mSKIPPED[0m
2026-01-14T08:26:42.4640703Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity0_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4642385Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity1_bfloat16 [33mSKIPPED[0m
2026-01-14T08:26:42.4644860Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4648430Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4652163Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4655350Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4771644Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4775122Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4778780Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4782002Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4785550Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4789144Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4792636Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4796680Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4800047Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4803495Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4806804Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4810381Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4814062Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4817452Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4820716Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4824160Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4827404Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4831005Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4834588Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4838062Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4841516Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4844677Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4962002Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4965651Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4969295Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4972533Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4976047Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4979423Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4983034Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4986621Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4989971Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.4993516Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.4996771Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5000308Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5003835Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5007322Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5010955Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5014208Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5017879Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5021192Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5024695Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5028145Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5031562Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5035169Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5150812Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5154434Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5158116Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5161355Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5165043Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5168485Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5172047Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5175590Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5179001Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5182616Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5185949Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5189569Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5193120Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5196620Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5200111Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5203381Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5207129Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5210575Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5214189Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5217691Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5221165Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5224762Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5339150Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5342727Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5346385Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5349898Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5353511Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5356880Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5360436Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5364054Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5367585Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5371088Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5374481Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5377991Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5381540Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5385247Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5388791Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5392117Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5395681Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5398966Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5402566Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5406205Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5409738Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5413392Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5525189Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5528605Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5532465Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5535832Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5539349Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5542775Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5545905Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5549381Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5552937Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5556277Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5559751Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5562856Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5566463Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5569946Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5573465Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5576886Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5579978Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5583687Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5586963Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5590492Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5593959Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5597256Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5713541Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5717005Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5720559Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5723823Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5727259Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5730657Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5734230Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5737646Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5740818Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5744342Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5747793Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5751129Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5754539Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5757926Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5761227Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5764767Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5768036Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5771309Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5774625Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5798363Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5801587Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5804999Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5901650Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5904848Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5908126Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5911341Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5914655Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5918141Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5921402Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5924725Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5927979Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5931264Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5934763Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5937947Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5941310Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5944561Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5947919Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5951451Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5954841Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5958142Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5961438Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5964596Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.5967959Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.5971462Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6091570Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6095073Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6098553Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6101752Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6105379Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6108976Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6112466Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6115911Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6119078Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6122831Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6126139Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6129696Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6133268Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6136589Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6140148Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6143407Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6146900Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6150627Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6154051Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6157421Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6160857Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6164199Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6280446Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6283956Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6287649Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6290842Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6294364Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6297826Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6301320Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6304873Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6308360Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6311967Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6315367Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6319019Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6322574Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6326123Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6329605Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6332907Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6336587Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6339881Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6343440Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6346923Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6350530Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6354221Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6468791Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6472341Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6475918Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6479120Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6482680Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6486288Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6489935Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6493517Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6496834Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6500383Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6503726Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6507396Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6510965Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6514368Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6517927Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6521126Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6524787Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6528353Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6531962Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6535461Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6538780Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6542333Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6655423Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6659043Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6662616Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6665814Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6669290Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6672862Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6676125Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6679892Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6683279Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6686767Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6690306Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6693780Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6697350Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6700751Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6704238Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6707727Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6711008Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6714456Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6717575Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6720960Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6724421Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6727801Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6842650Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6846134Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6849805Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6853012Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6856547Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6859919Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6863294Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6866916Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6870078Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6873565Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6876937Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6880036Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6883497Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6887030Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6890451Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6894066Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6897173Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6900572Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6904021Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6907566Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:42.6911023Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:42.6914142Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:43.1877935Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:43.1882215Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:43.1886495Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:43.1891200Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:43.1895521Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:43.1899711Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:43.1903870Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:43.1908047Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:43.1912067Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:43.1915311Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:43.1919672Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:43.1924763Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:43.1929667Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:43.1934625Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:43.1939547Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T08:26:43.1943880Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T08:26:43.1946793Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T08:26:43.1948958Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_ATEN_KLEIDIAI: 'opaque_aten_kleidiai'>} [33mSKIPPED[0m
2026-01-14T08:26:43.1951975Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>} [33mSKIPPED[0m
2026-01-14T08:26:43.1954411Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_conv2d [32mPASSED[0m
2026-01-14T08:26:43.1956397Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_embedding [32mPASSED[0m
2026-01-14T08:26:43.1958803Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T08:26:43.1961204Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config_with_unwrap [32mPASSED[0m
2026-01-14T08:26:43.1963644Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_intx_weight_only_config [32mPASSED[0m
2026-01-14T08:26:43.1965981Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T08:26:43.1968279Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_intx_weight_only_config [32mPASSED[0m
2026-01-14T08:26:43.1970363Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_linear [32mPASSED[0m
2026-01-14T08:26:43.1973896Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.4751459Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.4755317Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.4759401Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.4763139Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.4766865Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.4770590Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.4774392Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.4778235Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.4781975Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.4785712Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.4789440Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.4793245Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.4797002Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.4800872Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.4804639Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.4808344Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.4812143Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.4815904Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.4819654Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.4823463Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.4827279Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.4831035Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.4834873Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.4838557Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.4842289Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.7610254Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.7614262Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.7618119Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.7621862Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.7626323Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.7631272Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.7635553Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.7639456Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.7643196Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.7646908Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.7650808Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.7654756Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.7660145Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.7665340Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.7670440Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.7675340Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.7679042Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.7682739Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.7686691Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.7690428Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.7695325Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.7700426Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:43.7705991Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:43.7710617Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:43.7715090Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.0495533Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.0499330Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.0503042Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.0506777Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.0510776Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.0514502Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.0518221Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.0521953Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.0525664Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.0529392Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.0532499Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.0535669Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.0540176Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.0544594Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.0549350Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.0553974Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.0558242Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.0561935Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.0565628Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.0570102Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.0575067Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.0580035Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.0584640Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.0589158Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.0593546Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.3359657Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.3363438Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.3367141Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.3371127Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.3375022Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.3378740Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.3382469Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.3386200Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.3389916Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.3393799Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.3397503Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.3401392Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.3406010Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.3410373Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.3415182Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.3419776Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.3423971Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.3427734Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.3431473Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.3435197Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.3438947Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.3443109Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.3447654Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.3452746Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.3457082Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.6171964Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.6176044Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.6179778Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.6183472Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.6187702Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.6192660Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.6196758Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.6200627Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.6204360Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.6208206Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.6212012Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.6215983Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.6221122Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.6226458Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.6231655Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.6236598Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.6240345Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.6244093Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.6247819Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.6251829Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.6256673Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.6261759Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.6267161Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.6271763Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.6276547Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.8996381Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.9000303Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.9004141Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.9008002Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.9011796Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.9015674Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.9019652Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.9023484Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.9027300Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.9031013Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.9035477Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.9039870Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.9045368Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.9049779Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.9053585Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.9057320Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.9061099Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.9065666Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.9070224Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.9074624Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.9079253Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.9083648Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:44.9087965Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:44.9092427Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:44.9096160Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.1795194Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.1798998Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.1802726Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.1806459Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.1810592Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.1814389Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.1818121Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.1821828Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.1825645Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.1829336Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.1833186Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.1837104Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.1841663Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.1846248Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.1850397Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.1855250Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.1859665Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.1863422Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.1867154Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.1870888Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.1874644Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.1878720Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.1883121Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.1887866Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.1892541Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.4612223Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.4616023Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.4619740Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.4623782Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.4628028Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.4633005Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.4637136Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.4640840Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.4644534Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.4648362Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.4652441Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.4656930Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.4661375Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.4666302Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.4670893Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.4675391Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.4679312Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.4683095Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.4686836Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.4690581Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.4695727Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.4700337Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.4705710Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.4710139Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.4714607Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.6702910Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.6705962Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.6708727Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.6711496Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.6714268Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.6717035Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.6719800Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.6722686Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.6725461Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.6728214Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.6730980Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.6733803Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.6736560Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T08:26:45.6739381Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T08:26:45.6742147Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T08:26:45.6744279Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T08:26:45.6745847Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_intx_weight_only_config [32mPASSED[0m
2026-01-14T08:26:45.6747235Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice [32mPASSED[0m
2026-01-14T08:26:45.6748522Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice_and_copy_ [32mPASSED[0m
2026-01-14T08:26:45.6749950Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_to_dtype [32mPASSED[0m
2026-01-14T08:26:45.6751081Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_False [33mSKIPPED[0m
2026-01-14T08:26:45.6752077Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_True [33mSKIPPED[0m
2026-01-14T08:26:45.6753053Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_False [33mSKIPPED[0m
2026-01-14T08:26:45.6754117Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_True [33mSKIPPED[0m
2026-01-14T08:26:45.6755191Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.6756348Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.6757498Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.6758622Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.6759763Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.6760896Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.6762029Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.6763162Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.6764286Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.6765434Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.6766574Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.6767795Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.6768941Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.6770072Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.6771204Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.6772437Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8445370Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8447011Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8448555Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8450207Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8451730Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8453329Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8454850Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8456350Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8457879Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8459620Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8461135Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8462634Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8464159Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8465659Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8467150Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8468633Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8470135Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8471656Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8473164Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8474644Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8476261Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8477766Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8479250Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8480737Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8482225Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8483741Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8485243Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8486740Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8488240Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8489743Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8491226Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T08:26:45.8492799Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T08:26:45.8494109Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_add_tensors [33mSKIPPED[0m
2026-01-14T08:26:45.8495329Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_inplace_operation [33mSKIPPED[0m
2026-01-14T08:26:45.8496605Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_pad_unpad [33mSKIPPED[0m
2026-01-14T08:26:45.8497855Z test/quantization/test_gptq.py::TestMultiTensorInputRecorder::test_multitensor_input_recorder [33mSKIPPED[0m
2026-01-14T08:26:45.8499078Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_calc_success [32mPASSED[0m
2026-01-14T08:26:45.8500180Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_row_errors [32mPASSED[0m
2026-01-14T08:26:45.8501279Z test/quantization/test_observer.py::TestQuantFlow::test_fixed_qparams_observer [32mPASSED[0m
2026-01-14T08:26:45.8502409Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_channel_affine [32mPASSED[0m
2026-01-14T08:26:45.8503536Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_tensor_affine [32mPASSED[0m
2026-01-14T08:26:45.8504599Z test/quantization/test_observer.py::TestQuantFlow::test_mse_observer [32mPASSED[0m
2026-01-14T08:26:45.8505818Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_False [32mPASSED[0m
2026-01-14T08:26:45.8507234Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_True [32mPASSED[0m
2026-01-14T08:26:45.8508411Z test/quantization/test_qat.py::TestQAT::test_composable_qat_quantizer [32mPASSED[0m
2026-01-14T08:26:45.8509384Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dtype [32mPASSED[0m
2026-01-14T08:26:45.8510519Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dynamic_and_range_learning [32mPASSED[0m
2026-01-14T08:26:45.8511601Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_eps [32mPASSED[0m
2026-01-14T08:26:45.8512622Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity [32mPASSED[0m
2026-01-14T08:26:45.8513834Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity_error_cases [32mPASSED[0m
2026-01-14T08:26:45.8514960Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_mapping_type [32mPASSED[0m
2026-01-14T08:26:45.8516025Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_torch_intx [32mPASSED[0m
2026-01-14T08:26:45.8517055Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_channel_group [32mPASSED[0m
2026-01-14T08:26:45.8518054Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token [32mPASSED[0m
2026-01-14T08:26:45.8519142Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T08:26:45.8520145Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float16 [32mPASSED[0m
2026-01-14T08:26:45.8521029Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float32 [32mPASSED[0m
2026-01-14T08:26:45.8521834Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_embedding_4w [32mPASSED[0m
2026-01-14T08:26:45.8522574Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_4w [32mPASSED[0m
2026-01-14T08:26:45.8523301Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_8da4w [32mPASSED[0m
2026-01-14T08:26:45.8524152Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T08:26:45.8525080Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T08:26:45.8525866Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_repr [32mPASSED[0m
2026-01-14T08:26:45.8526655Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_int4_preshuffled_primitives [33mSKIPPED[0m
2026-01-14T08:26:45.8527428Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_primitives [33mSKIPPED[0m
2026-01-14T08:26:45.8528205Z test/quantization/test_qat.py::TestQAT::test_fbgemm_int4_weight_only_primitives [33mSKIPPED[0m
2026-01-14T08:26:45.8528993Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_config [32mPASSED[0m
2026-01-14T08:26:45.8529825Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity0 [32mPASSED[0m
2026-01-14T08:26:45.8530632Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity1 [32mPASSED[0m
2026-01-14T08:26:45.8531368Z test/quantization/test_qat.py::TestQAT::test_infer_fp8_int4_config [32mPASSED[0m
2026-01-14T08:26:45.8532201Z test/quantization/test_qat.py::TestQAT::test_infer_int4_weight_only_config [32mPASSED[0m
2026-01-14T08:26:45.8532951Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e [32mPASSED[0m
2026-01-14T08:27:03.3748967Z test/quantization/test_qat.py::TestQAT::test_nvfp4_fake_quanitzed_linear_mixed_precision [33mSKIPPED[0m
2026-01-14T08:27:03.3749941Z test/quantization/test_qat.py::TestQAT::test_qat_4w_embedding [32mPASSED[0m
2026-01-14T08:27:03.3750664Z test/quantization/test_qat.py::TestQAT::test_qat_4w_linear [33mSKIPPED[0m (...)
2026-01-14T08:27:03.3751363Z test/quantization/test_qat.py::TestQAT::test_qat_4w_primitives [33mSKIPPED[0m
2026-01-14T08:27:03.3752101Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer [33mSKIPPED[0m
2026-01-14T08:27:03.3752844Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer_gradients [32mPASSED[0m
2026-01-14T08:27:03.3753529Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_eps [32mPASSED[0m
2026-01-14T08:27:03.3754186Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_linear [32mPASSED[0m
2026-01-14T08:27:03.3755030Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T08:27:03.3755860Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float16 [32mPASSED[0m
2026-01-14T08:27:03.3756689Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float32 [32mPASSED[0m
2026-01-14T08:27:03.3757719Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer [32mPASSED[0m
2026-01-14T08:27:03.3758501Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant [32mPASSED[0m
2026-01-14T08:27:03.3759395Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant_backward [32mPASSED[0m
2026-01-14T08:27:03.3760313Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_gradients [32mPASSED[0m
2026-01-14T08:27:03.3761098Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_meta_weights [32mPASSED[0m
2026-01-14T08:27:03.3761904Z test/quantization/test_qat.py::TestQAT::test_qat_api_convert_no_quantization [32mPASSED[0m
2026-01-14T08:27:03.3762719Z test/quantization/test_qat.py::TestQAT::test_qat_api_deprecation [32mPASSED[0m
2026-01-14T08:27:03.3763402Z test/quantization/test_qat.py::TestQAT::test_qat_config_init [32mPASSED[0m
2026-01-14T08:27:03.3764068Z test/quantization/test_qat.py::TestQAT::test_qat_fp8a4w_quantizer [32mPASSED[0m
2026-01-14T08:27:03.3764744Z test/quantization/test_qat.py::TestQAT::test_qat_linear_bias [32mPASSED[0m
2026-01-14T08:27:03.3765529Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T08:27:03.3766439Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T08:27:03.3767352Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T08:27:03.3768198Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T08:27:03.3768942Z test/quantization/test_qat.py::TestQAT::test_qat_prototype_bc [32mPASSED[0m
2026-01-14T08:27:03.3769687Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T08:27:03.3770602Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T08:27:03.3771344Z test/quantization/test_qat.py::TestQAT::test_quantize_api_e2e [32mPASSED[0m
2026-01-14T08:27:03.3772217Z test/quantization/test_qat.py::TestQAT::test_quantize_api_errors [32mPASSED[0m
2026-01-14T08:27:03.3772991Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity0 [33mSKIPPED[0m
2026-01-14T08:27:03.3773796Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity1 [33mSKIPPED[0m
2026-01-14T08:27:03.3774561Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_int4 [33mSKIPPED[0m
2026-01-14T08:27:03.3775570Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T08:27:03.3776724Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T08:27:03.3777938Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T08:27:03.3779087Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T08:27:03.3780063Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_int4 [33mSKIPPED[0m
2026-01-14T08:27:03.3780955Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity0_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3781959Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity1_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3783047Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity2_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3784055Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity3_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3785069Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity4_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3786258Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity5_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3787270Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity6_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3788288Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity7_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3789301Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity10_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3790352Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity11_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3791428Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity8_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3792423Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity9_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3793522Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity12_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3794536Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity13_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3795552Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity14_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3796576Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity15_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3797584Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity16_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3798683Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity17_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3799691Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity18_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3800789Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity19_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3801885Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity20_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3802891Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity21_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3803911Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity22_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3804932Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity23_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3806011Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity24_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3807036Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity25_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3808047Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity26_bfloat16 [33mSKIPPED[0m
2026-01-14T08:27:03.3809150Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity27_float32 [33mSKIPPED[0m
2026-01-14T08:27:03.3810208Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity0_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:03.3811296Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity1_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:03.3812471Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity2_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:03.3813622Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity3_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:03.3814792Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity4_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:03.3815890Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity5_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:03.3817057Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity6_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:03.3818143Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity7_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:03.3819222Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity10_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:03.3820327Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity11_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2891457Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity12_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2892721Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity13_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2893849Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity14_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2894951Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity15_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2896037Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity8_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2897133Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity9_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2898283Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity16_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2899525Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity17_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2900892Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity18_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2902344Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity19_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2903898Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity20_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2905533Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity21_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2907191Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity22_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2908723Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity23_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2910316Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity24_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2911896Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity25_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2913498Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity26_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2915098Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity27_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2916645Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity28_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2918258Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity29_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2919979Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity30_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2921539Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity31_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2923183Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity32_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2924748Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity33_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2926339Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity34_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2927943Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity35_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2929501Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity36_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2931111Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity37_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2932822Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity38_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2934355Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity39_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2935954Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity40_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2937529Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity41_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2939166Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity42_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2940776Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity43_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2942502Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity44_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2944050Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity45_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2945652Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity46_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2947211Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity47_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2948794Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity48_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2950588Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity49_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2952174Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity50_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2953768Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity51_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2955384Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity52_bfloat16_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2956946Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity53_bfloat16_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2958528Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity54_float32_module_type_linear [33mSKIPPED[0m
2026-01-14T08:27:04.2960041Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity55_float32_module_type_embedding [33mSKIPPED[0m
2026-01-14T08:27:04.2961738Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T08:27:04.2963078Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T08:27:04.2964216Z test/quantization/test_qat.py::TestQAT::test_quantize_api_prepare [32mPASSED[0m
2026-01-14T08:27:04.2965514Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls0 [32mPASSED[0m
2026-01-14T08:27:04.2966879Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls1 [32mPASSED[0m
2026-01-14T08:27:04.2968235Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls2 [32mPASSED[0m
2026-01-14T08:27:04.2969209Z test/quantization/test_qat.py::TestQAT::test_replace_linear_8da4w [32mPASSED[0m
2026-01-14T08:27:04.2969951Z test/quantization/test_qat.py::TestQAT::test_replace_linear_int4 [32mPASSED[0m
2026-01-14T08:27:04.2970767Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer [32mPASSED[0m
2026-01-14T08:27:04.2971692Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer_linear_bias [32mPASSED[0m
2026-01-14T08:27:04.2972713Z test/quantization/test_quant_api.py::TestQuantFlow::test_config_deprecation [32mPASSED[0m
2026-01-14T08:27:04.2973654Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_singleline [32mPASSED[0m
2026-01-14T08:27:04.2974727Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_eager_mode_impl [33mSKIPPED[0m
2026-01-14T08:27:04.2975856Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_unified_impl [33mSKIPPED[0m
2026-01-14T08:27:04.2976855Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4_wo_quant_save_load [33mSKIPPED[0m
2026-01-14T08:27:04.2977882Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T08:27:04.2978976Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T08:27:04.2980105Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T08:27:04.2981216Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T08:27:04.2982294Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T08:27:04.2983313Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T08:27:04.8462936Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T08:27:04.8464312Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T08:27:04.8465430Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T08:27:04.8466471Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T08:27:04.8467578Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T08:27:04.8468649Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T08:27:04.8469612Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cuda_serialization [33mSKIPPED[0m
2026-01-14T08:27:04.8470619Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8_wo_quant_save_load [33mSKIPPED[0m
2026-01-14T08:27:04.8471719Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8wo_quantized_model_to_device [33mSKIPPED[0m
2026-01-14T08:27:04.8472723Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_default [33mSKIPPED[0m
2026-01-14T08:27:04.8474161Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_embedding_linear [32mPASSED[0m
2026-01-14T08:27:04.8475174Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_module_name [33mSKIPPED[0m
2026-01-14T08:27:04.8476186Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_basic [33mSKIPPED[0m
2026-01-14T08:27:04.8477200Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_fullmatch [33mSKIPPED[0m
2026-01-14T08:27:04.8478291Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence [33mSKIPPED[0m
2026-01-14T08:27:04.8479356Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence2 [33mSKIPPED[0m
2026-01-14T08:27:04.8480339Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_skip [33mSKIPPED[0m
2026-01-14T08:27:04.8481327Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_model_streaming [33mSKIPPED[0m
2026-01-14T08:27:04.8482338Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type0 [32mPASSED[0m
2026-01-14T08:27:04.8483486Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type1 [32mPASSED[0m
2026-01-14T08:27:04.8484710Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load [33mSKIPPED[0m
2026-01-14T08:27:04.8485792Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load_map_location [33mSKIPPED[0m
2026-01-14T08:27:04.8486918Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config0 [33mSKIPPED[0m
2026-01-14T08:27:04.8488056Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config1 [33mSKIPPED[0m
2026-01-14T08:27:04.8489021Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config2 [33mSKIPPED[0m
2026-01-14T08:27:04.8490037Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config3 [33mSKIPPED[0m
2026-01-14T08:27:04.8491134Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config4 [33mSKIPPED[0m
2026-01-14T08:27:04.8492226Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config5 [33mSKIPPED[0m
2026-01-14T08:27:04.8493255Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config6 [33mSKIPPED[0m
2026-01-14T08:27:04.8494214Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config7 [33mSKIPPED[0m
2026-01-14T08:27:04.8495202Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config8 [33mSKIPPED[0m
2026-01-14T08:27:04.8496124Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config9 [33mSKIPPED[0m
2026-01-14T08:27:04.8497197Z test/quantization/test_quant_api.py::TestFqnToConfig::test_filter_fn_and_fqn_to_config_error [33mSKIPPED[0m
2026-01-14T08:27:04.8498368Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_module_config_and_fqn_config_both_specified [33mSKIPPED[0m
2026-01-14T08:27:04.8499593Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module [33mSKIPPED[0m
2026-01-14T08:27:04.8500770Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_module_swap [33mSKIPPED[0m
2026-01-14T08:27:04.8501921Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_param [33mSKIPPED[0m
2026-01-14T08:27:04.8503056Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_custom [33mSKIPPED[0m
2026-01-14T08:27:04.8504152Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_linear [33mSKIPPED[0m
2026-01-14T08:27:04.8505209Z test/quantization/test_quant_api.py::TestFqnToConfig::test_non_fqn_config_filter_fn_none [33mSKIPPED[0m
2026-01-14T08:27:04.8506295Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_module_over_param_regex [33mSKIPPED[0m
2026-01-14T08:27:04.8507511Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_default [33mSKIPPED[0m
2026-01-14T08:27:04.8508596Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module [33mSKIPPED[0m
2026-01-14T08:27:04.8509723Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module_regex [33mSKIPPED[0m
2026-01-14T08:27:04.8510919Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_default [33mSKIPPED[0m
2026-01-14T08:27:04.8512343Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_module_regex [33mSKIPPED[0m
2026-01-14T08:27:04.8513504Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param [33mSKIPPED[0m
2026-01-14T08:27:04.8514753Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param_regex [33mSKIPPED[0m
2026-01-14T08:27:04.8515903Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_exact [33mSKIPPED[0m
2026-01-14T08:27:04.8516834Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_regex [33mSKIPPED[0m
2026-01-14T08:27:04.8517911Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantized_model_streaming_fqn_config [33mSKIPPED[0m
2026-01-14T08:27:04.8518891Z test/quantization/test_quant_api.py::TestFqnToConfig::test_top_level_param [33mSKIPPED[0m
2026-01-14T08:27:04.8519922Z test/quantization/test_quant_api.py::TestFqnToConfig::test_unsupported_param_config_raises_not_implemented_error [33mSKIPPED[0m
2026-01-14T08:27:04.8521224Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_and_quantize_scale_only_sinq [32mPASSED[0m
2026-01-14T08:27:04.8522468Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym [32mPASSED[0m
2026-01-14T08:27:04.8523600Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym_no_clipping_err [32mPASSED[0m
2026-01-14T08:27:04.8524938Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym [32mPASSED[0m
2026-01-14T08:27:04.8526022Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym_eps [32mPASSED[0m
2026-01-14T08:27:04.8527143Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_sym [32mPASSED[0m
2026-01-14T08:27:04.8528414Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_token_asym [32mPASSED[0m
2026-01-14T08:27:04.8529441Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine [32mPASSED[0m
2026-01-14T08:27:04.8530533Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine_cachemask [32mPASSED[0m
2026-01-14T08:27:04.8531683Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_blockwise_scaling [32mPASSED[0m
2026-01-14T08:27:04.8532883Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_rowwise_scaling_3d_weight_axis_1 [32mPASSED[0m
2026-01-14T08:27:04.8534050Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric [32mPASSED[0m
2026-01-14T08:27:04.8535167Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric_memory [33mSKIPPED[0m
2026-01-14T08:27:04.8536328Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_groupwise_affine_qparams [32mPASSED[0m
2026-01-14T08:27:04.8537630Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_dequantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T08:27:04.8539064Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_quantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T08:27:04.8540334Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_maybe_expand_scale_to_tensor_shape [32mPASSED[0m
2026-01-14T08:27:04.8541463Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max [32mPASSED[0m
2026-01-14T08:27:04.8542863Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_dtype [32mPASSED[0m
2026-01-14T08:29:52.3767347Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_zero_input [32mPASSED[0m
2026-01-14T08:29:52.3769219Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym [32mPASSED[0m
2026-01-14T08:29:52.3770844Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d [32mPASSED[0m
2026-01-14T08:29:52.3772704Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d_multi_dim_reduction [32mPASSED[0m
2026-01-14T08:29:52.3774297Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_group_sym [32mPASSED[0m
2026-01-14T08:29:52.3785237Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_tensor_asym [32mPASSED[0m
2026-01-14T08:29:52.3787005Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_raises [32mPASSED[0m
2026-01-14T08:29:52.3788308Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity [33mSKIPPED[0m
2026-01-14T08:29:52.3789752Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity_scaled [33mSKIPPED[0m
2026-01-14T08:29:52.3791001Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_srelu [33mSKIPPED[0m
2026-01-14T08:29:52.3792223Z test/sparsity/test_activation24.py::test_srelu_fp8_semi_sparse_activation_linear [33mSKIPPED[0m
2026-01-14T08:29:52.3793798Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_eye [33mSKIPPED[0m
2026-01-14T08:29:52.3795079Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_random_tensor [33mSKIPPED[0m
2026-01-14T08:29:52.3796502Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification [33mSKIPPED[0m
2026-01-14T08:29:52.3798173Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification_compile [33mSKIPPED[0m
2026-01-14T08:29:52.3799518Z test/sparsity/test_sparse_api.py::TestSemiStructuredSparse::test_sparse [33mSKIPPED[0m
2026-01-14T08:29:52.3800691Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T08:29:52.3801978Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T08:29:52.3803294Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T08:29:52.3804614Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T08:29:52.3805892Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_quant_semi_sparse_compile_False [33mSKIPPED[0m
2026-01-14T08:29:52.3807203Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1 [33mSKIPPED[0m
2026-01-14T08:29:52.3808551Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024 [33mSKIPPED[0m
2026-01-14T08:29:52.3809978Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1 [33mSKIPPED[0m
2026-01-14T08:29:52.3811473Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1024 [33mSKIPPED[0m
2026-01-14T08:29:52.3812870Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False [33mSKIPPED[0m
2026-01-14T08:29:52.3814179Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_True [33mSKIPPED[0m
2026-01-14T08:29:52.3815259Z test/sparsity/test_supermask.py::TestSupermask::test_from_linear [33mSKIPPED[0m
2026-01-14T08:29:52.3816411Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_2 [33mSKIPPED[0m
2026-01-14T08:29:52.3817728Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_4 [33mSKIPPED[0m
2026-01-14T08:29:52.3819019Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_8 [33mSKIPPED[0m
2026-01-14T08:29:52.3820303Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_2 [33mSKIPPED[0m
2026-01-14T08:29:52.3821593Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_4 [33mSKIPPED[0m
2026-01-14T08:29:52.3822878Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_8 [33mSKIPPED[0m
2026-01-14T08:29:52.3824022Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4 [32mPASSED[0m
2026-01-14T08:29:52.3825105Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T08:29:52.3826111Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:29:52.3827042Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_squash_mask [32mPASSED[0m
2026-01-14T08:29:52.3828083Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T08:29:52.3829309Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured_custom_config [32mPASSED[0m
2026-01-14T08:29:52.3830580Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_False [32mPASSED[0m
2026-01-14T08:29:52.3831878Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_True [32mPASSED[0m
2026-01-14T08:29:52.3833483Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_False [32mPASSED[0m
2026-01-14T08:29:52.3835253Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_True [32mPASSED[0m
2026-01-14T08:29:52.3836717Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3838133Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3839520Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3841120Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3842749Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_Adam4bit [33mSKIPPED[0m
2026-01-14T08:29:52.3844282Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_AdamW4bit [33mSKIPPED[0m
2026-01-14T08:29:52.3845636Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_Adam8bit [33mSKIPPED[0m
2026-01-14T08:29:52.3846979Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_AdamW8bit [33mSKIPPED[0m
2026-01-14T08:29:52.3848388Z test/test_low_bit_optim.py::TestOptim::test_optim_bf16_stochastic_round_correctness_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3850116Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_1 [33mSKIPPED[0m
2026-01-14T08:29:52.3851686Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_2 [33mSKIPPED[0m
2026-01-14T08:29:52.3853161Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_True_grad_accum_1 [33mSKIPPED[0m
2026-01-14T08:29:52.3854316Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_save_load [33mSKIPPED[0m
2026-01-14T08:29:52.3855477Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3856765Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3858054Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3859324Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3860556Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3861807Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3863042Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3864286Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3865521Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3866756Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3868016Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3869268Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3870524Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3871871Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3873103Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3874297Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3875440Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T08:29:52.3876587Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T08:30:01.7406100Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape0_device_cpu [32mPASSED[0m
2026-01-14T08:30:01.7407223Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape1_device_cpu [32mPASSED[0m
2026-01-14T08:30:01.7408106Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape0_device_cpu [32mPASSED[0m
2026-01-14T08:30:01.7408972Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape1_device_cpu [32mPASSED[0m
2026-01-14T08:30:01.7409997Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape0_device_cpu [32mPASSED[0m
2026-01-14T08:30:01.7410851Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape1_device_cpu [32mPASSED[0m
2026-01-14T08:30:01.7411938Z test/test_low_bit_optim.py::TestFSDP2::test_fsdp2 WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work
2026-01-14T08:30:01.7413017Z WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work
2026-01-14T08:30:01.7413599Z dist init r=1, world=2
2026-01-14T08:30:01.7414165Z dist init r=0, world=2
2026-01-14T08:30:01.7414501Z [33mSKIPPED[0m (Need at l...)
2026-01-14T08:30:01.7415302Z test/test_low_bit_optim.py::TestFSDP2::test_uneven_shard WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work
2026-01-14T08:30:01.7416395Z WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work
2026-01-14T08:30:01.7417069Z dist init r=0, world=2
2026-01-14T08:30:01.7417308Z dist init r=1, world=2
2026-01-14T08:30:01.7417575Z [33mSKIPPED[0m (Ne...)
2026-01-14T08:30:01.7418151Z test/test_model_architecture.py::TestModels::test_ln_linear_activation_model_0_cpu [32mPASSED[0m
2026-01-14T08:30:01.7418940Z test/test_model_architecture.py::TestModels::test_toy_linear_model_0_cpu [32mPASSED[0m
2026-01-14T08:30:01.7419773Z test/test_model_architecture.py::TestModels::test_transformer_block_0_cpu [32mPASSED[0m
2026-01-14T08:30:01.7420885Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7422377Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7423784Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7425260Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7426724Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7428143Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7429727Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7431128Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7432621Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7434075Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7435462Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7436962Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7438350Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7439803Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7441273Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7442677Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7444208Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7445608Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7447099Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7448544Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7450112Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7451626Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7453092Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7454541Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7455948Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7457414Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7458863Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7460377Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7461846Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7463232Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7464690Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7466131Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7467535Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7468929Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7470284Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7471743Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7473139Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7474679Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7654393Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7655920Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7657303Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7658761Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7660189Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7661646Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7663095Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7664497Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7665942Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7667340Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7668977Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7670429Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7671832Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7673277Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7674673Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7676164Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7677629Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7679009Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7680472Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7681973Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7683427Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7684889Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7686279Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7687725Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7689123Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7690593Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7692109Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7693523Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7694986Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7696364Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7697917Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7699311Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7700778Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7702227Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7703603Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7704980Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7706346Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7707799Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7709218Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7710600Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7712120Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7713504Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7714944Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7716334Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7717784Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7719223Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7720615Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7722063Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7912246Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7913727Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7915121Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7916787Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7918246Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7919608Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7921068Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7922456Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7923886Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7925284Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7926729Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7928122Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7929453Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7930953Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7932377Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7933792Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7935144Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7936549Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7937941Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7939298Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7940701Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7942023Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7943364Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7944750Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7946149Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7947565Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7948878Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7950420Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7951765Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7953075Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7954504Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7955905Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7957208Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7958623Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7959955Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7961438Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7962764Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7964177Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7965530Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7966844Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7968239Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7969566Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7970945Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7972349Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7973752Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7975083Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7976559Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.7977955Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.7979285Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.7980660Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8170741Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8172275Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8173608Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8174991Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8176298Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8177629Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8179202Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8180521Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8181913Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8183228Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8184630Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8185958Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8187346Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8188653Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8190065Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8191429Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8192736Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8194143Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8195538Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8196908Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8198229Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8199622Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8200988Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8202326Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8203697Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8205024Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8206414Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8207704Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8209171Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8210547Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8211917Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8213328Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8214650Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8216020Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8217334Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8218717Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8220070Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8221384Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8222762Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8224138Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8225534Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8226839Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8228219Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8229598Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8230916Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8232289Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8233598Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8234968Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8236263Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8237626Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8239020Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8514575Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8516105Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8517424Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T08:30:01.8518798Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T08:30:01.8520127Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T08:30:01.8521231Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8522151Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8523124Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8524046Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8524964Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8525937Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8526858Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8528000Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8528934Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8529856Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8530833Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8531750Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8532840Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8533765Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8534690Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8535616Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8536445Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8537299Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8538147Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8538984Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8539866Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8540810Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8541629Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8542537Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8543359Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8544174Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8545071Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8545887Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_2] [33mSKIPPED[0m
2026-01-14T08:30:01.8546711Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_4] [33mSKIPPED[0m
2026-01-14T08:30:01.8547619Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_8] [33mSKIPPED[0m
2026-01-14T08:30:01.8548548Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8550010Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8551104Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8552132Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8553210Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8554212Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8555356Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8556513Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8557651Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8558667Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8559726Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8560810Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8561879Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8562956Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8564031Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8565113Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8566143Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8567280Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8568301Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8569537Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8570562Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8571660Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8572875Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8574018Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8575109Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8576170Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8577259Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8578332Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8579413Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8580442Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8581462Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8582476Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8583503Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8584519Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8842216Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8843424Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8844456Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8845594Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8846624Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8847638Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8848736Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8849904Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8851053Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8852167Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8853304Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8854358Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8855629Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8856663Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8857738Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8858788Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8859823Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8860902Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8861933Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8863029Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8864054Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8865145Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8866167Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8867192Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8868230Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8869267Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8870359Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8871504Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8872633Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8873709Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8874823Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8875880Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8877001Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8878066Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8879179Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8880226Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8881285Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8882414Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8883463Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8884654Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8885733Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8886851Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8887920Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8889035Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8890111Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8891246Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8892405Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8893505Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8894587Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8895663Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8896835Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8897885Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8899082Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8900227Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8901413Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8902479Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8903595Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8904667Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8905794Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8906852Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8907984Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.8909050Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.8910191Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.8911293Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.8912404Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9219739Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9220911Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9221982Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9223115Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9224189Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9225269Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9226339Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9227402Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9228525Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9229596Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9230712Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9231780Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9232903Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9233983Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9235226Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9236295Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9237369Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9238423Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9239485Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9240557Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9241616Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9242549Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9243354Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9244152Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9244984Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9245781Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9246576Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9247426Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9248316Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9249156Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9250120Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9250931Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9251788Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9252698Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9253515Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9254325Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9255162Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9255988Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9256788Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9257608Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9258419Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9259237Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9260051Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9260859Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9261676Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9262579Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9263406Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9264230Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9265043Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9265864Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9266669Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9267492Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9268319Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9269129Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9269952Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9270764Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9271593Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9272411Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9273219Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9274116Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9274930Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9275754Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9276556Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9277378Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9278201Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9279007Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9279819Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9280624Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9281443Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9282266Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9283069Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9283886Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9284701Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9285580Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9286388Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9287210Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9658505Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9659602Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-32] [33mSKIPPED[0m
2026-01-14T08:30:01.9660424Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-64] [33mSKIPPED[0m
2026-01-14T08:30:01.9661263Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-128] [33mSKIPPED[0m
2026-01-14T08:30:01.9662113Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-256] [33mSKIPPED[0m
2026-01-14T08:30:01.9662802Z test/test_ops.py::test_swizzle_mm [33mSKIPPED[0m (ROCm not available)
2026-01-14T08:30:01.9663482Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9664212Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9664969Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9665727Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9666470Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9667218Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9667944Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9668678Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9669407Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9670156Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9671009Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9671747Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9672503Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9673245Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9674009Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9674780Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9675538Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9676303Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9677060Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9677833Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9678606Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9679368Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9680146Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9680914Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9681671Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9682394Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9683140Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9683895Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9684634Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9685438Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9686175Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9686910Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9687655Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9688402Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9689159Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9689907Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9690663Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9691417Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9692292Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9693070Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9693832Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9694605Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9695385Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9696137Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9696994Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9697764Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9698553Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9699329Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9700094Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9700838Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9701582Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9702339Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9703088Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9703851Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9704610Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9705331Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9706073Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9706811Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9707557Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9708309Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9709060Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9709813Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9710563Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9711390Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9712148Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9712922Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9713690Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9714440Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9715328Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9716098Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9716885Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9717674Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9718427Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9719181Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9719922Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9720689Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9721445Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9722196Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9723027Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9723767Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9724532Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:01.9725274Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:01.9726033Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0100585Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0101346Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0102104Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0102871Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0103657Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0104445Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0105208Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0105978Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0106733Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0107515Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0108296Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0109070Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0109851Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0110838Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0111578Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0112322Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0113058Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0113802Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0114533Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0115265Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0115996Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0116835Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0117577Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0118305Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0119049Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0119788Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0120520Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0121305Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0122059Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0122955Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0123723Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0124467Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0125224Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0125973Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0126745Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0127511Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0128268Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0129016Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0129722Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0130466Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0131206Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0132022Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0132773Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0133496Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0134229Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0134952Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0135704Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0136444Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0137239Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0137982Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0138705Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0139456Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0140217Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0140966Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0141726Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0142473Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0143232Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0143994Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0144748Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0145514Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0146262Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0147004Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0147720Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0148521Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0149265Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0150191Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0150937Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0151654Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0152381Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0153115Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0153845Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0154584Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0155319Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0156063Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0156806Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0157554Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0158320Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0159069Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0159827Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0160570Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0161331Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0162096Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0162958Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0163733Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0164488Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0165245Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0165993Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0166731Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0167489Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0168232Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0467527Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0468287Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0469018Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0469762Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0470493Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0471244Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0471988Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0472987Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0473737Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0474487Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0475256Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0476024Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0476773Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0477531Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0478276Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0479044Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0479811Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0480588Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T08:30:02.0481359Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T08:30:02.0482250Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0483269Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0484264Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0485260Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0486253Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0487230Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0488316Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0489325Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0490305Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0491283Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0492337Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0493343Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0494349Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0495342Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0496359Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0497383Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0498370Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0499367Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0500359Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0501470Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0502481Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0503471Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0504483Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0505486Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0506490Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0507480Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0508467Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0509475Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0510458Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0511436Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0512428Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0513422Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0514416Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0515391Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0516432Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0517435Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0518420Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0519410Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0520398Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0521409Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0522408Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0523392Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0524396Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0525407Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0526392Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0527385Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0528375Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0529447Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0530445Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0531418Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0532503Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0533497Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0534494Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0535479Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0536465Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0817812Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0818806Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0819788Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0820775Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0821799Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0822782Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0823806Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0825839Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0826896Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0827907Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0828890Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0829901Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0830905Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0831913Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0832918Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0833910Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0834923Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0835910Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0836907Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0837908Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0838981Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0839981Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0840957Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0841958Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0842967Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0843951Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0844937Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0845931Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0846932Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0847942Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0848928Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0850134Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0851151Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0852214Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0853211Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0854206Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0855304Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0856314Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0857293Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0858297Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0859300Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0860298Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0861320Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0862306Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0863312Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0864292Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0865273Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0866264Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0867255Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0868315Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0869285Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0870272Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0871269Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0872252Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0873247Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0874250Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0875269Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0876280Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0877261Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0878269Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0879284Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0880274Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0881264Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0882252Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0883334Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0884329Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0885292Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0886280Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.0887267Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.0888257Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1164235Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1165234Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1166235Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1167210Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1168192Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1169187Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1170175Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1171299Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1172383Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1173394Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1174407Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1175396Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1176388Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1177390Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1178397Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1179400Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1180387Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1181383Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1182395Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1183379Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1184369Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1185365Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1186435Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1187432Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1188401Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1189395Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1190397Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1201237Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1202277Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1203275Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1204292Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1205281Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1206277Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1207287Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1208291Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1209474Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1210476Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1211471Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1212593Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1213589Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1214587Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1215594Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1216593Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1217600Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1218578Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1219573Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1220582Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1221564Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1222548Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1223530Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1224661Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1225728Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1226709Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1227698Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1228704Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1229686Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1230685Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1231699Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1232700Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1233699Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1234692Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1235683Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1236694Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1237680Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1238725Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1239730Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1240730Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1241726Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1242696Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1243690Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1484120Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1485122Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1486199Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1487180Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1488349Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1489354Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1490323Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1491429Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1492529Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1493804Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1494809Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1495922Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1496974Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1498039Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1499025Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1500037Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1501114Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1502116Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1503169Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1504168Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T08:30:02.1505246Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T08:30:02.1506318Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1507579Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1508711Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1509812Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1510991Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1512094Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1513250Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1514366Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1515541Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1516650Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1517840Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1518977Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1520177Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1521300Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1522479Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1523667Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1524860Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1525988Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1527179Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1528294Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1529494Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1530618Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1531812Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1533022Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1534134Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1535272Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1536467Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1537656Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1538851Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1539973Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1541173Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1542314Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1543491Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1544629Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1545836Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1546961Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1548163Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1549294Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1550722Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1551870Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1553171Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1554322Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1555588Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1785785Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1786947Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1788077Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1789226Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1790372Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1791517Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1792658Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1793798Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1794925Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1796288Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1797434Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1798565Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1799703Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1800823Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1801963Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1803104Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1804239Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1805378Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1806506Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1807643Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1808778Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1809911Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1811122Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1812320Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1813450Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1814586Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1815711Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1816851Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1818000Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1819122Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1820251Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1821382Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1822497Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1823629Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1824816Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1825947Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1827074Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1828197Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1829326Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1830445Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1831576Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1832702Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1833818Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1834941Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1836068Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1837184Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1838307Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1839432Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1840607Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1841735Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1842849Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1843979Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1845099Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1846219Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1847349Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1848463Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1849748Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1850906Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1852103Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T08:30:02.1853349Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T08:30:02.1854484Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2091327Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2092545Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2093679Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2094829Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2095983Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2097134Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2098293Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2099447Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2100596Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2101747Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2102891Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2104051Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2105323Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2106469Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2107625Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2108788Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2109934Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2111093Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2112256Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2113401Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2114549Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2115688Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2116838Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2118095Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2119256Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2120399Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2121557Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2122715Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2123858Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2125011Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2126172Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2127320Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2128471Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2129614Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2130777Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2132014Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2133275Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2134523Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2135687Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2136830Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2137959Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2139059Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2140173Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2141289Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2142387Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2143493Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2144579Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2145683Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2146838Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2147937Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2149055Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2150310Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2151428Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2152556Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2153668Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2154802Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2155924Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2157042Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2158173Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2159305Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2160425Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2392418Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2393644Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2394777Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2395908Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2397023Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2398154Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2399275Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2400394Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2401519Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2402630Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2403761Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2404892Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2406006Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2407205Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2408339Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2409467Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2410606Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2411731Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2412952Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2414114Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2415247Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2416385Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2417522Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2418646Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2419784Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2420921Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2422097Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2423237Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2424365Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2425499Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2426631Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2427754Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2428898Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2430026Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2431160Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2432294Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2433417Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2434552Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2435733Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2436860Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2437994Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2439114Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2440248Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2441387Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2442514Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2443654Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2444792Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2445921Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2447057Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2448182Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2449317Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2450697Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2451817Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2453027Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2454140Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2455272Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2456393Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2457521Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2458645Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2459775Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2460892Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2692178Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2693322Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2694699Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2695859Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2697027Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2698161Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2699350Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2700467Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2701649Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2702784Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2703952Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2705087Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2706197Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2707378Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2708505Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2709686Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2710894Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2712082Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2713215Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2714424Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2715562Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2716755Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2717895Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2719084Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2720227Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2721507Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2722665Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2723909Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2725125Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2726351Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2727520Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2728727Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2729875Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2731086Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2732323Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2733565Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2734708Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2735930Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2737083Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2738220Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2739458Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2740677Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2741895Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2743051Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2744256Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2745413Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2746626Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2747776Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2748996Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2750296Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2751491Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2752683Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2754011Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2755182Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2756395Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2757540Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2758757Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2759899Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2761105Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2762276Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2945558Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2946730Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2948093Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype0-Xq_Wq_dtypes0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2949608Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype1-Xq_Wq_dtypes1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2950988Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype2-Xq_Wq_dtypes2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2952542Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype3-Xq_Wq_dtypes3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2953911Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype4-Xq_Wq_dtypes4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2955335Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype5-Xq_Wq_dtypes5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2956680Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype6-Xq_Wq_dtypes6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2958060Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype7-Xq_Wq_dtypes7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2959496Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype8-Xq_Wq_dtypes8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2960848Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype9-Xq_Wq_dtypes9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2962295Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype10-Xq_Wq_dtypes10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2963753Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype11-Xq_Wq_dtypes11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2965131Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype12-Xq_Wq_dtypes12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2966581Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype13-Xq_Wq_dtypes13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2968056Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype14-Xq_Wq_dtypes14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2969516Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype15-Xq_Wq_dtypes15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2970965Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype16-Xq_Wq_dtypes16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2972451Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype17-Xq_Wq_dtypes17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2973916Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype18-Xq_Wq_dtypes18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2975317Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype19-Xq_Wq_dtypes19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2976774Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype20-Xq_Wq_dtypes20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2978215Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype21-Xq_Wq_dtypes21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2979605Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype22-Xq_Wq_dtypes22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2981029Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype23-Xq_Wq_dtypes23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2982413Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype24-Xq_Wq_dtypes24-1-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2983951Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype25-Xq_Wq_dtypes25-1-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2985388Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype26-Xq_Wq_dtypes26-1-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2986777Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype27-Xq_Wq_dtypes27-1-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2988230Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype28-Xq_Wq_dtypes28-1-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2989605Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype29-Xq_Wq_dtypes29-1-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2991077Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype30-Xq_Wq_dtypes30-1-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2992542Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype31-Xq_Wq_dtypes31-1-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2993921Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype32-Xq_Wq_dtypes32-1-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2995374Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype33-Xq_Wq_dtypes33-1-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2996749Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype34-Xq_Wq_dtypes34-1-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T08:30:02.2998281Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype35-Xq_Wq_dtypes35-1-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T08:30:02.2999739Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype36-Xq_Wq_dtypes36-4-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3001116Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype37-Xq_Wq_dtypes37-4-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3002582Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype38-Xq_Wq_dtypes38-4-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3003974Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype39-Xq_Wq_dtypes39-4-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3005422Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype40-Xq_Wq_dtypes40-4-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3006895Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype41-Xq_Wq_dtypes41-4-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3008291Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype42-Xq_Wq_dtypes42-4-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3009739Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype43-Xq_Wq_dtypes43-4-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3011131Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype44-Xq_Wq_dtypes44-4-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3012601Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype45-Xq_Wq_dtypes45-4-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3014139Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype46-Xq_Wq_dtypes46-4-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3015522Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype47-Xq_Wq_dtypes47-4-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3016972Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype48-Xq_Wq_dtypes48-1-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3196411Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype49-Xq_Wq_dtypes49-1-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3197943Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype50-Xq_Wq_dtypes50-1-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3199339Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype51-Xq_Wq_dtypes51-1-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3200791Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype52-Xq_Wq_dtypes52-1-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3202181Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype53-Xq_Wq_dtypes53-1-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3203604Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype54-Xq_Wq_dtypes54-1-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3205017Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype55-Xq_Wq_dtypes55-1-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3206418Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype56-Xq_Wq_dtypes56-1-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3208039Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype57-Xq_Wq_dtypes57-1-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3209424Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype58-Xq_Wq_dtypes58-1-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3210911Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype59-Xq_Wq_dtypes59-1-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3212526Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype60-Xq_Wq_dtypes60-4-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3213925Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype61-Xq_Wq_dtypes61-4-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3215380Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype62-Xq_Wq_dtypes62-4-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3216756Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype63-Xq_Wq_dtypes63-4-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3218203Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype64-Xq_Wq_dtypes64-4-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3219632Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype65-Xq_Wq_dtypes65-4-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3221008Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype66-Xq_Wq_dtypes66-4-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3222455Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype67-Xq_Wq_dtypes67-4-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3223920Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype68-Xq_Wq_dtypes68-4-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3225363Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype69-Xq_Wq_dtypes69-4-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3226835Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype70-Xq_Wq_dtypes70-4-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3228216Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype71-Xq_Wq_dtypes71-4-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3229737Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype72-Xq_Wq_dtypes72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3231139Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype73-Xq_Wq_dtypes73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3232510Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype74-Xq_Wq_dtypes74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3233953Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype75-Xq_Wq_dtypes75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3235336Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype76-Xq_Wq_dtypes76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3236764Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype77-Xq_Wq_dtypes77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3238265Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype78-Xq_Wq_dtypes78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3239669Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype79-Xq_Wq_dtypes79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3241155Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype80-Xq_Wq_dtypes80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3242552Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype81-Xq_Wq_dtypes81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3243990Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype82-Xq_Wq_dtypes82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3245407Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype83-Xq_Wq_dtypes83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3246820Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype84-Xq_Wq_dtypes84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3248293Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype85-Xq_Wq_dtypes85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3249900Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype86-Xq_Wq_dtypes86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3251467Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype87-Xq_Wq_dtypes87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3252993Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype88-Xq_Wq_dtypes88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3254508Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype89-Xq_Wq_dtypes89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3255964Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype90-Xq_Wq_dtypes90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3257341Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype91-Xq_Wq_dtypes91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3258815Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype92-Xq_Wq_dtypes92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3260253Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype93-Xq_Wq_dtypes93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3261655Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype94-Xq_Wq_dtypes94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3263116Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype95-Xq_Wq_dtypes95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3264493Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype96-Xq_Wq_dtypes96-1-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3265954Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype97-Xq_Wq_dtypes97-1-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3267407Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype98-Xq_Wq_dtypes98-1-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3442794Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype99-Xq_Wq_dtypes99-1-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3444434Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype100-Xq_Wq_dtypes100-1-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3445860Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype101-Xq_Wq_dtypes101-1-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3447324Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype102-Xq_Wq_dtypes102-1-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3448739Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype103-Xq_Wq_dtypes103-1-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3450379Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype104-Xq_Wq_dtypes104-1-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3451995Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype105-Xq_Wq_dtypes105-1-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3453427Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype106-Xq_Wq_dtypes106-1-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3454842Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype107-Xq_Wq_dtypes107-1-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3456388Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype108-Xq_Wq_dtypes108-4-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3457816Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype109-Xq_Wq_dtypes109-4-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3459337Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype110-Xq_Wq_dtypes110-4-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3460880Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype111-Xq_Wq_dtypes111-4-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3462425Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype112-Xq_Wq_dtypes112-4-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3463946Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype113-Xq_Wq_dtypes113-4-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3465363Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype114-Xq_Wq_dtypes114-4-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3466919Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype115-Xq_Wq_dtypes115-4-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3468374Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype116-Xq_Wq_dtypes116-4-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3469836Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype117-Xq_Wq_dtypes117-4-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3471376Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype118-Xq_Wq_dtypes118-4-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3472874Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype119-Xq_Wq_dtypes119-4-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3474367Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype120-Xq_Wq_dtypes120-1-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3475962Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype121-Xq_Wq_dtypes121-1-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3477372Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype122-Xq_Wq_dtypes122-1-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3478865Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype123-Xq_Wq_dtypes123-1-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3480275Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype124-Xq_Wq_dtypes124-1-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3481750Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype125-Xq_Wq_dtypes125-1-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3483297Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype126-Xq_Wq_dtypes126-1-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3484719Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype127-Xq_Wq_dtypes127-1-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3486266Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype128-Xq_Wq_dtypes128-1-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3487687Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype129-Xq_Wq_dtypes129-1-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3489224Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype130-Xq_Wq_dtypes130-1-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3490790Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype131-Xq_Wq_dtypes131-1-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3492374Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype132-Xq_Wq_dtypes132-4-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3493913Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype133-Xq_Wq_dtypes133-4-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3495472Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype134-Xq_Wq_dtypes134-4-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3496899Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype135-Xq_Wq_dtypes135-4-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3498383Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype136-Xq_Wq_dtypes136-4-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3499810Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype137-Xq_Wq_dtypes137-4-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3501362Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype138-Xq_Wq_dtypes138-4-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3502915Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype139-Xq_Wq_dtypes139-4-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3504339Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype140-Xq_Wq_dtypes140-4-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3505828Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype141-Xq_Wq_dtypes141-4-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3507386Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype142-Xq_Wq_dtypes142-4-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3508812Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype143-Xq_Wq_dtypes143-4-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3510209Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype144-Xq_Wq_dtypes144-1-size_mnk144-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3511747Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype145-Xq_Wq_dtypes145-1-size_mnk145-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3513164Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype146-Xq_Wq_dtypes146-1-size_mnk146-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3514706Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype147-Xq_Wq_dtypes147-1-size_mnk147-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3809955Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype148-Xq_Wq_dtypes148-1-size_mnk148-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3811397Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype149-Xq_Wq_dtypes149-1-size_mnk149-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3812943Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype150-Xq_Wq_dtypes150-1-size_mnk150-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3814367Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype151-Xq_Wq_dtypes151-1-size_mnk151-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3815777Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype152-Xq_Wq_dtypes152-1-size_mnk152-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3817336Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype153-Xq_Wq_dtypes153-1-size_mnk153-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3818765Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype154-Xq_Wq_dtypes154-1-size_mnk154-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3820171Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype155-Xq_Wq_dtypes155-1-size_mnk155-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3821592Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype156-Xq_Wq_dtypes156-4-size_mnk156-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3823405Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype157-Xq_Wq_dtypes157-4-size_mnk157-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3824974Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype158-Xq_Wq_dtypes158-4-size_mnk158-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3827253Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype159-Xq_Wq_dtypes159-4-size_mnk159-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3829011Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype160-Xq_Wq_dtypes160-4-size_mnk160-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3830437Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype161-Xq_Wq_dtypes161-4-size_mnk161-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3831858Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype162-Xq_Wq_dtypes162-4-size_mnk162-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3833443Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype163-Xq_Wq_dtypes163-4-size_mnk163-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3834850Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype164-Xq_Wq_dtypes164-4-size_mnk164-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3836275Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype165-Xq_Wq_dtypes165-4-size_mnk165-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3837695Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype166-Xq_Wq_dtypes166-4-size_mnk166-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3839106Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype167-Xq_Wq_dtypes167-4-size_mnk167-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3840519Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype168-Xq_Wq_dtypes168-1-size_mnk168-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3841935Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype169-Xq_Wq_dtypes169-1-size_mnk169-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3843334Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype170-Xq_Wq_dtypes170-1-size_mnk170-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3844746Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype171-Xq_Wq_dtypes171-1-size_mnk171-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3846154Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype172-Xq_Wq_dtypes172-1-size_mnk172-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3847553Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype173-Xq_Wq_dtypes173-1-size_mnk173-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3849026Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype174-Xq_Wq_dtypes174-1-size_mnk174-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3850610Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype175-Xq_Wq_dtypes175-1-size_mnk175-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3852116Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype176-Xq_Wq_dtypes176-1-size_mnk176-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3853535Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype177-Xq_Wq_dtypes177-1-size_mnk177-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3854941Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype178-Xq_Wq_dtypes178-1-size_mnk178-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3856359Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype179-Xq_Wq_dtypes179-1-size_mnk179-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3857780Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype180-Xq_Wq_dtypes180-4-size_mnk180-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3859184Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype181-Xq_Wq_dtypes181-4-size_mnk181-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3860594Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype182-Xq_Wq_dtypes182-4-size_mnk182-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3862003Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype183-Xq_Wq_dtypes183-4-size_mnk183-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3863515Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype184-Xq_Wq_dtypes184-4-size_mnk184-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3864937Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype185-Xq_Wq_dtypes185-4-size_mnk185-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3866347Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype186-Xq_Wq_dtypes186-4-size_mnk186-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3867750Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype187-Xq_Wq_dtypes187-4-size_mnk187-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3869179Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype188-Xq_Wq_dtypes188-4-size_mnk188-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3870598Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype189-Xq_Wq_dtypes189-4-size_mnk189-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3872004Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype190-Xq_Wq_dtypes190-4-size_mnk190-False] [33mSKIPPED[0m
2026-01-14T08:30:02.3873425Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype191-Xq_Wq_dtypes191-4-size_mnk191-True] [33mSKIPPED[0m
2026-01-14T08:30:02.3874442Z test/test_utils.py::TestTorchVersion::test_torch_version_at_least [32mPASSED[0m
2026-01-14T08:30:02.3875147Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls [33mSKIPPED[0m
2026-01-14T08:30:02.3875921Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_attr [33mSKIPPED[0m
2026-01-14T08:30:02.3876759Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_data [33mSKIPPED[0m
2026-01-14T08:30:02.3877642Z test/test_utils.py::TestTorchAOBaseTensor::test_implements_and_torch_function_together [32mPASSED[0m
2026-01-14T08:30:02.3878431Z test/test_utils.py::TestTorchAOBaseTensor::test_print_arg_types [32mPASSED[0m
2026-01-14T08:30:02.3878888Z 
2026-01-14T08:30:02.3879156Z [33m=============================== warnings summary ===============================[0m
2026-01-14T08:30:02.3879751Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1
2026-01-14T08:30:02.3881823Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1: DeprecationWarning: Importing from torchao.dtypes.uintx.dyn_int8_act_int4_wei_cpu_layout is deprecated. Please use 'from torchao.prototype.dtypes import Int8DynamicActInt4WeightCPULayout' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T08:30:02.3883792Z     from .dyn_int8_act_int4_wei_cpu_layout import (
2026-01-14T08:30:02.3884044Z 
2026-01-14T08:30:02.3884342Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22
2026-01-14T08:30:02.3886259Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22: DeprecationWarning: Importing from torchao.dtypes.uintx.uintx_layout is deprecated. Please use 'from torchao.prototype.dtypes import UintxLayout, UintxTensor' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T08:30:02.3888118Z     from .uintx_layout import (
2026-01-14T08:30:02.3888301Z 
2026-01-14T08:30:02.3888575Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23
2026-01-14T08:30:02.3890637Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23: DeprecationWarning: Importing BlockSparseLayout from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import BlockSparseLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T08:30:02.3892619Z     from .uintx.block_sparse_layout import BlockSparseLayout
2026-01-14T08:30:02.3892906Z 
2026-01-14T08:30:02.3893181Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24
2026-01-14T08:30:02.3895033Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24: DeprecationWarning: Importing from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import CutlassInt4PackedLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T08:30:02.3896836Z     from .uintx.cutlass_int4_packed_layout import CutlassInt4PackedLayout
2026-01-14T08:30:02.3897176Z 
2026-01-14T08:30:02.3897531Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539
2026-01-14T08:30:02.3898334Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539
2026-01-14T08:30:02.3899049Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config5]
2026-01-14T08:30:02.3899643Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config13]
2026-01-14T08:30:02.3900980Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539: UserWarning: `UIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T08:30:02.3902172Z     warnings.warn(
2026-01-14T08:30:02.3902306Z 
2026-01-14T08:30:02.3902646Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T08:30:02.3903450Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T08:30:02.3904145Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7]
2026-01-14T08:30:02.3905610Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209: UserWarning: `Int4DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T08:30:02.3906879Z     warnings.warn(
2026-01-14T08:30:02.3907016Z 
2026-01-14T08:30:02.3907409Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: 3 warnings
2026-01-14T08:30:02.3908029Z test/core/test_config.py: 2 warnings
2026-01-14T08:30:02.3908366Z test/dtypes/test_affine_quantized.py: 1 warning
2026-01-14T08:30:02.3908707Z test/quantization/test_qat.py: 5 warnings
2026-01-14T08:30:02.3909058Z test/quantization/test_quant_api.py: 2 warnings
2026-01-14T08:30:02.3910348Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: UserWarning: `Int8DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T08:30:02.3911627Z     warnings.warn(
2026-01-14T08:30:02.3911764Z 
2026-01-14T08:30:02.3912121Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T08:30:02.3912916Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T08:30:02.3913613Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14]
2026-01-14T08:30:02.3914975Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272: UserWarning: `GemliteUIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T08:30:02.3916205Z     warnings.warn(
2026-01-14T08:30:02.3916339Z 
2026-01-14T08:30:02.3916752Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: 1 warning
2026-01-14T08:30:02.3917319Z test/core/test_config.py: 1 warning
2026-01-14T08:30:02.3917630Z test/prototype/test_parq.py: 25 warnings
2026-01-14T08:30:02.3918877Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: UserWarning: Config Deprecation: _default is deprecated and will no longer be supported in a future release. Please see https://github.com/pytorch/ao/issues/3229 for more details.
2026-01-14T08:30:02.3920111Z     warnings.warn(
2026-01-14T08:30:02.3920245Z 
2026-01-14T08:30:02.3920594Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360
2026-01-14T08:30:02.3922365Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360: UserWarning: `Float8StaticActivationFloat8WeightConfig` version 1 will be deleted in a future release of torchao. Please migrate to version 2 by setting version=2. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T08:30:02.3923883Z     warnings.warn(
2026-01-14T08:30:02.3924015Z 
2026-01-14T08:30:02.3924161Z test/dtypes/test_affine_quantized.py: 1 warning
2026-01-14T08:30:02.3924525Z test/integration/test_integration.py: 15 warnings
2026-01-14T08:30:02.3925965Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:30:02.3927333Z     warnings.warn(
2026-01-14T08:30:02.3927479Z 
2026-01-14T08:30:02.3927607Z test/dtypes/test_affine_quantized.py: 1 warning
2026-01-14T08:30:02.3927982Z test/integration/test_integration.py: 5 warnings
2026-01-14T08:30:02.3928347Z test/quantization/test_quant_api.py: 12 warnings
2026-01-14T08:30:02.3929818Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:827: UserWarning: Config Deprecation: version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T08:30:02.3931201Z     warnings.warn(
2026-01-14T08:30:02.3931345Z 
2026-01-14T08:30:02.3931473Z test/dtypes/test_affine_quantized.py: 1 warning
2026-01-14T08:30:02.3931940Z test/integration/test_integration.py: 31 warnings
2026-01-14T08:30:02.3932316Z test/quantization/test_quant_api.py: 108 warnings
2026-01-14T08:30:02.3934032Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/int4_cpu_layout.py:82: UserWarning: Models quantized with version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please upgrade torchao and quantize again, or download a newer torchao checkpoint, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T08:30:02.3935691Z     warnings.warn(
2026-01-14T08:30:02.3935840Z 
2026-01-14T08:30:02.3936026Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16
2026-01-14T08:30:02.3936506Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16
2026-01-14T08:30:02.3936963Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32
2026-01-14T08:30:02.3938399Z   /pytorch/ao/test/dtypes/test_nf4.py:224: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T08:30:02.3939903Z     torch.testing.assert_allclose(input_tensor, nf4_to_dtype, atol=0.13, rtol=0.13)
2026-01-14T08:30:02.3940275Z 
2026-01-14T08:30:02.3940493Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu
2026-01-14T08:30:02.3941040Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu
2026-01-14T08:30:02.3942578Z   /pytorch/ao/test/kernel/test_autotuner.py:96: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T08:30:02.3943998Z     torch.testing.assert_allclose(out32_1, out32_2)
2026-01-14T08:30:02.3944243Z 
2026-01-14T08:30:02.3944568Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook
2026-01-14T08:30:02.3945966Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py:903: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1531.)
2026-01-14T08:30:02.3947163Z     return callable(*args, **kwargs)
2026-01-14T08:30:02.3947356Z 
2026-01-14T08:30:02.3947604Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace
2026-01-14T08:30:02.3949345Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/sparsifier/utils.py:134: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
2026-01-14T08:30:02.3951119Z     assert self.mask.shape == x.shape
2026-01-14T08:30:02.3951320Z 
2026-01-14T08:30:02.3951556Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler
2026-01-14T08:30:02.3952078Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step
2026-01-14T08:30:02.3953453Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/scheduler/base_scheduler.py:133: UserWarning: Detected call of `scheduler.step()` before `sparsifier.step()`. You have to make sure you run the sparsifier.step() BEFORE any calls to the scheduler.step().
2026-01-14T08:30:02.3954711Z     warnings.warn(
2026-01-14T08:30:02.3954860Z 
2026-01-14T08:30:02.3955124Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu
2026-01-14T08:30:02.3956680Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:42: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T08:30:02.3958085Z     m, guards = torchdynamo.export(  # noqa: F841©
2026-01-14T08:30:02.3958343Z 
2026-01-14T08:30:02.3958588Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu
2026-01-14T08:30:02.3960027Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:86: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T08:30:02.3961346Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T08:30:02.3961593Z 
2026-01-14T08:30:02.3961921Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict
2026-01-14T08:30:02.3963440Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:118: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T08:30:02.3964767Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T08:30:02.3965003Z 
2026-01-14T08:30:02.3965188Z test/quantization/pt2e/test_quantize_pt2e.py: 18 warnings
2026-01-14T08:30:02.3965642Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 72 warnings
2026-01-14T08:30:02.3966110Z test/quantization/pt2e/test_representation.py: 8 warnings
2026-01-14T08:30:02.3966997Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/testing/pt2e/_xnnpack_quantizer.py:289: UserWarning: XNNPACKQuantizer is deprecated!
2026-01-14T08:30:02.3967817Z     warnings.warn(f"{self.__class__.__name__} is deprecated!")
2026-01-14T08:30:02.3968099Z 
2026-01-14T08:30:02.3968436Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_all_ops_before_quantize
2026-01-14T08:30:02.3969233Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe2
2026-01-14T08:30:02.3971112Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/export/_unlift.py:81: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer
2026-01-14T08:30:02.3972831Z     getattr_node = gm.graph.get_attr(lifted_node)
2026-01-14T08:30:02.3973074Z 
2026-01-14T08:30:02.3973399Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_all_ops_before_quantize
2026-01-14T08:30:02.3974698Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/graph.py:1772: UserWarning: Node weight target weight weight of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target
2026-01-14T08:30:02.3975754Z     warnings.warn(
2026-01-14T08:30:02.3975890Z 
2026-01-14T08:30:02.3976172Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported
2026-01-14T08:30:02.3977624Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:910: UserWarning: Was not able to add assertion to guarantee correct input x to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.
2026-01-14T08:30:02.3978858Z     warnings.warn(
2026-01-14T08:30:02.3979007Z 
2026-01-14T08:30:02.3979260Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T08:30:02.3980008Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node
2026-01-14T08:30:02.3980905Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node
2026-01-14T08:30:02.3982073Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/utils.py:145: UserWarning: must run observer before calling calculate_qparams. Returning default values.
2026-01-14T08:30:02.3982942Z     warnings.warn(
2026-01-14T08:30:02.3983090Z 
2026-01-14T08:30:02.3983342Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T08:30:02.3984540Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:1360: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point 
2026-01-14T08:30:02.3985561Z     warnings.warn(
2026-01-14T08:30:02.3985710Z 
2026-01-14T08:30:02.3986112Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T08:30:02.3987074Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T08:30:02.3988136Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype
2026-01-14T08:30:02.3989085Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T08:30:02.3990015Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T08:30:02.3990974Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype
2026-01-14T08:30:02.3991859Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec
2026-01-14T08:30:02.3993315Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:263: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
2026-01-14T08:30:02.3994463Z     warnings.warn(
2026-01-14T08:30:02.3994595Z 
2026-01-14T08:30:02.3994978Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe
2026-01-14T08:30:02.3999913Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:1325: UserWarning: The input of maxpool2d is not quantized, skip annotate maxpool2d with config QuantizationConfig(input_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), output_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), weight=QuantizationSpec(dtype=torch.int8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.PerChannelMinMaxObserver'>, eps=0.000244140625){}, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, ch_axis=0, is_dynamic=False), bias=None, is_qat=False).
2026-01-14T08:30:02.4004747Z     warnings.warn(
2026-01-14T08:30:02.4004880Z 
2026-01-14T08:30:02.4005239Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe2
2026-01-14T08:30:02.4006597Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/graph.py:1772: UserWarning: Node cls_token target cls_token cls_token of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target
2026-01-14T08:30:02.4007676Z     warnings.warn(
2026-01-14T08:30:02.4007818Z 
2026-01-14T08:30:02.4008379Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T08:30:02.4009737Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:484: UserWarning: Mixed dynamic and static quantization config is not supported.
2026-01-14T08:30:02.4010659Z     warnings.warn(
2026-01-14T08:30:02.4010800Z 
2026-01-14T08:30:19.7402316Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T08:30:19.7405337Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:383: UserWarning: Skip the quantization config for <class 'torch.nn.modules.linear.Linear'>.
2026-01-14T08:30:19.7407441Z     warnings.warn(
2026-01-14T08:30:19.7407718Z 
2026-01-14T08:30:19.7408169Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T08:30:19.7410289Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'IntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T08:30:19.7412225Z   
2026-01-14T08:30:19.7412751Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T08:30:19.7413550Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T08:30:19.7414145Z       # train (not shown)
2026-01-14T08:30:19.7414625Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T08:30:19.7415201Z   
2026-01-14T08:30:19.7415717Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T08:30:19.7416370Z   
2026-01-14T08:30:19.7417334Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T08:30:19.7418394Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T08:30:19.7419162Z       qat_config = QATConfig(
2026-01-14T08:30:19.7419639Z           activation_config=activation_config,
2026-01-14T08:30:19.7420283Z           weight_config=weight_config,
2026-01-14T08:30:19.7420834Z           step="prepare",
2026-01-14T08:30:19.7421290Z       )
2026-01-14T08:30:19.7421669Z       quantize_(model, qat_config)
2026-01-14T08:30:19.7422229Z   
2026-01-14T08:30:19.7422779Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T08:30:19.7423525Z           
2026-01-14T08:30:19.7423893Z     warnings.warn(
2026-01-14T08:30:19.7424145Z 
2026-01-14T08:30:19.7424594Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T08:30:19.7427120Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'FromIntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T08:30:19.7429291Z   
2026-01-14T08:30:19.7429924Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T08:30:19.7430939Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T08:30:19.7431653Z       # train (not shown)
2026-01-14T08:30:19.7432226Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T08:30:19.7432867Z   
2026-01-14T08:30:19.7433441Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T08:30:19.7434171Z   
2026-01-14T08:30:19.7434871Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T08:30:19.7435965Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T08:30:19.7436680Z       qat_config = QATConfig(
2026-01-14T08:30:19.7437199Z           activation_config=activation_config,
2026-01-14T08:30:19.7437783Z           weight_config=weight_config,
2026-01-14T08:30:19.7438301Z           step="prepare",
2026-01-14T08:30:19.7438704Z       )
2026-01-14T08:30:19.7439286Z       quantize_(model, qat_config)
2026-01-14T08:30:19.7439723Z   
2026-01-14T08:30:19.7440276Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T08:30:19.7440991Z           
2026-01-14T08:30:19.7441318Z     warnings.warn(
2026-01-14T08:30:19.7441561Z 
2026-01-14T08:30:19.7441977Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4
2026-01-14T08:30:19.7443782Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/wanda.py:46: UserWarning: WandaSparsifier got semi_structured_bock_size=4, sparsity_level fixed to 50% (2:4) sparsity
2026-01-14T08:30:19.7445287Z     warnings.warn(
2026-01-14T08:30:19.7445488Z 
2026-01-14T08:30:19.7445897Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-01-14T08:30:19.7447675Z [33m========= [32m1001 passed[0m, [33m[1m4875 skipped[0m, [33m[1m361 warnings[0m[33m in 998.59s (0:16:38)[0m[33m =========[0m
2026-01-14T08:30:19.7523189Z ##[group]Run pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1
2026-01-14T08:30:19.7523693Z with:
2026-01-14T08:30:19.7523987Z   path: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:19.7524382Z   fail-on-empty: false
2026-01-14T08:30:19.7524609Z env:
2026-01-14T08:30:19.7524848Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:19.7525172Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:19.7525429Z   PR_NUMBER: 3500
2026-01-14T08:30:19.7527281Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:19.7529515Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:19.7530092Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:19.7530649Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:19.7531035Z ##[endgroup]
2026-01-14T08:30:19.8079594Z Prepare all required actions
2026-01-14T08:30:19.8123209Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T08:30:19.8123575Z with:
2026-01-14T08:30:19.8123847Z   directory: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T08:30:19.8124323Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T08:30:19.8124738Z env:
2026-01-14T08:30:19.8124963Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:19.8125296Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:19.8125535Z   PR_NUMBER: 3500
2026-01-14T08:30:19.8127424Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:19.8129456Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:19.8130028Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:19.8130584Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:19.8130959Z ##[endgroup]
2026-01-14T08:30:19.8157865Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T08:30:19.8158590Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T08:30:19.8167806Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:30:19.8168165Z env:
2026-01-14T08:30:19.8168408Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:19.8168730Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:19.8168984Z   PR_NUMBER: 3500
2026-01-14T08:30:19.8170823Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:19.8172978Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:19.8173570Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:19.8174120Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:19.8174639Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T08:30:19.8175119Z   DIRECTORY: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T08:30:19.8175473Z ##[endgroup]
2026-01-14T08:30:19.8354823Z Unable to find image '308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest' locally
2026-01-14T08:30:20.0481778Z latest: Pulling from tool/alpine
2026-01-14T08:30:20.0482125Z 540db60ca938: Pulling fs layer
2026-01-14T08:30:20.1624688Z 540db60ca938: Download complete
2026-01-14T08:30:20.2422470Z 540db60ca938: Pull complete
2026-01-14T08:30:20.2528293Z Digest: sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T08:30:20.2569366Z Status: Downloaded newer image for 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T08:30:21.4865381Z Prepare all required actions
2026-01-14T08:30:21.4897201Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T08:30:21.4897568Z with:
2026-01-14T08:30:21.4897823Z   directory: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T08:30:21.4898309Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T08:30:21.4898713Z env:
2026-01-14T08:30:21.4898950Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:21.4899267Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:21.4899519Z   PR_NUMBER: 3500
2026-01-14T08:30:21.4901407Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:21.4903425Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:21.4904015Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:21.4904565Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:21.4904935Z ##[endgroup]
2026-01-14T08:30:21.4930329Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T08:30:21.4931113Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T08:30:21.4940329Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:30:21.4940688Z env:
2026-01-14T08:30:21.4940936Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:21.4941259Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:21.4941513Z   PR_NUMBER: 3500
2026-01-14T08:30:21.4943355Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:21.4945376Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:21.4945963Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:21.4946514Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:21.4947016Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T08:30:21.4947503Z   DIRECTORY: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T08:30:21.4947832Z ##[endgroup]
2026-01-14T08:30:22.5507724Z ##[group]Run # Only do these steps if we actually want to upload an artifact
2026-01-14T08:30:22.5508326Z [36;1m# Only do these steps if we actually want to upload an artifact[0m
2026-01-14T08:30:22.5508806Z [36;1mif [[ -n "${UPLOAD_ARTIFACT_NAME}" ]]; then[0m
2026-01-14T08:30:22.5509347Z [36;1m  # If the default execution path is followed then we should get a wheel in the dist/ folder[0m
2026-01-14T08:30:22.5509982Z [36;1m  # attempt to just grab whatever is in there and scoop it all up[0m
2026-01-14T08:30:22.5510489Z [36;1m  if find "dist/" -name "*.whl" >/dev/null 2>/dev/null; then[0m
2026-01-14T08:30:22.5510913Z [36;1m    mv -v dist/*.whl "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T08:30:22.5511251Z [36;1m  fi[0m
2026-01-14T08:30:22.5511512Z [36;1m  if [[ -d "artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T08:30:22.5511971Z [36;1m    mv -v artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T08:30:22.5512360Z [36;1m  fi[0m
2026-01-14T08:30:22.5512714Z [36;1m  if [[ -d "${RUNNER_TEMP}/artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T08:30:22.5513251Z [36;1m    mv -v "${RUNNER_TEMP}"/artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T08:30:22.5514410Z [36;1m  fi[0m
2026-01-14T08:30:22.5514608Z [36;1mfi[0m
2026-01-14T08:30:22.5514814Z [36;1m[0m
2026-01-14T08:30:22.5515029Z [36;1mupload_docs=0[0m
2026-01-14T08:30:22.5515423Z [36;1m# Check if there are files in the documentation folder to upload, note that[0m
2026-01-14T08:30:22.5515901Z [36;1m# empty folders do not count[0m
2026-01-14T08:30:22.5516345Z [36;1mif find "${RUNNER_DOCS_DIR}" -mindepth 1 -maxdepth 1 -type f | read -r; then[0m
2026-01-14T08:30:22.5516966Z [36;1m  # TODO: Add a check here to test if on ec2 because if we're not on ec2 then this[0m
2026-01-14T08:30:22.5517500Z [36;1m  # upload will probably not work correctly[0m
2026-01-14T08:30:22.5517838Z [36;1m  upload_docs=1[0m
2026-01-14T08:30:22.5518090Z [36;1mfi[0m
2026-01-14T08:30:22.5518407Z [36;1mecho "upload-docs=${upload_docs}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:30:22.5525470Z shell: /usr/bin/bash -e {0}
2026-01-14T08:30:22.5525740Z env:
2026-01-14T08:30:22.5525990Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:22.5526336Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:22.5526582Z   PR_NUMBER: 3500
2026-01-14T08:30:22.5528421Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:22.5530457Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:22.5531034Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:22.5531598Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:22.5532095Z   UPLOAD_ARTIFACT_NAME: 
2026-01-14T08:30:22.5532363Z ##[endgroup]
2026-01-14T08:30:22.5620721Z Prepare all required actions
2026-01-14T08:30:22.5663534Z ##[group]Run ./test-infra/.github/actions/teardown-linux
2026-01-14T08:30:22.5663899Z with:
2026-01-14T08:30:22.5664081Z env:
2026-01-14T08:30:22.5664328Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:22.5664670Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:22.5664912Z   PR_NUMBER: 3500
2026-01-14T08:30:22.5666740Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:22.5668767Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:22.5669386Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:22.5669929Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:22.5670314Z ##[endgroup]
2026-01-14T08:30:22.5723334Z ##[group]Run set -eou pipefail
2026-01-14T08:30:22.5723631Z [36;1mset -eou pipefail[0m
2026-01-14T08:30:22.5723890Z [36;1m[0m
2026-01-14T08:30:22.5724240Z [36;1mecho "Holding runner for 2 hours until all ssh sessions have logged out"[0m
2026-01-14T08:30:22.5724708Z [36;1mfor _ in $(seq 1440); do[0m
2026-01-14T08:30:22.5725025Z [36;1m    # Break if no ssh session exists anymore[0m
2026-01-14T08:30:22.5725376Z [36;1m    if [ "$(who)" = "" ]; then[0m
2026-01-14T08:30:22.5725664Z [36;1m      break[0m
2026-01-14T08:30:22.5725875Z [36;1m    fi[0m
2026-01-14T08:30:22.5726092Z [36;1m    echo "."[0m
2026-01-14T08:30:22.5726314Z [36;1m    sleep 5[0m
2026-01-14T08:30:22.5726541Z [36;1mdone[0m
2026-01-14T08:30:22.5732077Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:30:22.5732593Z env:
2026-01-14T08:30:22.5732827Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:22.5733158Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:22.5733399Z   PR_NUMBER: 3500
2026-01-14T08:30:22.5735226Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:22.5737250Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:22.5737838Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:22.5738382Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:22.5738778Z ##[endgroup]
2026-01-14T08:30:22.5761309Z Holding runner for 2 hours until all ssh sessions have logged out
2026-01-14T08:30:22.5861346Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T08:30:22.5861907Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T08:30:22.5862326Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T08:30:22.5862655Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T08:30:22.5862984Z [36;1m# Prune all of the docker images[0m
2026-01-14T08:30:22.5863304Z [36;1mdocker system prune -af[0m
2026-01-14T08:30:22.5868434Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:30:22.5868805Z env:
2026-01-14T08:30:22.5869037Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:22.5869371Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:22.5869612Z   PR_NUMBER: 3500
2026-01-14T08:30:22.5871602Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:22.5873655Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:22.5874240Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:22.5874783Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:22.5875174Z ##[endgroup]
2026-01-14T08:30:23.7633481Z bb906dca78c7
2026-01-14T08:30:25.7193365Z Deleted Containers:
2026-01-14T08:30:25.7193806Z bb906dca78c72976258a0b88307c77037106f7dc3b285e5af7aeed400cdfd2bb
2026-01-14T08:30:25.7194128Z 
2026-01-14T08:30:28.1599614Z Deleted Images:
2026-01-14T08:30:28.1599948Z untagged: pytorch/almalinux-builder:cpu
2026-01-14T08:30:28.1600662Z untagged: pytorch/almalinux-builder@sha256:66286600d3e57d1bc722d6fe6e53c8526ec521021cec2eaad02c70f350ba2d23
2026-01-14T08:30:28.1601531Z deleted: sha256:807149a03628d21a8b2f9489fce191225b934d445ae5087ab0b57f3f643d0654
2026-01-14T08:30:28.1602166Z deleted: sha256:fac9de54737e99d26cdee91c3d3cdecda578bedca9f55045dc3fa99e80b55685
2026-01-14T08:30:28.1602803Z deleted: sha256:e8fdabce7575f56ed2771a7fc9b4ed44839b7a44d516c88e78f1ddef1bc2e7fa
2026-01-14T08:30:28.1603431Z deleted: sha256:cd3c44305d64c95a54d5e1fca3493d30a1c7c2074e296d42f178dac34565b3e1
2026-01-14T08:30:28.1604044Z deleted: sha256:815d20fca516e3d914e8cb86f0ed0758a55059834b1edc5bcc083da8de5156f1
2026-01-14T08:30:28.1604663Z deleted: sha256:a8bed296e7797b30500931671710638e489ee7667ec467e98e70eff58d3656a9
2026-01-14T08:30:28.1605276Z deleted: sha256:e7a4f94065a79764d6377ade5e55840dda2ae06d8ada5327aca63547c04bd1aa
2026-01-14T08:30:28.1605894Z deleted: sha256:98461c2ab26e0f98e6a7a57bbfba24d779df95711e18bc5ab20bc825569eacf0
2026-01-14T08:30:28.1606796Z deleted: sha256:f11b8847481c47442bf481ec7b8d9c948df1266e63d069131f724b47c51c2c91
2026-01-14T08:30:28.1607396Z deleted: sha256:c13b010ba4d464f7a776912c6c1419b1b43a0be2d77016c341391f514598ddc9
2026-01-14T08:30:28.1608017Z deleted: sha256:f1da3c86dcb638ce4ed638694aa6d7c56895fcf4333a0394dfb6f68261b30ec4
2026-01-14T08:30:28.1608634Z deleted: sha256:5a4a4232527a9ccd10b081de854ab7bc96c1ee1148be096868c5c9110a7ad252
2026-01-14T08:30:28.1609255Z deleted: sha256:89f508f7267ace64991f702ce9dea98459ff52b1a6a6ac947b74b4c9897e4e4d
2026-01-14T08:30:28.1609878Z deleted: sha256:bf8caf15d3c3689b1967680b53e1270190951f019bb37aefa41b950e7f7b7f8d
2026-01-14T08:30:28.1610490Z deleted: sha256:3e8085631d6ea2e23cd9e0c9efa828b167bdf3b3efe07284bcda7fc7feaf1557
2026-01-14T08:30:28.1611121Z deleted: sha256:06e9019cea7989f41ca5a9fb9907e0e85911d968012b3b1779ff5bee48e3205f
2026-01-14T08:30:28.1611722Z deleted: sha256:ac3b32d784b2808c03ea80647508101b1a9a79978933113dad35f01bc5d7863e
2026-01-14T08:30:28.1612422Z deleted: sha256:1f7b9b871c33f3266151d53144f07c3db7e8630d8132a75d0c1769e4b25f67ce
2026-01-14T08:30:28.1613030Z deleted: sha256:ff4f19608a1944c0c2807cd533515673285a9632dc74bf020e83e18630d1ae35
2026-01-14T08:30:28.1613613Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T08:30:28.1614465Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine@sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T08:30:28.1615333Z deleted: sha256:6dbb9cc54074106d46d4ccb330f2a40a682d49dda5f4844962b7dce9fe44aaec
2026-01-14T08:30:28.1615968Z deleted: sha256:b2d5eeeaba3a22b9b8aa97261957974a6bd65274ebd43e1d81d0a7b8b752b116
2026-01-14T08:30:28.1616347Z 
2026-01-14T08:30:28.1622570Z Total reclaimed space: 6.793GB
2026-01-14T08:30:28.1674963Z ##[group]Run set +e
2026-01-14T08:30:28.1675238Z [36;1mset +e[0m
2026-01-14T08:30:28.1675499Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T08:30:28.1675901Z [36;1m  sudo rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T08:30:28.1676300Z [36;1melse[0m
2026-01-14T08:30:28.1676579Z [36;1m  rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T08:30:28.1676910Z [36;1mfi[0m
2026-01-14T08:30:28.1677117Z [36;1mset -e[0m
2026-01-14T08:30:28.1684361Z shell: /usr/bin/bash -e {0}
2026-01-14T08:30:28.1684642Z env:
2026-01-14T08:30:28.1684878Z   DOCKER_IMAGE: pytorch/almalinux-builder:cpu
2026-01-14T08:30:28.1685238Z   REPOSITORY: pytorch/ao
2026-01-14T08:30:28.1685479Z   PR_NUMBER: 3500
2026-01-14T08:30:28.1687377Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:30:28.1689406Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:30:28.1689989Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:30:28.1690541Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:30:28.1690915Z   NO_SUDO: false
2026-01-14T08:30:28.1691132Z ##[endgroup]
2026-01-14T08:30:28.6870226Z Post job cleanup.
2026-01-14T08:30:28.7901438Z Post job cleanup.
2026-01-14T08:30:28.8851441Z [command]/usr/bin/git version
2026-01-14T08:30:28.8894010Z git version 2.50.1
2026-01-14T08:30:28.8937422Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/22de7c7c-9eda-491c-be97-13b307cdf7b3' before making global git config changes
2026-01-14T08:30:28.8939164Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:30:28.8943147Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:30:28.8975239Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:30:28.9003588Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:30:28.9284903Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:30:28.9304125Z http.https://github.com/.extraheader
2026-01-14T08:30:28.9313695Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader
2026-01-14T08:30:28.9340369Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:30:28.9674702Z A job completed hook has been configured by the self-hosted runner administrator
2026-01-14T08:30:28.9702975Z ##[group]Run '/home/ec2-user/runner-scripts/after_job.sh'
2026-01-14T08:30:28.9708335Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:30:28.9708704Z ##[endgroup]
2026-01-14T08:30:28.9862472Z [!ALERT!] Swap in detected! [!ALERT!]
2026-01-14T08:30:39.7937983Z [!ALERT!] Swap out detected [!ALERT!]
2026-01-14T08:30:57.6043398Z Cleaning up orphan processes
